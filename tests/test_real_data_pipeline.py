"""
–¢–µ—Å—Ç —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –ø–∞–π–ø–ª–∞–π–Ω —Å fallback –º–µ—Ç–æ–¥–∞–º–∏ (–±–µ–∑ LLM)
"""

import asyncio
import json
import os
import shutil
import logging

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def test_real_pipeline():
    """
    –ü—Ä–æ–≥–æ–Ω—è–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω
    """
    # –ü—É—Ç—å –∫ —Ä–µ–∞–ª—å–Ω—ã–º –¥–∞–Ω–Ω—ã–º
    base_path = "/home/imort/Herzog_v3/projects/test/test"
    input_path = f"{base_path}/3_prepared"
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–æ–≤
    paths = {
        4: f"{base_path}/4_conceptualized",
        5: f"{base_path}/5_scheduled", 
        6: f"{base_path}/6_accounted",
        7: f"{base_path}/7_staffed",
        8: f"{base_path}/8_output"
    }
    
    for path in paths.values():
        os.makedirs(path, exist_ok=True)
    
    # –ß–∏—Ç–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    with open(f"{input_path}/project_data.json", 'r', encoding='utf-8') as f:
        initial_data = json.load(f)
    
    logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Ç–µ—Å—Ç —Å {initial_data['meta']['total_work_items']} —Ä–∞–±–æ—Ç–∞–º–∏")
    logger.info(f"üìÖ –ü—Ä–æ–µ–∫—Ç –Ω–∞ {initial_data['meta']['total_timeline_blocks']} –Ω–µ–¥–µ–ª—å")
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∞–≥–µ–Ω—Ç–æ–≤
    import sys
    sys.path.append('/home/imort/Herzog_v3')
    
    try:
        # –ê–≥–µ–Ω—Ç 1: –ö–æ–Ω—Ü–µ–ø—Ç—É–∞–ª–∏–∑–∞—Ç–æ—Ä (—Å fallback)
        logger.info("üéØ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ê–≥–µ–Ω—Ç 1: –ö–æ–Ω—Ü–µ–ø—Ç—É–∞–ª–∏–∑–∞—Ç–æ—Ä")
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å—Ç—É—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É
        data_step_1 = initial_data.copy()
        work_items = data_step_1['work_items']
        
        # –ü—Ä–æ—Å—Ç–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (fallback –º–µ—Ç–æ–¥)
        group_keywords = {
            'group_1': {
                'name': '–î–µ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã',
                'keywords': ['–¥–µ–º–æ–Ω—Ç–∞–∂', '—Å–Ω–æ—Å', '—Ä–∞–∑–±–æ—Ä–∫–∞', '–æ—Ç–±–∏–≤–∫–∞', '–æ—á–∏—Å—Ç–∫–∞']
            },
            'group_2': {
                'name': '–ó–µ–º–ª—è–Ω—ã–µ —Ä–∞–±–æ—Ç—ã', 
                'keywords': ['–∑–µ–º–ª—è', '–≥—Ä—É–Ω—Ç', '–∫–æ–ø–∫–∞', '—Ä—ã—Ç—å–µ', '—Ç—Ä–∞–Ω—à–µ—è', '–∫–æ—Ç–ª–æ–≤–∞–Ω']
            },
            'group_3': {
                'name': '–§—É–Ω–¥–∞–º–µ–Ω—Ç–Ω—ã–µ —Ä–∞–±–æ—Ç—ã',
                'keywords': ['—Ñ—É–Ω–¥–∞–º–µ–Ω—Ç', '–æ—Å–Ω–æ–≤–∞–Ω–∏–µ', '–±–µ—Ç–æ–Ω', '–∞—Ä–º–∞—Ç—É—Ä–∞', '–∫–∞—Ä–∫–∞—Å']
            },
            'group_4': {
                'name': '–ö–ª–∞–¥–æ—á–Ω—ã–µ —Ä–∞–±–æ—Ç—ã',
                'keywords': ['–∫–ª–∞–¥–∫–∞', '–∫–∏—Ä–ø–∏—á', '–±–ª–æ–∫', '—Å—Ç–µ–Ω–∞', '–ø–µ—Ä–µ–≥–æ—Ä–æ–¥–∫–∞']
            },
            'group_5': {
                'name': '–ö—Ä–æ–≤–µ–ª—å–Ω—ã–µ —Ä–∞–±–æ—Ç—ã',
                'keywords': ['–∫—Ä–æ–≤–ª—è', '–∫—Ä—ã—à–∞', '–ø–æ–∫—Ä—ã—Ç–∏–µ', '—á–µ—Ä–µ–ø–∏—Ü–∞', '–ø—Ä–æ—Ñ–ª–∏—Å—Ç']
            },
            'group_6': {
                'name': '–û—Ç–¥–µ–ª–æ—á–Ω—ã–µ —Ä–∞–±–æ—Ç—ã',
                'keywords': ['—à—Ç—É–∫–∞—Ç—É—Ä–∫–∞', '–ø–æ–∫—Ä–∞—Å–∫–∞', '–æ–±–ª–∏—Ü–æ–≤–∫–∞', '–ø–ª–∏—Ç–∫–∞', '–æ–±–æ–∏', '—à–ø–∞—Ç–ª–µ–≤–∫–∞']
            },
            'group_7': {
                'name': '–≠–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã',
                'keywords': ['—ç–ª–µ–∫—Ç—Ä', '–ø—Ä–æ–≤–æ–¥', '–∫–∞–±–µ–ª—å', '—Ä–æ–∑–µ—Ç–∫–∞', '–≤—ã–∫–ª—é—á–∞—Ç–µ–ª—å', '—â–∏—Ç']
            },
            'group_8': {
                'name': '–°–∞–Ω—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ä–∞–±–æ—Ç—ã', 
                'keywords': ['—Å–∞–Ω—Ç–µ—Ö–Ω–∏–∫', '—Ç—Ä—É–±–∞', '–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥', '–∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è', '–æ—Ç–æ–ø–ª–µ–Ω–∏–µ']
            }
        }
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É
        groups_data = {}
        for item in work_items:
            work_name = item.get('original_data', {}).get('name', '').lower()
            
            # –ò—â–µ–º –ø–æ–¥—Ö–æ–¥—è—â—É—é –≥—Ä—É–ø–ø—É
            assigned = False
            for group_id, group_info in group_keywords.items():
                if any(keyword in work_name for keyword in group_info['keywords']):
                    item['group_id'] = group_id
                    item['group_name'] = group_info['name']
                    assigned = True
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ groups_data
                    if group_id not in groups_data:
                        groups_data[group_id] = {
                            'group_name': group_info['name'],
                            'work_ids': [],
                            'schedule_phases': [],
                            'total_quantity': 0,
                            'common_unit': '',
                            'worker_counts': []
                        }
                    groups_data[group_id]['work_ids'].append(item['id'])
                    break
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≥—Ä—É–ø–ø—É - –æ–±—â–∏–µ —Ä–∞–±–æ—Ç—ã
            if not assigned:
                item['group_id'] = 'group_other'
                item['group_name'] = '–ü—Ä–æ—á–∏–µ —Ä–∞–±–æ—Ç—ã'
                if 'group_other' not in groups_data:
                    groups_data['group_other'] = {
                        'group_name': '–ü—Ä–æ—á–∏–µ —Ä–∞–±–æ—Ç—ã',
                        'work_ids': [],
                        'schedule_phases': [],
                        'total_quantity': 0,
                        'common_unit': '',
                        'worker_counts': []
                    }
                groups_data['group_other']['work_ids'].append(item['id'])
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        data_step_1['groups_data'] = groups_data
        data_step_1['processing_status']['conceptualization'] = 'completed'
        data_step_1['processing_status']['scheduling'] = 'pending'
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ê–≥–µ–Ω—Ç–∞ 1
        with open(f"{paths[4]}/project_data.json", 'w', encoding='utf-8') as f:
            json.dump(data_step_1, f, ensure_ascii=False, indent=2)
        
        # –ò–º–∏—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        with open(f"{paths[4]}/llm_input.json", 'w', encoding='utf-8') as f:
            json.dump({"status": "fallback_grouping", "groups_created": len(groups_data)}, f)
        
        with open(f"{paths[4]}/llm_response.json", 'w', encoding='utf-8') as f:
            json.dump({"status": "fallback_completed", "method": "keyword_matching"}, f)
        
        logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç 1: –°–æ–∑–¥–∞–Ω–æ {len(groups_data)} –≥—Ä—É–ø–ø")
        for gid, gdata in groups_data.items():
            logger.info(f"   {gid}: {gdata['group_name']} ({len(gdata['work_ids'])} —Ä–∞–±–æ—Ç)")
        
        # –ê–≥–µ–Ω—Ç 2: –°—Ç—Ä–∞—Ç–µ–≥ (–ø—Ä–æ—Å—Ç–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ)
        logger.info("üìã –¢–µ—Å—Ç–∏—Ä—É–µ–º –ê–≥–µ–Ω—Ç 2: –°—Ç—Ä–∞—Ç–µ–≥")
        
        data_step_2 = data_step_1.copy()
        timeline_blocks = data_step_2['timeline_blocks']
        groups_data = data_step_2['groups_data']
        
        # –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –Ω–µ–¥–µ–ª—è–º
        week_assignments = {
            'group_1': [1, 2],              # –î–µ–º–æ–Ω—Ç–∞–∂ - –ø–µ—Ä–≤—ã–µ –Ω–µ–¥–µ–ª–∏
            'group_2': [3, 4, 5],           # –ó–µ–º–ª—è–Ω—ã–µ - –ø–æ—Å–ª–µ –¥–µ–º–æ–Ω—Ç–∞–∂–∞
            'group_3': [6, 7, 8, 9],        # –§—É–Ω–¥–∞–º–µ–Ω—Ç - –ø–æ—Å–ª–µ –∑–µ–º–ª—è–Ω—ã—Ö
            'group_4': [10, 11, 12, 13],    # –ö–ª–∞–¥–æ—á–Ω—ã–µ - –ø–æ—Å–ª–µ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞
            'group_5': [14, 15, 16],        # –ö—Ä–æ–≤–µ–ª—å–Ω—ã–µ - –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å –∫–ª–∞–¥–æ—á–Ω—ã–º–∏
            'group_7': [17, 18, 19, 20],    # –≠–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂ - –ø–æ—Å–ª–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ä–∞–±–æ—Ç
            'group_8': [21, 22, 23, 24],    # –°–∞–Ω—Ç–µ—Ö–Ω–∏–∫–∞ - –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å —ç–ª–µ–∫—Ç—Ä–∏–∫–æ–π
            'group_6': [25, 26, 27, 28],    # –û—Ç–¥–µ–ª–∫–∞ - –≤ –∫–æ–Ω—Ü–µ
            'group_other': [29, 30]         # –ü—Ä–æ—á–∏–µ - –≤ –∫–æ–Ω—Ü–µ
        }
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∫ –≥—Ä—É–ø–ø–∞–º
        for group_id, group_data in groups_data.items():
            if group_id in week_assignments:
                weeks = week_assignments[group_id]
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ–¥–µ–ª–∏ –Ω–µ –≤—ã—Ö–æ–¥—è—Ç –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã –ø—Ä–æ–µ–∫—Ç–∞
                max_week = len(timeline_blocks)
                valid_weeks = [w for w in weeks if w <= max_week]
                group_data['schedule_phases'] = valid_weeks
            else:
                # –î–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –≥—Ä—É–ø–ø - –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–µ–¥–µ–ª–∏
                group_data['schedule_phases'] = [max(1, len(timeline_blocks) - 2), len(timeline_blocks) - 1]
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        data_step_2['processing_status']['scheduling'] = 'completed'
        data_step_2['processing_status']['accounting'] = 'pending'
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ê–≥–µ–Ω—Ç–∞ 2
        with open(f"{paths[5]}/project_data.json", 'w', encoding='utf-8') as f:
            json.dump(data_step_2, f, ensure_ascii=False, indent=2)
        
        with open(f"{paths[5]}/llm_input.json", 'w', encoding='utf-8') as f:
            json.dump({"status": "fallback_scheduling"}, f)
        
        with open(f"{paths[5]}/llm_response.json", 'w', encoding='utf-8') as f:
            json.dump({"status": "fallback_completed"}, f)
        
        scheduled_groups = sum(1 for g in groups_data.values() if g['schedule_phases'])
        logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç 2: –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ {scheduled_groups} –≥—Ä—É–ø–ø")
        for gid, gdata in groups_data.items():
            if gdata['schedule_phases']:
                logger.info(f"   {gid}: –Ω–µ–¥–µ–ª–∏ {gdata['schedule_phases']}")
        
        # –ê–≥–µ–Ω—Ç 3: –ë—É—Ö–≥–∞–ª—Ç–µ—Ä (–ø–æ–¥—Å—á–µ—Ç –æ–±—ä–µ–º–æ–≤ –ø–æ –≥—Ä—É–ø–ø–∞–º)
        logger.info("üí∞ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ê–≥–µ–Ω—Ç 3: –ë—É—Ö–≥–∞–ª—Ç–µ—Ä")
        
        data_step_3 = data_step_2.copy()
        work_items = data_step_3['work_items']
        groups_data = data_step_3['groups_data']
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ä–∞–±–æ—Ç—ã –∏ —Å—á–∏—Ç–∞–µ–º –æ–±—ä–µ–º—ã
        for group_id, group_data in groups_data.items():
            work_ids = group_data['work_ids']
            
            # –ù–∞—Ö–æ–¥–∏–º —Ä–∞–±–æ—Ç—ã —ç—Ç–æ–π –≥—Ä—É–ø–ø—ã
            group_works = [item for item in work_items if item['id'] in work_ids]
            
            # –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—É—é –µ–¥–∏–Ω–∏—Ü—É –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤ –≥—Ä—É–ø–ø–µ
            units = [item.get('original_data', {}).get('unit', '—à—Ç') for item in group_works]
            if units:
                common_unit = max(set(units), key=units.count)
            else:
                common_unit = '—à—Ç'
            
            # –°—É–º–º–∏—Ä—É–µ–º –æ–±—ä–µ–º—ã
            total_qty = 0
            for item in group_works:
                qty_str = str(item.get('original_data', {}).get('quantity', '0'))
                try:
                    qty = float(qty_str.replace(',', '.'))
                    total_qty += qty
                except:
                    total_qty += 1
            
            # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –≥—Ä—É–ø–ø–µ –æ–±—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            group_data['total_quantity'] = total_qty
            group_data['common_unit'] = common_unit
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        data_step_3['processing_status']['accounting'] = 'completed'
        data_step_3['processing_status']['staffing'] = 'pending'
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ê–≥–µ–Ω—Ç–∞ 3
        with open(f"{paths[6]}/project_data.json", 'w', encoding='utf-8') as f:
            json.dump(data_step_3, f, ensure_ascii=False, indent=2)
        
        with open(f"{paths[6]}/llm_input.json", 'w', encoding='utf-8') as f:
            json.dump({"status": "fallback_accounting"}, f)
        
        with open(f"{paths[6]}/llm_response.json", 'w', encoding='utf-8') as f:
            json.dump({"status": "fallback_completed"}, f)
        
        logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç 3: –ü–æ–¥—Å—á–∏—Ç–∞–Ω–æ –æ–±—ä–µ–º–æ–≤ –¥–ª—è {len(groups_data)} –≥—Ä—É–ø–ø")
        for gid, gdata in groups_data.items():
            logger.info(f"   {gid}: {gdata['total_quantity']} {gdata['common_unit']}")
        
        # –ê–≥–µ–Ω—Ç 4: –ü—Ä–æ—Ä–∞–± (—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–±–æ—á–∏—Ö)
        logger.info("‚ö° –¢–µ—Å—Ç–∏—Ä—É–µ–º –ê–≥–µ–Ω—Ç 4: –ü—Ä–æ—Ä–∞–±")
        
        data_step_4 = data_step_3.copy()
        groups_data = data_step_4['groups_data']
        workforce_range = data_step_4['directives']['workforce_range']
        
        # –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–±–æ—á–∏—Ö –ø–æ –≥—Ä—É–ø–ø–∞–º
        for group_id, group_data in groups_data.items():
            schedule_phases = group_data.get('schedule_phases', [])
            if schedule_phases:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—á–∏—Ö –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –≥—Ä—É–ø–ø—ã
                if 'group_1' in group_id:  # –î–µ–º–æ–Ω—Ç–∞–∂
                    base_workers = 3
                elif 'group_2' in group_id:  # –ó–µ–º–ª—è–Ω—ã–µ
                    base_workers = 5
                elif 'group_3' in group_id:  # –§—É–Ω–¥–∞–º–µ–Ω—Ç
                    base_workers = 6
                elif 'group_4' in group_id:  # –ö–ª–∞–¥–æ—á–Ω—ã–µ
                    base_workers = 4
                elif 'group_6' in group_id:  # –û—Ç–¥–µ–ª–∫–∞
                    base_workers = 5
                else:  # –ü—Ä–æ—á–∏–µ
                    base_workers = (workforce_range['min'] + workforce_range['max']) // 2
                
                # –°–æ–∑–¥–∞–µ–º –º–∞—Å—Å–∏–≤ —Ä–∞–±–æ—á–∏—Ö –¥–ª—è –∫–∞–∂–¥–æ–π –Ω–µ–¥–µ–ª–∏
                workers_per_week = [base_workers] * len(schedule_phases)
                group_data['worker_counts'] = workers_per_week
            else:
                group_data['worker_counts'] = []
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        data_step_4['processing_status']['staffing'] = 'completed' 
        data_step_4['processing_status']['reporting'] = 'pending'
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ê–≥–µ–Ω—Ç–∞ 4
        with open(f"{paths[7]}/project_data.json", 'w', encoding='utf-8') as f:
            json.dump(data_step_4, f, ensure_ascii=False, indent=2)
        
        with open(f"{paths[7]}/llm_input.json", 'w', encoding='utf-8') as f:
            json.dump({"status": "fallback_staffing"}, f)
        
        with open(f"{paths[7]}/llm_response.json", 'w', encoding='utf-8') as f:
            json.dump({"status": "fallback_completed"}, f)
        
        staffed_groups = sum(1 for g in groups_data.values() if g['worker_counts'])
        logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç 4: –£–∫–æ–º–ø–ª–µ–∫—Ç–æ–≤–∞–Ω–æ {staffed_groups} –≥—Ä—É–ø–ø")
        for gid, gdata in groups_data.items():
            if gdata['worker_counts']:
                logger.info(f"   {gid}: —Ä–∞–±–æ—á–∏–µ {gdata['worker_counts']}")
        
        # –®–∞–≥ 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Excel –æ—Ç—á–µ—Ç–∞
        logger.info("üìä –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π Excel –æ—Ç—á–µ—Ç")
        
        from src.data_processing.reporter import generate_excel_report
        
        final_input = f"{paths[7]}/project_data.json"
        excel_file = generate_excel_report(final_input, paths[8])
        
        logger.info(f"‚úÖ Excel –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {excel_file}")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        logger.info("üéâ –¢–ï–°–¢ –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
        logger.info(f"üìà –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        logger.info(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ä–∞–±–æ—Ç: {len(work_items)}")
        logger.info(f"   –°–æ–∑–¥–∞–Ω–æ –≥—Ä—É–ø–ø: {len(groups_data)}")
        logger.info(f"   –ù–µ–¥–µ–ª—å –≤ –ø—Ä–æ–µ–∫—Ç–µ: {len(timeline_blocks)}")
        logger.info(f"   –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {base_path}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–µ: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    result = asyncio.run(test_real_pipeline())
    if result:
        print("\nüéØ –¢–µ—Å—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print("üìÅ –ü—Ä–æ–≤–µ—Ä—å –ø–∞–ø–∫–∏ 4_conceptualized, 5_scheduled, 6_accounted, 7_staffed, 8_output")
        print("üìä –ü–æ—Å–º–æ—Ç—Ä–∏ –∫–∞–∫ –∏–∑–º–µ–Ω—è–ª—Å—è project_data.json –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ")
    else:
        print("\n‚ùå –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–∞–º–∏")
        exit(1)