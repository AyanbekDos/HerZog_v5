"""
–ú–æ–¥—É–ª—å PREPARER –¥–ª—è HerZog v3.0
–ó–∞–¥–∞—á–∞: –û–†–ö–ï–°–¢–†–ê–¢–û–† - –≤—ã–∑—ã–≤–∞–µ—Ç classifier.py –∏ timeline_blocks.py, —Å–æ–±–∏—Ä–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–®–∞–≥ 3 –ø–∞–π–ø–ª–∞–π–Ω–∞)
"""

import json
import logging
from datetime import datetime
from typing import Dict, List, Any
import os

from ..shared.timeline_blocks import generate_weekly_blocks

logger = logging.getLogger(__name__)


def filter_works_from_classified(classified_data: List[Dict]) -> List[Dict]:
    """
    –ü—Ä–æ—Å—Ç–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç + –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è AI-–∞–≥–µ–Ω—Ç–æ–≤
    
    Args:
        classified_data: –†–µ–∑—É–ª—å—Ç–∞—Ç classifier.classify_estimates()
        
    Returns:
        –°–ø–∏—Å–æ–∫ —Ä–∞–±–æ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è AI-–∞–≥–µ–Ω—Ç–æ–≤
    """
    import uuid
    
    work_items = []
    
    for item in classified_data:
        if item.get('classification') == '–†–∞–±–æ—Ç–∞':
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –µ–¥–∏–Ω—ã–π ID –±–µ–∑ –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏ - –ø–ª–æ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
            work_item = {
                'id': item.get('id'),
                'source_file': item.get('source_file'),
                'position_num': item.get('position_num'),
                'code': item.get('code'),
                'name': item.get('name'),
                'unit': item.get('unit'),
                'quantity': item.get('quantity'),
                'classification': item.get('classification')
                # –ü–æ–ª—è group_id, group_name –¥–æ–±–∞–≤—è—Ç AI-–∞–≥–µ–Ω—Ç—ã –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
            }
            
            work_items.append(work_item)
    
    logger.info(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(work_items)} —Ä–∞–±–æ—á–∏—Ö –ø–æ–∑–∏—Ü–∏–π –∏–∑ {len(classified_data)}")
    return work_items


def prepare_project_data(raw_estimates_file: str, directives_file: str) -> Dict[str, Any]:
    """
    –û–†–ö–ï–°–¢–†–ê–¢–û–†: –í—ã–∑—ã–≤–∞–µ—Ç –º–æ–¥—É–ª–∏ –∏ —Å–æ–±–∏—Ä–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ project_data.json
    
    Args:
        raw_estimates_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É raw_estimates.json (–∏–∑ extractor)
        directives_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É directives.json
        
    Returns:
        –ï–¥–∏–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ–µ–∫—Ç–∞
    """
    
    logger.info("üé≠ PREPARER: –ù–∞—á–∏–Ω–∞—é –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—é –º–æ–¥—É–ª–µ–π...")
    
    # –®–ê–ì 1: –ß–∏—Ç–∞–µ–º —É–∂–µ –≥–æ—Ç–æ–≤—ã–µ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    logger.info("üìã –ß–∏—Ç–∞—é –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
    classified_file = raw_estimates_file.replace('1_extracted/raw_estimates.json', '2_classified/classified_estimates.json')
    
    with open(classified_file, 'r', encoding='utf-8') as f:
        classified_data = json.load(f)
    
    # –®–ê–ì 2: –ß–∏—Ç–∞–µ–º –¥–∏—Ä–µ–∫—Ç–∏–≤—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    with open(directives_file, 'r', encoding='utf-8') as f:
        directives = json.load(f)
    
    logger.info(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∏—Ä–µ–∫—Ç–∏–≤—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    
    # –®–ê–ì 3: –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—Ç—ã –¥–ª—è AI-–∞–≥–µ–Ω—Ç–æ–≤
    work_items = filter_works_from_classified(classified_data)
    
    # –®–ê–ì 4: –í—ã–∑—ã–≤–∞–µ–º TIMELINE_BLOCKS –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–µ–¥–µ–ª—å–Ω—ã—Ö –±–ª–æ–∫–æ–≤
    timeline = directives.get('project_timeline', {})
    start_date = timeline.get('start_date', '01.01.2024')
    end_date = timeline.get('end_date', '31.12.2024')
    
    logger.info(f"üìÖ –í—ã–∑—ã–≤–∞—é TIMELINE_BLOCKS –¥–ª—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞ {start_date} - {end_date}")
    timeline_result = generate_weekly_blocks(start_date, end_date)
    timeline_blocks = timeline_result['blocks']
    
    # –®–ê–ì 5: –°–æ–±–∏—Ä–∞–µ–º –µ–¥–∏–Ω—ã–π project_data.json
    project_data = {
        'meta': {
            'created_at': datetime.now().isoformat(),
            'total_work_items': len(work_items),
            'total_timeline_blocks': len(timeline_blocks),
            'project_duration_weeks': len(timeline_blocks)
        },
        'directives': directives,
        'timeline_blocks': timeline_blocks,
        'work_items': work_items,
        'processing_status': {
            'extraction': 'completed',
            'classification': 'completed', 
            'preparation': 'completed',
            'conceptualization': 'pending',
            'scheduling': 'pending',
            'accounting': 'pending',
            'staffing': 'pending',
            'reporting': 'pending'
        },
        'groups_data': {}
    }
    
    logger.info(f"‚úÖ PREPARER –∑–∞–≤–µ—Ä—à–µ–Ω: {len(work_items)} —Ä–∞–±–æ—Ç, {len(timeline_blocks)} –Ω–µ–¥–µ–ª—å")
    
    return project_data


def validate_project_data(project_data: Dict) -> bool:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞
    
    Args:
        project_data: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ–µ–∫—Ç–∞
        
    Returns:
        True –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –≤–∞–ª–∏–¥–Ω—ã
    """
    required_keys = ['meta', 'directives', 'timeline_blocks', 'work_items']
    
    for key in required_keys:
        if key not in project_data:
            logger.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ: {key}")
            return False
    
    if not project_data['work_items']:
        logger.error("–ù–µ—Ç —Ä–∞–±–æ—á–∏—Ö –ø–æ–∑–∏—Ü–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return False
    
    if not project_data['timeline_blocks']:
        logger.error("–ù–µ —Å–æ–∑–¥–∞–Ω—ã –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–∞–±–æ—á–∏—Ö –ø–æ–∑–∏—Ü–∏–π
    for item in project_data['work_items']:
        required_item_keys = ['id', 'source_file', 'code', 'name']
        for key in required_item_keys:
            if key not in item:
                logger.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ {key} –≤ —Ä–∞–±–æ—á–µ–π –ø–æ–∑–∏—Ü–∏–∏")
                return False
    
    logger.info("–í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–∞")
    return True


if __name__ == "__main__":
    import sys
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(level=logging.INFO)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) > 1:
        # –†–µ–∂–∏–º —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è - –∞—Ä–≥—É–º–µ–Ω—Ç = –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        project_dir = sys.argv[1]
        raw_estimates_file = os.path.join(project_dir, '1_extracted', 'raw_estimates.json')
        directives_file = os.path.join(project_dir, '0_input', 'directives.json')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª—ã —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        if not os.path.exists(raw_estimates_file):
            logger.error(f"–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {raw_estimates_file}")
            sys.exit(1)
            
        if not os.path.exists(directives_file):
            logger.error(f"–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {directives_file}")
            sys.exit(1)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
        try:
            result = prepare_project_data(raw_estimates_file, directives_file)
            is_valid = validate_project_data(result)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            output_file = os.path.join(project_dir, '3_prepared', 'project_data.json')
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            logger.info(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
            print(f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í–∞–ª–∏–¥–Ω–æ—Å—Ç—å: {is_valid}")
            print(f"–†–∞–±–æ—á–∏—Ö –ø–æ–∑–∏—Ü–∏–π: {len(result['work_items'])}")
            print(f"–í—Ä–µ–º–µ–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤: {len(result['timeline_blocks'])}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
            sys.exit(1)
    
    else:
        # –†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è - –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
        logger.info("–†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è preparer...")
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–∏–≤
        test_directives = {
            'target_work_count': 15,
            'project_timeline': {
                'start_date': '01.01.2024',
                'end_date': '30.06.2024'
            },
            'workforce_range': {'min': 10, 'max': 20}
        }
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_classified = [
            {
                'id': 'test-1',
                'classification': '–†–∞–±–æ—Ç–∞',
                'name': '–¢–µ—Å—Ç–æ–≤–∞—è —Ä–∞–±–æ—Ç–∞ 1',
                'code': '–ì–≠–°–ù-001',
                'quantity': '100',
                'source_file': 'test.xlsx',
                'position_num': '1',
                'unit': '–º2'
            },
            {
                'id': 'test-2', 
                'classification': '–ú–∞—Ç–µ—Ä–∏–∞–ª',
                'name': '–¢–µ—Å—Ç–æ–≤—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª',
                'code': '–§–°–°–¶-001',
                'source_file': 'test.xlsx',
                'position_num': '2',
                'unit': '–∫–≥',
                'quantity': '1000'
            }
        ]
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        import tempfile
        
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f1:
            json.dump(test_classified, f1, ensure_ascii=False)
            classified_file = f1.name
        
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f2:
            json.dump(test_directives, f2, ensure_ascii=False)
            directives_file = f2.name
        
        try:
            result = prepare_project_data(classified_file, directives_file)
            is_valid = validate_project_data(result)
            
            print(f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í–∞–ª–∏–¥–Ω–æ—Å—Ç—å: {is_valid}")
            print(f"–†–∞–±–æ—á–∏—Ö –ø–æ–∑–∏—Ü–∏–π: {len(result['work_items'])}")
            print(f"–í—Ä–µ–º–µ–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤: {len(result['timeline_blocks'])}")
            
        finally:
            # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            os.unlink(classified_file)
            os.unlink(directives_file)