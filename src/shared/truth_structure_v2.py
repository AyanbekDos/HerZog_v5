"""
–ù–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ true.json v2.0 –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
–ò–µ—Ä–∞—Ä—Ö–∏—á–Ω–∞—è, –ø–æ–Ω—è—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –ª—é–¥–µ–π –∏ –º–∞—à–∏–Ω
"""

import json
from typing import Dict, List, Any, Optional
from datetime import datetime


class TruthStructureV2:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã true.json v2.0
    
    –ü—Ä–∏–Ω—Ü–∏–ø—ã –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:
    1. –ß–µ—Ç–∫–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å–µ–∫—Ü–∏–π
    2. –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ—Å—Ç—å
    3. –ú–∞—à–∏–Ω–Ω–∞—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º–æ—Å—Ç—å  
    4. –ò–µ—Ä–∞—Ä—Ö–∏—á–Ω–æ—Å—Ç—å
    5. –ú–∏–Ω–∏–º–∞–ª–∏–∑–º (—Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ)
    """
    
    @staticmethod
    def create_empty_structure(project_id: str, project_name: str, source_file: str) -> Dict[str, Any]:
        """
        –°–æ–∑–¥–∞–µ—Ç –ø—É—Å—Ç—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É true.json v2.0
        """
        return {
            # üèóÔ∏è –ú–ï–¢–ê–ò–ù–§–û–†–ú–ê–¶–ò–Ø
            "meta": {
                "structure_version": "2.0",
                "project_id": project_id,
                "project_name": project_name,
                "source_file_name": source_file,
                "created_at": datetime.now().isoformat(),
                "last_updated": datetime.now().isoformat()
            },
            
            # üë§ –í–•–û–î–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø  
            "user_inputs": {
                "project_settings": {
                    "target_work_package_count": 10,
                    "timeline": {
                        "start_date": None,
                        "end_date": None
                    },
                    "workforce": {
                        "min_workers": 5,
                        "max_workers": 20
                    }
                },
                "agent_directives": {
                    "work_packager": "",
                    "works_to_packages": "",
                    "counter": "",
                    "scheduler_and_staffer": ""
                },
                "project_context": {
                    "project_type": "",
                    "building_type": "",
                    "location_type": "",
                    "season": "",
                    "special_conditions": []
                }
            },
            
            # ‚è±Ô∏è –í–†–ï–ú–ï–ù–ù–´–ï –ë–õ–û–ö–ò (–ù–ï–î–ï–õ–ò)
            "timeline_blocks": [],
            
            # üìã –ò–°–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï –ò–ó –°–ú–ï–¢–´
            "source_data": {
                "total_work_items": 0,
                "work_items": []
            },
            
            # üéØ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–†–ê–ë–û–¢–ö–ò –ê–ì–ï–ù–¢–ê–ú–ò
            "results": {
                "work_packages": [],
                "volume_summary": {},
                "schedule_summary": {},
                "staffing_summary": {}
            },
            
            # üîÑ –°–¢–ê–¢–£–° PIPELINE
            "pipeline": {
                "current_stage": "initialized",
                "agents_status": [],
                "last_successful_stage": None,
                "errors": []
            }
        }
    
    @staticmethod
    def restructure_old_format(old_truth: Dict[str, Any]) -> Dict[str, Any]:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç true.json –≤ –Ω–æ–≤—ã–π v2.0
        """
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
        old_meta = old_truth.get("metadata", {})
        old_inputs = old_truth.get("project_inputs", {})
        old_results = old_truth.get("results", {})
        old_timeline = old_truth.get("timeline_blocks", [])
        old_source = old_truth.get("source_work_items", [])
        old_pipeline = old_truth.get("metadata", {}).get("pipeline_status", [])
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        new_structure = {
            # üèóÔ∏è –ú–ï–¢–ê–ò–ù–§–û–†–ú–ê–¶–ò–Ø
            "meta": {
                "structure_version": "2.0",
                "project_id": old_meta.get("project_id", "unknown"),
                "project_name": old_inputs.get("project_name", "–ë–µ–∑—ã–º—è–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç"),
                "source_file_name": old_meta.get("source_file_name", "unknown.xlsx"),
                "created_at": old_meta.get("created_at", datetime.now().isoformat()),
                "last_updated": datetime.now().isoformat(),
                "migrated_from": "v1.0"
            },
            
            # üë§ –í–•–û–î–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø
            "user_inputs": {
                "project_settings": {
                    "target_work_package_count": old_inputs.get("target_work_package_count", 10),
                    "timeline": {
                        "start_date": old_inputs.get("project_timeline", {}).get("start_date"),
                        "end_date": old_inputs.get("project_timeline", {}).get("end_date")
                    },
                    "workforce": {
                        "min_workers": old_inputs.get("workforce_range", {}).get("min", 5),
                        "max_workers": old_inputs.get("workforce_range", {}).get("max", 20)
                    }
                },
                "agent_directives": old_inputs.get("agent_directives", {}),
                "project_context": {
                    "project_type": old_inputs.get("external_context", {}).get("object_characteristics", {}).get("project_type", ""),
                    "building_type": old_inputs.get("external_context", {}).get("object_characteristics", {}).get("building_type", ""),
                    "location_type": old_inputs.get("external_context", {}).get("site_conditions", {}).get("location_type", ""),
                    "season": old_inputs.get("external_context", {}).get("climate_factors", {}).get("season", ""),
                    "special_conditions": old_inputs.get("external_context", {}).get("site_conditions", {}).get("work_time_restrictions", [])
                }
            },
            
            # ‚è±Ô∏è –í–†–ï–ú–ï–ù–ù–´–ï –ë–õ–û–ö–ò (—É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
            "timeline_blocks": [
                {
                    "week_id": block.get("block_id", block.get("week_id", i+1)),
                    "start_date": block.get("start_date"),
                    "end_date": block.get("end_date"),
                    "working_days": block.get("working_days", 5),
                    "calendar_days": block.get("calendar_days", 7),
                    "holidays": block.get("excluded_holidays", [])
                }
                for i, block in enumerate(old_timeline)
            ],
            
            # üìã –ò–°–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï –ò–ó –°–ú–ï–¢–´ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ)
            "source_data": {
                "total_work_items": len(old_source),
                "extraction_summary": {
                    "total_rows_processed": len(old_source),
                    "work_items_identified": len([item for item in old_source if item.get("is_work", True)]),
                    "material_items_identified": len([item for item in old_source if not item.get("is_work", True)])
                },
                # –°–æ–∫—Ä–∞—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (—Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è)
                "work_items_summary": [
                    {
                        "id": item.get("id"),
                        "code": item.get("code"),
                        "name": item.get("name", "")[:50] + "..." if len(item.get("name", "")) > 50 else item.get("name", ""),
                        "unit": item.get("unit"),
                        "quantity": item.get("quantity"),
                        "assigned_package": item.get("package_id")
                    }
                    for item in old_source if item.get("is_work", True)
                ]
            },
            
            # üéØ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–†–ê–ë–û–¢–ö–ò –ê–ì–ï–ù–¢–ê–ú–ò
            "results": {
                "work_packages": old_results.get("work_packages", []),
                "volume_summary": old_results.get("volume_summary", {}),
                "schedule_summary": TruthStructureV2._extract_schedule_summary(old_results.get("work_packages", [])),
                "staffing_summary": TruthStructureV2._extract_staffing_summary(old_results.get("work_packages", []))
            },
            
            # üîÑ –°–¢–ê–¢–£–° PIPELINE
            "pipeline": {
                "current_stage": TruthStructureV2._determine_current_stage(old_pipeline),
                "agents_status": [
                    {
                        "agent": status.get("agent_name"),
                        "status": status.get("status"),
                        "started": status.get("started_at"),
                        "completed": status.get("completed_at"),
                        "duration": TruthStructureV2._calculate_duration(
                            status.get("started_at"), 
                            status.get("completed_at")
                        )
                    }
                    for status in old_pipeline
                ],
                "last_successful_stage": TruthStructureV2._find_last_successful(old_pipeline),
                "errors": [
                    status.get("agent_name") 
                    for status in old_pipeline 
                    if status.get("status") == "error"
                ]
            }
        }
        
        return new_structure
    
    @staticmethod
    def _extract_schedule_summary(work_packages: List[Dict]) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–º—É –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é"""
        if not work_packages:
            return {}
        
        scheduled_packages = [
            pkg for pkg in work_packages 
            if pkg.get("schedule_blocks") or pkg.get("progress_per_block")
        ]
        
        return {
            "total_packages": len(work_packages),
            "scheduled_packages": len(scheduled_packages),
            "scheduling_completeness": len(scheduled_packages) / len(work_packages) * 100 if work_packages else 0
        }
    
    @staticmethod
    def _extract_staffing_summary(work_packages: List[Dict]) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ –∫–∞–¥—Ä–æ–≤–æ–º—É –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é"""
        if not work_packages:
            return {}
        
        staffed_packages = [
            pkg for pkg in work_packages 
            if pkg.get("staffing_per_block")
        ]
        
        return {
            "total_packages": len(work_packages),
            "staffed_packages": len(staffed_packages),
            "staffing_completeness": len(staffed_packages) / len(work_packages) * 100 if work_packages else 0
        }
    
    @staticmethod
    def _determine_current_stage(pipeline_status: List[Dict]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–µ–∫—É—â—É—é —Å—Ç–∞–¥–∏—é pipeline"""
        if not pipeline_status:
            return "initialized"
        
        last_status = pipeline_status[-1]
        if last_status.get("status") == "error":
            return f"error_at_{last_status.get('agent_name', 'unknown')}"
        elif last_status.get("status") == "in_progress":
            return f"processing_{last_status.get('agent_name', 'unknown')}"
        elif last_status.get("status") == "completed":
            return f"completed_{last_status.get('agent_name', 'unknown')}"
        
        return "unknown"
    
    @staticmethod
    def _find_last_successful(pipeline_status: List[Dict]) -> Optional[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é —É—Å–ø–µ—à–Ω—É—é —Å—Ç–∞–¥–∏—é"""
        for status in reversed(pipeline_status):
            if status.get("status") == "completed":
                return status.get("agent_name")
        return None
    
    @staticmethod
    def _calculate_duration(start_time: Optional[str], end_time: Optional[str]) -> Optional[float]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö"""
        if not start_time or not end_time:
            return None
        
        try:
            start = datetime.fromisoformat(start_time.replace('Z', '+00:00'))
            end = datetime.fromisoformat(end_time.replace('Z', '+00:00'))
            return (end - start).total_seconds()
        except:
            return None

    @staticmethod
    def validate_structure(truth_data: Dict[str, Any]) -> List[str]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É true.json v2.0
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫ (–ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ = —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤–∞–ª–∏–¥–Ω–∞)
        """
        errors = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å–µ–∫—Ü–∏–∏
        required_sections = ["meta", "user_inputs", "timeline_blocks", "source_data", "results", "pipeline"]
        for section in required_sections:
            if section not in truth_data:
                errors.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è —Å–µ–∫—Ü–∏—è: {section}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Ä—Å–∏—é —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        if truth_data.get("meta", {}).get("structure_version") != "2.0":
            errors.append("–ù–µ–≤–µ—Ä–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–æ–∂–∏–¥–∞–µ—Ç—Å—è 2.0)")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        work_packages = truth_data.get("results", {}).get("work_packages", [])
        for pkg in work_packages:
            if not pkg.get("package_id"):
                errors.append(f"–ü–∞–∫–µ—Ç –±–µ–∑ package_id: {pkg.get('name', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π')}")
        
        return errors


def migrate_truth_file(old_file_path: str, new_file_path: str) -> bool:
    """
    –ú–∏–≥—Ä–∞—Ü–∏—è —Ñ–∞–π–ª–∞ true.json –∏–∑ v1.0 –≤ v2.0
    
    Args:
        old_file_path: –ü—É—Ç—å –∫ —Å—Ç–∞—Ä–æ–º—É —Ñ–∞–π–ª—É
        new_file_path: –ü—É—Ç—å –¥–ª—è –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
        
    Returns:
        True –µ—Å–ª–∏ –º–∏–≥—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
    """
    try:
        # –ß–∏—Ç–∞–µ–º —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª
        with open(old_file_path, 'r', encoding='utf-8') as f:
            old_data = json.load(f)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        new_data = TruthStructureV2.restructure_old_format(old_data)
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        errors = TruthStructureV2.validate_structure(new_data)
        if errors:
            print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –ø—Ä–∏ –º–∏–≥—Ä–∞—Ü–∏–∏: {errors}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–π —Ñ–∞–π–ª
        with open(new_file_path, 'w', encoding='utf-8') as f:
            json.dump(new_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {old_file_path} -> {new_file_path}")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏: {e}")
        return False


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º —Ñ–∞–π–ª–µ
    test_old_file = "/home/imort/Herzog_v3/projects/34975055/a61b42bf/true.json"
    test_new_file = "/tmp/true_v2_migrated.json"
    
    if migrate_truth_file(test_old_file, test_new_file):
        print("üß™ –¢–µ—Å—Ç–æ–≤–∞—è –º–∏–≥—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        import os
        old_size = os.path.getsize(test_old_file)
        new_size = os.path.getsize(test_new_file) 
        print(f"üìä –†–∞–∑–º–µ—Ä —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª–∞: {old_size:,} –±–∞–π—Ç")
        print(f"üìä –†–∞–∑–º–µ—Ä –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞: {new_size:,} –±–∞–π—Ç")
        print(f"üìä –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞: {((new_size - old_size) / old_size * 100):+.1f}%")
    else:
        print("‚ùå –¢–µ—Å—Ç–æ–≤–∞—è –º–∏–≥—Ä–∞—Ü–∏—è –ø—Ä–æ–≤–∞–ª–∏–ª–∞—Å—å")