# –°–ù–ê–ü–®–û–¢ –ü–†–û–ï–ö–¢–ê HERZOG V3.0
# –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: 2025-09-14 23:02:46
# –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: /home/imort/Herzog_v3
================================================================================

## –°–¢–†–£–ö–¢–£–†–ê –ü–†–û–ï–ö–¢–ê

Herzog_v3/
  run_agent.py
  test_simple_agents.py
  test_classifier_system_instruction.py
  requirements.txt
  .env.example
  new_vision.md
  proposed_structure.json
  CODE_GUIDELINES.md
  README.md
  new_agent_architecture.md
  snapshot.txt
  AGENT_SYSTEM_GUIDE.md
  true.json
  test_scheduler_recitation_fix.py
  create_snapshot.py
  debug_recitation_error.py
  test_system_instruction.py
  test_gemini_fixes.py
  CLAUDE.md
  main_bot.py
  test_refactored_agents.py
  .github/
    workflows/
  .claude/
    settings.local.json
  RECITATION_ERROR_REPORT/
    test_fix.py
    README.txt
    scheduler_and_staffer_prompt.txt
    new_agent_runner.py
    prompt_analysis.txt
    error_log.txt
    gemini_client.py
    scheduler_and_staffer.py
  temp_uploads/
    34975055/
  src/
    __init__.py
    pipeline_launcher.py
    main_pipeline.py
    telegram_bot/
      questionnaire.py
      file_sender.py
      handlers.py
      __init__.py
    prompts/
      works_to_packages_prompt.txt
      gemini_classification_prompt.txt
      scheduler_and_staffer_prompt.txt
      work_packager_prompt.txt
      counter_prompt.txt
    shared/
      __init__.py
      truth_initializer.py
      timeline_blocks.py
      truth_structure_v2.py
      gemini_client.py
    ai_agents/
      new_agent_runner.py
      works_to_packages.py
      __init__.py
      agent_runner.py
      counter.py
      work_packager.py
      scheduler_and_staffer.py
    data_processing/
      classifier.py
      reporter_v3.py
      extractor.py
      __init__.py
      preparer.py
      pdf_exporter.py
      gemini_classifier.py
  test_results/
    README.md
    real_api_test_result/
      true.json
      8_output/
      4_work_packager/
        llm_input.json
        llm_response.json
      7_scheduler_and_staffer/
        llm_input.json
        llm_response.json
      5_works_to_packages/
        batch_004_input.json
        batch_002_response.json
        batch_005_input.json
        batch_003_input.json
        batch_004_response.json
        batch_003_response.json
        batch_002_input.json
        batch_001_response.json
        batch_001_input.json
        batch_005_response.json
      6_counter/
        pkg_003_response.json
        pkg_008_input.json
        pkg_001_response.json
        pkg_005_input.json
        pkg_001_input.json
        pkg_007_response.json
        pkg_010_response.json
        pkg_009_response.json
        pkg_002_input.json
        pkg_007_input.json
        pkg_002_response.json
        pkg_011_input.json
        pkg_004_response.json
        pkg_011_response.json
        pkg_006_input.json
        pkg_008_response.json
        pkg_005_response.json
        pkg_004_input.json
        pkg_006_response.json
        pkg_012_response.json
        pkg_010_input.json
        pkg_009_input.json
        pkg_012_input.json
        pkg_003_input.json
    work_packager_only/
      true.json
      4_work_packager/
        llm_input.json
        llm_response.json
  examples/
    add_new_agent_example.py
    34975055/
      99570c7a/
        5_scheduled/
        4_conceptualized/
        8_output/
        1_extracted/
          raw_estimates.json
        2_classified/
          classified_estimates.json
        0_input/
          directives.json
        6_accounted/
        3_prepared/
          project_data.json
        7_staffed/
      d63ba5c8/
        5_scheduled/
        4_conceptualized/
        8_output/
        1_extracted/
          raw_estimates.json
        2_classified/
          classified_estimates.json
        0_input/
          directives.json
        6_accounted/
        3_prepared/
          project_data.json
        7_staffed/
      e618621f/
        5_scheduled/
        4_conceptualized/
        8_output/
        1_extracted/
          raw_estimates.json
        2_classified/
          classified_estimates.json
        0_input/
          directives.json
        6_accounted/
        3_prepared/
          project_data.json
        7_staffed/
      dc31f6f1/
        5_scheduled/
          llm_response.json
        4_conceptualized/
        8_output/
        1_extracted/
          raw_estimates.json
        2_classified/
          classified_estimates.json
          llm_input.json
          llm_response.json
        0_input/
          directives.json
        6_accounted/
        3_prepared/
          project_data.json
        7_staffed/
        4.1_grouped/
          llm_input.json
          llm_response.json
          project_data.json
      fdebae37/
        5_scheduled/
        4_conceptualized/
          llm_input.json
          llm_response.json
        8_output/
        1_extracted/
          raw_estimates.json
        2_classified/
          classified_estimates.json
          llm_input.json
          llm_response.json
        0_input/
          directives.json
        6_accounted/
        3_prepared/
          project_data.json
        7_staffed/
        4.1_grouped/
          llm_input.json
          llm_response.json
          project_data.json
      194523c8/
        5_scheduled/
          llm_input.json
          llm_response.json
          project_data.json
        4_conceptualized/
          llm_input.json
          llm_response.json
          project_data.json
        8_output/
        1_extracted/
          raw_estimates.json
        2_classified/
          classified_estimates.json
          llm_input.json
          llm_response.json
        0_input/
          directives.json
        6_accounted/
          llm_input.json
          llm_response.json
        3_prepared/
          project_data.json
        7_staffed/
        4.1_grouped/
          llm_input.json
          llm_response.json
          project_data.json
      8340692a/
        5_scheduled/
        4_conceptualized/
        8_output/
        1_extracted/
          raw_estimates.json
        2_classified/
          classified_estimates.json
        0_input/
          directives.json
        6_accounted/
        3_prepared/
          project_data.json
        7_staffed/
      94b9a7b6/
        5_scheduled/
          llm_input.json
          llm_response.json
        4_conceptualized/
          llm_input.json
          llm_response.json
          project_data.json
        8_output/
        1_extracted/
          raw_estimates.json
        2_classified/
          classified_estimates.json
          llm_input.json
          llm_response.json
        0_input/
          directives.json
        6_accounted/
        3_prepared/
          project_data.json
        7_staffed/
        4.1_grouped/
          llm_input.json
          llm_response.json
          project_data.json
      0976851d/
        5_scheduled/
        4_conceptualized/
          llm_input.json
          llm_response.json
        8_output/
        1_extracted/
          raw_estimates.json
        2_classified/
          classified_estimates.json
          llm_input.json
          llm_response.json
        0_input/
          directives.json
        6_accounted/
        3_prepared/
          project_data.json
        7_staffed/
        4.1_grouped/
          llm_input.json
          llm_response.json
          project_data.json
      ab716a88/
        5_scheduled/
        4_conceptualized/
        8_output/
        1_extracted/
          raw_estimates.json
        2_classified/
          classified_estimates.json
          llm_input.json
          llm_response.json
        0_input/
          directives.json
        6_accounted/
        3_prepared/
          project_data.json
        7_staffed/
      d19120ef/
        5_scheduled/
        4_conceptualized/
          llm_input.json
          llm_response.json
          project_data.json
        8_output/
        1_extracted/
          raw_estimates.json
        2_classified/
          classified_estimates.json
          llm_input.json
          llm_response.json
        0_input/
          directives.json
        6_accounted/
        3_prepared/
          project_data.json
        7_staffed/
        4.1_grouped/
          llm_input.json
          llm_response.json
          project_data.json
  tests/
    test_multi_model_system.py
    test_fixed_classifier.py
    test_simple_pdf.py
    test_pdf_cyrillic.py
    test_reporter_v4.py
    test_clean_structure.py
    test_agents_full.py
    test_work_packager.py
    test_counter.py
    test_agents.py
    test_fixed_work_packager.py
    test_new_agent_system.py
    test_gemini_client.py
    test_json_recovery.py
    test_copy_project.py
    test_real_data_pipeline.py
    test_scheduler_and_staffer.py
    test_full_pipeline.py
    mock_gemini_client.py
    run_all_tests.py
    test_works_to_packages.py
    test_new_test_command.py
    test_preparer_filtering.py
    test_pipeline_fix.py
    test_preparer_orchestrator.py
    test_flat_structure.py
    test_final_structure.py
    real_api/
      test_real_full_pipeline.py
      test_real_work_packager.py
  grf/
    project_002_blago/
      –ì—Ä–∞—Ñ–∏–∫ –ø—Ä.—Ä–∞–±–æ—Ç –ê–º—É—Ä—Å–∫–æ–µ –ë–õ–ê–ì–û_data.json
      –ì—Ä–∞—Ñ–∏–∫ –ø—Ä.—Ä–∞–±–æ—Ç –ê–º—É—Ä—Å–∫–æ–µ –ë–õ–ê–ì–û_summary.md
      classified_data.json
    project_001_alena/
      –ì—Ä–∞—Ñ–∏–∫ –ø—Ä.—Ä–∞–±–æ—Ç –ê–ª–µ–Ω—É—à–∫–∞_summary.md
      –ì—Ä–∞—Ñ–∏–∫ –ø—Ä.—Ä–∞–±–æ—Ç –ê–ª–µ–Ω—É—à–∫–∞_data.json
      classified_data.json
    project_005_tretiy/
      –≥—Ä–∞—Ñ–∏–∫ –¢–†–ï–¢–ò–ô_summary.md
      classified_data.json
      –≥—Ä–∞—Ñ–∏–∫ –¢–†–ï–¢–ò–ô_data.json
    project_003_perviy/
      –≥—Ä–∞—Ñ–∏–∫ –ü–ï–†–í–´–ô_data.json
      –≥—Ä–∞—Ñ–∏–∫ –ü–ï–†–í–´–ô_summary.md
      classified_data.json
    project_004_vtoroy/
      –≥—Ä–∞—Ñ–∏–∫ –í–¢–û–†–û–ô_data.json
      –≥—Ä–∞—Ñ–∏–∫ –í–¢–û–†–û–ô_summary.md
      classified_data.json

================================================================================

## –§–ê–ô–õ: .env.example
------------------------------------------------------------
# HerZog v3.0 Configuration

# Telegram Bot
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here

# Google Gemini API  
GEMINI_API_KEY=your_google_gemini_api_key_here

# –°–º–µ—Ç–Ω–æ–µ –î–µ–ª–æ API (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
SMETNOEDELO_API_KEY=your_smetnoedelo_api_key_here

# Environment
ENVIRONMENT=production

# Logging
LOG_LEVEL=INFO

# File Paths
PROJECTS_DIR=./projects
TEMP_DIR=./temp
LOGS_DIR=./logs

# Pipeline Settings
DEFAULT_BATCH_SIZE=50
MAX_RETRIES=5
API_TIMEOUT=120

# Digital Ocean Deployment
DO_DROPLET_IP=your_droplet_ip_here
DO_SSH_KEY_PATH=/path/to/your/ssh/key

================================================================================

## –§–ê–ô–õ: CLAUDE.md
------------------------------------------------------------
# –°–∏—Å—Ç–µ–º–∞ HerZog v3.0 - –¢–ï–ö–£–©–ï–ï –°–û–°–¢–û–Ø–ù–ò–ï –†–ê–ó–†–ê–ë–û–¢–ö–ò

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π –û–±–∑–æ—Ä

–°–∏—Å—Ç–µ–º–∞ HerZog - —ç—Ç–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è —É–ø—Ä–∞–≤–ª—è–µ–º–æ–≥–æ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–±–æ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–º–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ –∫–æ–Ω–≤–µ–π–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç—Ç–∞–ø–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º AI-–∞–≥–µ–Ω—Ç–æ–≤.

### –û—Å–Ω–æ–≤–Ω—ã–µ –ü—Ä–∏–Ω—Ü–∏–ø—ã
- –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞
- –ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- –ì–∏–±–∫–æ—Å—Ç—å –¥–ª—è –±–∏–∑–Ω–µ—Å-—Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∑–∞–∫–∞–∑—á–∏–∫–∞
- –ü–æ–ª–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤
- –ü—Ä–æ–º—Ç—ã —Ö—Ä–∞–Ω—è—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ –≤ –ø–∞–ø–∫–µ prompts/

## –¢–ï–ö–£–©–ê–Ø –†–ï–ê–õ–ò–ó–û–í–ê–ù–ù–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê

### –ê–∫—Ç—É–∞–ª—å–Ω–∞—è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ü—Ä–æ–µ–∫—Ç–∞
```
/Herzog_v3/
‚îú‚îÄ‚îÄ .env                              # API –∫–ª—é—á–∏ –∏ —Ç–æ–∫–µ–Ω—ã
‚îú‚îÄ‚îÄ main_bot.py                       # ‚úÖ –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ - –¢–µ–ª–µ–≥—Ä–∞–º –±–æ—Ç
‚îú‚îÄ‚îÄ create_snapshot.py                # ‚úÖ –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–Ω–∞–ø—à–æ—Ç–æ–≤
‚îú‚îÄ‚îÄ /src/                             # –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥
‚îÇ   ‚îú‚îÄ‚îÄ main_pipeline.py              # ‚úÖ –ì–ª–∞–≤–Ω—ã–π –¥–∏—Ä–∏–∂–µ—Ä –∫–æ–Ω–≤–µ–π–µ—Ä–∞
‚îÇ   ‚îú‚îÄ‚îÄ pipeline_launcher.py          # ‚úÖ –õ–æ–Ω—á–µ—Ä –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞
‚îÇ   ‚îú‚îÄ‚îÄ /telegram_bot/                # ‚úÖ –õ–æ–≥–∏–∫–∞ —Ç–µ–ª–µ–≥—Ä–∞–º-–±–æ—Ç–∞
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ handlers.py               # ‚úÖ –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥ –∏ —Å–æ–æ–±—â–µ–Ω–∏–π
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ questionnaire.py          # ‚úÖ –ü–æ—à–∞–≥–æ–≤—ã–π –æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ file_sender.py            # ‚úÖ –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–æ–≤ –≤ —Ç–µ–ª–µ–≥—Ä–∞–º
‚îÇ   ‚îú‚îÄ‚îÄ /data_processing/             # ‚úÖ –ú–æ–¥—É–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extractor.py              # ‚úÖ –®–∞–≥ 1: –ü–∞—Ä—Å–µ—Ä Excel
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classifier.py             # ‚úÖ –®–∞–≥ 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (–ø—Ä–∞–≤–∏–ª–∞)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini_classifier.py      # ‚úÖ AI-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —á–µ—Ä–µ–∑ Gemini
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preparer.py               # ‚úÖ –®–∞–≥ 3: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –µ–¥–∏–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reporter_v3.py            # ‚úÖ Excel-–æ—Ç—á–µ—Ç (–∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pdf_exporter.py           # ‚úÖ PDF —ç–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ /ai_agents/                   # ‚úÖ AI –∞–≥–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent_runner.py           # ‚úÖ –ë–∞–∑–æ–≤—ã–π —Ä–∞–Ω–Ω–µ—Ä –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ new_agent_runner.py       # ‚úÖ –ù–æ–≤—ã–π —É–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–∞–Ω–Ω–µ—Ä
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ work_packager.py          # ‚úÖ –ê–≥–µ–Ω—Ç –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ —Ä–∞–±–æ—Ç –≤ –ø–∞–∫–µ—Ç—ã
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ works_to_packages.py      # ‚úÖ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç –≤ –ø–∞–∫–µ—Ç—ã
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ counter.py                # ‚úÖ –ê–≥–µ–Ω—Ç –ø–æ–¥—Å—á–µ—Ç–∞ –æ–±—ä–µ–º–æ–≤
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scheduler_and_staffer.py  # ‚úÖ –ê–≥–µ–Ω—Ç –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∞
‚îÇ   ‚îú‚îÄ‚îÄ /shared/                      # ‚úÖ –û–±—â–∏–µ —É—Ç–∏–ª–∏—Ç—ã
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ timeline_blocks.py        # ‚úÖ –†–∞–±–æ—Ç–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –±–ª–æ–∫–∞–º–∏
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ truth_structure_v2.py     # ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö v2
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ truth_initializer.py      # ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã truth
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gemini_client.py          # ‚úÖ –ö–ª–∏–µ–Ω—Ç –¥–ª—è Gemini API
‚îÇ   ‚îî‚îÄ‚îÄ /prompts/                     # ‚úÖ –ü—Ä–æ–º—Ç—ã –¥–ª—è AI –∞–≥–µ–Ω—Ç–æ–≤
‚îÇ       ‚îú‚îÄ‚îÄ gemini_classification_prompt.txt     # ‚úÖ –ü—Ä–æ–º—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
‚îÇ       ‚îú‚îÄ‚îÄ work_packager_prompt.txt             # ‚úÖ –ü—Ä–æ–º—Ç –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ —Ä–∞–±–æ—Ç
‚îÇ       ‚îú‚îÄ‚îÄ works_to_packages_prompt.txt         # ‚úÖ –ü—Ä–æ–º—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
‚îÇ       ‚îú‚îÄ‚îÄ counter_prompt.txt                   # ‚úÖ –ü—Ä–æ–º—Ç –ø–æ–¥—Å—á–µ—Ç–∞
‚îÇ       ‚îî‚îÄ‚îÄ scheduler_and_staffer_prompt.txt     # ‚úÖ –ü—Ä–æ–º—Ç –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
‚îî‚îÄ‚îÄ /projects/                        # –†–∞–±–æ—á–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–æ–≤
    ‚îî‚îÄ‚îÄ /{user_id}/
        ‚îî‚îÄ‚îÄ /{project_id}/
            ‚îú‚îÄ‚îÄ 0_input/              # –í—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã –∏ –¥–∏—Ä–µ–∫—Ç–∏–≤—ã
            ‚îú‚îÄ‚îÄ 1_extracted/          # –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            ‚îú‚îÄ‚îÄ 2_classified/         # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            ‚îú‚îÄ‚îÄ 3_prepared/           # –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (truth.json)
            ‚îú‚îÄ‚îÄ 4_packaged/           # –°–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤ –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç—ã
            ‚îú‚îÄ‚îÄ 5_counted/            # –ü–æ–¥—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –æ–±—ä–µ–º—ã
            ‚îú‚îÄ‚îÄ 6_scheduled/          # –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–∞–±–æ—Ç—ã
            ‚îî‚îÄ‚îÄ 7_output/             # –§–∏–Ω–∞–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã
```

## –†–ï–ê–õ–ò–ó–û–í–ê–ù–ù–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´

### ‚úÖ –¢–µ–ª–µ–≥—Ä–∞–º-–ë–æ—Ç (–≠—Ç–∞–ø 2)
- **handlers.py**: –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥ –∏ —Ñ–∞–π–ª–æ–≤
- **questionnaire.py**: –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
- **file_sender.py**: –û—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ç–µ–ª–µ–≥—Ä–∞–º
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ XLSX —Ñ–∞–π–ª–æ–≤
- –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–æ–≤
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–∏–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

### ‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –î–∞–Ω–Ω—ã—Ö (–≠—Ç–∞–ø 3)
- **extractor.py**: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel
- **classifier.py**: –ü—Ä–∞–≤–∏–ª–æ-–æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
- **gemini_classifier.py**: AI-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —á–µ—Ä–µ–∑ Gemini
- **preparer.py**: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –µ–¥–∏–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ truth.json
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Å–º–µ—Ç

### ‚úÖ AI-–ê–≥–µ–Ω—Ç—ã (–≠—Ç–∞–ø 4)
–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –Ω–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å 4 –∞–≥–µ–Ω—Ç–∞–º–∏:

#### 1. Work Packager (work_packager.py)
- –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ä–∞–±–æ—Ç—ã –≤ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø–∞–∫–µ—Ç—ã
- –°–æ–∑–¥–∞–µ—Ç –∏–µ—Ä–∞—Ä—Ö–∏—é: –ø–∞–∫–µ—Ç ‚Üí –ø–æ–¥–ø–∞–∫–µ—Ç—ã ‚Üí —Ä–∞–±–æ—Ç—ã
- –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø–∞–∫–µ—Ç–æ–≤

#### 2. Works to Packages (works_to_packages.py)
- –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É work_items ‚Üí packages
- –ü–µ—Ä–µ–Ω–æ—Å–∏—Ç –¥–∞–Ω–Ω—ã–µ –≤ –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç
- –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤

#### 3. Counter (counter.py)
- –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—ä–µ–º—ã —Ä–∞–±–æ—Ç –≤ –ø–∞–∫–µ—Ç–∞—Ö
- –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç—Ä—É–¥–æ–∑–∞—Ç—Ä–∞—Ç—ã –∏ —Ä–µ—Å—É—Ä—Å—ã
- –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

#### 4. Scheduler and Staffer (scheduler_and_staffer.py)
- –ü–ª–∞–Ω–∏—Ä—É–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —ç—Ç–∞–ø—ã —Ä–∞–±–æ—Ç
- –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ª—é–¥—Å–∫–∏–µ —Ä–µ—Å—É—Ä—Å—ã
- –°–æ–∑–¥–∞–µ—Ç –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω

### ‚úÖ –û—Ç—á–µ—Ç–Ω–æ—Å—Ç—å (–≠—Ç–∞–ø 5)
- **reporter_v3.py**: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Excel –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∞
- **pdf_exporter.py**: –≠–∫—Å–ø–æ—Ä—Ç –≤ PDF —Ñ–æ—Ä–º–∞—Ç
- –î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç—ã –ø–æ –ø–∞–∫–µ—Ç–∞–º –∏ —Ä–∞–±–æ—Ç–∞–º

### ‚úÖ –ü–∞–π–ø–ª–∞–π–Ω –∏ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
- **main_pipeline.py**: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤
- **pipeline_launcher.py**: –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
- –í–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ç–µ–ª–µ–≥—Ä–∞–º

### ‚úÖ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –£—Ç–∏–ª–∏—Ç—ã
- **timeline_blocks.py**: –†–∞–±–æ—Ç–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –±–ª–æ–∫–∞–º–∏
- **truth_structure_v2.py**: –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö v2
- **truth_initializer.py**: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è truth –æ–±—ä–µ–∫—Ç–æ–≤
- **gemini_client.py**: API –∫–ª–∏–µ–Ω—Ç –¥–ª—è Gemini
- **create_snapshot.py**: –°–æ–∑–¥–∞–Ω–∏–µ —Å–Ω–∞–ø—à–æ—Ç–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞

## –§–û–†–ú–ê–¢ –î–ê–ù–ù–´–• TRUTH.JSON

```json
{
  "meta": {
    "user_id": "123456",
    "project_id": "uuid",
    "created_at": "2024-01-01T00:00:00Z",
    "updated_at": "2024-01-01T12:00:00Z",
    "current_stage": "6_scheduled",
    "stages_completed": ["1_extracted", "2_classified", ...]
  },
  "directives": {
    "target_package_count": 15,
    "project_timeline": {
      "start_date": "2024-01-01",
      "end_date": "2024-06-30",
      "total_weeks": 26
    },
    "workforce": {"min": 10, "max": 25, "average": 18},
    "special_instructions": {
      "work_packager": "–æ–±—ä–µ–¥–∏–Ω–∏ –≤—Å—é —ç–ª–µ–∫—Ç—Ä–∏–∫—É",
      "counter": "—Å—á–∏—Ç–∞–π –ø–ª–æ—â–∞–¥–∏ —Ç–æ—á–Ω–æ",
      "scheduler": "–ø–µ—Ä–≤—ã–π –º–µ—Å—è—Ü —Ç–æ–ª—å–∫–æ –¥–µ–º–æ–Ω—Ç–∞–∂"
    }
  },
  "timeline_blocks": [
    {
      "week_id": 1,
      "start_date": "2024-01-01",
      "end_date": "2024-01-07",
      "days_count": 7
    }
  ],
  "packages": [
    {
      "package_id": "pkg_001",
      "name": "–î–µ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã",
      "category": "demolition",
      "priority": "high",
      "complexity": "medium",
      "estimated_duration_weeks": 4,
      "worker_count_per_week": [12, 15, 10, 8],
      "schedule_weeks": [1, 2, 3, 4],
      "total_cost": 150000.0,
      "work_items": [...]
    }
  ],
  "work_items": [
    {
      "id": "work_001",
      "package_id": "pkg_001",
      "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫",
      "classification": "work",
      "unit": "–º¬≤",
      "quantity": 45.5,
      "unit_cost": 890.0,
      "total_cost": 40495.0,
      "original_data": {...}
    }
  ]
}
```

## –¢–ï–ö–£–©–ò–ô –°–¢–ê–¢–£–° –†–ê–ó–†–ê–ë–û–¢–ö–ò

### ‚úÖ –ü–û–õ–ù–û–°–¢–¨–Æ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û
1. **–¢–µ–ª–µ–≥—Ä–∞–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å** - —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é
2. **–û–±—Ä–∞–±–æ—Ç–∫–∞ Excel —Ñ–∞–π–ª–æ–≤** - –≤—Å–µ —Ñ–æ—Ä–º–∞—Ç—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è
3. **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç** - –ø—Ä–∞–≤–∏–ª–∞ + AI
4. **AI-–∞–≥–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã** - –≤—Å–µ 4 –∞–≥–µ–Ω—Ç–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä—É—é—Ç
5. **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤** - Excel + PDF
6. **–ü–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏** - –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª —Ä–∞–±–æ—Ç–∞–µ—Ç

### üîß –í –ü–†–û–¶–ï–°–°–ï –î–û–†–ê–ë–û–¢–ö–ò
1. **–ü—Ä–æ–º—Ç—ã –∞–≥–µ–Ω—Ç–æ–≤** - –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–¥ —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã —Å–º–µ—Ç
2. **–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫** - —É–ª—É—á—à–µ–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
3. **–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ** - –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏

### üìã –ü–õ–ê–ù–´ –ù–ê –î–û–†–ê–ë–û–¢–ö–£
1. **UI —É–ª—É—á—à–µ–Ω–∏—è** - –±–æ–ª–µ–µ –∏–Ω—Ç—É–∏—Ç–∏–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –±–æ—Ç–∞
2. **–ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è** - –±–æ–ª—å—à–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
3. **–ê–Ω–∞–ª–∏—Ç–∏–∫–∞** - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–æ–µ–∫—Ç–∞–º
4. **–≠–∫—Å–ø–æ—Ä—Ç** - –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –≤—ã–≤–æ–¥–∞

## –ö–û–ú–ê–ù–î–´ –î–õ–Ø –†–ê–ó–†–ê–ë–û–¢–ö–ò

```bash
# –ê–∫—Ç–∏–≤–∞—Ü–∏—è –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
source venv/bin/activate

# –ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –±–æ—Ç–∞
python main_bot.py

# –°–æ–∑–¥–∞–Ω–∏–µ —Å–Ω–∞–ø—à–æ—Ç–∞ –ø—Ä–æ–µ–∫—Ç–∞
python create_snapshot.py

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
python test_gemini_fixes.py
```

## API –ò –ò–ù–¢–ï–ì–†–ê–¶–ò–ò

- **Telegram Bot API** - –æ—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- **Google Gemini API** - AI –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞
- **Excel/XLSX** - –∏–º–ø–æ—Ä—Ç —Å–º–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- **PDF –≥–µ–Ω–µ—Ä–∞—Ü–∏—è** - —ç–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–æ–≤

---

*–°–∏—Å—Ç–µ–º–∞ HerZog v3.0 - –ì–æ—Ç–æ–≤–∞ –∫ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É!*
*–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: –°–µ–Ω—Ç—è–±—Ä—å 2024*

================================================================================

## –§–ê–ô–õ: README.md
------------------------------------------------------------
# HerZog v3.0 üèóÔ∏è

**–ü–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç** –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è —É–ø—Ä–∞–≤–ª—è–µ–º–æ–≥–æ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–±–æ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–º–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

## üöÄ –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- **AI-Powered Planning**: 8-—ç—Ç–∞–ø–Ω—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Google Gemini
- **Telegram Bot Interface**: –ü—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å–º–µ—Ç –∏ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–ª–∞–Ω–æ–≤  
- **Multi-Model Architecture**: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
- **RECITATION Bypass**: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫ AI
- **Professional Reports**: –ú–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω—ã–µ Excel –æ—Ç—á–µ—Ç—ã —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è–º–∏
- **Docker Ready**: –ü–æ–ª–Ω–∞—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –ª–µ–≥–∫–æ–≥–æ –¥–µ–ø–ª–æ—è

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
üìä Excel –°–º–µ—Ç–∞ ‚Üí ü§ñ AI Pipeline ‚Üí üìÖ –ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ü–ª–∞–Ω
```

### –≠—Ç–∞–ø—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏:
1. **Extractor** - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel
2. **Classifier** - –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç/–º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤  
3. **Preparer** - –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –µ–¥–∏–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
4. **Work Packager** - –°–æ–∑–¥–∞–Ω–∏–µ —É–∫—Ä—É–ø–Ω–µ–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç
5. **Works to Packages** - –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–±–æ—Ç –ø–æ –ø–∞–∫–µ—Ç–∞–º
6. **Counter** - –ü–æ–¥—Å—á–µ—Ç –æ–±—ä–µ–º–æ–≤ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç–µ–π
7. **Scheduler & Staffer** - –ö–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ä–µ—Å—É—Ä—Å—ã
8. **Reporter** - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤—ã—Ö –æ—Ç—á–µ—Ç–æ–≤

## üõ†Ô∏è –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

- **Backend**: Python 3.11, asyncio
- **AI**: Google Gemini 2.5 Pro/Flash-Lite
- **Reports**: OpenPyXL, ReportLab
- **Bot**: python-telegram-bot
- **Deploy**: Docker, Docker Compose
- **CI/CD**: GitHub Actions

## üì¶ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
```bash
git clone https://github.com/AyanbekDos/HerZog_v5.git
cd HerZog_v5
```

### 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
```bash
cp .env.example .env
# –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ .env —Å–æ —Å–≤–æ–∏–º–∏ —Ç–æ–∫–µ–Ω–∞–º–∏
```

### 3. –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ Docker
```bash
docker-compose up -d
```

### 4. –õ–æ–∫–∞–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞
```bash
python -m venv venv
source venv/bin/activate  # –∏–ª–∏ venv\Scripts\activate –Ω–∞ Windows
pip install -r requirements.txt
python main_bot.py
```

## üåä Digital Ocean Deploy

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –¥–µ–ø–ª–æ–π —á–µ—Ä–µ–∑ GitHub Actions
1. –î–æ–±–∞–≤—å—Ç–µ —Å–µ–∫—Ä–µ—Ç—ã –≤ GitHub:
   - `DO_SSH_PRIVATE_KEY`
   - `DO_DROPLET_IP` 
   - `TELEGRAM_BOT_TOKEN`
   - `GEMINI_API_KEY`

2. Push –≤ main –≤–µ—Ç–∫—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–¥–µ–ø–ª–æ–∏—Ç –Ω–∞ —Å–µ—Ä–≤–µ—Ä

### –†—É—á–Ω–æ–π –¥–µ–ø–ª–æ–π
```bash
export DO_DROPLET_IP="your_server_ip"
export DO_SSH_KEY_PATH="/path/to/your/ssh/key"
./deploy.sh
```

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (.env)
```bash
TELEGRAM_BOT_TOKEN=your_telegram_bot_token
GEMINI_API_KEY=your_google_gemini_api_key  
ENVIRONMENT=production
LOG_LEVEL=INFO
```

### Docker Compose
–ù–∞—Å—Ç—Ä–æ–µ–Ω –¥–ª—è production —Å:
- –ê–≤—Ç–æ–ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
- Health checks
- Persistent volumes –¥–ª—è –ø—Ä–æ–µ–∫—Ç–æ–≤ –∏ –ª–æ–≥–æ–≤
- Network isolation

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
# –¢–µ—Å—Ç —Å–∏—Å—Ç–µ–º—ã –æ–±—Ö–æ–¥–∞ RECITATION
python test_recitation_bypass.py

# –¢–µ—Å—Ç –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤  
python -m src.ai_agents.work_packager projects/path/to/project
python -m src.ai_agents.scheduler_and_staffer projects/path/to/project
```

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

–°–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ Excel –æ—Ç—á–µ—Ç—ã —Å:
- **üìä –ì—Ä–∞—Ñ–∏–∫** - –ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω Gantt —Å —Ü–≤–µ—Ç–æ–≤—ã–º –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
- **üìÖ –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ** - –î–µ—Ç–∞–ª—å–Ω—ã–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è —Ä–µ—à–µ–Ω–∏–π AI
- **üìã –ü–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç** - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∫–∞–∂–¥–æ–º—É –ø–∞–∫–µ—Ç—É
- **üßÆ –õ–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–æ–≤** - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

## üö® –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ñ–∏—á–∏

### Anti-RECITATION System
–°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ö–æ–¥–∏—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ Gemini:
- Multi-model fallback (Pro ‚Üí Flash-Lite)
- Dynamic prompt modification
- Temperature/top_p adjustment
- UUID-based prompt randomization

### Multi-Agent Architecture  
- –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á
- –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
- Batch processing –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –¥–∞–Ω–Ω—ã—Ö

## üêõ Troubleshooting

### –ß–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:
1. **RECITATION –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏** - –°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ö–æ–¥–∏—Ç
2. **–¢–æ–∫–µ–Ω –ª–∏–º–∏—Ç—ã** - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è batch processing
3. **–ö–æ–¥–∏—Ä–æ–≤–∫–∞ PDF** - –ù–∞—Å—Ç—Ä–æ–µ–Ω DejaVu Sans –¥–ª—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã

## üìà –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

- **–û–±—Ä–∞–±–æ—Ç–∫–∞**: 168 —Ä–∞–±–æ—Ç ‚Üí 29 –ø–∞–∫–µ—Ç–æ–≤ –∑–∞ ~2 –º–∏–Ω—É—Ç—ã
- **–¢–æ–∫–µ–Ω—ã**: 6-–∫—Ä–∞—Ç–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (453‚Üí75 —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤)  
- **–ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å**: 99%+ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –±–ª–∞–≥–æ–¥–∞—Ä—è fallback —Å–∏—Å—Ç–µ–º–µ

## ü§ù Contributing

1. Fork —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
2. –°–æ–∑–¥–∞–π—Ç–µ feature branch
3. –ö–æ–º–º–∏—Ç—å—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è  
4. Push –≤ branch
5. –°–æ–∑–¥–∞–π—Ç–µ Pull Request

## üìÑ License

MIT License - —Å–º–æ—Ç—Ä–∏—Ç–µ —Ñ–∞–π–ª LICENSE –¥–ª—è –¥–µ—Ç–∞–ª–µ–π

## üéØ Roadmap

- [ ] Web –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- [ ] API endpoints  
- [ ] Multiple file support
- [ ] Advanced scheduling algorithms
- [ ] Cost estimation
- [ ] Integration —Å 1–°

---

**HerZog v3.0** - –ö–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –±—ã—Å—Ç—Ä–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ! üöÄ

================================================================================

## –§–ê–ô–õ: create_snapshot.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–Ω–∞–ø—à–æ—Ç–∞ –ø—Ä–æ–µ–∫—Ç–∞ Herzog v3.0
–°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ .py —Ñ–∞–π–ª—ã –∏ –≤–∞–∂–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
–¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤ —Å—Ç–æ—Ä–æ–Ω–Ω–µ–º –õ–õ–ú
"""

import os
from pathlib import Path
from datetime import datetime


def create_project_snapshot(output_file="snapshot.txt"):
    """
    –°–æ–∑–¥–∞–µ—Ç —Å–Ω–∞–ø—à–æ—Ç –ø—Ä–æ–µ–∫—Ç–∞ —Å–æ –≤—Å–µ–º–∏ .py —Ñ–∞–π–ª–∞–º–∏ –∏ –≤–∞–∂–Ω—ã–º–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏
    """

    # –§–∞–π–ª—ã –∏ –ø–∞–ø–∫–∏ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è
    include_extensions = ['.py', '.txt', '.md', '.json', '.env.example']
    include_files = ['CLAUDE.md', 'requirements.txt', '.env.example', 'README.md']

    # –ü–∞–ø–∫–∏ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
    exclude_dirs = {
        '__pycache__',
        '.git',
        'venv',
        'env',
        '.venv',
        'node_modules',
        'projects',  # –†–∞–±–æ—á–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–æ–≤
        '.pytest_cache'
    }

    project_root = Path.cwd()

    with open(output_file, 'w', encoding='utf-8') as snapshot:
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å–Ω–∞–ø—à–æ—Ç–∞
        snapshot.write(f"# –°–ù–ê–ü–®–û–¢ –ü–†–û–ï–ö–¢–ê HERZOG V3.0\n")
        snapshot.write(f"# –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        snapshot.write(f"# –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {project_root}\n")
        snapshot.write("=" * 80 + "\n\n")

        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞
        snapshot.write("## –°–¢–†–£–ö–¢–£–†–ê –ü–†–û–ï–ö–¢–ê\n\n")
        for root, dirs, files in os.walk(project_root):
            # –ò—Å–∫–ª—é—á–∞–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            dirs[:] = [d for d in dirs if d not in exclude_dirs]

            level = root.replace(str(project_root), '').count(os.sep)
            indent = '  ' * level

            if level == 0:
                snapshot.write(f"{os.path.basename(root)}/\n")
            else:
                snapshot.write(f"{indent}{os.path.basename(root)}/\n")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
            sub_indent = '  ' * (level + 1)
            for file in files:
                if (any(file.endswith(ext) for ext in include_extensions) or
                    file in include_files):
                    snapshot.write(f"{sub_indent}{file}\n")

        snapshot.write("\n" + "=" * 80 + "\n\n")

        # –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤
        file_count = 0

        for root, dirs, files in os.walk(project_root):
            # –ò—Å–∫–ª—é—á–∞–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            dirs[:] = [d for d in dirs if d not in exclude_dirs]

            for file in sorted(files):
                file_path = Path(root) / file
                relative_path = file_path.relative_to(project_root)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –≤–∫–ª—é—á–∞—Ç—å —ç—Ç–æ—Ç —Ñ–∞–π–ª
                should_include = False

                # –í–∫–ª—é—á–∞–µ–º .py —Ñ–∞–π–ª—ã
                if file.endswith('.py'):
                    should_include = True

                # –í–∫–ª—é—á–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≤–∞–∂–Ω—ã–µ —Ñ–∞–π–ª—ã
                elif file in include_files:
                    should_include = True

                # –í–∫–ª—é—á–∞–µ–º —Ñ–∞–π–ª—ã –ø—Ä–æ–º–ø—Ç–æ–≤
                elif file.endswith('.txt') and 'prompt' in file.lower():
                    should_include = True

                if should_include:
                    try:
                        snapshot.write(f"## –§–ê–ô–õ: {relative_path}\n")
                        snapshot.write("-" * 60 + "\n")

                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read()
                            snapshot.write(content)

                        snapshot.write("\n\n" + "=" * 80 + "\n\n")
                        file_count += 1

                    except Exception as e:
                        snapshot.write(f"–û–®–ò–ë–ö–ê –ß–¢–ï–ù–ò–Ø –§–ê–ô–õ–ê: {e}\n\n")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        snapshot.write("## –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ù–ê–ü–®–û–¢–ê\n")
        snapshot.write(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –≤–∫–ª—é—á–µ–Ω–æ: {file_count}\n")
        snapshot.write(f"–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    print(f"‚úÖ –°–Ω–∞–ø—à–æ—Ç –ø—Ä–æ–µ–∫—Ç–∞ —Å–æ–∑–¥–∞–Ω: {output_file}")
    print(f"üìÅ –í–∫–ª—é—á–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {file_count}")
    return output_file


if __name__ == "__main__":
    # –°–æ–∑–¥–∞–µ–º —Å–Ω–∞–ø—à–æ—Ç
    snapshot_file = create_project_snapshot()

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
    size_mb = os.path.getsize(snapshot_file) / (1024 * 1024)
    print(f"üìä –†–∞–∑–º–µ—Ä —Å–Ω–∞–ø—à–æ—Ç–∞: {size_mb:.2f} –ú–ë")

================================================================================

## –§–ê–ô–õ: debug_recitation_error.py
------------------------------------------------------------
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –æ—à–∏–±–∫–∏ RECITATION –≤ Gemini API
–°–æ–∑–¥–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–±–ª–µ–º–µ –¥–ª—è –¥—Ä—É–≥–∏—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
"""

import json
import os
import shutil
from datetime import datetime
from pathlib import Path


def create_recitation_debug_report():
    """–°–æ–∑–¥–∞–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –æ–± –æ—à–∏–±–∫–µ RECITATION"""

    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –æ—Ç—á–µ—Ç–∞
    report_dir = Path("RECITATION_ERROR_REPORT")
    if report_dir.exists():
        shutil.rmtree(report_dir)
    report_dir.mkdir()

    # –û—Å–Ω–æ–≤–Ω–æ–π –æ—Ç—á–µ—Ç
    report_content = f"""
# –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: Gemini RECITATION –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞

## –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## –û–ü–ò–°–ê–ù–ò–ï –ü–†–û–ë–õ–ï–ú–´

–°–∏—Å—Ç–µ–º–∞ HerZog v3.0 —Å—Ç–∞–ª–∫–∏–≤–∞–µ—Ç—Å—è —Å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–æ–π –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å Gemini API:
- –û—à–∏–±–∫–∞: "–ö–æ–Ω—Ç–µ–Ω—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω Gemini –∏–∑-–∑–∞ RECITATION"
- –ê–≥–µ–Ω—Ç: scheduler_and_staffer
- –ú–æ–¥–µ–ª—å: gemini-2.5-pro
- –†–∞–∑–º–µ—Ä –ø—Ä–æ–º–ø—Ç–∞: 20364 —Å–∏–º–≤–æ–ª–æ–≤
- –í—Å–µ 5 –ø–æ–ø—ã—Ç–æ–∫ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã

RECITATION –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ Gemini —Å—á–∏—Ç–∞–µ—Ç –ø—Ä–æ–º–ø—Ç —Å–ª–∏—à–∫–æ–º –ø–æ—Ö–æ–∂–∏–º –Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç
–∏–∑ —Å–≤–æ–∏—Ö –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –±–ª–æ–∫–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –∏–∑ —Å–æ–æ–±—Ä–∞–∂–µ–Ω–∏–π –∞–≤—Ç–æ—Ä—Å–∫–∏—Ö –ø—Ä–∞–≤.

## –õ–û–ö–ê–õ–ò–ó–ê–¶–ò–Ø –ü–†–û–ë–õ–ï–ú–´

–ü—Ä–æ–±–ª–µ–º–Ω—ã–π –ø—Ä–æ–µ–∫—Ç: /home/imort/Herzog_v3/projects/34975055/2b07f457
–í—Ä–µ–º—è –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏—è: 2025-09-14 22:48:32

## –§–ê–ô–õ–´ –í –û–¢–ß–ï–¢–ï

1. scheduler_and_staffer_prompt.txt - –ø—Ä–æ–±–ª–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
2. gemini_client.py - –∫–ª–∏–µ–Ω—Ç API —Å –ª–æ–≥–∏–∫–æ–π –ø–æ–≤—Ç–æ—Ä–æ–≤
3. scheduler_and_staffer.py - –∞–≥–µ–Ω—Ç –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
4. truth.json - –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç–∞ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)
5. error_log.txt - –ø–æ–ª–Ω—ã–π –ª–æ–≥ –æ—à–∏–±–æ–∫

## –í–û–ó–ú–û–ñ–ù–´–ï –†–ï–®–ï–ù–ò–Ø

1. **–ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–∞**: –ò–∑–º–µ–Ω–∏—Ç—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏, –¥–æ–±–∞–≤–∏—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
2. **–°–º–µ–Ω–∞ –º–æ–¥–µ–ª–∏**: –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥—É—é –≤–µ—Ä—Å–∏—é Gemini
3. **–†–∞–∑–±–∏–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞**: –£–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä, –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —á–∞—Å—Ç—è–º–∏
4. **–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö**: –£–±—Ä–∞—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
5. **Fallback –Ω–∞ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å**: OpenAI GPT –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç

## –ö–†–ò–¢–ò–ß–ù–û–°–¢–¨

üî¥ –í–´–°–û–ö–ê–Ø - –±–ª–æ–∫–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É –≤—Å–µ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
–ë–µ–∑ —Ä–µ—à–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º–∞ –Ω–µ –º–æ–∂–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ –ø–ª–∞–Ω—ã.
"""

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –æ—Ç—á–µ—Ç
    with open(report_dir / "README.txt", "w", encoding="utf-8") as f:
        f.write(report_content)

    # –ö–æ–ø–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–π–ª—ã
    files_to_copy = [
        ("src/prompts/scheduler_and_staffer_prompt.txt", "scheduler_and_staffer_prompt.txt"),
        ("src/shared/gemini_client.py", "gemini_client.py"),
        ("src/ai_agents/scheduler_and_staffer.py", "scheduler_and_staffer.py"),
        ("src/ai_agents/new_agent_runner.py", "new_agent_runner.py")
    ]

    for source, dest in files_to_copy:
        source_path = Path(source)
        if source_path.exists():
            shutil.copy2(source_path, report_dir / dest)
            print(f"‚úÖ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω: {source}")
        else:
            print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω: {source}")

    # –ö–æ–ø–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–π truth.json –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
    problem_project = Path("projects/34975055/2b07f457")
    for stage in ["3_prepared", "4_packaged", "5_counted"]:
        truth_file = problem_project / stage / "truth.json"
        if truth_file.exists():
            shutil.copy2(truth_file, report_dir / f"truth_{stage}.json")
            print(f"‚úÖ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω truth.json –∏–∑ {stage}")
            break

    # –°–æ–∑–¥–∞–µ–º –ª–æ–≥ –æ—à–∏–±–æ–∫
    error_log = """
2025-09-14 22:48:32,607 - src.shared.gemini_client - ERROR - ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Gemini (–ø–æ–ø—ã—Ç–∫–∞ 1): –ö–æ–Ω—Ç–µ–Ω—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω Gemini –∏–∑-–∑–∞ RECITATION
2025-09-14 22:48:33,608 - src.shared.gemini_client - INFO - üì° –ü–æ–ø—ã—Ç–∫–∞ 2/5: gemini-2.5-pro (scheduler_and_staffer) (–ø—Ä–æ–º—Ç: 20364 —Å–∏–º–≤–æ–ª–æ–≤)
2025-09-14 22:49:07,580 - src.shared.gemini_client - ERROR - ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Gemini (–ø–æ–ø—ã—Ç–∫–∞ 2): –ö–æ–Ω—Ç–µ–Ω—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω Gemini –∏–∑-–∑–∞ RECITATION
2025-09-14 22:49:08,582 - src.shared.gemini_client - INFO - üì° –ü–æ–ø—ã—Ç–∫–∞ 3/5: gemini-2.5-pro (scheduler_and_staffer) (–ø—Ä–æ–º—Ç: 20364 —Å–∏–º–≤–æ–ª–æ–≤)
2025-09-14 22:49:42,683 - src.shared.gemini_client - ERROR - ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Gemini (–ø–æ–ø—ã—Ç–∫–∞ 3): –ö–æ–Ω—Ç–µ–Ω—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω Gemini –∏–∑-–∑–∞ RECITATION
2025-09-14 22:49:43,684 - src.shared.gemini_client - INFO - üì° –ü–æ–ø—ã—Ç–∫–∞ 4/5: gemini-2.5-pro (scheduler_and_staffer) (–ø—Ä–æ–º—Ç: 20364 —Å–∏–º–≤–æ–ª–æ–≤)
2025-09-14 22:50:18,304 - src.shared.gemini_client - ERROR - ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Gemini (–ø–æ–ø—ã—Ç–∫–∞ 4): –ö–æ–Ω—Ç–µ–Ω—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω Gemini –∏–∑-–∑–∞ RECITATION
2025-09-14 22:50:19,306 - src.shared.gemini_client - INFO - üì° –ü–æ–ø—ã—Ç–∫–∞ 5/5: gemini-2.5-pro (scheduler_and_staffer) (–ø—Ä–æ–º—Ç: 20364 —Å–∏–º–≤–æ–ª–æ–≤)
2025-09-14 22:50:54,013 - src.shared.gemini_client - ERROR - ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Gemini (–ø–æ–ø—ã—Ç–∫–∞ 5): –ö–æ–Ω—Ç–µ–Ω—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω Gemini –∏–∑-–∑–∞ RECITATION
2025-09-14 22:50:54,013 - src.ai_agents.scheduler_and_staffer - ERROR - ‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê Gemini API –¥–ª—è –±–∞—Ç—á–∞ 1: –ö–æ–Ω—Ç–µ–Ω—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω Gemini –∏–∑-–∑–∞ RECITATION
2025-09-14 22:50:54,013 - src.ai_agents.scheduler_and_staffer - ERROR - ‚ùå –û—à–∏–±–∫–∞ –∞–≥–µ–Ω—Ç–∞ scheduler_and_staffer: Gemini API –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –±–∞—Ç—á 1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–æ–º–ø—Ç –∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ.
2025-09-14 22:50:54,019 - src.ai_agents.new_agent_runner - ERROR - ‚ùå –ê–≥–µ–Ω—Ç scheduler_and_staffer –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: Gemini API –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –±–∞—Ç—á 1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–æ–º–ø—Ç –∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ.
2025-09-14 22:50:55,255 - src.main_pipeline - ERROR - ‚ùå –û—à–∏–±–∫–∞ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ: –ê–≥–µ–Ω—Ç scheduler_and_staffer –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π
"""

    with open(report_dir / "error_log.txt", "w", encoding="utf-8") as f:
        f.write(error_log.strip())

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä –ø—Ä–æ–º–ø—Ç–∞
    prompt_file = Path("src/prompts/scheduler_and_staffer_prompt.txt")
    if prompt_file.exists():
        prompt_text = prompt_file.read_text(encoding="utf-8")
        analysis = f"""
# –ê–ù–ê–õ–ò–ó –ü–†–û–ú–ü–¢–ê

–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {len(prompt_text)} —Å–∏–º–≤–æ–ª–æ–≤
–°—Ç—Ä–æ–∫–∏: {len(prompt_text.splitlines())}

–ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–´–ï –ü–†–û–ë–õ–ï–ú–´:
- –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä (20364 —Å–∏–º–≤–æ–ª–∞)
- –í–æ–∑–º–æ–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç —à–∞–±–ª–æ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞
- –ú–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ø–∏—Ä–∞–π—Ç-–∫–æ–Ω—Ç–µ–Ω—Ç

–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:
1. –°–æ–∫—Ä–∞—Ç–∏—Ç—å –ø—Ä–æ–º–ø—Ç –Ω–∞ 50%
2. –ó–∞–º–µ–Ω–∏—Ç—å —à–∞–±–ª–æ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏
3. –£–±—Ä–∞—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
4. –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–µ–∫—Ç–∞
"""

        with open(report_dir / "prompt_analysis.txt", "w", encoding="utf-8") as f:
            f.write(analysis)

    # –°–æ–∑–¥–∞–µ–º —Å–∫—Ä–∏–ø—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    test_script = '''#!/usr/bin/env python3
# –¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è RECITATION –æ—à–∏–±–∫–∏

import sys
sys.path.append('..')
from src.shared.gemini_client import GeminiClient

def test_recitation_fix():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –Ω–∞ RECITATION"""
    client = GeminiClient()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    with open("../src/prompts/scheduler_and_staffer_prompt.txt", "r", encoding="utf-8") as f:
        prompt = f.read()

    print(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Ä–∞–∑–º–µ—Ä–æ–º: {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")

    try:
        # –¢–µ—Å—Ç —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        test_data = {"packages": [{"name": "test", "work_items": []}]}
        result = client.call_gemini(prompt, test_data, "test_recitation")
        print("‚úÖ –£–°–ü–ï–•: –ü—Ä–æ–º–ø—Ç –ø—Ä–æ—à–µ–ª –±–µ–∑ RECITATION –æ—à–∏–±–∫–∏!")
        return True
    except Exception as e:
        print(f"‚ùå –û–®–ò–ë–ö–ê: {e}")
        return False

if __name__ == "__main__":
    test_recitation_fix()
'''

    with open(report_dir / "test_fix.py", "w", encoding="utf-8") as f:
        f.write(test_script)

    print(f"\nüéØ –û–¢–ß–ï–¢ –°–û–ó–î–ê–ù: {report_dir.absolute()}")
    print(f"üìÅ –í–∫–ª—é—á–µ–Ω–æ {len(list(report_dir.glob('*')))} —Ñ–∞–π–ª–æ–≤")
    print("\nüìã –î–õ–Ø –†–ê–ó–†–ê–ë–û–¢–ß–ò–ö–û–í:")
    print("1. –ß–∏—Ç–∞–π—Ç–µ README.txt –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã")
    print("2. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ scheduler_and_staffer_prompt.txt")
    print("3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ test_fix.py –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π")
    print("4. –ü—Ä–æ–±–ª–µ–º–∞ –∫—Ä–∏—Ç–∏—á–Ω–∞—è - –±–ª–æ–∫–∏—Ä—É–µ—Ç –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω!")


if __name__ == "__main__":
    create_recitation_debug_report()

================================================================================

## –§–ê–ô–õ: main_bot.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
HerZog v3.0 - –ì–ª–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞
–¢–µ–ª–µ–≥—Ä–∞–º-–±–æ—Ç –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º–æ–π –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞
"""

import os
import logging
from dotenv import load_dotenv
from telegram.ext import Application

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO,
    handlers=[
        logging.StreamHandler(),  # –í—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
        logging.FileHandler('herzog_bot.log', encoding='utf-8')  # –í—ã–≤–æ–¥ –≤ —Ñ–∞–π–ª
    ]
)

# –û—Ç–∫–ª—é—á–∞–µ–º —Å–ø–∞–º –æ—Ç –≤–Ω–µ—à–Ω–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("telegram").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)

logger = logging.getLogger(__name__)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞"""
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω –±–æ—Ç–∞
    token = os.getenv('TELEGRAM_BOT_TOKEN')
    if not token:
        logger.error("TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
        return
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    application = Application.builder().token(token).build()
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    from src.telegram_bot.handlers import setup_handlers
    setup_handlers(application)
    
    logger.info("–ó–∞–ø—É—Å–∫ HerZog v3.0...")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
    application.run_polling(allowed_updates=['message', 'callback_query'])

if __name__ == '__main__':
    main()

================================================================================

## –§–ê–ô–õ: requirements.txt
------------------------------------------------------------
annotated-types==0.7.0
anyio==4.10.0
cachetools==5.5.2
certifi==2025.8.3
charset-normalizer==3.4.3
et_xmlfile==2.0.0
google-ai-generativelanguage==0.6.15
google-api-core==2.25.1
google-api-python-client==2.181.0
google-auth==2.40.3
google-auth-httplib2==0.2.0
google-generativeai==0.8.5
googleapis-common-protos==1.70.0
grpcio==1.74.0
grpcio-status==1.71.2
h11==0.16.0
holidays==0.80
httpcore==1.0.9
httplib2==0.30.0
httpx==0.28.1
idna==3.10
numpy==2.3.2
openpyxl==3.1.5
pandas==2.3.2
pillow==11.3.0
proto-plus==1.26.1
protobuf==5.29.5
pyasn1==0.6.1
pyasn1_modules==0.4.2
pydantic==2.11.7
pydantic_core==2.33.2
pyparsing==3.2.3
python-dateutil==2.9.0.post0
python-dotenv==1.1.1
python-telegram-bot==22.3
pytz==2025.2
reportlab==4.4.3
requests==2.32.5
rsa==4.9.1
six==1.17.0
sniffio==1.3.1
tqdm==4.67.1
typing-inspection==0.4.1
typing_extensions==4.15.0
tzdata==2025.2
uritemplate==4.2.0
urllib3==2.5.0


================================================================================

## –§–ê–ô–õ: run_agent.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–≥–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã HerZog v3.0
"""

import sys
import os
import logging

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–∏–∫–∞–º
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from ai_agents.agent_runner import run_agent, run_pipeline

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def main():
    if len(sys.argv) < 3:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
        print("  python run_agent.py <–ø—É—Ç—å_–∫_–ø—Ä–æ–µ–∫—Ç—É> <–∏–º—è_–∞–≥–µ–Ω—Ç–∞>")
        print("  python run_agent.py <–ø—É—Ç—å_–∫_–ø—Ä–æ–µ–∫—Ç—É> pipeline [start_from]")
        print()
        print("–ü—Ä–∏–º–µ—Ä—ã:")
        print("  python run_agent.py projects/34975055/94b9a7b6 2_strategist")
        print("  python run_agent.py projects/34975055/94b9a7b6 pipeline 2_strategist")
        return 1
    
    project_dir = sys.argv[1]
    command = sys.argv[2]
    
    if not os.path.exists(project_dir):
        print(f"‚ùå –ü—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {project_dir}")
        return 1
    
    if command == "pipeline":
        # –ó–∞–ø—É—Å–∫ –≤—Å–µ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞
        start_from = sys.argv[3] if len(sys.argv) > 3 else "1.1_group_creator"
        print(f"üè≠ –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ {project_dir} —Å –∞–≥–µ–Ω—Ç–∞ {start_from}")
        success = run_pipeline(project_dir, start_from)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {'‚úÖ –£—Å–ø–µ—Ö' if success else '‚ùå –û—à–∏–±–∫–∞'}")
        return 0 if success else 1
    
    else:
        # –ó–∞–ø—É—Å–∫ –æ–¥–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
        agent_name = command
        print(f"ü§ñ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ {agent_name} –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ {project_dir}")
        success = run_agent(agent_name, project_dir)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {'‚úÖ –£—Å–ø–µ—Ö' if success else '‚ùå –û—à–∏–±–∫–∞'}")
        return 0 if success else 1

if __name__ == "__main__":
    sys.exit(main())

================================================================================

## –§–ê–ô–õ: test_classifier_system_instruction.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç gemini_classifier —Å –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π system_instruction
"""

import asyncio
import sys
import os
import json
import logging
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –æ—Å–Ω–æ–≤–Ω–æ–º—É –∫–æ–¥—É
sys.path.insert(0, str(Path(__file__).parent))

from src.data_processing.gemini_classifier import classify_with_gemini

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def test_gemini_classifier_with_system_instruction():
    """–¢–µ—Å—Ç gemini_classifier —Å –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π"""
    logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ gemini_classifier —Å system_instruction")

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_items = [
        {
            "id": "test_001",
            "code": "1.1-01",
            "name": "–ü–æ–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤"
        },
        {
            "id": "test_002",
            "code": "2.2-03",
            "name": "–¶–µ–º–µ–Ω—Ç –ø–æ—Ä—Ç–ª–∞–Ω–¥—Å–∫–∏–π –ú400"
        },
        {
            "id": "test_003",
            "code": "3.3-05",
            "name": "–ú–æ–Ω—Ç–∞–∂ –º–µ—Ç–∞–ª–ª–æ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π"
        },
        {
            "id": "test_004",
            "code": "4.4-07",
            "name": "–ù–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã"
        }
    ]

    try:
        result = await classify_with_gemini(test_items)

        if result and len(result) > 0:
            logger.info("‚úÖ Gemini classifier —É—Å–ø–µ—à–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–ª –ø–æ–∑–∏—Ü–∏–∏!")
            for item_id, classification in result.items():
                logger.info(f"üìù {item_id}: {classification.get('classification')} - {classification.get('reasoning')}")

            return True
        else:
            logger.error("‚ùå Gemini classifier –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            return False

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ gemini_classifier: {e}")
        return False

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    logger.info("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ gemini_classifier —Å –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π")

    classifier_ok = await test_gemini_classifier_with_system_instruction()

    # –ò—Ç–æ–≥–∏
    logger.info("üìä === –ò–¢–û–ì–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø ===")
    logger.info(f"Gemini Classifier: {'‚úÖ OK' if classifier_ok else '‚ùå FAIL'}")

    return 0 if classifier_ok else 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)

================================================================================

## –§–ê–ô–õ: test_gemini_fixes.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π GeminiClient
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:
1. –û–±—Ä–∞–±–æ—Ç–∫–∞ JSONDecodeError –∫–∞–∫ retry
2. –§—É–Ω–∫—Ü–∏—è _add_salt_to_prompt
3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Å—Ç—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç API
"""

import asyncio
import json
import logging

# –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
import sys
import os
sys.path.insert(0, '/home/imort/Herzog_v3')

from src.shared.gemini_client import GeminiClient

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_salt_function():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–æ–ª–∏ –∫ –ø—Ä–æ–º–ø—Ç—É"""
    print("\nüß™ –¢–ï–°–¢ 1: –§—É–Ω–∫—Ü–∏—è _add_salt_to_prompt")

    client = GeminiClient()

    original_prompt = "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞"

    # –ü–æ–ø—ã—Ç–∫–∞ 1 - –±–µ–∑ —Å–æ–ª–∏
    salted_1 = client._add_salt_to_prompt(original_prompt, 1)
    assert salted_1 == original_prompt, "–ù–∞ –ø–µ—Ä–≤–æ–π –ø–æ–ø—ã—Ç–∫–µ —Å–æ–ª—å –Ω–µ –¥–æ–ª–∂–Ω–∞ –¥–æ–±–∞–≤–ª—è—Ç—å—Å—è"
    print("‚úÖ –ü–æ–ø—ã—Ç–∫–∞ 1: —Å–æ–ª—å –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω–∞ (–ø—Ä–∞–≤–∏–ª—å–Ω–æ)")

    # –ü–æ–ø—ã—Ç–∫–∞ 2 - —Å —Å–æ–ª—å—é
    salted_2 = client._add_salt_to_prompt(original_prompt, 2)
    assert "–£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –∑–∞–ø—Ä–æ—Å–∞:" in salted_2, "–ù–∞ –≤—Ç–æ—Ä–æ–π –ø–æ–ø—ã—Ç–∫–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–ª—å"
    assert "HRZ-" in salted_2, "–î–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ–¥ –ø—Ä–æ–µ–∫—Ç–∞"
    assert original_prompt in salted_2, "–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–æ–ª–∂–µ–Ω —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å—Å—è"
    print("‚úÖ –ü–æ–ø—ã—Ç–∫–∞ 2: —Å–æ–ª—å –¥–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")

    print(f"üìè –î–ª–∏–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞: {len(original_prompt)} ‚Üí {len(salted_2)} (+{len(salted_2) - len(original_prompt)} —Å–∏–º–≤–æ–ª–æ–≤)")

async def test_json_validation():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ—Å—Ç–æ–π JSON –∑–∞–ø—Ä–æ—Å"""
    print("\nüß™ –¢–ï–°–¢ 2: –í–∞–ª–∏–¥–∞—Ü–∏—è JSON –æ—Ç–≤–µ—Ç–∞")

    client = GeminiClient()

    # –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å —Å —á–µ—Ç–∫–∏–º JSON
    prompt = """
–î–∞–π –º–Ω–µ –ø—Ä–æ—Å—Ç–æ–π JSON –æ—Ç–≤–µ—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ç—Ä–æ–π–∫–µ:

{
    "project": "–¢–µ—Å—Ç–æ–≤–∞—è —Å—Ç—Ä–æ–π–∫–∞",
    "status": "active",
    "days": 30
}

–û—Ç–≤–µ—Ç—å –°–¢–†–û–ì–û —ç—Ç–∏–º JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
"""

    try:
        print("üîÑ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ Gemini...")
        response = await client.generate_response(prompt, max_retries=3)

        if response.get('success'):
            print("‚úÖ –ó–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")
            print(f"ü§ñ –ú–æ–¥–µ–ª—å: {response.get('model_used')}")
            print(f"üî¢ –ü–æ–ø—ã—Ç–æ–∫: {response.get('attempt')}")
            print(f"üìä –¢–æ–∫–µ–Ω–æ–≤: {response.get('usage_metadata', {}).get('total_token_count', 0)}")

            if response.get('json_parse_success'):
                print("‚úÖ JSON —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω")
                parsed_json = response.get('response')
                print(f"üìã –û—Ç–≤–µ—Ç: {json.dumps(parsed_json, ensure_ascii=False, indent=2)}")
            else:
                print("‚ùå JSON –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å")
                print(f"üóíÔ∏è –°—ã—Ä–æ–π —Ç–µ–∫—Å—Ç: {response.get('raw_text', '')[:200]}...")
        else:
            print(f"‚ùå –ó–∞–ø—Ä–æ—Å –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –æ—à–∏–±–∫–æ–π: {response.get('error')}")

    except Exception as e:
        print(f"üí• –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}")

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ô GEMINI CLIENT")
    print("=" * 50)

    try:
        await test_salt_function()
        await test_json_validation()

        print("\nüéâ –í–°–ï –¢–ï–°–¢–´ –ó–ê–í–ï–†–®–ï–ù–´")

    except Exception as e:
        print(f"üí• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())

================================================================================

## –§–ê–ô–õ: test_refactored_agents.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—Ä–µ—Ñ–∞–∫—Ç–æ—Ä–µ–Ω–Ω—ã—Ö AI-–∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç—ã pattern "system_instruction + user_prompt"
"""

import asyncio
import json
import os
import sys
import logging
from typing import Dict, Any

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.insert(0, '/home/imort/Herzog_v3')

from src.ai_agents.counter import WorkVolumeCalculator
from src.ai_agents.works_to_packages import WorksToPackagesAssigner
from src.ai_agents.scheduler_and_staffer import SchedulerAndStaffer

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

async def test_counter_format_prompt():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–π _format_prompt –º–µ—Ç–æ–¥ –∞–≥–µ–Ω—Ç–∞ Counter"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Counter._format_prompt")

    agent = WorkVolumeCalculator()

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    input_data = {
        'package': {
            'package_id': 'pkg_001',
            'name': '–î–µ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã'
        },
        'works': [
            {'id': 'work_001', 'name': '–î–µ–º–æ–Ω—Ç–∞–∂ –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫', 'unit': '–º¬≤', 'quantity': 45.5}
        ],
        'user_directive': '—Å—á–∏—Ç–∞–π –ø–ª–æ—â–∞–¥–∏ —Ç–æ—á–Ω–æ'
    }

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç
    prompt_template = agent._load_prompt()

    try:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç –≤–æ–∑–≤—Ä–∞—Ç–∞ (–∫–æ—Ä—Ç–µ–∂)
        system_instruction, user_prompt = agent._format_prompt(input_data, prompt_template)

        print(f"‚úÖ System instruction –ø–æ–ª—É—á–µ–Ω–∞: {len(system_instruction)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"‚úÖ User prompt –ø–æ–ª—É—á–µ–Ω: {len(user_prompt)} —Å–∏–º–≤–æ–ª–æ–≤")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ user_prompt –≤–∞–ª–∏–¥–Ω—ã–π JSON
        user_data = json.loads(user_prompt)

        assert 'package' in user_data, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'package' –≤ user_prompt"
        assert 'works' in user_data, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'works' –≤ user_prompt"
        assert 'user_directive' in user_data, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'user_directive' –≤ user_prompt"

        print("‚úÖ Counter._format_prompt —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ Counter._format_prompt: {e}")
        return False

async def test_works_to_packages_format_prompt():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–π _format_prompt –º–µ—Ç–æ–¥ –∞–≥–µ–Ω—Ç–∞ WorksToPackagesAssigner"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ WorksToPackagesAssigner._format_prompt")

    agent = WorksToPackagesAssigner()

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    input_data = {
        'work_packages': [
            {'package_id': 'pkg_001', 'name': '–î–µ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã'}
        ],
        'batch_works': [
            {'id': 'work_001', 'name': '–î–µ–º–æ–Ω—Ç–∞–∂ –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫', 'code': '01-01-001'}
        ],
        'batch_number': 1
    }

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç
    prompt_template = agent._load_prompt()

    try:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç –≤–æ–∑–≤—Ä–∞—Ç–∞ (–∫–æ—Ä—Ç–µ–∂)
        system_instruction, user_prompt = agent._format_prompt(input_data, prompt_template)

        print(f"‚úÖ System instruction –ø–æ–ª—É—á–µ–Ω–∞: {len(system_instruction)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"‚úÖ User prompt –ø–æ–ª—É—á–µ–Ω: {len(user_prompt)} —Å–∏–º–≤–æ–ª–æ–≤")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ user_prompt –≤–∞–ª–∏–¥–Ω—ã–π JSON
        user_data = json.loads(user_prompt)

        assert 'work_packages' in user_data, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'work_packages' –≤ user_prompt"
        assert 'batch_works' in user_data, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'batch_works' –≤ user_prompt"
        assert 'batch_number' in user_data, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'batch_number' –≤ user_prompt"

        print("‚úÖ WorksToPackagesAssigner._format_prompt —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ WorksToPackagesAssigner._format_prompt: {e}")
        return False

async def test_scheduler_format_prompt():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–π _format_prompt –º–µ—Ç–æ–¥ –∞–≥–µ–Ω—Ç–∞ SchedulerAndStaffer"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ SchedulerAndStaffer._format_prompt")

    agent = SchedulerAndStaffer()

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    input_data = {
        'work_packages': [
            {
                'package_id': 'pkg_001',
                'package_name': '–î–µ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã',
                'total_volume': {'quantity': 150.0, 'unit': '–º¬≤'}
            }
        ],
        'timeline_blocks': [
            {'week_id': 1, 'start_date': '2024-01-01', 'end_date': '2024-01-07'}
        ],
        'workforce_range': {'min': 10, 'max': 20},
        'user_directive': '–ø–µ—Ä–≤—ã–π –º–µ—Å—è—Ü —Ç–æ–ª—å–∫–æ –¥–µ–º–æ–Ω—Ç–∞–∂'
    }

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç
    prompt_template = agent._load_prompt()

    try:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç –≤–æ–∑–≤—Ä–∞—Ç–∞ (–∫–æ—Ä—Ç–µ–∂)
        system_instruction, user_prompt = agent._format_prompt(input_data, prompt_template)

        print(f"‚úÖ System instruction –ø–æ–ª—É—á–µ–Ω–∞: {len(system_instruction)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"‚úÖ User prompt –ø–æ–ª—É—á–µ–Ω: {len(user_prompt)} —Å–∏–º–≤–æ–ª–æ–≤")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ user_prompt –≤–∞–ª–∏–¥–Ω—ã–π JSON
        user_data = json.loads(user_prompt)

        assert 'work_packages' in user_data, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'work_packages' –≤ user_prompt"
        assert 'timeline_blocks' in user_data, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'timeline_blocks' –≤ user_prompt"
        assert 'workforce_range' in user_data, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'workforce_range' –≤ user_prompt"
        assert 'user_directive' in user_data, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'user_directive' –≤ user_prompt"

        print("‚úÖ SchedulerAndStaffer._format_prompt —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ SchedulerAndStaffer._format_prompt: {e}")
        return False

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—Ä–µ—Ñ–∞–∫—Ç–æ—Ä–µ–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤")

    results = []

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –∞–≥–µ–Ω—Ç
    results.append(await test_counter_format_prompt())
    results.append(await test_works_to_packages_format_prompt())
    results.append(await test_scheduler_format_prompt())

    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    print(f"‚úÖ –ü—Ä–æ–π–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {sum(results)}")
    print(f"‚ùå –ü—Ä–æ–≤–∞–ª–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {len(results) - sum(results)}")

    if all(results):
        print("\nüéâ –í–°–ï –ê–ì–ï–ù–¢–´ –û–¢–†–ï–§–ê–ö–¢–û–†–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        print("‚úÖ –ü–∞—Ç—Ç–µ—Ä–Ω 'system_instruction + user_prompt' –ø—Ä–∏–º–µ–Ω–µ–Ω –∫–æ –≤—Å–µ–º –∞–≥–µ–Ω—Ç–∞–º")
        print("‚úÖ –û—à–∏–±–∫–∏ RECITATION –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —É—Å—Ç—Ä–∞–Ω–µ–Ω—ã")
    else:
        print("\n‚ö†Ô∏è –ï–°–¢–¨ –ü–†–û–ë–õ–ï–ú–´ –í –†–ï–§–ê–ö–¢–û–†–ò–ù–ì–ï!")
        print("‚ùå –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∞–≥–µ–Ω—Ç—ã —Ç—Ä–µ–±—É—é—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏")
        return False

    return True

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)

================================================================================

## –§–ê–ô–õ: test_scheduler_recitation_fix.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è RECITATION –æ—à–∏–±–∫–∏ –≤ scheduler_and_staffer
"""

import asyncio
import json
import sys
import logging

sys.path.insert(0, '/home/imort/Herzog_v3')

from src.ai_agents.scheduler_and_staffer import SchedulerAndStaffer

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)

async def test_scheduler_format_prompt():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–æ–≤–æ–µ —Å–æ–ª–µ–Ω–∏–µ –≤ scheduler_and_staffer"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ SchedulerAndStaffer —Å —É—Å–∏–ª–µ–Ω–Ω—ã–º —Å–æ–ª–µ–Ω–∏–µ–º")

    agent = SchedulerAndStaffer()

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ)
    input_data = {
        'work_packages': [
            {
                'package_id': 'pkg_001',
                'package_name': '–î–µ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã',
                'total_volume': {'quantity': 150.0, 'unit': '–º¬≤'},
                'source_works_count': 5,
                'complexity': 'medium'
            }
        ],
        'timeline_blocks': [
            {'week_id': 1, 'start_date': '2024-01-01', 'end_date': '2024-01-07'}
        ],
        'workforce_range': {'min': 10, 'max': 20},
        'user_directive': '—Ç–µ—Å—Ç–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–∏–≤–∞'
    }

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç
    prompt_template = agent._load_prompt()

    try:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Å —Å–æ–ª–µ–Ω–∏–µ–º
        system_instruction, user_prompt = agent._format_prompt(input_data, prompt_template)

        print(f"‚úÖ System instruction –ø–æ–ª—É—á–µ–Ω–∞: {len(system_instruction)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"‚úÖ User prompt –ø–æ–ª—É—á–µ–Ω: {len(user_prompt)} —Å–∏–º–≤–æ–ª–æ–≤")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ user_prompt –≤–∞–ª–∏–¥–Ω—ã–π JSON
        user_data = json.loads(user_prompt)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∞–Ω—Ç–∏-RECITATION –º–µ—Ç–∞-–¥–∞–Ω–Ω—ã—Ö
        assert '_meta' in user_data, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á '_meta' —Å –∞–Ω—Ç–∏-RECITATION –¥–∞–Ω–Ω—ã–º–∏"
        assert 'session_id' in user_data['_meta'], "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç session_id"
        assert 'timestamp' in user_data['_meta'], "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç timestamp"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        assert 'work_packages' in user_data, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'work_packages'"
        assert 'timeline_blocks' in user_data, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'timeline_blocks'"

        print("‚úÖ –ê–Ω—Ç–∏-RECITATION –º–µ—Ç–∞-–¥–∞–Ω–Ω—ã–µ –¥–æ–±–∞–≤–ª–µ–Ω—ã")
        print(f"‚úÖ Session ID: {user_data['_meta']['session_id']}")

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–æ–ª–µ–Ω–∏–µ –∫ system_instruction
        salted_system_instruction = agent._add_salt_to_prompt(system_instruction)
        print(f"‚úÖ –°–æ–ª–µ–Ω–∞—è system_instruction: {len(salted_system_instruction)} —Å–∏–º–≤–æ–ª–æ–≤")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–æ–ª–µ–Ω–∏–µ –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ
        assert "TASK_ID" in salted_system_instruction, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç TASK_ID –≤ —Å–æ–ª–µ–Ω–∏–∏"
        assert "ANTI_RECITATION_SALT" in salted_system_instruction, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ANTI_RECITATION_SALT"

        print("üéâ SchedulerAndStaffer —Å —É—Å–∏–ª–µ–Ω–Ω—ã–º —Å–æ–ª–µ–Ω–∏–µ–º –≥–æ—Ç–æ–≤!")
        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        return False

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è RECITATION –¥–ª—è scheduler_and_staffer")

    success = await test_scheduler_format_prompt()

    if success:
        print("\n‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ì–û–¢–û–í–û –ö –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Æ!")
        print("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ —É—Å–∏–ª–µ–Ω–Ω–æ–µ —Å–æ–ª–µ–Ω–∏–µ –ø—Ä–æ—Ç–∏–≤ RECITATION")
        print("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã –º–µ—Ç–∞-–¥–∞–Ω–Ω—ã–µ –≤ user_prompt")
    else:
        print("\n‚ùå –ï–°–¢–¨ –ü–†–û–ë–õ–ï–ú–´ –í –ò–°–ü–†–ê–í–õ–ï–ù–ò–ò!")

    return success

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)

================================================================================

## –§–ê–ô–õ: test_simple_agents.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –º–µ–Ω—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö
"""

import asyncio
import sys
import os
import json
import logging
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –æ—Å–Ω–æ–≤–Ω–æ–º—É –∫–æ–¥—É
sys.path.insert(0, str(Path(__file__).parent))

from src.ai_agents.work_packager import WorkPackager
from src.ai_agents.works_to_packages import WorksToPackagesAssigner
from src.ai_agents.counter import WorkVolumeCalculator
from src.ai_agents.scheduler_and_staffer import SchedulerAndStaffer

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def test_salt_mechanism():
    """–¢–µ—Å—Ç –º–µ—Ö–∞–Ω–∏–∑–º–∞ —Å–æ–ª–∏ –æ—Ç–¥–µ–ª—å–Ω–æ"""
    logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ö–∞–Ω–∏–∑–º–∞ —Å–æ–ª–∏")

    agent = WorkPackager()
    test_prompt = "–¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–ª–∏"
    salted_prompt = agent._add_salt_to_prompt(test_prompt)

    logger.info(f"‚úÖ –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {len(test_prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
    logger.info(f"‚úÖ –° —Å–æ–ª—å—é: {len(salted_prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
    logger.info(f"‚úÖ –°–æ–ª—å –¥–æ–±–∞–≤–ª–µ–Ω–∞: {'ID:' in salted_prompt and '–ö–æ–Ω—Ç—Ä–æ–ª—å:' in salted_prompt}")

    return True

async def test_small_project():
    """–¢–µ—Å—Ç –Ω–∞ –ø—Ä–æ–µ–∫—Ç–µ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ä–∞–±–æ—Ç"""
    logger.info("üß™ –ü–æ–∏—Å–∫ –ø—Ä–æ–µ–∫—Ç–∞ —Å –º–∞–ª—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ä–∞–±–æ—Ç")

    # –ò—â–µ–º –ø—Ä–æ–µ–∫—Ç—ã
    projects_dir = "/home/imort/Herzog_v3/projects"
    small_project_path = None

    for user_id in os.listdir(projects_dir):
        user_path = os.path.join(projects_dir, user_id)
        if not os.path.isdir(user_path):
            continue

        for project_id in os.listdir(user_path):
            project_path = os.path.join(user_path, project_id)
            truth_path = os.path.join(project_path, "true.json")

            if os.path.exists(truth_path):
                try:
                    with open(truth_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)

                    work_items = data.get('source_work_items', [])
                    if 10 <= len(work_items) <= 50:  # –ò—â–µ–º –ø—Ä–æ–µ–∫—Ç —Å 10-50 —Ä–∞–±–æ—Ç–∞–º–∏
                        small_project_path = project_path
                        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω –ø–æ–¥—Ö–æ–¥—è—â–∏–π –ø—Ä–æ–µ–∫—Ç: {project_path}")
                        logger.info(f"‚úÖ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—Ç: {len(work_items)}")
                        break

                except Exception as e:
                    continue

        if small_project_path:
            break

    if not small_project_path:
        logger.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω –ø—Ä–æ–µ–∫—Ç —Å –º–∞–ª—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ä–∞–±–æ—Ç")
        return False

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º work_packager –Ω–∞ –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ work_packager –Ω–∞ –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    agent = WorkPackager()
    result = await agent.process(small_project_path)

    if result.get('success'):
        logger.info(f"‚úÖ work_packager: –°–æ–∑–¥–∞–Ω–æ {result.get('packages_created', 0)} –ø–∞–∫–µ—Ç–æ–≤")
        return True
    else:
        logger.error(f"‚ùå work_packager: {result.get('error')}")
        return False

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤")

    # –¢–µ—Å—Ç 1: –ú–µ—Ö–∞–Ω–∏–∑–º —Å–æ–ª–∏
    salt_ok = await test_salt_mechanism()

    # –¢–µ—Å—Ç 2: –ú–∞–ª—ã–π –ø—Ä–æ–µ–∫—Ç
    small_project_ok = await test_small_project()

    # –ò—Ç–æ–≥–∏
    logger.info("üìä === –ò–¢–û–ì–ò –¢–ï–°–¢–û–í ===")
    logger.info(f"–ú–µ—Ö–∞–Ω–∏–∑–º —Å–æ–ª–∏: {'‚úÖ OK' if salt_ok else '‚ùå FAIL'}")
    logger.info(f"–ú–∞–ª—ã–π –ø—Ä–æ–µ–∫—Ç: {'‚úÖ OK' if small_project_ok else '‚ùå FAIL'}")

    return 0 if (salt_ok and small_project_ok) else 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)

================================================================================

## –§–ê–ô–õ: test_system_instruction.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å system_instruction –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è RECITATION
"""

import asyncio
import sys
import os
import json
import logging
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –æ—Å–Ω–æ–≤–Ω–æ–º—É –∫–æ–¥—É
sys.path.insert(0, str(Path(__file__).parent))

from src.ai_agents.work_packager import WorkPackager

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def test_work_packager_with_system_instruction():
    """–¢–µ—Å—Ç work_packager —Å –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π system_instruction"""
    logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ WorkPackager —Å system_instruction –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π")

    # –ò—â–µ–º –ø—Ä–æ–µ–∫—Ç —Å –º–∞–ª—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ä–∞–±–æ—Ç
    projects_dir = "/home/imort/Herzog_v3/projects"
    test_project_path = None

    for user_id in os.listdir(projects_dir):
        user_path = os.path.join(projects_dir, user_id)
        if not os.path.isdir(user_path):
            continue

        for project_id in os.listdir(user_path):
            project_path = os.path.join(user_path, project_id)
            truth_path = os.path.join(project_path, "true.json")

            if os.path.exists(truth_path):
                try:
                    with open(truth_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)

                    work_items = data.get('source_work_items', [])
                    if 10 <= len(work_items) <= 30:  # –ò—â–µ–º –ø—Ä–æ–µ–∫—Ç —Å 10-30 —Ä–∞–±–æ—Ç–∞–º–∏
                        test_project_path = project_path
                        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç: {project_path}")
                        logger.info(f"‚úÖ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—Ç: {len(work_items)}")
                        break

                except Exception as e:
                    continue

        if test_project_path:
            break

    if not test_project_path:
        logger.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç")
        return False

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º work_packager —Å –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π
    agent = WorkPackager()
    result = await agent.process(test_project_path)

    if result.get('success'):
        logger.info(f"‚úÖ WorkPackager —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        logger.info(f"üìä –°–æ–∑–¥–∞–Ω–æ {result.get('work_packages_created', 0)} –ø–∞–∫–µ—Ç–æ–≤")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª—ã –æ—Ç–ª–∞–¥–∫–∏ —Å–æ–∑–¥–∞–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
        debug_path = os.path.join(test_project_path, "4_packaged", "llm_input.json")
        if os.path.exists(debug_path):
            with open(debug_path, 'r', encoding='utf-8') as f:
                debug_data = json.load(f)

            if 'system_instruction' in debug_data and 'user_prompt' in debug_data:
                logger.info("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç–ª–∞–¥–∫–∏ —Å–æ–∑–¥–∞–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
                logger.info(f"üìù System instruction: {len(debug_data['system_instruction'])} —Å–∏–º–≤–æ–ª–æ–≤")
                logger.info(f"üìù User prompt: {len(debug_data['user_prompt'])} —Å–∏–º–≤–æ–ª–æ–≤")
            else:
                logger.warning("‚ö†Ô∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–ª–∞–¥–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞")

        return True
    else:
        logger.error(f"‚ùå WorkPackager –ø—Ä–æ–≤–∞–ª–µ–Ω: {result.get('error')}")
        return False

async def test_simple_system_instruction():
    """–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –º–µ—Ö–∞–Ω–∏–∑–º–∞ system_instruction"""
    logger.info("üß™ –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç system_instruction")

    from src.shared.gemini_client import gemini_client

    system_instruction = "–¢—ã - –ø–æ–º–æ—â–Ω–∏–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–∞. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ."
    user_prompt = '{"question": "What is 2+2?"}'

    try:
        response = await gemini_client.generate_response(
            prompt=user_prompt,
            system_instruction=system_instruction
        )

        if response.get('success'):
            logger.info("‚úÖ –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç system_instruction –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ")
            return True
        else:
            logger.error(f"‚ùå –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –ø—Ä–æ–≤–∞–ª–µ–Ω: {response.get('error')}")
            return False
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ—Å—Ç–æ–º —Ç–µ—Å—Ç–µ: {e}")
        return False

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    logger.info("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å system_instruction")

    # –¢–µ—Å—Ç 1: –ü—Ä–æ—Å—Ç–æ–π –º–µ—Ö–∞–Ω–∏–∑–º
    simple_test_ok = await test_simple_system_instruction()

    # –¢–µ—Å—Ç 2: WorkPackager
    work_packager_ok = await test_work_packager_with_system_instruction()

    # –ò—Ç–æ–≥–∏
    logger.info("üìä === –ò–¢–û–ì–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø ===")
    logger.info(f"–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç: {'‚úÖ OK' if simple_test_ok else '‚ùå FAIL'}")
    logger.info(f"WorkPackager: {'‚úÖ OK' if work_packager_ok else '‚ùå FAIL'}")

    if simple_test_ok and work_packager_ok:
        logger.info("üéâ –ù–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —É—Å–ø–µ—à–Ω–æ!")
        return 0
    else:
        logger.error("üí• –ù–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏")
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)

================================================================================

## –§–ê–ô–õ: RECITATION_ERROR_REPORT/gemini_client.py
------------------------------------------------------------
"""
–û–±—â–∏–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Gemini API
"""

import os
import json
import logging
import asyncio
import time
import uuid
import google.generativeai as genai
from typing import Dict, Any, Optional
from dotenv import load_dotenv

load_dotenv()
logger = logging.getLogger(__name__)

class GeminiClient:
    def __init__(self):
        self.api_key = os.getenv('GEMINI_API_KEY')
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        
        genai.configure(api_key=self.api_key)
        
        # –ú–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ —Å —É—á–µ—Ç–æ–º –∏—Ö –∑–∞–¥–∞—á –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
        self.agent_models = {
            'work_packager': 'gemini-2.5-pro',        # –°–ª–æ–∂–Ω–æ–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç - –Ω—É–∂–Ω—ã –º–æ—â–Ω–æ—Å—Ç–∏
            'works_to_packages': 'gemini-2.5-flash-lite',  # –ü—Ä–æ—Å—Ç–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ - —ç–∫–æ–Ω–æ–º–∏–º —Ç–æ–∫–µ–Ω—ã
            'counter': 'gemini-2.5-flash-lite',       # –ü–æ–¥—Å—á–µ—Ç—ã - –±—ã—Å—Ç—Ä–æ –∏ –¥–µ—à–µ–≤–æ
            'scheduler_and_staffer': 'gemini-2.5-pro', # –°–ª–æ–∂–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ - –Ω—É–∂–Ω—ã –º–æ—â–Ω–æ—Å—Ç–∏
            'classifier': 'gemini-2.5-flash-lite'     # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç - –±—ã—Å—Ç—Ä–æ –∏ –¥–µ—à–µ–≤–æ
        }
        
        # –ö—ç—à –º–æ–¥–µ–ª–µ–π –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–π
        self._model_cache = {}
        
        # –î–µ—Ñ–æ–ª—Ç–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        self.model = self._get_model('gemini-2.5-pro')

    
    def _get_model(self, model_name: str):
        """–ü–æ–ª—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ –∫—ç—à–∞ –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é"""
        if model_name not in self._model_cache:
            self._model_cache[model_name] = genai.GenerativeModel(model_name)
            logger.info(f"üìã –°–æ–∑–¥–∞–Ω–∞ –º–æ–¥–µ–ª—å: {model_name}")
        return self._model_cache[model_name]
    
    def get_model_for_agent(self, agent_name: str):
        """–ü–æ–ª—É—á–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞"""
        model_name = self.agent_models.get(agent_name, 'gemini-2.5-pro')
        return self._get_model(model_name)
        
    async def generate_response(self, prompt: str, max_retries: int = 5, agent_name: str = None, system_instruction: Optional[str] = None) -> Dict[str, Any]:
        """
        –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ Gemini –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —Å retry –ª–æ–≥–∏–∫–æ–π

        Args:
            prompt: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º—Ç (–¥–∞–Ω–Ω—ã–µ)
            max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ 429 –æ—à–∏–±–∫–µ
            agent_name: –ò–º—è –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            system_instruction: –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è (—Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∞–≤–∏–ª–∞ –∏ —à–∞–±–ª–æ–Ω—ã)

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ—Ç–≤–µ—Ç–æ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –∞–≥–µ–Ω—Ç–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—É—é
        if agent_name and agent_name in self.agent_models:
            model_name = self.agent_models[agent_name]
        else:
            model_name = 'gemini-2.5-pro'

        # –ï—Å–ª–∏ –µ—Å—Ç—å system_instruction, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å —Å —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π
        if system_instruction:
            model = genai.GenerativeModel(model_name, system_instruction=system_instruction)
            logger.info(f"üß† –°–æ–∑–¥–∞–Ω–∞ –º–æ–¥–µ–ª—å —Å —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π: {model_name}")
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
            if agent_name and agent_name in self.agent_models:
                model = self.get_model_for_agent(agent_name)
            else:
                model = self.model

        for attempt in range(max_retries):
            try:
                logger.info(f"üì° –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}: {model_name} {f'({agent_name})' if agent_name else ''} (–ø—Ä–æ–º—Ç: {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤)")
                
                # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ–º –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∞–≥–µ–Ω—Ç–∞
                if agent_name == 'work_packager':
                    max_tokens = 8000
                elif agent_name == 'counter':
                    max_tokens = 8000  # Counter –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–µ –æ—Ç–≤–µ—Ç—ã
                else:
                    max_tokens = 4000
                    
                
                response = await model.generate_content_async(
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.3,
                        top_p=0.8,
                        max_output_tokens=max_tokens,
                        response_mime_type="application/json"
                    )
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç API
                if not response.candidates:
                    logger.warning(f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini API")
                    if response.prompt_feedback:
                        feedback_reason = getattr(response.prompt_feedback, 'block_reason', 'UNKNOWN')
                        logger.warning(f"‚ö†Ô∏è –ü—Ä–∏—á–∏–Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏: {feedback_reason}")
                    if attempt < max_retries - 1:
                        await asyncio.sleep(2 + attempt)
                        continue
                    else:
                        raise Exception("API –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º finish_reason –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
                finish_reason = getattr(response.candidates[0], 'finish_reason', None)

                if finish_reason == 2:  # RECITATION - –∫–æ–Ω—Ç–µ–Ω—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω
                    raise Exception(f"–ö–æ–Ω—Ç–µ–Ω—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω Gemini –∏–∑-–∑–∞ RECITATION")

                if finish_reason == 3:  # SAFETY - –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–æ –∏–∑-–∑–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
                    raise Exception("–ö–æ–Ω—Ç–µ–Ω—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω Gemini –∏–∑-–∑–∞ –ø–æ–ª–∏—Ç–∏–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
                
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
                try:
                    response_text = response.text
                except Exception as text_error:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å response.text: {text_error}")
                    if finish_reason == 4:  # MAX_TOKENS - –æ—Ç–≤–µ—Ç –æ–±—Ä–µ–∑–∞–Ω
                        logger.warning("‚ö†Ô∏è –û—Ç–≤–µ—Ç –æ–±—Ä–µ–∑–∞–Ω –∏–∑-–∑–∞ –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤. –£–≤–µ–ª–∏—á–∏–≤–∞—é –ª–∏–º–∏—Ç...")
                        # –ü–æ–≤—Ç–æ—Ä—è–µ–º —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º –ª–∏–º–∏—Ç–æ–º —Ç–æ–∫–µ–Ω–æ–≤
                        if attempt < max_retries - 1:
                            continue
                    raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç Gemini: {text_error}")
                
                # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º markdown –æ–±–µ—Ä—Ç–∫–∏
                try:
                    cleaned_text = self._clean_json_from_markdown(response_text)
                    response_json = self._try_fix_broken_json(cleaned_text)
                    json_parse_success = True
                except json.JSONDecodeError as e:
                    logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç Gemini: {e}")

                    # JSONDecodeError —Å—á–∏—Ç–∞–µ—Ç—Å—è –Ω–µ—É—Å–ø–µ—à–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π - —Ä–µ—Ç—Ä–∞–∏–º
                    if attempt < max_retries - 1:
                        logger.info(f"üîÑ –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –∏–∑-–∑–∞ –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–≥–æ JSON (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 2}/{max_retries})")
                        await asyncio.sleep(1 + attempt)
                        continue
                    else:
                        # –ù–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ–ø—ã—Ç–∫–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
                        return {
                            'success': False,
                            'error': f'JSON –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫: {e}',
                            'response': None,
                            'raw_text': response_text
                        }
                
                result = {
                    'success': True,
                    'response': response_json,
                    'json_parse_success': json_parse_success,
                    'raw_text': response_text,
                    'model_used': model_name,
                    'agent_name': agent_name,
                    'prompt_feedback': str(response.prompt_feedback) if response.prompt_feedback else None,
                    'usage_metadata': {
                        'prompt_token_count': getattr(response.usage_metadata, 'prompt_token_count', 0),
                        'candidates_token_count': getattr(response.usage_metadata, 'candidates_token_count', 0),
                        'total_token_count': getattr(response.usage_metadata, 'total_token_count', 0)
                    },
                    'attempt': attempt + 1,
                    'llm_input': prompt  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç
                }
                
                logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç {model_name} {f'({agent_name})' if agent_name else ''} –∑–∞ {attempt + 1} –ø–æ–ø—ã—Ç–∫—É, —Ç–æ–∫–µ–Ω–æ–≤: {result['usage_metadata']['total_token_count']}")
                return result
                
            except Exception as e:
                error_str = str(e)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ 429 –æ—à–∏–±–∫—É (rate limiting)
                if "429" in error_str or "quota" in error_str.lower() or "rate" in error_str.lower():
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –∏–∑ –æ—à–∏–±–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                    retry_delay = self._extract_retry_delay(error_str)
                    if retry_delay is None:
                        # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π backoff: 2^attempt —Å–µ–∫—É–Ω–¥
                        retry_delay = 2 ** attempt
                    
                    if attempt < max_retries - 1:  # –ù–µ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞
                        logger.warning(f"‚è∞ 429 Rate Limit! –ñ–¥–µ–º {retry_delay} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –ø–æ–ø—ã—Ç–∫–æ–π {attempt + 2}...")
                        await asyncio.sleep(retry_delay)
                        continue
                    else:
                        logger.error(f"‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ ({max_retries}) –¥–ª—è rate limit")
                
                # –î—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏ –∏–ª–∏ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Gemini (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {e}")
                
                if attempt == max_retries - 1:  # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞
                    return {
                        'success': False,
                        'error': error_str,
                        'response': None,
                        'attempts': max_retries
                    }
                
                # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –æ–±—ã—á–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
                await asyncio.sleep(1)
        
        # –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –¥–æ–ª–∂–Ω–æ –¥–æ–π—Ç–∏ —Å—é–¥–∞, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
        return {
            'success': False,
            'error': "Unexpected error: exhausted all retries",
            'response': None
        }
    
    def _extract_retry_delay(self, error_str: str) -> Optional[int]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—É—é –∑–∞–¥–µ—Ä–∂–∫—É –∏–∑ –æ—à–∏–±–∫–∏ 429"""
        import re
        
        # –ò—â–µ–º "retry_delay {\n  seconds: 44\n}"
        match = re.search(r'retry_delay\s*\{\s*seconds:\s*(\d+)', error_str)
        if match:
            return int(match.group(1))
        
        return None
    
    def _clean_json_from_markdown(self, text: str) -> str:
        """
        –û—á–∏—â–∞–µ—Ç JSON –æ—Ç markdown –æ–±–µ—Ä—Ç–∫–∏, –∫–æ—Ç–æ—Ä—É—é —á–∞—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ—Ç Gemini
        
        Args:
            text: –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini
            
        Returns:
            –û—á–∏—â–µ–Ω–Ω—ã–π JSON —Ç–µ–∫—Å—Ç
        """
        import re
        
        # –£–¥–∞–ª—è–µ–º markdown –±–ª–æ–∫–∏ —Ç–∏–ø–∞ ```json ... ```
        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω: ```json –∏–ª–∏ ``` –≤ –Ω–∞—á–∞–ª–µ, –∑–∞—Ç–µ–º JSON, –∑–∞—Ç–µ–º ``` –≤ –∫–æ–Ω—Ü–µ
        markdown_pattern = r'^```(?:json)?\s*\n?(.*?)\n?```\s*$'
        match = re.search(markdown_pattern, text.strip(), re.DOTALL | re.IGNORECASE)
        
        if match:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –º–µ–∂–¥—É ```
            cleaned = match.group(1).strip()
            return cleaned
        
        # –ï—Å–ª–∏ markdown –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        return text.strip()
    
    def _try_fix_broken_json(self, text: str):
        """
        –ü–∞—Ä—Å–∏–Ω–≥ JSON —Å –æ—á–∏—Å—Ç–∫–æ–π —É–ø—Ä–∞–≤–ª—è—é—â–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤

        Args:
            text: JSON —Ç–µ–∫—Å—Ç

        Returns:
            –†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç JSON
        """
        import re

        # –£–¥–∞–ª—è–µ–º —É–ø—Ä–∞–≤–ª—è—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –ª–æ–º–∞—é—Ç JSON
        # –†–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–µ —É–ø—Ä–∞–≤–ª—è—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã: \n, \r, \t, \", \\
        cleaned_text = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', text)

        # –ü—ã—Ç–∞–µ–º—Å—è –ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ –µ—Å—Ç—å
        try:
            return json.loads(cleaned_text)
        except json.JSONDecodeError:
            # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è, –ø—Ä–æ–±—É–µ–º –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –æ—á–∏—Å—Ç–∫—É
            # –ó–∞–º–µ–Ω—è–µ–º –Ω–µ—ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–∞ \\n
            # –¢–æ–ª—å–∫–æ –≤–Ω—É—Ç—Ä–∏ –∑–Ω–∞—á–µ–Ω–∏–π, –∞ –Ω–µ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ JSON
            cleaned_text = re.sub(r'(?<="[^"]*)\n(?=[^"]*"[,}\]])', '\\\\n', cleaned_text)
            return json.loads(cleaned_text)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∏–µ–Ω—Ç–∞
gemini_client = GeminiClient()

================================================================================

## –§–ê–ô–õ: RECITATION_ERROR_REPORT/new_agent_runner.py
------------------------------------------------------------
"""
–ù–æ–≤—ã–π runner –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ HerZog v3.0
–ó–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–µ –∞–≥–µ–Ω—Ç—ã: work_packager, works_to_packages, counter, scheduler_and_staffer
"""

import json
import logging
import os
import asyncio
from typing import Dict, Any, Optional

# –ò–º–ø–æ—Ä—Ç –Ω–∞—à–∏—Ö –Ω–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
from .work_packager import run_work_packager
from .works_to_packages import run_works_to_packages
from .counter import run_counter
from .scheduler_and_staffer import run_scheduler_and_staffer

logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
NEW_AGENTS = {
    "work_packager": {
        "name": "–ê—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä - —Å–æ–∑–¥–∞–Ω–∏–µ –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç",
        "function": run_work_packager,
        "description": "–°–æ–∑–¥–∞–µ—Ç —É–∫—Ä—É–ø–Ω–µ–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç –∏–∑ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–∞–±–æ—Ç"
    },
    "works_to_packages": {
        "name": "–†–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–ª—å - –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ —Ä–∞–±–æ—Ç –∫ –ø–∞–∫–µ—Ç–∞–º", 
        "function": run_works_to_packages,
        "description": "–†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞–∂–¥—É—é —Ä–∞–±–æ—Ç—É –ø–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º –ø–∞–∫–µ—Ç–∞–º"
    },
    "counter": {
        "name": "–°–º–µ—Ç—á–∏–∫ - —Ä–∞—Å—á–µ—Ç –æ–±—ä–µ–º–æ–≤",
        "function": run_counter,
        "description": "–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–º—ã –¥–ª—è –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç"
    },
    "scheduler_and_staffer": {
        "name": "–°—É–ø–µ—Ä-–ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ - –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω",
        "function": run_scheduler_and_staffer,
        "description": "–°–æ–∑–¥–∞–µ—Ç –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∞"
    }
}

async def run_new_agent(agent_name: str, project_path: str) -> Dict[str, Any]:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–¥–∏–Ω –∏–∑ –Ω–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
    
    Args:
        agent_name: –ò–º—è –∞–≥–µ–Ω—Ç–∞ (work_packager, works_to_packages, counter, scheduler_and_staffer)
        project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞
    """
    
    if agent_name not in NEW_AGENTS:
        return {
            'success': False,
            'error': f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞–≥–µ–Ω—Ç: {agent_name}",
            'available_agents': list(NEW_AGENTS.keys())
        }
    
    agent_config = NEW_AGENTS[agent_name]
    
    logger.info(f"ü§ñ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞: {agent_config['name']}")
    logger.info(f"üìù {agent_config['description']}")
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≥–µ–Ω—Ç–∞
        result = await agent_config['function'](project_path)
        
        if result.get('success'):
            logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç {agent_name} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        else:
            logger.error(f"‚ùå –ê–≥–µ–Ω—Ç {agent_name} –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: {result.get('error')}")
        
        return result
        
    except Exception as e:
        error_result = {
            'success': False,
            'error': str(e),
            'agent': agent_name
        }
        logger.error(f"üí• –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –≤ –∞–≥–µ–Ω—Ç–µ {agent_name}: {e}")
        return error_result

async def run_new_pipeline(project_path: str, start_from: str = "work_packager") -> Dict[str, Any]:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –Ω–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
    
    Args:
        project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        start_from: –° –∫–∞–∫–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ –Ω–∞—á–∞—Ç—å
        
    Returns:
        –û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞–π–ø–ª–∞–π–Ω–∞
    """
    
    # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–æ–≤
    pipeline_sequence = [
        "work_packager",
        "works_to_packages", 
        "counter",
        "scheduler_and_staffer"
    ]
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å –∫–∞–∫–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ –Ω–∞—á–∏–Ω–∞—Ç—å
    try:
        start_index = pipeline_sequence.index(start_from)
        agents_to_run = pipeline_sequence[start_index:]
    except ValueError:
        return {
            'success': False,
            'error': f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å—Ç–∞—Ä—Ç–æ–≤—ã–π –∞–≥–µ–Ω—Ç: {start_from}",
            'available_agents': pipeline_sequence
        }
    
    logger.info(f"üèóÔ∏è –ó–∞–ø—É—Å–∫ –Ω–æ–≤–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ HerZog v3.0")
    logger.info(f"üìÇ –ü—Ä–æ–µ–∫—Ç: {project_path}")
    logger.info(f"üéØ –ê–≥–µ–Ω—Ç—ã: {' ‚Üí '.join(agents_to_run)}")
    
    pipeline_result = {
        'success': False,
        'project_path': project_path,
        'agents_completed': [],
        'agents_failed': [],
        'start_from': start_from,
        'total_agents': len(agents_to_run),
        'results': {}
    }
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≥–µ–Ω—Ç–æ–≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
    for agent_name in agents_to_run:
        logger.info(f"\n{'='*50}")
        logger.info(f"üöÄ –≠–¢–ê–ü: {agent_name.upper()}")
        logger.info(f"{'='*50}")
        
        agent_result = await run_new_agent(agent_name, project_path)
        pipeline_result['results'][agent_name] = agent_result
        
        if agent_result.get('success'):
            pipeline_result['agents_completed'].append(agent_name)
            logger.info(f"‚úÖ –≠—Ç–∞–ø {agent_name} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        else:
            pipeline_result['agents_failed'].append(agent_name)
            logger.error(f"‚ùå –≠—Ç–∞–ø {agent_name} –ø—Ä–æ–≤–∞–ª–µ–Ω: {agent_result.get('error')}")
            
            # –ü—Ä–µ—Ä—ã–≤–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω –ø—Ä–∏ –æ—à–∏–±–∫–µ
            pipeline_result['error'] = f"–ü–∞–π–ø–ª–∞–π–Ω –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ —ç—Ç–∞–ø–µ {agent_name}: {agent_result.get('error')}"
            return pipeline_result
    
    # –ï—Å–ª–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞ - –≤—Å–µ –∞–≥–µ–Ω—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ
    pipeline_result['success'] = True
    logger.info(f"\nüéâ –ü–ê–ô–ü–õ–ê–ô–ù –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
    logger.info(f"‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–æ –∞–≥–µ–Ω—Ç–æ–≤: {len(pipeline_result['agents_completed'])}")
    
    return pipeline_result

def run_new_agent_sync(agent_name: str, project_path: str) -> bool:
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–≥–µ–Ω—Ç–∞ (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ç–∞—Ä—ã–º –∫–æ–¥–æ–º)
    
    Args:
        agent_name: –ò–º—è –∞–≥–µ–Ω—Ç–∞
        project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        
    Returns:
        True –µ—Å–ª–∏ –∞–≥–µ–Ω—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ
    """
    try:
        result = asyncio.run(run_new_agent(agent_name, project_path))
        return result.get('success', False)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±–µ—Ä—Ç–∫–µ –¥–ª—è {agent_name}: {e}")
        return False

def get_new_agent_info(agent_name: Optional[str] = None) -> Dict[str, Any]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–∞—Ö
    
    Args:
        agent_name: –ò–º—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ –∏–ª–∏ None –¥–ª—è –≤—Å–µ—Ö
        
    Returns:
        –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–≥–µ–Ω—Ç–µ(–∞—Ö)
    """
    if agent_name:
        if agent_name in NEW_AGENTS:
            return NEW_AGENTS[agent_name]
        else:
            return {'error': f'–ê–≥–µ–Ω—Ç {agent_name} –Ω–µ –Ω–∞–π–¥–µ–Ω'}
    else:
        return NEW_AGENTS

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ runner'–∞
    import sys
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    if len(sys.argv) >= 3:
        # –ó–∞–ø—É—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞: python new_agent_runner.py work_packager /path/to/project
        agent_name = sys.argv[1]
        project_path = sys.argv[2]
        
        print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞: {agent_name}")
        print(f"üìÇ –ü—Ä–æ–µ–∫—Ç: {project_path}")
        
        result = asyncio.run(run_new_agent(agent_name, project_path))
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
    elif len(sys.argv) == 2:
        # –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞: python new_agent_runner.py /path/to/project  
        project_path = sys.argv[1]
        
        print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞")
        print(f"üìÇ –ü—Ä–æ–µ–∫—Ç: {project_path}")
        
        result = asyncio.run(run_new_pipeline(project_path))
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
    else:
        # –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–≥–µ–Ω—Ç–∞—Ö
        print("ü§ñ –ù–æ–≤—ã–µ –∞–≥–µ–Ω—Ç—ã HerZog v3.0:")
        print("=" * 50)
        
        for agent_name, config in NEW_AGENTS.items():
            print(f"üì¶ {agent_name}:")
            print(f"   –ù–∞–∑–≤–∞–Ω–∏–µ: {config['name']}")
            print(f"   –û–ø–∏—Å–∞–Ω–∏–µ: {config['description']}")
            print()
        
        print("üí° –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
        print("   python new_agent_runner.py work_packager /path/to/project  # –æ–¥–∏–Ω –∞–≥–µ–Ω—Ç")
        print("   python new_agent_runner.py /path/to/project               # –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω")

================================================================================

## –§–ê–ô–õ: RECITATION_ERROR_REPORT/prompt_analysis.txt
------------------------------------------------------------

# –ê–ù–ê–õ–ò–ó –ü–†–û–ú–ü–¢–ê

–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: 1420 —Å–∏–º–≤–æ–ª–æ–≤
–°—Ç—Ä–æ–∫–∏: 39

–ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–´–ï –ü–†–û–ë–õ–ï–ú–´:
- –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä (20364 —Å–∏–º–≤–æ–ª–∞)
- –í–æ–∑–º–æ–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç —à–∞–±–ª–æ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞
- –ú–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ø–∏—Ä–∞–π—Ç-–∫–æ–Ω—Ç–µ–Ω—Ç

–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:
1. –°–æ–∫—Ä–∞—Ç–∏—Ç—å –ø—Ä–æ–º–ø—Ç –Ω–∞ 50%
2. –ó–∞–º–µ–Ω–∏—Ç—å —à–∞–±–ª–æ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏
3. –£–±—Ä–∞—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
4. –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–µ–∫—Ç–∞


================================================================================

## –§–ê–ô–õ: RECITATION_ERROR_REPORT/scheduler_and_staffer.py
------------------------------------------------------------
"""
–ê–≥–µ–Ω—Ç 4: "–°—É–ø–µ—Ä-–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫" (scheduler_and_staffer.py)
–°–æ–∑–¥–∞–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç: —Å—Ä–æ–∫–∏, –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª—é–¥–µ–π
"""

import json
import os
import asyncio
import logging
import math
import uuid
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from collections import defaultdict

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –Ω–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã
from ..shared.gemini_client import gemini_client
from ..shared.truth_initializer import update_pipeline_status

logger = logging.getLogger(__name__)

class SchedulerAndStaffer:
    """
    –ê–≥–µ–Ω—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∞
    –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–æ–±–ª—é–¥–µ–Ω–∏–µ –ª–∏–º–∏—Ç–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ä–∞–±–æ—á–∏—Ö
    """
    
    def __init__(self, batch_size: int = 12):
        self.agent_name = "scheduler_and_staffer"
        self.batch_size = batch_size

    
    async def process(self, project_path: str) -> Dict[str, Any]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ —Å–æ–∑–¥–∞–Ω–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∞
        
        Args:
            project_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        try:
            logger.info(f"üîÑ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ {self.agent_name}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º true.json
            truth_path = os.path.join(project_path, "true.json")
            if not os.path.exists(truth_path):
                raise FileNotFoundError(f"–§–∞–π–ª true.json –Ω–µ –Ω–∞–π–¥–µ–Ω: {truth_path}")
            
            with open(truth_path, 'r', encoding='utf-8') as f:
                truth_data = json.load(f)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∞–≥–µ–Ω—Ç–∞
            update_pipeline_status(truth_path, self.agent_name, "in_progress")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞
            agent_folder = os.path.join(project_path, "7_scheduler_and_staffer")
            os.makedirs(agent_folder, exist_ok=True)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            work_packages = truth_data.get('results', {}).get('work_packages', [])
            timeline_blocks = truth_data.get('timeline_blocks', [])
            project_inputs = truth_data.get('project_inputs', {})
            
            if not work_packages:
                raise Exception("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç —Å —Ä–∞—Å—á–µ—Ç–∞–º–∏. –°–Ω–∞—á–∞–ª–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–ø—É—â–µ–Ω counter")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–∞–∫–µ—Ç—ã –∏–º–µ—é—Ç volume_data
            packages_with_calcs = [p for p in work_packages if 'volume_data' in p]
            if not packages_with_calcs:
                raise Exception("–ü–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç –Ω–µ –∏–º–µ—é—Ç volume_data. –°–Ω–∞—á–∞–ª–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–ø—É—â–µ–Ω counter")
            
            logger.info(f"üìä –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –¥–ª—è {len(packages_with_calcs)} –ø–∞–∫–µ—Ç–æ–≤")
            logger.info(f"üìÖ –í—Ä–µ–º–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏: {len(timeline_blocks)} –Ω–µ–¥–µ–ª—å")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
            workforce_range = project_inputs.get('workforce_range', {'min': 10, 'max': 20})
            user_directives = project_inputs.get('agent_directives', {})
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∏—Ä–µ–∫—Ç–∏–≤—ã strategist + foreman –≤ –æ–¥–Ω—É
            scheduler_and_staffer_directive = (
                user_directives.get('scheduler_and_staffer') or
                f"{user_directives.get('strategist', '')} {user_directives.get('foreman', '')}".strip()
            )
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç
            prompt_template = self._load_prompt()
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –ø–∞–∫–µ—Ç–∞—Ö –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
            compact_packages = self._prepare_compact_packages(packages_with_calcs, project_path)

            # –†–∞–∑–±–∏–≤–∞–µ–º –ø–∞–∫–µ—Ç—ã –Ω–∞ –±–∞—Ç—á–∏ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
            scheduled_packages = []
            total_batches = math.ceil(len(compact_packages) / self.batch_size)

            for batch_num in range(total_batches):
                start_idx = batch_num * self.batch_size
                end_idx = min((batch_num + 1) * self.batch_size, len(compact_packages))
                batch_packages = compact_packages[start_idx:end_idx]

                logger.info(f"üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ {batch_num + 1}/{total_batches} ({len(batch_packages)} –ø–∞–∫–µ—Ç–æ–≤)")

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á
                batch_result = await self._process_batch(
                    batch_packages, timeline_blocks, workforce_range,
                    scheduler_and_staffer_directive, prompt_template,
                    batch_num, agent_folder
                )

                scheduled_packages.extend(batch_result)

            logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(scheduled_packages)} –ø–∞–∫–µ—Ç–æ–≤ –≤ {total_batches} –±–∞—Ç—á–∞—Ö")
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ –ø–µ—Ä—Å–æ–Ω–∞–ª—É
            validation_result = self._validate_workforce_constraints(
                scheduled_packages, timeline_blocks, workforce_range
            )
            
            if not validation_result['valid']:
                logger.warning(f"‚ö†Ô∏è –ù–∞—Ä—É—à–µ–Ω–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ –ø–µ—Ä—Å–æ–Ω–∞–ª—É: {validation_result['violations']}")
                # –ü—ã—Ç–∞–µ–º—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–∏—Ç—å
                scheduled_packages = self._fix_workforce_constraints(
                    scheduled_packages, timeline_blocks, workforce_range
                )
            
            # –û–±–Ω–æ–≤–ª—è–µ–º true.json —Å —Ñ–∏–Ω–∞–ª—å–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            self._update_truth_data(truth_data, scheduled_packages, truth_path)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ
            update_pipeline_status(truth_path, self.agent_name, "completed")
            
            logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç {self.agent_name} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
            logger.info(f"üìä –°–æ–∑–¥–∞–Ω –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω –¥–ª—è {len(scheduled_packages)} –ø–∞–∫–µ—Ç–æ–≤")
            
            return {
                'success': True,
                'packages_scheduled': len(scheduled_packages),
                'workforce_valid': validation_result['valid'],
                'agent': self.agent_name
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≥–µ–Ω—Ç–∞ {self.agent_name}: {e}")
            # –ü—ã—Ç–∞–µ–º—Å—è –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –Ω–∞ –æ—à–∏–±–∫—É
            try:
                update_pipeline_status(truth_path, self.agent_name, "error")
            except:
                pass
            
            return {
                'success': False,
                'error': str(e),
                'agent': self.agent_name
            }
    
    def _load_prompt(self) -> str:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ–º–ø—Ç-—à–∞–±–ª–æ–Ω –¥–ª—è –∞–≥–µ–Ω—Ç–∞
        """
        prompt_path = os.path.join(
            os.path.dirname(__file__), "..", "prompts", "scheduler_and_staffer_prompt.txt"
        )
        
        try:
            with open(prompt_path, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            logger.warning(f"–ü—Ä–æ–º–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {prompt_path}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π")
            return self._get_default_prompt()
    
    def _get_default_prompt(self) -> str:
        """
        –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç, –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        return """
# –†–û–õ–¨
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–º—É –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é.

# –ó–ê–î–ê–ß–ê
–°–æ–∑–¥–∞–π —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏–≤ –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç –ø–æ –Ω–µ–¥–µ–ª—è–º –∏ –Ω–∞–∑–Ω–∞—á–∏–≤ –ø–µ—Ä—Å–æ–Ω–∞–ª.

# –í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï
–í –∑–∞–ø—Ä–æ—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Ç—ã –ø–æ–ª—É—á–∏—à—å JSON-–æ–±—ä–µ–∫—Ç —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –∫–ª—é—á–∞–º–∏:
- "work_packages": –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç —Å –∏—Ö —Å–æ—Å—Ç–∞–≤–æ–º
- "timeline_blocks": –¥–æ—Å—Ç—É–ø–Ω—ã–µ –Ω–µ–¥–µ–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞
- "workforce_range": –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ –ø–µ—Ä—Å–æ–Ω–∞–ª—É
- "user_directive": –¥–∏—Ä–µ–∫—Ç–∏–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

# –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø
1. **–õ–∏–º–∏—Ç—ã –ø–µ—Ä—Å–æ–Ω–∞–ª–∞ (—Å—É–º–º–∞ –ø–æ –≤—Å–µ–º –ø–∞–∫–µ—Ç–∞–º –≤ –Ω–µ–¥–µ–ª—é):** –í –ø—Ä–µ–¥–µ–ª–∞—Ö –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ workforce_range.
2. **–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** –î–µ–º–æ–Ω—Ç–∞–∂ -> –ö–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ -> –ò–Ω–∂–µ–Ω–µ—Ä–Ω—ã–µ —Å–µ—Ç–∏ -> –û—Ç–¥–µ–ª–∫–∞.

# –§–û–†–ú–ê–¢ –í–´–í–û–î–ê (–°–¢–†–û–ì–û JSON)
{
    "scheduled_packages": [
        {
            "package_id": "pkg_001",
            "schedule_blocks": [1, 2],
            "progress_per_block": { "1": 60, "2": 40 },
            "staffing_per_block": { "1": 10, "2": 8 },
            "scheduling_reasoning": {
                "why_these_weeks": "–ö—Ä–∞—Ç–∫–æ.",
                "why_this_duration": "–ö—Ä–∞—Ç–∫–æ.",
                "why_this_sequence": "–ö—Ä–∞—Ç–∫–æ.",
                "why_this_staffing": "–ö—Ä–∞—Ç–∫–æ."
            }
        }
    ]
}

# –ü–†–û–í–ï–†–ö–ò –ü–ï–†–ï–î –û–¢–í–ï–¢–û–ú
1. **–õ–∏–º–∏—Ç—ã:** –°—É–º–º–∞ `staffing_per_block` –¥–ª—è –ö–ê–ñ–î–û–ô –Ω–µ–¥–µ–ª–∏ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ workforce_range.
2. **100%:** –°—É–º–º–∞ `progress_per_block` –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞–∫–µ—Ç–∞ —Ä–∞–≤–Ω–∞ 100.
3. **–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:** –ü–æ–ª—è `scheduling_reasoning` –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã.
"""
    
    def _add_salt_to_prompt(self, prompt: str) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—É—é —Å–æ–ª—å –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è RECITATION."""
        unique_id = str(uuid.uuid4())[:8]
        session_id = str(uuid.uuid4())[:12]
        prefix = f"# TASK_ID: {unique_id} | SESSION: {session_id} | MODE: STRICT_JSON_OUTPUT\n"
        prefix += f"# ANTI_RECITATION_SALT: {session_id}{unique_id}\n"
        suffix = f"\n# END_TASK: {unique_id} | VERIFY: {session_id}"
        return prefix + prompt + suffix

    def _format_prompt(self, input_data: Dict, prompt_template: str) -> Tuple[str, str]:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–º–ø—Ç —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ system_instruction –∏ user_prompt

        Returns:
            Tuple[str, str]: (system_instruction, user_prompt)
        """
        # System instruction - —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç –±–µ–∑ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤
        system_instruction = prompt_template

        # User prompt - JSON —Å –¥–∞–Ω–Ω—ã–º–∏ + –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–ª–µ–Ω–∏–µ –ø—Ä–æ—Ç–∏–≤ RECITATION
        anti_recitation_id = str(uuid.uuid4())[:10]
        user_prompt_data = {
            '_meta': {
                'task_type': 'schedule_planning',
                'session_id': anti_recitation_id,
                'timestamp': datetime.now().isoformat()
            },
            'work_packages': input_data['work_packages'],
            'timeline_blocks': input_data['timeline_blocks'],
            'workforce_range': input_data['workforce_range'],
            'user_directive': input_data['user_directive']
        }
        user_prompt = json.dumps(user_prompt_data, ensure_ascii=False, indent=2)

        return system_instruction, user_prompt

    async def _process_batch(self, batch_packages: List[Dict], timeline_blocks: List[Dict],
                           workforce_range: Dict, user_directive: str, prompt_template: str,
                           batch_num: int, agent_folder: str) -> List[Dict]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –±–∞—Ç—á –ø–∞–∫–µ—Ç–æ–≤ –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±–∞—Ç—á–∞
        input_data = {
            'work_packages': batch_packages,
            'timeline_blocks': timeline_blocks,
            'workforce_range': workforce_range,
            'user_directive': user_directive
        }

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è LLM
        system_instruction, user_prompt = self._format_prompt(input_data, prompt_template)

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–ª—å –∫ —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è RECITATION
        salted_system_instruction = self._add_salt_to_prompt(system_instruction)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (–∫–∞–∫ –≤ work_packager)
        debug_data = {
            "system_instruction": salted_system_instruction,
            "user_prompt": user_prompt
        }
        batch_input_path = os.path.join(agent_folder, f"batch_{batch_num+1:03d}_input.json")
        with open(batch_input_path, 'w', encoding='utf-8') as f:
            json.dump(debug_data, f, ensure_ascii=False, indent=2)

        # –í—ã–∑—ã–≤–∞–µ–º Gemini API —Å system_instruction –∏ user_prompt
        logger.info(f"üì° –û—Ç–ø—Ä–∞–≤–∫–∞ –±–∞—Ç—á–∞ {batch_num + 1} –≤ Gemini (scheduler_and_staffer -> gemini-2.5-pro)")
        gemini_response = await gemini_client.generate_response(
            prompt=user_prompt,
            system_instruction=salted_system_instruction,
            agent_name="scheduler_and_staffer"
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –æ—Ç LLM
        batch_response_path = os.path.join(agent_folder, f"batch_{batch_num+1:03d}_response.json")
        with open(batch_response_path, 'w', encoding='utf-8') as f:
            json.dump(gemini_response, f, ensure_ascii=False, indent=2)

        if not gemini_response.get('success', False):
            logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê Gemini API –¥–ª—è –±–∞—Ç—á–∞ {batch_num + 1}: {gemini_response.get('error')}")
            raise Exception(f"Gemini API –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –±–∞—Ç—á {batch_num + 1}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–æ–º–ø—Ç –∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ.")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç
        scheduled_batch = self._process_scheduling_response(
            gemini_response['response'], batch_packages, timeline_blocks, workforce_range
        )

        return scheduled_batch


    def _process_scheduling_response(self, llm_response: Any, original_packages: List[Dict],
                                   timeline_blocks: List[Dict], workforce_range: Dict) -> List[Dict]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç LLM —Å –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–º –ø–ª–∞–Ω–æ–º
        """
        try:
            if isinstance(llm_response, str):
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–ø—Ä—è–º—É—é –ø–∞—Ä—Å–∏—Ç—å
                response_data = json.loads(llm_response)
            else:
                response_data = llm_response
            
            scheduled_packages = response_data.get('scheduled_packages', [])
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∏ –æ–±–æ–≥–∞—â–∞–µ–º –∫–∞–∂–¥—ã–π –ø–∞–∫–µ—Ç
            validated_packages = []
            for pkg in scheduled_packages:
                validated_pkg = self._validate_and_fix_package_schedule(pkg, timeline_blocks)
                validated_packages.append(validated_pkg)
            
            logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(validated_packages)} –ø–∞–∫–µ—Ç–æ–≤ –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM")
            return validated_packages
            
        except (json.JSONDecodeError, KeyError, AttributeError) as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞: {e}")
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            if isinstance(llm_response, str):
                response_length = len(llm_response)
                lines_count = llm_response.count('\n')
                logger.error(f"üìè –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {response_length} —Å–∏–º–≤–æ–ª–æ–≤, —Å—Ç—Ä–æ–∫: {lines_count}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                tail = llm_response[-200:] if len(llm_response) > 200 else llm_response
                logger.error(f"üìÑ –ü–æ—Å–ª–µ–¥–Ω–∏–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞: ...{tail}")
                
                # –ü—Ä–æ–±—É–µ–º –ø–æ—á–∏–Ω–∏—Ç—å –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π JSON
                fixed_response = self._try_fix_truncated_json(llm_response)
                if fixed_response:
                    try:
                        response_data = json.loads(fixed_response)
                        scheduled_packages = response_data.get('scheduled_packages', [])
                        
                        validated_packages = []
                        for pkg in scheduled_packages:
                            validated_pkg = self._validate_and_fix_package_schedule(pkg, timeline_blocks)
                            validated_packages.append(validated_pkg)
                        
                        logger.info(f"üîß –£—Å–ø–µ—à–Ω–æ –ø–æ—á–∏–Ω–∏–ª–∏ JSON –∏ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∏ {len(validated_packages)} –ø–∞–∫–µ—Ç–æ–≤")
                        return validated_packages
                        
                    except Exception as fix_error:
                        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—á–∏–Ω–∏—Ç—å JSON: {fix_error}")
            
            logger.warning(f"üîÑ –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ fallback –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è {len(original_packages)} –ø–∞–∫–µ—Ç–æ–≤")
            return self._create_fallback_schedule(original_packages, timeline_blocks, workforce_range)
    
    def _try_fix_truncated_json(self, broken_json: str) -> Optional[str]:
        """
        –ü—ã—Ç–∞–µ—Ç—Å—è –ø–æ—á–∏–Ω–∏—Ç—å –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π JSON –æ—Ç–≤–µ—Ç –æ—Ç LLM
        """
        try:
            # –û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–æ—á–∏–Ω–∫–∏:
            
            # 1. –£–±–∏—Ä–∞–µ–º –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –∫–æ–Ω—Ü–µ
            lines = broken_json.split('\n')
            
            # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É —Å —Ñ–∏–≥—É—Ä–Ω–æ–π —Å–∫–æ–±–∫–æ–π –∏–ª–∏ –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ–π —Å–∫–æ–±–∫–æ–π
            fixed_lines = []
            for i, line in enumerate(lines):
                # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –∫–ª—é—á –±–µ–∑ –∑–Ω–∞—á–µ–Ω–∏—è - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è
                if '"unit":' in line and line.strip().endswith('"unit":'):
                    logger.info("üîß –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ —Å 'unit:', –æ–±—Ä–µ–∑–∞–µ–º")
                    break
                    
                # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–µ–ø–æ–ª–Ω–∞—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–µ –∑–∞–∫—Ä—ã—Ç–∞ –∫–∞–≤—ã—á–∫–∞) - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è  
                if line.strip() and not line.strip().endswith((',', '{', '}', '[', ']', '"')):
                    logger.info(f"üîß –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞: '{line.strip()}', –æ–±—Ä–µ–∑–∞–µ–º")
                    break
                    
                fixed_lines.append(line)
            
            # 2. –ù–∞—Ö–æ–¥–∏–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –º–µ—Å—Ç–æ –¥–ª—è –∑–∞–∫—Ä—ã—Ç–∏—è JSON
            fixed_content = '\n'.join(fixed_lines)
            
            # 3. –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Ç–∫—Ä—ã—Ç—ã–µ —Å–∫–æ–±–∫–∏ –∏ –∑–∞–∫—Ä—ã–≤–∞–µ–º –∏—Ö
            open_braces = fixed_content.count('{') - fixed_content.count('}')
            open_brackets = fixed_content.count('[') - fixed_content.count(']')
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–µ —Å–∫–æ–±–∫–∏
            closing = ''
            for _ in range(open_brackets):
                closing += '\n    ]'
            for _ in range(open_braces):
                closing += '\n  }'
            
            fixed_json = fixed_content + closing
            
            # 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–Ω—ã–π
            json.loads(fixed_json)  # –ï—Å–ª–∏ –Ω–µ –≤–∞–ª–∏–¥–Ω—ã–π - exception
            
            logger.info("üîß JSON —É—Å–ø–µ—à–Ω–æ –ø–æ—á–∏–Ω–µ–Ω")
            return fixed_json
            
        except Exception as e:
            logger.error(f"üîß –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –ø–æ—á–∏–Ω–∏—Ç—å JSON: {e}")
            return None
    
    def _validate_and_fix_package_schedule(self, package: Dict, timeline_blocks: List[Dict]) -> Dict:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω –¥–ª—è –ø–∞–∫–µ—Ç–∞
        """
        package_id = package.get('package_id', 'unknown')
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è schedule_blocks
        schedule_blocks = package.get('schedule_blocks', [])
        max_week = len(timeline_blocks)
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è schedule_blocks
        valid_blocks = []
        for week in schedule_blocks:
            try:
                week_num = int(week) if isinstance(week, str) else week
                if 1 <= week_num <= max_week:
                    valid_blocks.append(week_num)
            except (ValueError, TypeError):
                continue
        schedule_blocks = valid_blocks
        
        if not schedule_blocks:
            schedule_blocks = [1]  # fallback
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è progress_per_block
        progress_per_block = package.get('progress_per_block', {})
        total_progress = 0
        
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫–ª—é—á–∏ –∫ —Å—Ç—Ä–æ–∫–æ–≤–æ–º—É –≤–∏–¥—É –∏ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        normalized_progress = {}
        for week in schedule_blocks:
            week_str = str(week)
            progress = progress_per_block.get(week_str, progress_per_block.get(week, 0))
            normalized_progress[week_str] = max(0, min(100, progress))
            total_progress += normalized_progress[week_str]
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫ 100%
        if total_progress != 100 and total_progress > 0:
            scale_factor = 100.0 / total_progress
            for week_str in normalized_progress:
                normalized_progress[week_str] = round(normalized_progress[week_str] * scale_factor)
        elif total_progress == 0:
            # –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
            progress_per_week = round(100.0 / len(schedule_blocks))
            for week in schedule_blocks:
                normalized_progress[str(week)] = progress_per_week
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è staffing_per_block
        staffing_per_block = package.get('staffing_per_block', {})
        normalized_staffing = {}
        
        for week in schedule_blocks:
            week_str = str(week)
            staff = staffing_per_block.get(week_str, staffing_per_block.get(week, 1))
            normalized_staffing[week_str] = max(1, min(20, staff))  # –û—Ç 1 –¥–æ 20 —á–µ–ª–æ–≤–µ–∫
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        scheduling_reasoning = package.get('scheduling_reasoning', {})
        if not scheduling_reasoning:
            # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
            scheduling_reasoning = {
                'why_these_weeks': f'–ü–∞–∫–µ—Ç –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω –Ω–∞ –Ω–µ–¥–µ–ª–∏ {schedule_blocks} –ø–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏',
                'why_this_duration': f'–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å {len(schedule_blocks)} –Ω–µ–¥–µ–ª—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–±—ä–µ–º—É —Ä–∞–±–æ—Ç',
                'why_this_sequence': '–†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ –Ω–µ–¥–µ–ª—è–º',
                'why_this_staffing': f'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä—Å–æ–Ω–∞–ª–∞ –æ—Ç {min(normalized_staffing.values())} –¥–æ {max(normalized_staffing.values())} —á–µ–ª–æ–≤–µ–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞ —Ä–∞–±–æ—Ç'
            }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞–∫–µ—Ç
        package['schedule_blocks'] = schedule_blocks
        package['progress_per_block'] = normalized_progress
        package['staffing_per_block'] = normalized_staffing
        package['scheduling_reasoning'] = scheduling_reasoning
        
        return package
    
    def _validate_workforce_constraints(self, packages: List[Dict], 
                                      timeline_blocks: List[Dict], workforce_range: Dict) -> Dict:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–±–ª—é–¥–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ –ø–µ—Ä—Å–æ–Ω–∞–ª—É
        """
        max_workers = workforce_range['max']
        violations = []
        weekly_totals = {}
        
        # –°—á–∏—Ç–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª—é–¥–µ–π –ø–æ –Ω–µ–¥–µ–ª—è–º
        for week_num in range(1, len(timeline_blocks) + 1):
            week_str = str(week_num)
            total_workers = 0
            
            for package in packages:
                staffing = package.get('staffing_per_block', {})
                if week_str in staffing:
                    total_workers += staffing[week_str]
            
            weekly_totals[week_str] = total_workers
            
            if total_workers > max_workers:
                violations.append(f"–ù–µ–¥–µ–ª—è {week_num}: {total_workers} > {max_workers}")
        
        return {
            'valid': len(violations) == 0,
            'violations': violations,
            'weekly_totals': weekly_totals
        }
    
    def _fix_workforce_constraints(self, packages: List[Dict], 
                                 timeline_blocks: List[Dict], workforce_range: Dict) -> List[Dict]:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–∞—Ä—É—à–µ–Ω–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ –ø–µ—Ä—Å–æ–Ω–∞–ª—É
        """
        max_workers = workforce_range['max']
        
        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞: –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —É–º–µ–Ω—å—à–∞–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª –≤ –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –Ω–µ–¥–µ–ª–∏
        for week_num in range(1, len(timeline_blocks) + 1):
            week_str = str(week_num)
            
            # –°—á–∏—Ç–∞–µ–º —Ç–µ–∫—É—â–∏–π –ø–µ—Ä—Å–æ–Ω–∞–ª –≤ —ç—Ç—É –Ω–µ–¥–µ–ª—é
            current_workers = 0
            week_packages = []
            
            for package in packages:
                staffing = package.get('staffing_per_block', {})
                if week_str in staffing:
                    current_workers += staffing[week_str]
                    week_packages.append(package)
            
            # –ï—Å–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ - –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —É–º–µ–Ω—å—à–∞–µ–º
            if current_workers > max_workers:
                scale_factor = max_workers / current_workers
                
                for package in week_packages:
                    original_staff = package['staffing_per_block'][week_str]
                    new_staff = max(1, round(original_staff * scale_factor))
                    package['staffing_per_block'][week_str] = new_staff
        
        return packages
    
    def _create_fallback_schedule(self, packages: List[Dict], timeline_blocks: List[Dict],
                                workforce_range: Dict) -> List[Dict]:
        """
        –°–æ–∑–¥–∞–µ—Ç –±–∞–∑–æ–≤—ã–π –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω, –µ—Å–ª–∏ AI –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª
        """
        fallback_packages = []
        max_workers = workforce_range['max']
        workers_per_package = max(1, max_workers // len(packages))
        
        for i, package in enumerate(packages):
            # –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞–∫–µ—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏
            weeks_per_package = max(1, len(timeline_blocks) // len(packages))
            start_week = (i * weeks_per_package) + 1
            end_week = min(start_week + weeks_per_package - 1, len(timeline_blocks))
            
            schedule_blocks = list(range(start_week, end_week + 1))
            
            # –†–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å
            progress_per_week = round(100.0 / len(schedule_blocks))
            progress_per_block = {}
            staffing_per_block = {}
            
            for week in schedule_blocks:
                week_str = str(week)
                progress_per_block[week_str] = progress_per_week
                staffing_per_block[week_str] = workers_per_package
            
            fallback_package = package.copy()
            fallback_package['schedule_blocks'] = schedule_blocks
            fallback_package['progress_per_block'] = progress_per_block
            fallback_package['staffing_per_block'] = staffing_per_block
            
            fallback_packages.append(fallback_package)
        
        return fallback_packages
    
    def _update_truth_data(self, truth_data: Dict, scheduled_packages: List[Dict], truth_path: str):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç true.json —Å —Ñ–∏–Ω–∞–ª—å–Ω—ã–º –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–º –ø–ª–∞–Ω–æ–º
        –°–û–•–†–ê–ù–Ø–Ø volume_data –æ—Ç Counter –∞–≥–µ–Ω—Ç–∞
        """
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –û–±—ä–µ–¥–∏–Ω—è–µ–º scheduled_packages —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (volume_data)
        existing_packages = truth_data.get('results', {}).get('work_packages', [])
        existing_by_id = {pkg.get('package_id'): pkg for pkg in existing_packages}
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ: –±–µ—Ä–µ–º –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω –∏–∑ scheduled_packages + volume_data –∏–∑ existing
        merged_packages = []
        for scheduled_pkg in scheduled_packages:
            package_id = scheduled_pkg.get('package_id')
            existing_pkg = existing_by_id.get(package_id, {})
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º: scheduled (–∫–∞–ª–µ–Ω–¥–∞—Ä—å) + existing (volume_data)
            merged_pkg = scheduled_pkg.copy()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º volume_data –æ—Ç Counter –∞–≥–µ–Ω—Ç–∞, –µ—Å–ª–∏ –µ—Å—Ç—å
            if 'volume_data' in existing_pkg:
                merged_pkg['volume_data'] = existing_pkg['volume_data']
                
            merged_packages.append(merged_pkg)
        
        truth_data['results']['work_packages'] = merged_packages
        
        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–º –ø–ª–∞–Ω–µ
        schedule_summary = self._create_schedule_summary(scheduled_packages, truth_data.get('timeline_blocks', []))
        
        truth_data['results']['schedule'] = schedule_summary['schedule_info']
        truth_data['results']['staffing'] = schedule_summary['staffing_info']
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞
        truth_data['metadata']['pipeline_completed'] = True
        truth_data['metadata']['final_updated_at'] = datetime.now().isoformat()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with open(truth_path, 'w', encoding='utf-8') as f:
            json.dump(truth_data, f, ensure_ascii=False, indent=2)
    
    def _create_schedule_summary(self, packages: List[Dict], timeline_blocks: List[Dict]) -> Dict:
        """
        –°–æ–∑–¥–∞–µ—Ç —Å–≤–æ–¥–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–º –ø–ª–∞–Ω–µ
        """
        weekly_workload = {}
        total_packages = len(packages)
        
        for week_num in range(1, len(timeline_blocks) + 1):
            week_str = str(week_num)
            active_packages = 0
            total_workers = 0
            
            for package in packages:
                if week_str in package.get('staffing_per_block', {}):
                    active_packages += 1
                    total_workers += package['staffing_per_block'][week_str]
            
            weekly_workload[week_str] = {
                'active_packages': active_packages,
                'total_workers': total_workers
            }
        
        return {
            'schedule_info': {
                'total_packages': total_packages,
                'project_duration_weeks': len(timeline_blocks),
                'weekly_workload': weekly_workload,
                'created_at': datetime.now().isoformat()
            },
            'staffing_info': {
                'peak_workforce': max([w['total_workers'] for w in weekly_workload.values()]) if weekly_workload else 0,
                'average_workforce': (sum([w['total_workers'] for w in weekly_workload.values()]) / len(weekly_workload)) if weekly_workload else 0,
                'workforce_utilization': weekly_workload
            }
        }
    
    def _prepare_compact_packages(self, packages_with_calcs: List[Dict], project_path: str) -> List[Dict]:
        """
        –ì–æ—Ç–æ–≤–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –ø–∞–∫–µ—Ç–∞—Ö –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞.
        –ò–°–ü–†–ê–í–õ–ï–ù–û: –¢–µ–ø–µ—Ä—å –∏–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ volume_data, –≤–∫–ª—é—á–∞—è component_analysis
        """
        compact_packages = []

        for package in packages_with_calcs:
            package_id = package.get('package_id', 'unknown')
            package_name = package.get('name', package.get('package_name', f'–ü–∞–∫–µ—Ç {package_id}'))

            # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ volume_data –≤ true.json
            volume_data = package.get('volume_data', {})

            if not volume_data:
                logger.warning(f"‚ö†Ô∏è –ü–∞–∫–µ—Ç {package_id} –Ω–µ –∏–º–µ–µ—Ç volume_data, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ–±—ä–µ–º–∞
            final_quantity = volume_data.get('quantity', 0)
            final_unit = volume_data.get('unit', '—à—Ç')

            # –ò–∑–≤–ª–µ–∫–∞–µ–º component_analysis –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–æ—Å—Ç–∞–≤–µ
            component_analysis = volume_data.get('component_analysis', [])
            source_works_count = len(component_analysis)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç
            calculation_logic = volume_data.get('calculation_logic', '')
            complexity = self._determine_package_complexity(package_name, calculation_logic)

            # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
            compact_package = {
                'package_id': package_id,
                'package_name': package_name,
                'total_volume': {
                    'quantity': final_quantity,
                    'unit': final_unit
                },
                'source_works_count': source_works_count,
                'component_analysis': component_analysis,
                'complexity': complexity
            }

            compact_packages.append(compact_package)
            logger.info(f"üì¶ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –ø–∞–∫–µ—Ç: {package_name} ({final_quantity} {final_unit}, {source_works_count} —Ä–∞–±–æ—Ç, —Å–ª–æ–∂–Ω–æ—Å—Ç—å: {complexity})")

        return compact_packages
    
    def _determine_package_complexity(self, package_name: str, logic: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø–∞–∫–µ—Ç–∞ —Ä–∞–±–æ—Ç –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤
        """
        name_lower = package_name.lower()
        logic_lower = logic.lower()
        
        # –í—ã—Å–æ–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        if any(keyword in name_lower for keyword in ['–¥–µ–º–æ–Ω—Ç–∞–∂', '—Ä–∞–∑–±–æ—Ä–∫–∞', '—Å–Ω–æ—Å']):
            return 'high'
        if any(keyword in logic_lower for keyword in ['–±–µ—Ç–æ–Ω', '–∂–µ–ª–µ–∑–æ–±–µ—Ç–æ–Ω', '–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏']):
            return 'high'
            
        # –°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å  
        if any(keyword in name_lower for keyword in ['—É—Å—Ç–∞–Ω–æ–≤–∫–∞', '–º–æ–Ω—Ç–∞–∂', '—Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ']):
            return 'medium'
        if any(keyword in logic_lower for keyword in ['—Å—Ç–µ–Ω', '–ø–µ—Ä–µ–∫—Ä—ã', '–æ—Å–Ω–æ–≤–∞–Ω–∏']):
            return 'medium'
            
        # –ù–∏–∑–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        if any(keyword in name_lower for keyword in ['–æ—Ç–¥–µ–ª–∫', '–ø–æ–∫—Ä–∞—Å–∫', '—à—Ç—É–∫–∞—Ç—É—Ä–∫', '–ø–æ–¥–≥–æ—Ç–æ–≤–∫']):
            return 'low'
        if any(keyword in logic_lower for keyword in ['–ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç', '–∫—Ä–∞—Å–∫', '—à—Ç—É–∫–∞—Ç—É—Ä']):
            return 'low'
            
        return 'medium'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–≥–µ–Ω—Ç–∞ –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ –∫–æ–¥–∞
async def run_scheduler_and_staffer(project_path: str, batch_size: int = 12) -> Dict[str, Any]:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –∞–≥–µ–Ω—Ç–∞ scheduler_and_staffer –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞

    Args:
        project_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 12)

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞
    """
    agent = SchedulerAndStaffer(batch_size=batch_size)
    return await agent.process(project_path)

if __name__ == "__main__":
    import sys
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) > 1:
        test_project_path = sys.argv[1]
    else:
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        test_project_path = "/home/imort/Herzog_v3/projects/34975055/d490876a"
    
    if os.path.exists(test_project_path):
        print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ scheduler_and_staffer")
        result = asyncio.run(run_scheduler_and_staffer(test_project_path))
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
    else:
        print(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {test_project_path}")


================================================================================

## –§–ê–ô–õ: RECITATION_ERROR_REPORT/scheduler_and_staffer_prompt.txt
------------------------------------------------------------
# –†–û–õ–¨
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–º—É –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é.

# –ó–ê–î–ê–ß–ê
–°–æ–∑–¥–∞–π —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏–≤ –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç –ø–æ –Ω–µ–¥–µ–ª—è–º –∏ –Ω–∞–∑–Ω–∞—á–∏–≤ –ø–µ—Ä—Å–æ–Ω–∞–ª.

# –í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï
–í –∑–∞–ø—Ä–æ—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Ç—ã –ø–æ–ª—É—á–∏—à—å JSON-–æ–±—ä–µ–∫—Ç —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –∫–ª—é—á–∞–º–∏:
- "work_packages": –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç —Å –∏—Ö —Å–æ—Å—Ç–∞–≤–æ–º
- "timeline_blocks": –¥–æ—Å—Ç—É–ø–Ω—ã–µ –Ω–µ–¥–µ–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞
- "workforce_range": –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ –ø–µ—Ä—Å–æ–Ω–∞–ª—É
- "user_directive": –¥–∏—Ä–µ–∫—Ç–∏–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

# –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø
1. **–õ–∏–º–∏—Ç—ã –ø–µ—Ä—Å–æ–Ω–∞–ª–∞ (—Å—É–º–º–∞ –ø–æ –≤—Å–µ–º –ø–∞–∫–µ—Ç–∞–º –≤ –Ω–µ–¥–µ–ª—é):** –í –ø—Ä–µ–¥–µ–ª–∞—Ö –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ workforce_range.
2. **–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** –î–µ–º–æ–Ω—Ç–∞–∂ -> –ö–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ -> –ò–Ω–∂–µ–Ω–µ—Ä–Ω—ã–µ —Å–µ—Ç–∏ -> –û—Ç–¥–µ–ª–∫–∞.

# –§–û–†–ú–ê–¢ –í–´–í–û–î–ê (–°–¢–†–û–ì–û JSON)
{
    "scheduled_packages": [
        {
            "package_id": "pkg_001",
            "schedule_blocks": [1, 2],
            "progress_per_block": { "1": 60, "2": 40 },
            "staffing_per_block": { "1": 10, "2": 8 },
            "scheduling_reasoning": {
                "why_these_weeks": "–ö—Ä–∞—Ç–∫–æ.",
                "why_this_duration": "–ö—Ä–∞—Ç–∫–æ.",
                "why_this_sequence": "–ö—Ä–∞—Ç–∫–æ.",
                "why_this_staffing": "–ö—Ä–∞—Ç–∫–æ."
            }
        }
    ]
}

# –ü–†–û–í–ï–†–ö–ò –ü–ï–†–ï–î –û–¢–í–ï–¢–û–ú
1. **–õ–∏–º–∏—Ç—ã:** –°—É–º–º–∞ `staffing_per_block` –¥–ª—è –ö–ê–ñ–î–û–ô –Ω–µ–¥–µ–ª–∏ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ workforce_range.
2. **100%:** –°—É–º–º–∞ `progress_per_block` –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞–∫–µ—Ç–∞ —Ä–∞–≤–Ω–∞ 100.
3. **–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:** –ü–æ–ª—è `scheduling_reasoning` –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã.

================================================================================

## –§–ê–ô–õ: RECITATION_ERROR_REPORT/test_fix.py
------------------------------------------------------------
#!/usr/bin/env python3
# –¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è RECITATION –æ—à–∏–±–∫–∏

import sys
sys.path.append('..')
from src.shared.gemini_client import GeminiClient

def test_recitation_fix():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –Ω–∞ RECITATION"""
    client = GeminiClient()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    with open("../src/prompts/scheduler_and_staffer_prompt.txt", "r", encoding="utf-8") as f:
        prompt = f.read()

    print(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Ä–∞–∑–º–µ—Ä–æ–º: {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")

    try:
        # –¢–µ—Å—Ç —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        test_data = {"packages": [{"name": "test", "work_items": []}]}
        result = client.call_gemini(prompt, test_data, "test_recitation")
        print("‚úÖ –£–°–ü–ï–•: –ü—Ä–æ–º–ø—Ç –ø—Ä–æ—à–µ–ª –±–µ–∑ RECITATION –æ—à–∏–±–∫–∏!")
        return True
    except Exception as e:
        print(f"‚ùå –û–®–ò–ë–ö–ê: {e}")
        return False

if __name__ == "__main__":
    test_recitation_fix()


================================================================================

## –§–ê–ô–õ: src/__init__.py
------------------------------------------------------------


================================================================================

## –§–ê–ô–õ: src/main_pipeline.py
------------------------------------------------------------
"""
–ì–ª–∞–≤–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω HerZog v3.0 - —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —á–µ—Ä–µ–∑ true.json
–ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –µ–¥–∏–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –ø—Ä–∞–≤–¥—ã
"""

import os
import json
import logging
from typing import Dict, Optional
from datetime import datetime

from .shared.truth_initializer import create_true_json, get_current_agent, update_pipeline_status
from .ai_agents.agent_runner import run_agent
from .ai_agents.new_agent_runner import run_new_agent

logger = logging.getLogger(__name__)

class HerzogPipeline:
    """–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    
    def __init__(self, project_path: str):
        self.project_path = project_path
        self.progress_callback = None
        self.steps = {
            1: "extraction",
            2: "classification", 
            3: "preparation",
            4: "conceptualization",
            5: "scheduling",
            6: "accounting",
            7: "staffing",
            8: "reporting"
        }
    
    async def _notify_progress(self, step: int, status: str, message: str, data: dict = None):
        """–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        if self.progress_callback:
            try:
                await self.progress_callback({
                    'step': step,
                    'step_name': self.steps.get(step, 'unknown'),
                    'status': status,  # 'started', 'completed', 'error'
                    'message': message,
                    'data': data or {},
                    'project_path': self.project_path
                })
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {e}")
        
    async def run_full_pipeline(self) -> Dict:
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ —á–µ—Ä–µ–∑ true.json –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É"""
        logger.info(f"–ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞: {self.project_path}")
        
        results = {
            'project_path': self.project_path,
            'started_at': datetime.now().isoformat(),
            'success': False,
            'error': None,
            'agents_completed': []
        }
        
        try:
            # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ
            await self._notify_progress(0, 'started', 'üöÄ –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞...')
            
            # –®–∞–≥ 1-3: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–∫–∞–∫ —Ä–∞–Ω—å—à–µ)
            await self._prepare_project_data()
            
            # –°–æ–∑–¥–∞–µ–º true.json –∏–∑ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            truth_path = os.path.join(self.project_path, "true.json")
            
            if not os.path.exists(truth_path):
                logger.info("üìÑ –°–æ–∑–¥–∞–Ω–∏–µ true.json...")
                success = create_true_json(self.project_path)
                if not success:
                    raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å true.json")
                logger.info("‚úÖ true.json —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≥–µ–Ω—Ç–æ–≤ –ø–æ –æ—á–µ—Ä–µ–¥–∏
            while True:
                current_agent = get_current_agent(truth_path)
                
                if current_agent is None:
                    logger.info("üéâ –í—Å–µ –∞–≥–µ–Ω—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
                    break
                
                logger.info(f"ü§ñ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞: {current_agent}")
                
                # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –∞–≥–µ–Ω—Ç–∞
                agent_steps = {
                    'work_packager': (4, '—Å–æ–∑–¥–∞–µ—Ç —É–∫—Ä—É–ø–Ω–µ–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç'),
                    'works_to_packages': (5, '—Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–∞–±–æ—Ç—ã –ø–æ –ø–∞–∫–µ—Ç–∞–º'),
                    'counter': (6, '—Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—ä–µ–º—ã'),
                    'scheduler_and_staffer': (7, '—Å–æ–∑–¥–∞–µ—Ç –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω'),
                    'reporter': (8, '–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Excel –æ—Ç—á–µ—Ç')
                }
                
                step_num, step_desc = agent_steps.get(current_agent, (0, f'–≤—ã–ø–æ–ª–Ω—è–µ—Ç {current_agent}'))
                await self._notify_progress(step_num, 'started', f'üîÑ {step_desc.title()}...')
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ in_progress
                update_pipeline_status(truth_path, current_agent, "in_progress")
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∞–≥–µ–Ω—Ç–∞ –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –ª–æ–≥–∏–∫—É
                new_agents = ["work_packager", "works_to_packages", "counter", "scheduler_and_staffer"]
                
                if current_agent in new_agents:
                    # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–æ–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
                    result = await run_new_agent(current_agent, self.project_path)
                    success = result.get('success', False)
                else:
                    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É
                    success = run_agent(current_agent, self.project_path)
                
                if success:
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ completed
                    update_pipeline_status(truth_path, current_agent, "completed")
                    results['agents_completed'].append(current_agent)
                    logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç {current_agent} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                    
                    # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –∞–≥–µ–Ω—Ç–∞
                    step_num, step_desc = agent_steps.get(current_agent, (0, f'–≤—ã–ø–æ–ª–Ω—è–µ—Ç {current_agent}'))
                    await self._notify_progress(step_num, 'completed', f'‚úÖ {step_desc.title()} –∑–∞–≤–µ—Ä—à–µ–Ω!')
                else:
                    # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
                    step_num, step_desc = agent_steps.get(current_agent, (0, f'–≤—ã–ø–æ–ª–Ω—è–µ—Ç {current_agent}'))
                    await self._notify_progress(step_num, 'error', f'‚ùå –û—à–∏–±–∫–∞ –≤ {step_desc}')
                    raise Exception(f"–ê–≥–µ–Ω—Ç {current_agent} –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π")
            
            # –®–∞–≥ 8: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            logger.info("–®–∞–≥ 8: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞...")
            step8_result = await self.run_reporting()
            
            if not step8_result['success']:
                raise Exception(f"–û—à–∏–±–∫–∞ –Ω–∞ —à–∞–≥–µ 8: {step8_result['error']}")
            
            results['success'] = True
            results['completed_at'] = datetime.now().isoformat()
            logger.info("üéØ –ü–∞–π–ø–ª–∞–π–Ω —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
            
            # –§–∏–Ω–∞–ª—å–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
            await self._notify_progress(9, 'completed', 'üéâ –ü—Ä–æ–µ–∫—Ç –≥–æ—Ç–æ–≤! –ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω —Å–æ–∑–¥–∞–Ω.')
            
        except Exception as e:
            results['error'] = str(e)
            results['failed_at'] = datetime.now().isoformat()
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ: {e}")
        
        return results
    
    async def _prepare_project_data(self):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç —à–∞–≥–∏ 1-3: –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è true.json"""
        
        # –®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel
        await self._notify_progress(1, 'started', 'üìä –ò–∑–≤–ª–µ–∫–∞—é –¥–∞–Ω–Ω—ã–µ –∏–∑ Excel —Ñ–∞–π–ª–æ–≤...')
        logger.info("–®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")
        step1_result = await self.run_extraction()
        if not step1_result['success']:
            await self._notify_progress(1, 'error', '‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö')
            raise Exception(f"–û—à–∏–±–∫–∞ –Ω–∞ —à–∞–≥–µ 1: {step1_result['error']}")
        await self._notify_progress(1, 'completed', '‚úÖ –î–∞–Ω–Ω—ã–µ –∏–∑–≤–ª–µ—á–µ–Ω—ã')
        
        # –®–∞–≥ 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç/–º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤
        await self._notify_progress(2, 'started', 'üè∑Ô∏è –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É—é —Ä–∞–±–æ—Ç—ã –∏ –º–∞—Ç–µ—Ä–∏–∞–ª—ã...')
        logger.info("–®–∞–≥ 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è...")
        step2_result = await self.run_classification()
        if not step2_result['success']:
            await self._notify_progress(2, 'error', '‚ùå –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏')
            raise Exception(f"–û—à–∏–±–∫–∞ –Ω–∞ —à–∞–≥–µ 2: {step2_result['error']}")
        await self._notify_progress(2, 'completed', '‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞')
        
        # –®–∞–≥ 3: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –µ–¥–∏–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –ø—Ä–æ–µ–∫—Ç–∞
        await self._notify_progress(3, 'started', 'üìã –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞—é –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç–∞...')
        logger.info("–®–∞–≥ 3: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞...")
        step3_result = await self.run_preparation()
        if not step3_result['success']:
            await self._notify_progress(3, 'error', '‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö')
            raise Exception(f"–û—à–∏–±–∫–∞ –Ω–∞ —à–∞–≥–µ 3: {step3_result['error']}")
        await self._notify_progress(3, 'completed', '‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã')
    
    async def run_extraction(self) -> Dict:
        """–®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel —Ñ–∞–π–ª–æ–≤"""
        try:
            from .data_processing.extractor import extract_estimates
            
            input_path = f"{self.project_path}/0_input"
            output_path = f"{self.project_path}/1_extracted"
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Å–µ—Ö Excel —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ input
            raw_data = extract_estimates(input_path)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
            with open(f"{output_path}/raw_estimates.json", 'w', encoding='utf-8') as f:
                json.dump(raw_data, f, ensure_ascii=False, indent=2)
            
            return {
                'success': True,
                'items_extracted': len(raw_data),
                'output_file': f"{output_path}/raw_estimates.json"
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {e}")
            return {'success': False, 'error': str(e)}
    
    async def run_classification(self) -> Dict:
        """–®–∞–≥ 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç –∏ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤"""
        try:
            from .data_processing.classifier import classify_estimates
            
            input_file = f"{self.project_path}/1_extracted/raw_estimates.json"
            output_path = f"{self.project_path}/2_classified"
            
            # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –≤—Å–µ –ø–æ–∑–∏—Ü–∏–∏
            classified_data = await classify_estimates(input_file)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            with open(f"{output_path}/classified_estimates.json", 'w', encoding='utf-8') as f:
                json.dump(classified_data, f, ensure_ascii=False, indent=2)
            
            # –°—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            work_count = len([item for item in classified_data if item.get('classification') == '–†–∞–±–æ—Ç–∞'])
            material_count = len([item for item in classified_data if item.get('classification') == '–ú–∞—Ç–µ—Ä–∏–∞–ª'])
            
            return {
                'success': True,
                'total_items': len(classified_data),
                'work_items': work_count,
                'material_items': material_count,
                'output_file': f"{output_path}/classified_estimates.json"
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
            return {'success': False, 'error': str(e)}
    
    async def run_preparation(self) -> Dict:
        """–®–∞–≥ 3: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –µ–¥–∏–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –ø—Ä–æ–µ–∫—Ç–∞"""
        try:
            from .data_processing.preparer import prepare_project_data
            
            raw_estimates_file = f"{self.project_path}/1_extracted/raw_estimates.json"
            directives_file = f"{self.project_path}/0_input/directives.json"
            output_path = f"{self.project_path}/3_prepared"
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –µ–¥–∏–Ω—ã–π —Ñ–∞–π–ª –ø—Ä–æ–µ–∫—Ç–∞ (preparer —Å–∞–º –≤—ã–∑–æ–≤–µ—Ç classifier)
            project_data = prepare_project_data(raw_estimates_file, directives_file)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            with open(f"{output_path}/project_data.json", 'w', encoding='utf-8') as f:
                json.dump(project_data, f, ensure_ascii=False, indent=2)
            
            return {
                'success': True,
                'work_items': len(project_data.get('work_items', [])),
                'timeline_blocks': len(project_data.get('timeline_blocks', [])),
                'output_file': f"{output_path}/project_data.json"
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏: {e}")
            return {'success': False, 'error': str(e)}
    
    # –°—Ç–∞—Ä–∞—è —Ñ—É–Ω–∫—Ü–∏—è AI –∞–≥–µ–Ω—Ç–æ–≤ - –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ
    # –û—Å—Ç–∞–≤–ª–µ–Ω–∞ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    async def run_ai_agent(self, step_num: int) -> Dict:
        """DEPRECATED: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —á–µ—Ä–µ–∑ true.json"""
        logger.warning(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç–∞—Ä–µ–≤—à–∞—è —Ñ—É–Ω–∫—Ü–∏—è run_ai_agent –¥–ª—è —à–∞–≥–∞ {step_num}")
        return {'success': True, 'deprecated': True}
    
    async def run_reporting(self) -> Dict:
        """–®–∞–≥ 8: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ–≥–æ Excel + PDF + –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram"""
        try:
            logger.info("üìä –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º reporter_v3 + PDF + Telegram")
            
            from .data_processing.reporter_v3 import generate_multipage_excel_report
            from .data_processing.pdf_exporter import export_schedule_to_pdf
            
            # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ true.json  
            input_file = f"{self.project_path}/true.json"
            output_path = f"{self.project_path}/8_output"
            
            results = {}
            
            # 1. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω—ã–π Excel –æ—Ç—á–µ—Ç
            logger.info("üìã –°–æ–∑–¥–∞–Ω–∏–µ –º–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ–≥–æ Excel –æ—Ç—á–µ—Ç–∞...")
            excel_file = generate_multipage_excel_report(input_file, output_path)
            results['excel_file'] = excel_file
            logger.info(f"‚úÖ Excel —Å–æ–∑–¥–∞–Ω: {excel_file}")
            
            # 2. –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤ PDF
            logger.info("üìÑ –≠–∫—Å–ø–æ—Ä—Ç –≤ PDF...")
            try:
                pdf_file = export_schedule_to_pdf(excel_file, output_path)
                results['pdf_file'] = pdf_file
                logger.info(f"‚úÖ PDF —Å–æ–∑–¥–∞–Ω: {pdf_file}")
            except Exception as pdf_error:
                logger.warning(f"‚ö†Ô∏è PDF –Ω–µ —Å–æ–∑–¥–∞–Ω: {pdf_error}")
                results['pdf_error'] = str(pdf_error)
            
            # 3. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª—ã –≤ Telegram (–µ—Å–ª–∏ –µ—Å—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏)
            logger.info("üì§ –ü–æ–ø—ã—Ç–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram...")
            try:
                # –¢—É—Ç –Ω—É–∂–µ–Ω chat_id –∏ bot_token, –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö
                # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –≥–æ—Ç–æ–≤–∞
                results['telegram_ready'] = True
                logger.info("‚úÖ Telegram –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≥–æ—Ç–æ–≤–∞ (–Ω—É–∂–Ω—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ bot_token –∏ chat_id)")
            except Exception as tg_error:
                logger.warning(f"‚ö†Ô∏è Telegram –æ—Ç–ø—Ä–∞–≤–∫–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞: {tg_error}")
                results['telegram_error'] = str(tg_error)
            
            return {
                'success': True,
                'results': results
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
            import traceback
            logger.error(f"üìã –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞: {traceback.format_exc()}")
            return {'success': False, 'error': str(e)}

# –ü—É–±–ª–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞
async def run_pipeline(project_path: str, progress_callback=None) -> Dict:
    """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞"""
    pipeline = HerzogPipeline(project_path)
    pipeline.progress_callback = progress_callback
    return await pipeline.run_full_pipeline()

================================================================================

## –§–ê–ô–õ: src/pipeline_launcher.py
------------------------------------------------------------
"""
–û—Ç–¥–µ–ª—å–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞ –±–µ–∑ —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
"""

import logging
import asyncio
from typing import Dict

logger = logging.getLogger(__name__)

async def launch_pipeline(project_path: str, progress_callback=None) -> Dict:
    """
    –ó–∞–ø—É—Å–∫ –≥–ª–∞–≤–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ HerZog v3.0
    
    Args:
        project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞
    """
    try:
        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞: {project_path}")
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø–∞–π–ø–ª–∞–π–Ω
        from .main_pipeline import run_pipeline
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω —Å –∫–æ–ª–±–µ–∫–æ–º
        result = await run_pipeline(project_path, progress_callback)
        
        logger.info(f"üìä –ü–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω: success={result.get('success')}")
        
        return result
        
    except Exception as e:
        logger.error(f"üí• –û—à–∏–±–∫–∞ –≤ pipeline_launcher: {e}", exc_info=True)
        return {
            'success': False,
            'error': str(e),
            'project_path': project_path
        }

================================================================================

## –§–ê–ô–õ: src/telegram_bot/__init__.py
------------------------------------------------------------


================================================================================

## –§–ê–ô–õ: src/telegram_bot/file_sender.py
------------------------------------------------------------
"""
File Sender –¥–ª—è HerZog v3.0 
–ú–æ–¥—É–ª—å –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≥–æ—Ç–æ–≤—ã—Ö Excel –∏ PDF —Ñ–∞–π–ª–æ–≤ –≤ Telegram
"""

import os
import logging
from typing import List, Optional, Dict, Any
import asyncio
from datetime import datetime
import mimetypes

logger = logging.getLogger(__name__)

class TelegramFileSender:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–∞–π–ª–æ–≤ –≤ Telegram
    """
    
    def __init__(self, bot_token: str = None):
        self.bot_token = bot_token
        self.max_file_size = 50 * 1024 * 1024  # 50MB - –ª–∏–º–∏—Ç Telegram
        
    async def send_project_files(self, chat_id: int, project_files: Dict[str, str], 
                               project_name: str = "–ü—Ä–æ–µ–∫—Ç") -> Dict[str, Any]:
        """
        –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –≤ Telegram
        
        Args:
            chat_id: ID —á–∞—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            project_files: –°–ª–æ–≤–∞—Ä—å {—Ç–∏–ø_—Ñ–∞–π–ª–∞: –ø—É—Ç—å_–∫_—Ñ–∞–π–ª—É}
            project_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç–ø—Ä–∞–≤–∫–∏
        """
        try:
            logger.info(f"üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞ '{project_name}' –≤ —á–∞—Ç {chat_id}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ bot_token
            if not self.bot_token:
                logger.error("‚ùå Bot token –Ω–µ –∑–∞–¥–∞–Ω")
                return {
                    'success': False,
                    'error': 'Bot token –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω'
                }
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º telegram –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
            try:
                from telegram import Bot
                from telegram.constants import ParseMode
            except ImportError:
                logger.error("‚ùå python-telegram-bot –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                return {
                    'success': False,
                    'error': 'Telegram –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞'
                }
            
            # –°–æ–∑–¥–∞–µ–º –±–æ—Ç–∞
            bot = Bot(token=self.bot_token)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã
            valid_files = self._validate_files(project_files)
            if not valid_files:
                return {
                    'success': False,
                    'error': '–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏'
                }
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            header_text = f"üìä *–ö–ê–õ–ï–ù–î–ê–†–ù–´–ô –ì–†–ê–§–ò–ö –ì–û–¢–û–í*\\n\\n" \
                         f"üèóÔ∏è –ü—Ä–æ–µ–∫—Ç: *{self._escape_markdown(project_name)}*\\n" \
                         f"üìÖ –î–∞—Ç–∞: {datetime.now().strftime('%d\\.%m\\.%Y %H:%M')}\\n" \
                         f"üìÑ –§–∞–π–ª–æ–≤: {len(valid_files)}"
            
            await bot.send_message(
                chat_id=chat_id,
                text=header_text,
                parse_mode=ParseMode.MARKDOWN_V2
            )
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª—ã
            sent_files = []
            failed_files = []
            
            for file_type, file_path in valid_files.items():
                try:
                    result = await self._send_single_file(bot, chat_id, file_path, file_type)
                    if result['success']:
                        sent_files.append(file_type)
                        logger.info(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω {file_type}: {file_path}")
                    else:
                        failed_files.append((file_type, result['error']))
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ {file_type}: {result['error']}")
                
                except Exception as e:
                    failed_files.append((file_type, str(e)))
                    logger.error(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ {file_type}: {e}")
                
                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏
                await asyncio.sleep(1)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            summary_text = self._create_summary_message(sent_files, failed_files, project_name)
            await bot.send_message(
                chat_id=chat_id,
                text=summary_text,
                parse_mode=ParseMode.MARKDOWN_V2
            )
            
            return {
                'success': True,
                'sent_files': sent_files,
                'failed_files': failed_files,
                'total_sent': len(sent_files)
            }
            
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–∞–π–ª–æ–≤: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _validate_files(self, project_files: Dict[str, str]) -> Dict[str, str]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π"""
        valid_files = {}
        
        for file_type, file_path in project_files.items():
            if not file_path or not os.path.exists(file_path):
                logger.warning(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {file_type} -> {file_path}")
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size = os.path.getsize(file_path)
            if file_size > self.max_file_size:
                logger.warning(f"‚ö†Ô∏è –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {file_type} -> {file_size} bytes")
                continue
            
            if file_size == 0:
                logger.warning(f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π —Ñ–∞–π–ª: {file_type} -> {file_path}")
                continue
                
            valid_files[file_type] = file_path
            logger.info(f"‚úÖ –§–∞–π–ª –≤–∞–ª–∏–¥–µ–Ω: {file_type} -> {file_path} ({file_size} bytes)")
        
        return valid_files
    
    async def _send_single_file(self, bot, chat_id: int, file_path: str, file_type: str) -> Dict[str, Any]:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª"""
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º MIME-type
            mime_type, _ = mimetypes.guess_type(file_path)
            
            # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Å–∏–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            filename = self._create_filename(file_path, file_type)
            
            # –°–æ–∑–¥–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
            caption = self._create_file_caption(file_path, file_type)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç
            with open(file_path, 'rb') as file:
                await bot.send_document(
                    chat_id=chat_id,
                    document=file,
                    filename=filename,
                    caption=caption,
                    parse_mode="Markdown"
                )
            
            return {'success': True}
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _create_filename(self, file_path: str, file_type: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –∫—Ä–∞—Å–∏–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M')
        base_name = os.path.splitext(os.path.basename(file_path))[0]
        extension = os.path.splitext(file_path)[1]
        
        # –ú–∞–ø–ø–∏–Ω–≥ —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤ –Ω–∞ –∫—Ä–∞—Å–∏–≤—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
        type_names = {
            'excel': '–ì—Ä–∞—Ñ–∏–∫',
            'pdf': 'PDF_–ì—Ä–∞—Ñ–∏–∫', 
            'xlsx': 'Excel_–û—Ç—á–µ—Ç',
            'report': '–û—Ç—á–µ—Ç'
        }
        
        nice_name = type_names.get(file_type, file_type)
        return f"HerZog_{nice_name}_{timestamp}{extension}"
    
    def _create_file_caption(self, file_path: str, file_type: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ —Ñ–∞–π–ª–∞"""
        file_size = os.path.getsize(file_path)
        size_mb = round(file_size / (1024 * 1024), 2)
        
        # –ú–∞–ø–ø–∏–Ω–≥ –æ–ø–∏—Å–∞–Ω–∏–π
        descriptions = {
            'excel': 'üìä *Excel –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫*',
            'pdf': 'üìÑ *PDF –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫*',
            'xlsx': 'üìã *–ú–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω—ã–π Excel –æ—Ç—á–µ—Ç*',
            'report': 'üìä *–û—Ç—á–µ—Ç –ø–æ –ø—Ä–æ–µ–∫—Ç—É*'
        }
        
        description = descriptions.get(file_type, f'üìé *{file_type.capitalize()} —Ñ–∞–π–ª*')
        
        return f"{description}\\n–†–∞–∑–º–µ—Ä: {size_mb} MB"
    
    def _create_summary_message(self, sent_files: List[str], failed_files: List[tuple], project_name: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –∏—Ç–æ–≥–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"""
        summary = f"‚úÖ *–û–¢–ü–†–ê–í–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê*\\n\\n"
        summary += f"üèóÔ∏è –ü—Ä–æ–µ–∫—Ç: *{self._escape_markdown(project_name)}*\\n"
        
        if sent_files:
            summary += f"üì§ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: *{len(sent_files)}*\\n"
            for file_type in sent_files:
                summary += f"   ‚úì {file_type}\\n"
        
        if failed_files:
            summary += f"‚ùå –û—à–∏–±–∫–∏ –æ—Ç–ø—Ä–∞–≤–∫–∏: *{len(failed_files)}*\\n"
            for file_type, error in failed_files:
                summary += f"   ‚úó {file_type}: {error[:30]}\\.\\.\\n"
        
        summary += f"\\nüïê –í—Ä–µ–º—è: {datetime.now().strftime('%d\\.%m\\.%Y %H:%M')}"
        
        return summary
    
    def _escape_markdown(self, text: str) -> str:
        """–≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –¥–ª—è Markdown V2"""
        special_chars = ['_', '*', '[', ']', '(', ')', '~', '`', '>', '#', '+', '-', '=', '|', '{', '}', '.', '!']
        for char in special_chars:
            text = text.replace(char, f'\\{char}')
        return text


class FileDeliveryManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä –¥–æ—Å—Ç–∞–≤–∫–∏ —Ñ–∞–π–ª–æ–≤ - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –æ—Å–Ω–æ–≤–Ω—ã–º pipeline
    """
    
    def __init__(self, bot_token: str = None):
        self.sender = TelegramFileSender(bot_token)
    
    async def deliver_project_results(self, chat_id: int, project_path: str, 
                                    project_name: str = None) -> Dict[str, Any]:
        """
        –î–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        
        Args:
            chat_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ Telegram
            project_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
            project_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ—Å—Ç–∞–≤–∫–∏
        """
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
            if not project_name:
                # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∏–∑ true.json
                truth_file = os.path.join(project_path, 'true.json')
                if os.path.exists(truth_file):
                    import json
                    with open(truth_file, 'r', encoding='utf-8') as f:
                        truth_data = json.load(f)
                    
                    # –î–ª—è v2.0 —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                    project_name = truth_data.get('meta', {}).get('project_name')
                    # –î–ª—è v1.0 —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                    if not project_name:
                        project_name = truth_data.get('project_inputs', {}).get('project_name')
                    
                    if not project_name:
                        project_name = "–ë–µ–∑—ã–º—è–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç"
                else:
                    project_name = "–ü—Ä–æ–µ–∫—Ç"
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∞–π–ª—ã –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
            project_files = self._collect_project_files(project_path)
            
            if not project_files:
                return {
                    'success': False,
                    'error': '–ù–µ—Ç –≥–æ—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏'
                }
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª—ã
            return await self.sender.send_project_files(chat_id, project_files, project_name)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ—Å—Ç–∞–≤–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _collect_project_files(self, project_path: str) -> Dict[str, str]:
        """–°–æ–±–∏—Ä–∞–µ—Ç —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏"""
        files = {}
        
        # –ò—â–µ–º –≤ –ø–∞–ø–∫–µ 8_output
        output_dir = os.path.join(project_path, '8_output')
        if os.path.exists(output_dir):
            for filename in os.listdir(output_dir):
                file_path = os.path.join(output_dir, filename)
                if os.path.isfile(file_path):
                    if filename.endswith('.xlsx'):
                        files['excel'] = file_path
                    elif filename.endswith('.pdf'):
                        files['pdf'] = file_path
        
        # –ò—â–µ–º –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
        for filename in os.listdir(project_path):
            file_path = os.path.join(project_path, filename)
            if os.path.isfile(file_path):
                if filename.endswith('.xlsx') and 'excel' not in files:
                    files['excel'] = file_path
                elif filename.endswith('.pdf') and 'pdf' not in files:
                    files['pdf'] = file_path
        
        # –ò—â–µ–º –≤ /tmp (–≥–¥–µ —Å–æ–∑–¥–∞—é—Ç—Å—è –Ω–∞—à–∏ —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã)
        tmp_files = [f for f in os.listdir('/tmp') if f.startswith(('–û—Ç—á–µ—Ç_', '–ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π_–≥—Ä–∞—Ñ–∏–∫_'))]
        for filename in tmp_files:
            file_path = os.path.join('/tmp', filename)
            if filename.endswith('.xlsx') and 'excel' not in files:
                files['xlsx'] = file_path
            elif filename.endswith('.pdf') and 'pdf' not in files:
                files['pdf'] = file_path
        
        return files


# –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ pipeline
async def send_project_files_to_user(chat_id: int, project_path: str, 
                                   bot_token: str, project_name: str = None) -> Dict[str, Any]:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≥–æ—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –≤ Telegram
    
    Args:
        chat_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ Telegram
        project_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
        bot_token: –¢–æ–∫–µ–Ω Telegram –±–æ—Ç–∞
        project_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç–ø—Ä–∞–≤–∫–∏
    """
    manager = FileDeliveryManager(bot_token)
    return await manager.deliver_project_results(chat_id, project_path, project_name)


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–∞–π–ª–æ–≤ (—Ç—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ bot_token)
    import asyncio
    
    async def test_file_sending():
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_chat_id = 123456789  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π chat_id
        test_project_path = "/home/imort/Herzog_v3/projects/34975055/a61b42bf"
        test_bot_token = "YOUR_BOT_TOKEN_HERE"  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω
        
        print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–∞–π–ª–æ–≤...")
        print("‚ö†Ô∏è –î–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω—É–∂–µ–Ω bot_token –∏ chat_id")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        manager = FileDeliveryManager()
        files = manager._collect_project_files(test_project_path)
        
        print(f"üìã –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏:")
        for file_type, file_path in files.items():
            size = os.path.getsize(file_path) if os.path.exists(file_path) else 0
            print(f"   {file_type}: {file_path} ({size} bytes)")
        
        print("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–±–æ—Ä–∞ —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    
    asyncio.run(test_file_sending())

================================================================================

## –§–ê–ô–õ: src/telegram_bot/handlers.py
------------------------------------------------------------
"""
–û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥ –∏ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —Ç–µ–ª–µ–≥—Ä–∞–º-–±–æ—Ç–∞ HerZog
"""

import os
import logging
from datetime import datetime
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes, CommandHandler, MessageHandler, CallbackQueryHandler, filters
from .questionnaire import ProjectQuestionnaire, STEP_MESSAGES

logger = logging.getLogger(__name__)
questionnaire = ProjectQuestionnaire()

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ /start - –Ω–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã —Å –±–æ—Ç–æ–º"""
    user = update.effective_user
    
    welcome_text = f"""
üèóÔ∏è **–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ HerZog v3.0!**

–ü—Ä–∏–≤–µ—Ç, {user.first_name}! 

–Ø –ø–æ–º–æ–≥—É —Å–æ–∑–¥–∞—Ç—å –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–±–æ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—à–∏—Ö —Å–º–µ—Ç.

–î–ª—è –Ω–∞—á–∞–ª–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /new —á—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç.

üìã **–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:**
/new - –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç  
/test - –°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç —Å –≥–æ—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ üß™
/help - –ü–æ–º–æ—â—å
/cancel - –û—Ç–º–µ–Ω–∏—Ç—å —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–µ–∫—Ç
    """
    
    await update.message.reply_text(welcome_text, parse_mode='Markdown')

async def new_project_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ /new - —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞"""
    user_id = update.effective_user.id
    
    # –°–±—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
    context.user_data.clear()
    context.user_data['user_id'] = user_id
    context.user_data['current_step'] = 'files'
    context.user_data['files'] = []
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–π —à–∞–≥
    await update.message.reply_text(
        STEP_MESSAGES['files'],
        parse_mode='Markdown'
    )

async def test_project_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ /test - —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ —Å –≤—ã–±–æ—Ä–æ–º —ç—Ç–∞–ø–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    user_id = update.effective_user.id
    
    # –ü—É—Ç—å –∫ —ç—Ç–∞–ª–æ–Ω–Ω–æ–º—É –ø—Ä–æ–µ–∫—Ç—É
    test_source_project = "/home/imort/Herzog_v3/projects/34975055/da1ac471"
    
    if not os.path.exists(test_source_project):
        await update.message.reply_text(
            "‚ùå –≠—Ç–∞–ª–æ–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ da1ac471."
        )
        return
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —ç—Ç–∞–ø—ã –ø–∞–π–ø–ª–∞–π–Ω–∞
    stages = {
        "0": "0Ô∏è‚É£ –ù–∞—á–∞—Ç—å —Å –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤ (0_input)",
        "1": "1Ô∏è‚É£ –ü–æ—Å–ª–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è (1_extracted)", 
        "2": "2Ô∏è‚É£ –ü–æ—Å–ª–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (2_classified)",
        "3": "3Ô∏è‚É£ –ü–æ—Å–ª–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ (3_prepared)",
        "4": "4Ô∏è‚É£ –ü–æ—Å–ª–µ work_packager (4_work_packager)",
        "5": "5Ô∏è‚É£ –ü–æ—Å–ª–µ works_to_packages (5_works_to_packages)",
        "6": "6Ô∏è‚É£ –ü–æ—Å–ª–µ counter (6_counter)",
        "7": "7Ô∏è‚É£ –ü–æ—Å–ª–µ scheduler_and_staffer (7_scheduler_and_staffer)",
        "8": "8Ô∏è‚É£ –ü–æ–ª–Ω—ã–π –ø—Ä–æ–µ–∫—Ç (–≤—Å–µ —ç—Ç–∞–ø—ã)"
    }
    
    keyboard = []
    for stage_key, stage_name in stages.items():
        keyboard.append([InlineKeyboardButton(stage_name, callback_data=f"test_stage_{stage_key}")])
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await update.message.reply_text(
        "üß™ **–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞**\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ —Å –∫–∞–∫–æ–≥–æ —ç—Ç–∞–ø–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞ –Ω–∞—á–∞—Ç—å:\n\n"
        "‚Ä¢ –í—ã–±–µ—Ä–∏—Ç–µ —ç—Ç–∞–ø 0 –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è\n"
        "‚Ä¢ –í—ã–±–µ—Ä–∏—Ç–µ –±–æ–ª–µ–µ –ø–æ–∑–¥–Ω–∏–π —ç—Ç–∞–ø –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏\n"
        "‚Ä¢ –í—Å–µ —Ñ–∞–π–ª—ã –¥–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —ç—Ç–∞–ø–∞ –±—É–¥—É—Ç —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã",
        reply_markup=reply_markup,
        parse_mode='Markdown'
    )

async def handle_test_stage_selection(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ —ç—Ç–∞–ø–∞ –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞"""
    query = update.callback_query
    await query.answer()
    
    user_id = query.from_user.id
    stage = query.data.split('_')[-1]  # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä —ç—Ç–∞–ø–∞
    
    test_source_project = "/home/imort/Herzog_v3/projects/34975055/da1ac471"
    
    await query.edit_message_text(
        f"üîÑ **–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞...**\n\n"
        f"–ö–æ–ø–∏—Ä—É—é —Ñ–∞–π–ª—ã –¥–æ —ç—Ç–∞–ø–∞ {stage}...",
        parse_mode='Markdown'
    )
    
    try:
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞
        project_path = questionnaire.create_project_structure(user_id)
        
        # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –¥–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —ç—Ç–∞–ø–∞
        success = _copy_project_files_up_to_stage(test_source_project, project_path, stage)
        
        if success:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —ç—Ç–∞–ø–µ
            context.user_data['test_stage'] = stage
            context.user_data['project_path'] = project_path
            
            # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å /process
            input_folder = os.path.join(project_path, "0_input")
            files_info = []
            
            # –ò—â–µ–º Excel —Ñ–∞–π–ª—ã –≤ input –ø–∞–ø–∫–µ
            if os.path.exists(input_folder):
                for file_name in os.listdir(input_folder):
                    if file_name.endswith(('.xlsx', '.xls')):
                        file_path = os.path.join(input_folder, file_name)
                        file_info = {
                            'file_name': file_name,
                            'file_id': f'test_{file_name}',
                            'file_size': os.path.getsize(file_path),
                            'local_path': file_path,
                            'uploaded_at': datetime.now().isoformat()
                        }
                        files_info.append(file_info)
            
            context.user_data['files'] = files_info
            context.user_data['user_id'] = user_id
            
            await query.edit_message_text(
                f"‚úÖ **–¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç —Å–æ–∑–¥–∞–Ω!**\n\n"
                f"üìÅ –ü—É—Ç—å: `{project_path}`\n"
                f"üéØ –≠—Ç–∞–ø: –¥–æ {stage}\n\n"
                f"–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ:\n"
                f"‚Ä¢ –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É —Å —ç—Ç–∞–ø–∞ {int(stage)+1 if stage.isdigit() and int(stage) < 8 else '—Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ'}\n"
                f"‚Ä¢ –ò–∑—É—á–∏—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n"
                f"‚Ä¢ –û—Ç–ª–∞–¥–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∞–≥–µ–Ω—Ç",
                parse_mode='Markdown'
            )
        else:
            await query.edit_message_text(
                "‚ùå **–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞**\n\n"
                "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏.",
                parse_mode='Markdown'
            )
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞: {e}")
        await query.edit_message_text(
            f"‚ùå **–û—à–∏–±–∫–∞**: {str(e)}",
            parse_mode='Markdown'
        )

def _copy_project_files_up_to_stage(source_project: str, target_project: str, stage: str) -> bool:
    """–ö–æ–ø–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞ –¥–æ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —ç—Ç–∞–ø–∞"""
    import shutil
    
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ –ø–∞–ø–∫–∏ –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å
        stage_folders = {
            "0": ["0_input"],
            "1": ["0_input", "1_extracted"], 
            "2": ["0_input", "1_extracted", "2_classified"],
            "3": ["0_input", "1_extracted", "2_classified", "3_prepared"],
            "4": ["0_input", "1_extracted", "2_classified", "3_prepared", "4_work_packager"],
            "5": ["0_input", "1_extracted", "2_classified", "3_prepared", "4_work_packager", "5_works_to_packages"],
            "6": ["0_input", "1_extracted", "2_classified", "3_prepared", "4_work_packager", "5_works_to_packages", "6_counter"],
            "7": ["0_input", "1_extracted", "2_classified", "3_prepared", "4_work_packager", "5_works_to_packages", "6_counter", "7_scheduler_and_staffer"],
            "8": ["0_input", "1_extracted", "2_classified", "3_prepared", "4_work_packager", "5_works_to_packages", "6_counter", "7_scheduler_and_staffer", "8_output"]
        }
        
        folders_to_copy = stage_folders.get(stage, ["0_input"])
        
        # –ö–æ–ø–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –ø–∞–ø–∫—É
        for folder in folders_to_copy:
            source_folder = os.path.join(source_project, folder)
            target_folder = os.path.join(target_project, folder)
            
            if os.path.exists(source_folder):
                if os.path.exists(target_folder):
                    shutil.rmtree(target_folder)
                shutil.copytree(source_folder, target_folder)
                logger.info(f"–°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∞ –ø–∞–ø–∫–∞: {folder}")
        
        # –ö–æ–ø–∏—Ä—É–µ–º true.json –µ—Å–ª–∏ –µ—Å—Ç—å
        source_truth = os.path.join(source_project, "true.json")
        target_truth = os.path.join(target_project, "true.json")
        
        if os.path.exists(source_truth):
            shutil.copy2(source_truth, target_truth)
            logger.info("–°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω true.json")
        
        return True
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤: {e}")
        return False

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ /help - —Å–ø—Ä–∞–≤–∫–∞"""
    help_text = """
üÜò **–°–ø—Ä–∞–≤–∫–∞ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é HerZog**

**–ü—Ä–æ—Ü–µ—Å—Å —Ä–∞–±–æ—Ç—ã:**
1. –°–æ–∑–¥–∞–π—Ç–µ –ø—Ä–æ–µ–∫—Ç –∫–æ–º–∞–Ω–¥–æ–π /new
2. –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel-—Ñ–∞–π–ª—ã —Å–º–µ—Ç  
3. –û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –±–æ—Ç–∞
4. –ü–æ–ª—É—á–∏—Ç–µ –≥–æ—Ç–æ–≤—ã–π –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω

**–ö–æ–º–∞–Ω–¥—ã:**
/new - –ù–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç
/test - –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç (–≥–æ—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ) üß™
/next - –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥ (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)
/skip - –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Ç–µ–∫—É—â–∏–π —à–∞–≥
/cancel - –û—Ç–º–µ–Ω–∏—Ç—å –ø—Ä–æ–µ–∫—Ç
/help - –≠—Ç–∞ —Å–ø—Ä–∞–≤–∫–∞

**–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:**
- Excel —Ñ–∞–π–ª—ã (.xlsx) —Å–æ —Å–º–µ—Ç–∞–º–∏
- –î–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ –î–î.–ú–ú.–ì–ì–ì–ì
    """
    
    await update.message.reply_text(help_text, parse_mode='Markdown')

async def cancel_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ /cancel - –æ—Ç–º–µ–Ω–∞ —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞"""
    context.user_data.clear()
    await update.message.reply_text(
        "‚ùå –¢–µ–∫—É—â–∏–π –ø—Ä–æ–µ–∫—Ç –æ—Ç–º–µ–Ω–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /new –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞."
    )

async def next_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ /next - –ø–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —à–∞–≥—É"""
    current_step = questionnaire.get_current_step(context)
    
    if current_step == 'files' and not context.user_data.get('files'):
        await update.message.reply_text(
            "‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω Excel-—Ñ–∞–π–ª —Å —Å–º–µ—Ç–æ–π!"
        )
        return
    
    next_step = questionnaire.next_step(context)
    await update.message.reply_text(
        STEP_MESSAGES[next_step],
        parse_mode='Markdown'
    )

async def skip_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ /skip - –ø—Ä–æ–ø—É—Å–∫ —Ç–µ–∫—É—â–µ–≥–æ —à–∞–≥–∞"""
    current_step = questionnaire.get_current_step(context)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω–æ–≥–æ —à–∞–≥–∞
    context.user_data[current_step] = ''
    
    next_step = questionnaire.next_step(context)
    await update.message.reply_text(
        f"‚û°Ô∏è –®–∞–≥ –ø—Ä–æ–ø—É—â–µ–Ω\n\n{STEP_MESSAGES[next_step]}",
        parse_mode='Markdown'
    )

async def process_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ /process - –∑–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞"""
    user_id = update.effective_user.id
    
    if not context.user_data.get('files'):
        await update.message.reply_text(
            "‚ùå –ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏!"
        )
        return
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞
    project_path = questionnaire.create_project_structure(user_id)
    context.user_data['project_path'] = project_path
    
    # –ö–æ–ø–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞
    import shutil
    for file_info in context.user_data['files']:
        if 'local_path' in file_info and os.path.exists(file_info['local_path']):
            target_path = f"{project_path}/0_input/{file_info['file_name']}"
            shutil.copy2(file_info['local_path'], target_path)
            logger.info(f"–°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω —Ñ–∞–π–ª: {file_info['file_name']}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∏—Ä–µ–∫—Ç–∏–≤—ã
    directives_path = questionnaire.save_directives(context, project_path)
    
    await update.message.reply_text(
        f"üöÄ **–ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏...**\n\n"
        f"üìÅ –ü—Ä–æ–µ–∫—Ç —Å–æ–∑–¥–∞–Ω: `{project_path}`\n"
        f"üìã –î–∏—Ä–µ–∫—Ç–∏–≤—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: `{directives_path}`\n\n"
        f"‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...",
        parse_mode='Markdown'
    )
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–±–µ–∫ –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ
    progress_message = None
    
    async def progress_callback(progress_data):
        nonlocal progress_message
        step = progress_data['step']
        status = progress_data['status'] 
        message = progress_data['message']
        
        # –≠–º–æ–¥–∑–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        step_icons = {
            0: 'üöÄ', 1: 'üìä', 2: 'üè∑Ô∏è', 3: 'üìã', 
            4: 'üì¶', 5: 'üîÑ', 6: 'üßÆ', 7: 'üìÖ', 8: 'üìÑ', 9: 'üéâ'
        }
        
        if status == 'started':
            if progress_message:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                progress_text = f"{step_icons.get(step, '‚öôÔ∏è')} {message}"
                await progress_message.edit_text(progress_text, parse_mode='Markdown')
            else:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                progress_text = f"{step_icons.get(step, '‚öôÔ∏è')} {message}"
                progress_message = await context.bot.send_message(
                    chat_id=update.effective_chat.id,
                    text=progress_text,
                    parse_mode='Markdown'
                )
        elif status == 'completed':
            if progress_message:
                progress_text = f"{step_icons.get(step, '‚úÖ')} {message}"
                await progress_message.edit_text(progress_text, parse_mode='Markdown')
        elif status == 'error':
            if progress_message:
                progress_text = f"‚ùå {message}"
                await progress_message.edit_text(progress_text, parse_mode='Markdown')
    
    # –ó–∞–ø—É—Å–∫ –≥–ª–∞–≤–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å –∫–æ–ª–±–µ–∫–æ–º
    try:
        from ..pipeline_launcher import launch_pipeline
        result = await launch_pipeline(project_path, progress_callback)
        
        if result['success']:
            # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–∞—Ö
            output_path = f"{project_path}/8_output"
            excel_files = []
            pdf_files = []
            
            if os.path.exists(output_path):
                for file in os.listdir(output_path):
                    if file.endswith('.xlsx'):
                        excel_files.append(file)
                    elif file.endswith('.pdf'):
                        pdf_files.append(file)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ true.json
            summary_info = await _get_project_summary(f"{project_path}/true.json")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            message_parts = [
                "‚úÖ **–û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!**",
                "",
                "üìä **–†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–†–ê–ë–û–¢–ö–ò:**"
            ]
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–∫–µ—Ç–∞—Ö —Ä–∞–±–æ—Ç
            if summary_info:
                message_parts.extend([
                    f"üì¶ –ü–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç: `{summary_info['packages_count']}`",
                    f"üìÖ –ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: `{summary_info['duration_weeks']} –Ω–µ–¥–µ–ª—å`",
                    f"üë• –ü–∏–∫–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞: `{summary_info['peak_workers']} —á–µ–ª–æ–≤–µ–∫`"
                ])
            
            message_parts.append("")
            message_parts.append("üìã **–°–û–ó–î–ê–ù–ù–´–ï –û–¢–ß–ï–¢–´:**")
            
            # Excel –æ—Ç—á–µ—Ç—ã
            if excel_files:
                for excel_file in excel_files:
                    file_path = f"{output_path}/{excel_file}"
                    file_size = os.path.getsize(file_path) if os.path.exists(file_path) else 0
                    message_parts.append(f"üìÑ Excel: `{excel_file}` ({file_size} –±–∞–π—Ç)")
            else:
                message_parts.append("üìÑ Excel: ‚ùå –ù–µ —Å–æ–∑–¥–∞–Ω")
            
            # PDF –æ—Ç—á–µ—Ç—ã
            if pdf_files:
                for pdf_file in pdf_files:
                    file_path = f"{output_path}/{pdf_file}"
                    file_size = os.path.getsize(file_path) if os.path.exists(file_path) else 0
                    message_parts.append(f"üìë PDF: `{pdf_file}` ({file_size} –±–∞–π—Ç)")
            else:
                message_parts.append("üìë PDF: ‚ö†Ô∏è –ù–µ —Å–æ–∑–¥–∞–Ω")
            
            message_parts.extend([
                "",
                f"‚è±Ô∏è **–í—Ä–µ–º—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:** {result.get('completed_at', 'N/A')}",
                f"üîß **–ê–≥–µ–Ω—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ:** `{len(result.get('agents_completed', []))}`"
            ])
            
            await update.message.reply_text(
                "\n".join(message_parts),
                parse_mode='Markdown'
            )
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            await _send_project_files(update, output_path, excel_files, pdf_files)
        else:
            await update.message.reply_text(
                f"‚ùå **–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ:**\n\n"
                f"`{result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}`",
                parse_mode='Markdown'
            )
    except Exception as e:
        logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ: {e}", exc_info=True)
        await update.message.reply_text(
            f"‚ùå **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞:**\n\n`{str(e)}`",
            parse_mode='Markdown'
        )

async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    current_step = questionnaire.get_current_step(context)
    
    if current_step != 'files':
        await update.message.reply_text(
            "‚ùå –°–µ–π—á–∞—Å –Ω–µ –≤—Ä–µ–º—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /new –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞."
        )
        return
    
    document = update.message.document
    
    if not document.file_name.endswith('.xlsx'):
        await update.message.reply_text(
            "‚ùå –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ Excel-—Ñ–∞–π–ª—ã (.xlsx)!"
        )
        return
    
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª –∏–∑ Telegram
        file = await document.get_file()
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        user_id = update.effective_user.id
        temp_path = f"temp_uploads/{user_id}"
        os.makedirs(temp_path, exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –ª–æ–∫–∞–ª—å–Ω–æ
        local_file_path = f"{temp_path}/{document.file_name}"
        await file.download_to_drive(local_file_path)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
        file_info = {
            'file_name': document.file_name,
            'file_id': document.file_id,
            'file_size': document.file_size,
            'local_path': local_file_path,
            'uploaded_at': datetime.now().isoformat()
        }
        
        if 'files' not in context.user_data:
            context.user_data['files'] = []
        
        context.user_data['files'].append(file_info)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫—Ä–∞—Ç–∫–æ–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –±–µ–∑ —Å–ø–∞–º–∞
        await update.message.reply_text(f"üìÅ +{document.file_name}")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å –∫–∞–∂–¥—ã–µ 3 —Ñ–∞–π–ª–∞ –∏–ª–∏ –µ—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤—ã–π —Ñ–∞–π–ª
        if len(context.user_data['files']) == 1 or len(context.user_data['files']) % 3 == 0:
            await update.message.reply_text(
                f"üìä **–ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(context.user_data['files'])}**\n\n"
                f"–ú–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –µ—â–µ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å /next –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è.",
                parse_mode='Markdown'
            )
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")
        await update.message.reply_text(
            f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {str(e)}"
        )

async def handle_text_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ —à–∞–≥–∞–º –æ–ø—Ä–æ—Å–∞"""
    current_step = questionnaire.get_current_step(context)
    text = update.message.text.strip()
    
    if current_step == 'work_count':
        try:
            work_count = int(text)
            if work_count <= 0:
                raise ValueError
            context.user_data['work_count'] = work_count
            next_step = questionnaire.next_step(context)
            await update.message.reply_text(
                f"‚úÖ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {work_count}\n\n{STEP_MESSAGES[next_step]}",
                parse_mode='Markdown'
            )
        except ValueError:
            await update.message.reply_text(
                "‚ùå –í–≤–µ–¥–∏—Ç–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —á–∏—Å–ª–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä: 15)"
            )
    
    elif current_step == 'timeline':
        # –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç - –ø—Ä–∏–Ω–∏–º–∞–µ–º —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
        try:
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –∏—â–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
            clean_text = text.strip()
            
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏: -, ‚Äì, ‚Äî, –ø—Ä–æ–±–µ–ª
            separators = [' - ', '-', ' ‚Äì ', '‚Äì', ' ‚Äî ', '‚Äî', ' ']
            parts = None
            
            for sep in separators:
                if sep in clean_text:
                    temp_parts = clean_text.split(sep)
                    if len(temp_parts) >= 2:
                        parts = [temp_parts[0].strip(), temp_parts[-1].strip()]
                        break
            
            if not parts:
                raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –¥–≤–µ –¥–∞—Ç—ã")
            
            start_date = parts[0]
            end_date = parts[1]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç
            try:
                start_parsed = datetime.strptime(start_date, '%d.%m.%Y')
                start_normalized = start_parsed.strftime('%d.%m.%Y')
            except ValueError:
                raise ValueError(f"–ù–µ–≤–µ—Ä–Ω–∞—è –¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞: {start_date}")
            
            try:
                end_parsed = datetime.strptime(end_date, '%d.%m.%Y')
                end_normalized = end_parsed.strftime('%d.%m.%Y')
            except ValueError:
                raise ValueError(f"–ù–µ–≤–µ—Ä–Ω–∞—è –¥–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è: {end_date}")
            
            context.user_data['timeline'] = {
                'start_date': start_normalized,
                'end_date': end_normalized
            }
            
            next_step = questionnaire.next_step(context)
            await update.message.reply_text(
                f"‚úÖ –ü–µ—Ä–∏–æ–¥: {start_normalized} - {end_normalized}\n\n{STEP_MESSAGES[next_step]}",
                parse_mode='Markdown'
            )
        except (ValueError, IndexError) as e:
            await update.message.reply_text(
                "‚ùå –ü—Ä–æ–±–ª–µ–º–∞ —Å –¥–∞—Ç–∞–º–∏! –£–∫–∞–∂–∏—Ç–µ –¥–≤–µ –¥–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ –î–î.–ú–ú.–ì–ì–ì–ì\n"
                "–ü—Ä–∏–º–µ—Ä—ã: `01.01.2024 - 30.06.2024` –∏–ª–∏ `01.01.2024 30.06.2024`\n"
                f"–û—à–∏–±–∫–∞: {str(e)}"
            )
    
    elif current_step == 'workforce':
        # –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ä–∞–±–æ—á–∏—Ö
        try:
            # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –ª–∏—à–Ω–µ–µ –∏ –∏—â–µ–º —á–∏—Å–ª–∞
            import re
            clean_text = text.strip().replace(' ', '').replace(',', '')
            
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã: 10-20, 10‚Äì20, 10 20, 10–¥–æ20, –æ—Ç10–¥–æ20
            range_patterns = [
                r'(\d+)[-‚Äì‚Äî](\d+)',
                r'(\d+)\s+(\d+)',
                r'–æ—Ç\s*(\d+)\s*–¥–æ\s*(\d+)',
                r'(\d+)\s*–¥–æ\s*(\d+)'
            ]
            
            found_range = False
            for pattern in range_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    min_workers = int(match.group(1))
                    max_workers = int(match.group(2))
                    context.user_data['workforce'] = {
                        'min': min_workers,
                        'max': max_workers
                    }
                    workers_text = f"{min_workers}-{max_workers} —á–µ–ª–æ–≤–µ–∫"
                    found_range = True
                    break
            
            if not found_range:
                # –ü—Ä–æ—Å—Ç–æ –æ–¥–Ω–æ —á–∏—Å–ª–æ
                workers = int(re.search(r'\d+', text).group())
                context.user_data['workforce'] = {
                    'min': workers,
                    'max': workers
                }
                workers_text = f"{workers} —á–µ–ª–æ–≤–µ–∫"
            
            next_step = questionnaire.next_step(context)
            await update.message.reply_text(
                f"‚úÖ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—á–∏—Ö: {workers_text}\n\n{STEP_MESSAGES[next_step]}",
                parse_mode='Markdown'
            )
        except (ValueError, AttributeError):
            await update.message.reply_text(
                "‚ùå –£–∫–∞–∂–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—á–∏—Ö!\n"
                "–ü—Ä–∏–º–µ—Ä—ã: `15`, `10-20`, `–æ—Ç 10 –¥–æ 20`"
            )
    
    elif current_step in ['work_packager', 'counter', 'scheduler_and_staffer']:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∏—Ä–µ–∫—Ç–∏–≤—É –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –∞–≥–µ–Ω—Ç–∞
        context.user_data[current_step] = text
        next_step = questionnaire.next_step(context)
        await update.message.reply_text(
            f"‚úÖ –£–∫–∞–∑–∞–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ\n\n{STEP_MESSAGES[next_step]}",
            parse_mode='Markdown'
        )
    
    else:
        await update.message.reply_text(
            "‚ùì –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /new –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ –∏–ª–∏ /help –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏."
        )

async def _send_project_files(update: Update, output_path: str, excel_files: list, pdf_files: list):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é"""
    try:
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º Excel —Ñ–∞–π–ª—ã
        for excel_file in excel_files:
            file_path = f"{output_path}/{excel_file}"
            if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                await update.message.reply_document(
                    document=open(file_path, 'rb'),
                    filename=excel_file,
                    caption=f"üìÑ {excel_file}"
                )
            else:
                logger.warning(f"Excel —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –ø—É—Å—Ç: {file_path}")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º PDF —Ñ–∞–π–ª—ã  
        for pdf_file in pdf_files:
            file_path = f"{output_path}/{pdf_file}"
            if os.path.exists(file_path) and os.path.getsize(file_path) > 100:  # PDF –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–æ–ª—å—à–µ 100 –±–∞–π—Ç
                await update.message.reply_document(
                    document=open(file_path, 'rb'),
                    filename=pdf_file,
                    caption=f"üìë {pdf_file}"
                )
            else:
                logger.warning(f"PDF —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π: {file_path}")
                
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–∞–π–ª–æ–≤: {e}")
        await update.message.reply_text(
            f"‚ö†Ô∏è –§–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏—Ö –æ—Ç–ø—Ä–∞–≤–∏—Ç—å: {e}"
        )

async def _get_project_summary(true_json_path: str) -> dict:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–µ–∫—Ç–µ –∏–∑ true.json"""
    try:
        import json
        
        if not os.path.exists(true_json_path):
            return None
            
        with open(true_json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        results = data.get('results', {})
        work_packages = results.get('work_packages', [])
        schedule = results.get('schedule', {})
        staffing = results.get('staffing', {})
        
        return {
            'packages_count': len(work_packages),
            'duration_weeks': schedule.get('project_duration_weeks', 'N/A'),
            'peak_workers': staffing.get('peak_workforce', 'N/A'),
            'total_workers': schedule.get('weekly_workload', {})
        }
        
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–æ–¥–∫—É –ø—Ä–æ–µ–∫—Ç–∞: {e}")
        return None

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤—Å–µ—Ö –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
def setup_handlers(application):
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤—Å–µ—Ö –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –∫–æ–º–∞–Ω–¥"""
    # –ö–æ–º–∞–Ω–¥—ã
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("new", new_project_command))  
    application.add_handler(CommandHandler("test", test_project_command))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("cancel", cancel_command))
    application.add_handler(CommandHandler("next", next_command))
    application.add_handler(CommandHandler("skip", skip_command))
    application.add_handler(CommandHandler("process", process_command))
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ callback'–æ–≤
    application.add_handler(CallbackQueryHandler(handle_test_stage_selection, pattern="^test_stage_"))
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
    application.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text_message))

================================================================================

## –§–ê–ô–õ: src/telegram_bot/questionnaire.py
------------------------------------------------------------
"""
–ú–æ–¥—É–ª—å –ø–æ—à–∞–≥–æ–≤–æ–≥–æ –æ–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —Å–±–æ—Ä–∞ –¥–∏—Ä–µ–∫—Ç–∏–≤ –ø—Ä–æ–µ–∫—Ç–∞
"""

import json
import os
import uuid
from datetime import datetime, timedelta
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes
from typing import Dict, Any

class ProjectQuestionnaire:
    """–ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ—à–∞–≥–æ–≤—ã–º –æ–ø—Ä–æ—Å–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    
    def __init__(self):
        self.steps = [
            'files',           # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ —Å–º–µ—Ç
            'work_count',      # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –≤ –≥—Ä–∞—Ñ–∏–∫–µ
            'timeline',        # –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –ø—Ä–æ–µ–∫—Ç–∞
            'workforce',       # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—á–∏—Ö
            'work_packager',   # –î–∏—Ä–µ–∫—Ç–∏–≤—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç
            'counter',         # –î–∏—Ä–µ–∫—Ç–∏–≤—ã –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –æ–±—ä–µ–º–æ–≤
            'scheduler_and_staffer',  # –î–∏—Ä–µ–∫—Ç–∏–≤—ã –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∞
            'confirm'          # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫
        ]
    
    def get_current_step(self, context: ContextTypes.DEFAULT_TYPE) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π —à–∞–≥ –æ–ø—Ä–æ—Å–∞"""
        return context.user_data.get('current_step', 'files')
    
    def next_step(self, context: ContextTypes.DEFAULT_TYPE) -> str:
        """–ü–µ—Ä–µ–π—Ç–∏ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —à–∞–≥—É"""
        current = self.get_current_step(context)
        try:
            current_idx = self.steps.index(current)
            next_step = self.steps[current_idx + 1] if current_idx + 1 < len(self.steps) else 'confirm'
            context.user_data['current_step'] = next_step
            return next_step
        except ValueError:
            return 'files'
    
    def create_project_structure(self, user_id: int, project_id: str = None) -> str:
        """–°–æ–∑–¥–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞"""
        if not project_id:
            project_id = str(uuid.uuid4())[:8]
        
        project_path = f"projects/{user_id}/{project_id}"
        
        folders = [
            '0_input', '1_extracted', '2_classified', '3_prepared',
            '4_conceptualized', '5_scheduled', '6_accounted', 
            '7_staffed', '8_output'
        ]
        
        for folder in folders:
            os.makedirs(f"{project_path}/{folder}", exist_ok=True)
        
        return project_path
    
    def save_directives(self, context: ContextTypes.DEFAULT_TYPE, project_path: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–∏–≤—ã –≤ —Ñ–∞–π–ª"""
        directives = {
            'target_work_count': context.user_data.get('work_count', 15),
            'project_timeline': context.user_data.get('timeline', {}),
            'workforce_range': context.user_data.get('workforce', {}),
            'agent_directives': {
                'work_packager': context.user_data.get('work_packager', ''),
                'counter': context.user_data.get('counter', ''),
                'scheduler_and_staffer': context.user_data.get('scheduler_and_staffer', '')
            },
            'created_at': datetime.now().isoformat()
        }
        
        directives_path = f"{project_path}/0_input/directives.json"
        with open(directives_path, 'w', encoding='utf-8') as f:
            json.dump(directives, f, ensure_ascii=False, indent=2)
        
        return directives_path

# –°–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞
STEP_MESSAGES = {
    'files': "üìÅ **–®–∞–≥ 1/7: –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤**\n\n–ü—Ä–∏—à–ª–∏—Ç–µ —Ñ–∞–π–ª—ã —Å–º–µ—Ç—ã (.xlsx)\n–ú–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤ –∏–ª–∏ –Ω–∞–∂–∞—Ç—å /next –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —à–∞–≥—É.",

    'work_count': "üìä **–®–∞–≥ 2/7: –†–∞–∑–º–µ—Ä –≥—Ä–∞—Ñ–∏–∫–∞**\n\n–£–∫–∞–∂–∏—Ç–µ –∂–µ–ª–∞–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –≤ –∏—Ç–æ–≥–æ–≤–æ–º –≥—Ä–∞—Ñ–∏–∫–µ\n(–Ω–∞–ø—Ä–∏–º–µ—Ä: 15)",

    'timeline': "üìÖ **–®–∞–≥ 3/7: –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏**\n\n–£–∫–∞–∂–∏—Ç–µ –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –ø—Ä–æ–µ–∫—Ç–∞\n–§–æ—Ä–º–∞—Ç: –î–î.–ú–ú.–ì–ì–ì–ì - –î–î.–ú–ú.–ì–ì–ì–ì\n(–Ω–∞–ø—Ä–∏–º–µ—Ä: 01.01.2024 - 30.06.2024)",

    'workforce': "üë∑ **–®–∞–≥ 4/7: –¢—Ä—É–¥–æ–≤—ã–µ —Ä–µ—Å—É—Ä—Å—ã**\n\n–£–∫–∞–∂–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—á–∏—Ö –Ω–∞ –ø–ª–æ—â–∞–¥–∫–µ\n–ú–æ–∂–Ω–æ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä: 10-20) –∏–ª–∏ —Ç–æ—á–Ω–æ–µ —á–∏—Å–ª–æ",
    
    'work_packager': "üéØ **–®–∞–≥ 5/7: –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Ä–∞–±–æ—Ç**\n\n–ï—Å—Ç—å –ª–∏ –æ—Å–æ–±—ã–µ —É–∫–∞–∑–∞–Ω–∏—è –ø–æ –ì–†–£–ü–ü–ò–†–û–í–ö–ï —Ä–∞–±–æ—Ç –≤ –ø–∞–∫–µ—Ç—ã?\n(–ù–∞–ø—Ä–∏–º–µ—Ä: '–≤—Å—é —ç–ª–µ–∫—Ç—Ä–∏–∫—É –≤ –æ–¥–∏–Ω –±–ª–æ–∫', '–æ—Ç–¥–µ–ª–∏ –¥–µ–º–æ–Ω—Ç–∞–∂ –æ—Ç –º–æ–Ω—Ç–∞–∂–∞')\n\n–ò–ª–∏ –Ω–∞–∂–º–∏—Ç–µ /skip –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞",

    'counter': "üí∞ **–®–∞–≥ 6/7: –ü–æ–¥—Å—á–µ—Ç –æ–±—ä–µ–º–æ–≤**\n\n–ï—Å—Ç—å –ª–∏ –æ—Å–æ–±—ã–µ —É–∫–∞–∑–∞–Ω–∏—è –ø–æ –ü–û–î–°–ß–ï–¢–£ –æ–±—ä–µ–º–æ–≤ –ø—Ä–∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–µ?\n(–ù–∞–ø—Ä–∏–º–µ—Ä: '–ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ –ø–æ–ª–æ–≤ —Å—á–∏—Ç–∞–π —Ç–æ–ª—å–∫–æ –ø–ª–æ—â–∞–¥—å')\n\n–ò–ª–∏ –Ω–∞–∂–º–∏—Ç–µ /skip –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞",

    'scheduler_and_staffer': "üìã **–®–∞–≥ 7/7: –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª**\n\n–ï—Å—Ç—å –ª–∏ –æ—Å–æ–±—ã–µ —É–∫–∞–∑–∞–Ω–∏—è –ø–æ –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–Æ —ç—Ç–∞–ø–æ–≤ –∏ –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–Æ –ª—é–¥–µ–π?\n(–ù–∞–ø—Ä–∏–º–µ—Ä: '—Ä–∞—Å—Ç—è–Ω–∏ –¥–µ–º–æ–Ω—Ç–∞–∂ –Ω–∞ –ø–µ—Ä–≤—ã–π –º–µ—Å—è—Ü, –Ω–∞ –æ—Ç–¥–µ–ª–∫—É –º–∞–∫—Å–∏–º—É–º –ª—é–¥–µ–π')\n\n–ò–ª–∏ –Ω–∞–∂–º–∏—Ç–µ /skip –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞",
    
    'confirm': "‚úÖ **–ì–æ—Ç–æ–≤–æ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ!**\n\n–í—Å–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–±—Ä–∞–Ω—ã. –ù–∞–∂–º–∏—Ç–µ /process –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–º–µ—Ç—ã."
}

================================================================================

## –§–ê–ô–õ: src/prompts/counter_prompt.txt
------------------------------------------------------------
# –†–û–õ–¨
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç-—Å–º–µ—Ç—á–∏–∫.

# –ó–ê–î–ê–ß–ê
–†–∞—Å—Å—á–∏—Ç–∞–π –∏—Ç–æ–≥–æ–≤—ã–π –æ–±—ä–µ–º –¥–ª—è –ø–∞–∫–µ—Ç–∞ —Ä–∞–±–æ—Ç, –ø—Ä–∏–º–µ–Ω—è—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é –ª–æ–≥–∏–∫—É –∞–≥—Ä–µ–≥–∞—Ü–∏–∏.

# –í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï
–í –∑–∞–ø—Ä–æ—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Ç—ã –ø–æ–ª—É—á–∏—à—å JSON-–æ–±—ä–µ–∫—Ç —Å –∫–ª—é—á–∞–º–∏:
- "package": –ø–∞–∫–µ—Ç —Ä–∞–±–æ—Ç –¥–ª—è –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω—É–∂–Ω–æ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –æ–±—ä–µ–º—ã
- "works": —Å–æ—Å—Ç–∞–≤ —Ä–∞–±–æ—Ç –≤–Ω—É—Ç—Ä–∏ –ø–∞–∫–µ—Ç–∞
- "user_directive": –¥–∏—Ä–µ–∫—Ç–∏–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–æ–≤

# –ü–†–ê–í–ò–õ–ê –†–ê–°–ß–ï–¢–ê
- **–û–¥–Ω–æ—Ç–∏–ø–Ω—ã–µ —Ä–∞–±–æ—Ç—ã** (—Ä–∞–∑–Ω—ã–µ —Ç—Ä—É–±—ã) -> **–°–£–ú–ú–ò–†–£–ô**.
- **"–°–ª–æ–µ–Ω—ã–µ" —Ä–∞–±–æ—Ç—ã** –Ω–∞ –æ–¥–Ω–æ–π –ø–ª–æ—â–∞–¥–∏ (—à—Ç—É–∫–∞—Ç—É—Ä–∫–∞ + –ø–æ–∫—Ä–∞—Å–∫–∞) -> –±–µ—Ä–∏ **–ú–ê–ö–°–ò–ú–£–ú**.
- **–†–∞–∑–Ω–æ—Ä–æ–¥–Ω—ã–µ —Ä–∞–±–æ—Ç—ã** -> –≤—ã–±–µ—Ä–∏ –µ–¥–∏–Ω–∏—Ü—É **–ù–ê–ò–ë–û–õ–ï–ï –ó–ù–ê–ß–ò–ú–û–ô** —Ä–∞–±–æ—Ç—ã (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –º¬≤ > –º¬≥ > –º > —à—Ç).

# –§–û–†–ú–ê–¢ –í–´–í–û–î–ê (–°–¢–†–û–ì–û JSON)
{
    "calculation": {
        "unit": "–º¬≤",
        "quantity": 125.5,
        "applied_rule": "–ü–†–ê–í–ò–õ–û –ú–ê–ö–°–ò–ú–£–ú–ê",
        "calculation_steps": ["–ê–Ω–∞–ª–∏–∑...", "–û–±—ä–µ–º—ã...", "–†–µ–∑—É–ª—å—Ç–∞—Ç..."],
        "component_analysis": [{"work_name": "–®—Ç—É–∫–∞—Ç—É—Ä–∫–∞", "unit": "–º¬≤", "quantity": 125.5}]
    }
}

================================================================================

## –§–ê–ô–õ: src/prompts/gemini_classification_prompt.txt
------------------------------------------------------------
# –†–û–õ–¨
–¢—ã ‚Äî –∏–Ω–∂–µ–Ω–µ—Ä-—Å–º–µ—Ç—á–∏–∫.

# –ó–ê–î–ê–ß–ê
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º, –∏ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ–∑–∏—Ü–∏–∏ –æ–ø—Ä–µ–¥–µ–ª–∏: "–†–∞–±–æ—Ç–∞" –∏–ª–∏ "–ú–∞—Ç–µ—Ä–∏–∞–ª".

**–ö—Ä–∏—Ç–µ—Ä–∏–π:** –ü–æ–∑–∏—Ü–∏—è –≤–Ω–æ—Å–∏—Ç—Å—è –≤ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç? –î–ê -> "–†–∞–±–æ—Ç–∞", –ù–ï–¢ -> "–ú–∞—Ç–µ—Ä–∏–∞–ª".

# –ò–ù–°–¢–†–£–ö–¶–ò–Ø
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç JSON-–º–∞—Å—Å–∏–≤ —Å–æ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø–æ–∑–∏—Ü–∏—è–º–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.

# –ü–†–ê–í–ò–õ–ê
- "–ü–æ–≥—Ä—É–∑–∫–∞", "—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞", "–≤—ã–≤–æ–∑" -> **"–†–∞–±–æ—Ç–∞"**.
- "–ù–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã", "—Å–º–µ—Ç–Ω–∞—è –ø—Ä–∏–±—ã–ª—å" -> **"–ú–∞—Ç–µ—Ä–∏–∞–ª"**.

# –§–û–†–ú–ê–¢ –í–´–í–û–î–ê (–°–¢–†–û–ì–û JSON)
[
  {
    "id": "UUID_–ø–æ–∑–∏—Ü–∏–∏",
    "classification": "–†–∞–±–æ—Ç–∞" | "–ú–∞—Ç–µ—Ä–∏–∞–ª",
    "reasoning": "–ö—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ."
  }
]

================================================================================

## –§–ê–ô–õ: src/prompts/scheduler_and_staffer_prompt.txt
------------------------------------------------------------
# –†–û–õ–¨
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–º—É –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é.

# –ó–ê–î–ê–ß–ê
–°–æ–∑–¥–∞–π —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏–≤ –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç –ø–æ –Ω–µ–¥–µ–ª—è–º –∏ –Ω–∞–∑–Ω–∞—á–∏–≤ –ø–µ—Ä—Å–æ–Ω–∞–ª.

# –í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï
–í –∑–∞–ø—Ä–æ—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Ç—ã –ø–æ–ª—É—á–∏—à—å JSON-–æ–±—ä–µ–∫—Ç —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –∫–ª—é—á–∞–º–∏:
- "work_packages": –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç —Å –∏—Ö —Å–æ—Å—Ç–∞–≤–æ–º
- "timeline_blocks": –¥–æ—Å—Ç—É–ø–Ω—ã–µ –Ω–µ–¥–µ–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞
- "workforce_range": –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ –ø–µ—Ä—Å–æ–Ω–∞–ª—É
- "user_directive": –¥–∏—Ä–µ–∫—Ç–∏–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

# –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø
1. **–õ–∏–º–∏—Ç—ã –ø–µ—Ä—Å–æ–Ω–∞–ª–∞ (—Å—É–º–º–∞ –ø–æ –≤—Å–µ–º –ø–∞–∫–µ—Ç–∞–º –≤ –Ω–µ–¥–µ–ª—é):** –í –ø—Ä–µ–¥–µ–ª–∞—Ö –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ workforce_range.
2. **–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** –î–µ–º–æ–Ω—Ç–∞–∂ -> –ö–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ -> –ò–Ω–∂–µ–Ω–µ—Ä–Ω—ã–µ —Å–µ—Ç–∏ -> –û—Ç–¥–µ–ª–∫–∞.

# –§–û–†–ú–ê–¢ –í–´–í–û–î–ê (–°–¢–†–û–ì–û JSON)
{
    "scheduled_packages": [
        {
            "package_id": "pkg_001",
            "schedule_blocks": [1, 2],
            "progress_per_block": { "1": 60, "2": 40 },
            "staffing_per_block": { "1": 10, "2": 8 },
            "scheduling_reasoning": {
                "why_these_weeks": "–ö—Ä–∞—Ç–∫–æ.",
                "why_this_duration": "–ö—Ä–∞—Ç–∫–æ.",
                "why_this_sequence": "–ö—Ä–∞—Ç–∫–æ.",
                "why_this_staffing": "–ö—Ä–∞—Ç–∫–æ."
            }
        }
    ]
}

# –ü–†–û–í–ï–†–ö–ò –ü–ï–†–ï–î –û–¢–í–ï–¢–û–ú
1. **–õ–∏–º–∏—Ç—ã:** –°—É–º–º–∞ `staffing_per_block` –¥–ª—è –ö–ê–ñ–î–û–ô –Ω–µ–¥–µ–ª–∏ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ workforce_range.
2. **100%:** –°—É–º–º–∞ `progress_per_block` –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞–∫–µ—Ç–∞ —Ä–∞–≤–Ω–∞ 100.
3. **–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:** –ü–æ–ª—è `scheduling_reasoning` –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã.

================================================================================

## –§–ê–ô–õ: src/prompts/work_packager_prompt.txt
------------------------------------------------------------
# –†–û–õ–¨
–¢—ã ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞.

# –ó–ê–î–ê–ß–ê
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ø–∏—Å–æ–∫ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–±–æ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º, –∏ —Å–æ–∑–¥–∞–π —Ä–æ–≤–Ω–æ {target_work_package_count} —É–∫—Ä—É–ø–Ω–µ–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç.

# –ö–û–ù–¢–ï–ö–°–¢
- –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—Ç: {total_work_items} —à—Ç.
- –î–∏—Ä–µ–∫—Ç–∏–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: "{user_directive}"
- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç JSON-–º–∞—Å—Å–∏–≤ —Å –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–º–∏ —Ä–∞–±–æ—Ç–∞–º–∏

# –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø
1. **–¢–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ:** –†–æ–≤–Ω–æ {target_work_package_count} –ø–∞–∫–µ—Ç–æ–≤.
2. **–õ–æ–≥–∏–∫–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏:** –û–±—ä–µ–¥–∏–Ω—è–π —Ä–∞–±–æ—Ç—ã –ø–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º —ç—Ç–∞–ø–∞–º (–¥–µ–º–æ–Ω—Ç–∞–∂, –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, —ç–ª–µ–∫—Ç—Ä–∏–∫–∞, –æ—Ç–¥–µ–ª–∫–∞).
3. **–ù–∞–∑–≤–∞–Ω–∏—è –∏ –û–ø–∏—Å–∞–Ω–∏—è:** –ö—Ä–∞—Ç–∫–∏–µ –∏ –ø–æ–Ω—è—Ç–Ω—ã–µ –¥–ª—è –∑–∞–∫–∞–∑—á–∏–∫–∞.

# –§–û–†–ú–ê–¢ –í–´–í–û–î–ê (–°–¢–†–û–ì–û JSON)
{{
    "work_packages": [
        {{ "package_id": "pkg_001", "name": "–ù–∞–∑–≤–∞–Ω–∏–µ 1", "description": "–û–ø–∏—Å–∞–Ω–∏–µ 1." }}
    ]
}}

================================================================================

## –§–ê–ô–õ: src/prompts/works_to_packages_prompt.txt
------------------------------------------------------------
# –†–û–õ–¨
–¢—ã ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∏—Å–ø–µ—Ç—á–µ—Ä.

# –ó–ê–î–ê–ß–ê
–î–ª—è –ö–ê–ñ–î–û–ô —Ä–∞–±–æ—Ç—ã –∏–∑ —Å–ø–∏—Å–∫–∞ `–†–ê–ë–û–¢–´ –î–õ–Ø –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–Ø` –Ω–∞–∑–Ω–∞—á—å –û–î–ò–ù –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π `package_id` –∏–∑ `–î–û–°–¢–£–ü–ù–´–• –ü–ê–ö–ï–¢–û–í`.

# –í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï
–í –∑–∞–ø—Ä–æ—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Ç—ã –ø–æ–ª—É—á–∏—à—å JSON-–æ–±—ä–µ–∫—Ç —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –∫–ª—é—á–∞–º–∏:
- "work_packages": –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç
- "batch_works": —Ä–∞–±–æ—Ç—ã –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤ —Ç–µ–∫—É—â–µ–º –±–∞—Ç—á–µ
- "batch_number": –Ω–æ–º–µ—Ä —Ç–µ–∫—É—â–µ–≥–æ –±–∞—Ç—á–∞

# –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–ê–í–ò–õ–ê
1. **–ü–û–õ–ù–û–¢–ê –û–¢–í–ï–¢–ê:** –¢–≤–æ–π –æ—Ç–≤–µ—Ç –≤ –∫–ª—é—á–µ "assignments" –î–û–õ–ñ–ï–ù —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ä–æ–≤–Ω–æ —Å—Ç–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç–æ–≤, —Å–∫–æ–ª—å–∫–æ –±—ã–ª–æ –≤–æ –≤—Ö–æ–¥–Ω—ã—Ö "batch_works". –≠—Ç–æ —Å–∞–º–æ–µ –≥–ª–∞–≤–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ.
2. **–í–ê–õ–ò–î–ù–û–°–¢–¨ ID:** –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ `work_id` –∏ `package_id` –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–≤—ã–µ.
3. **–õ–û–ì–ò–ö–ê:** –í—ã–±–∏—Ä–∞–π –ø–∞–∫–µ—Ç, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –Ω–∞–∑–≤–∞–Ω–∏—é —Ä–∞–±–æ—Ç—ã.

# –§–û–†–ú–ê–¢ –í–´–í–û–î–ê (–°–¢–†–û–ì–û JSON)
{
    "assignments": [
        { "work_id": "id_—Ä–∞–±–æ—Ç—ã_1", "package_id": "pkg_003" }
    ]
}

================================================================================

## –§–ê–ô–õ: src/shared/__init__.py
------------------------------------------------------------


================================================================================

## –§–ê–ô–õ: src/shared/gemini_client.py
------------------------------------------------------------
"""
–û–±—â–∏–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Gemini API
"""

import os
import json
import logging
import asyncio
import time
import uuid
import google.generativeai as genai
from typing import Dict, Any, Optional
from dotenv import load_dotenv

load_dotenv()
logger = logging.getLogger(__name__)

class GeminiClient:
    def __init__(self):
        self.api_key = os.getenv('GEMINI_API_KEY')
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        
        genai.configure(api_key=self.api_key)
        
        # –ú–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ —Å —É—á–µ—Ç–æ–º –∏—Ö –∑–∞–¥–∞—á –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
        self.agent_models = {
            'work_packager': 'gemini-2.5-pro',        # –°–ª–æ–∂–Ω–æ–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç - –Ω—É–∂–Ω—ã –º–æ—â–Ω–æ—Å—Ç–∏
            'works_to_packages': 'gemini-2.5-flash-lite',  # –ü—Ä–æ—Å—Ç–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ - —ç–∫–æ–Ω–æ–º–∏–º —Ç–æ–∫–µ–Ω—ã
            'counter': 'gemini-2.5-flash-lite',       # –ü–æ–¥—Å—á–µ—Ç—ã - –±—ã—Å—Ç—Ä–æ –∏ –¥–µ—à–µ–≤–æ
            'scheduler_and_staffer': 'gemini-2.5-pro', # –°–ª–æ–∂–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ - –Ω—É–∂–Ω—ã –º–æ—â–Ω–æ—Å—Ç–∏
            'classifier': 'gemini-2.5-flash-lite'     # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç - –±—ã—Å—Ç—Ä–æ –∏ –¥–µ—à–µ–≤–æ
        }
        
        # –ö—ç—à –º–æ–¥–µ–ª–µ–π –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–π
        self._model_cache = {}
        
        # –î–µ—Ñ–æ–ª—Ç–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        self.model = self._get_model('gemini-2.5-pro')

    
    def _get_model(self, model_name: str):
        """–ü–æ–ª—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ –∫—ç—à–∞ –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é"""
        if model_name not in self._model_cache:
            self._model_cache[model_name] = genai.GenerativeModel(model_name)
            logger.info(f"üìã –°–æ–∑–¥–∞–Ω–∞ –º–æ–¥–µ–ª—å: {model_name}")
        return self._model_cache[model_name]
    
    def get_model_for_agent(self, agent_name: str):
        """–ü–æ–ª—É—á–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞"""
        model_name = self.agent_models.get(agent_name, 'gemini-2.5-pro')
        return self._get_model(model_name)
        
    async def generate_response(self, prompt: str, max_retries: int = 5, agent_name: str = None, system_instruction: Optional[str] = None) -> Dict[str, Any]:
        """
        –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ Gemini –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —Å retry –ª–æ–≥–∏–∫–æ–π

        Args:
            prompt: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º—Ç (–¥–∞–Ω–Ω—ã–µ)
            max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ 429 –æ—à–∏–±–∫–µ
            agent_name: –ò–º—è –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            system_instruction: –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è (—Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∞–≤–∏–ª–∞ –∏ —à–∞–±–ª–æ–Ω—ã)

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ—Ç–≤–µ—Ç–æ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –∞–≥–µ–Ω—Ç–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—É—é
        if agent_name and agent_name in self.agent_models:
            model_name = self.agent_models[agent_name]
        else:
            model_name = 'gemini-2.5-pro'

        # –ï—Å–ª–∏ –µ—Å—Ç—å system_instruction, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å —Å —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π
        if system_instruction:
            model = genai.GenerativeModel(model_name, system_instruction=system_instruction)
            logger.info(f"üß† –°–æ–∑–¥–∞–Ω–∞ –º–æ–¥–µ–ª—å —Å —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π: {model_name}")
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
            if agent_name and agent_name in self.agent_models:
                model = self.get_model_for_agent(agent_name)
            else:
                model = self.model

        for attempt in range(max_retries):
            try:
                logger.info(f"üì° –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}: {model_name} {f'({agent_name})' if agent_name else ''} (–ø—Ä–æ–º—Ç: {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤)")
                
                # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ–º –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∞–≥–µ–Ω—Ç–∞
                if agent_name == 'work_packager':
                    max_tokens = 8000
                elif agent_name == 'counter':
                    max_tokens = 8000  # Counter –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–µ –æ—Ç–≤–µ—Ç—ã
                else:
                    max_tokens = 4000
                    
                
                response = await model.generate_content_async(
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.3,
                        top_p=0.8,
                        max_output_tokens=max_tokens,
                        response_mime_type="application/json"
                    )
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç API
                if not response.candidates:
                    logger.warning(f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini API")
                    if response.prompt_feedback:
                        feedback_reason = getattr(response.prompt_feedback, 'block_reason', 'UNKNOWN')
                        logger.warning(f"‚ö†Ô∏è –ü—Ä–∏—á–∏–Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏: {feedback_reason}")
                    if attempt < max_retries - 1:
                        await asyncio.sleep(2 + attempt)
                        continue
                    else:
                        raise Exception("API –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º finish_reason –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
                finish_reason = getattr(response.candidates[0], 'finish_reason', None)

                if finish_reason == 2:  # RECITATION - –∫–æ–Ω—Ç–µ–Ω—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω
                    raise Exception(f"–ö–æ–Ω—Ç–µ–Ω—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω Gemini –∏–∑-–∑–∞ RECITATION")

                if finish_reason == 3:  # SAFETY - –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–æ –∏–∑-–∑–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
                    raise Exception("–ö–æ–Ω—Ç–µ–Ω—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω Gemini –∏–∑-–∑–∞ –ø–æ–ª–∏—Ç–∏–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
                
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
                try:
                    response_text = response.text
                except Exception as text_error:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å response.text: {text_error}")
                    if finish_reason == 4:  # MAX_TOKENS - –æ—Ç–≤–µ—Ç –æ–±—Ä–µ–∑–∞–Ω
                        logger.warning("‚ö†Ô∏è –û—Ç–≤–µ—Ç –æ–±—Ä–µ–∑–∞–Ω –∏–∑-–∑–∞ –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤. –£–≤–µ–ª–∏—á–∏–≤–∞—é –ª–∏–º–∏—Ç...")
                        # –ü–æ–≤—Ç–æ—Ä—è–µ–º —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º –ª–∏–º–∏—Ç–æ–º —Ç–æ–∫–µ–Ω–æ–≤
                        if attempt < max_retries - 1:
                            continue
                    raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç Gemini: {text_error}")
                
                # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º markdown –æ–±–µ—Ä—Ç–∫–∏
                try:
                    cleaned_text = self._clean_json_from_markdown(response_text)
                    response_json = self._try_fix_broken_json(cleaned_text)
                    json_parse_success = True
                except json.JSONDecodeError as e:
                    logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç Gemini: {e}")

                    # JSONDecodeError —Å—á–∏—Ç–∞–µ—Ç—Å—è –Ω–µ—É—Å–ø–µ—à–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π - —Ä–µ—Ç—Ä–∞–∏–º
                    if attempt < max_retries - 1:
                        logger.info(f"üîÑ –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –∏–∑-–∑–∞ –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–≥–æ JSON (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 2}/{max_retries})")
                        await asyncio.sleep(1 + attempt)
                        continue
                    else:
                        # –ù–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ–ø—ã—Ç–∫–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
                        return {
                            'success': False,
                            'error': f'JSON –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫: {e}',
                            'response': None,
                            'raw_text': response_text
                        }
                
                result = {
                    'success': True,
                    'response': response_json,
                    'json_parse_success': json_parse_success,
                    'raw_text': response_text,
                    'model_used': model_name,
                    'agent_name': agent_name,
                    'prompt_feedback': str(response.prompt_feedback) if response.prompt_feedback else None,
                    'usage_metadata': {
                        'prompt_token_count': getattr(response.usage_metadata, 'prompt_token_count', 0),
                        'candidates_token_count': getattr(response.usage_metadata, 'candidates_token_count', 0),
                        'total_token_count': getattr(response.usage_metadata, 'total_token_count', 0)
                    },
                    'attempt': attempt + 1,
                    'llm_input': prompt  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç
                }
                
                logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç {model_name} {f'({agent_name})' if agent_name else ''} –∑–∞ {attempt + 1} –ø–æ–ø—ã—Ç–∫—É, —Ç–æ–∫–µ–Ω–æ–≤: {result['usage_metadata']['total_token_count']}")
                return result
                
            except Exception as e:
                error_str = str(e)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ 429 –æ—à–∏–±–∫—É (rate limiting)
                if "429" in error_str or "quota" in error_str.lower() or "rate" in error_str.lower():
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –∏–∑ –æ—à–∏–±–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                    retry_delay = self._extract_retry_delay(error_str)
                    if retry_delay is None:
                        # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π backoff: 2^attempt —Å–µ–∫—É–Ω–¥
                        retry_delay = 2 ** attempt
                    
                    if attempt < max_retries - 1:  # –ù–µ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞
                        logger.warning(f"‚è∞ 429 Rate Limit! –ñ–¥–µ–º {retry_delay} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –ø–æ–ø—ã—Ç–∫–æ–π {attempt + 2}...")
                        await asyncio.sleep(retry_delay)
                        continue
                    else:
                        logger.error(f"‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ ({max_retries}) –¥–ª—è rate limit")
                
                # –î—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏ –∏–ª–∏ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Gemini (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {e}")
                
                if attempt == max_retries - 1:  # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞
                    return {
                        'success': False,
                        'error': error_str,
                        'response': None,
                        'attempts': max_retries
                    }
                
                # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –æ–±—ã—á–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
                await asyncio.sleep(1)
        
        # –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –¥–æ–ª–∂–Ω–æ –¥–æ–π—Ç–∏ —Å—é–¥–∞, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
        return {
            'success': False,
            'error': "Unexpected error: exhausted all retries",
            'response': None
        }
    
    def _extract_retry_delay(self, error_str: str) -> Optional[int]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—É—é –∑–∞–¥–µ—Ä–∂–∫—É –∏–∑ –æ—à–∏–±–∫–∏ 429"""
        import re
        
        # –ò—â–µ–º "retry_delay {\n  seconds: 44\n}"
        match = re.search(r'retry_delay\s*\{\s*seconds:\s*(\d+)', error_str)
        if match:
            return int(match.group(1))
        
        return None
    
    def _clean_json_from_markdown(self, text: str) -> str:
        """
        –û—á–∏—â–∞–µ—Ç JSON –æ—Ç markdown –æ–±–µ—Ä—Ç–∫–∏, –∫–æ—Ç–æ—Ä—É—é —á–∞—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ—Ç Gemini
        
        Args:
            text: –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini
            
        Returns:
            –û—á–∏—â–µ–Ω–Ω—ã–π JSON —Ç–µ–∫—Å—Ç
        """
        import re
        
        # –£–¥–∞–ª—è–µ–º markdown –±–ª–æ–∫–∏ —Ç–∏–ø–∞ ```json ... ```
        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω: ```json –∏–ª–∏ ``` –≤ –Ω–∞—á–∞–ª–µ, –∑–∞—Ç–µ–º JSON, –∑–∞—Ç–µ–º ``` –≤ –∫–æ–Ω—Ü–µ
        markdown_pattern = r'^```(?:json)?\s*\n?(.*?)\n?```\s*$'
        match = re.search(markdown_pattern, text.strip(), re.DOTALL | re.IGNORECASE)
        
        if match:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –º–µ–∂–¥—É ```
            cleaned = match.group(1).strip()
            return cleaned
        
        # –ï—Å–ª–∏ markdown –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        return text.strip()
    
    def _try_fix_broken_json(self, text: str):
        """
        –ü–∞—Ä—Å–∏–Ω–≥ JSON —Å –æ—á–∏—Å—Ç–∫–æ–π —É–ø—Ä–∞–≤–ª—è—é—â–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤

        Args:
            text: JSON —Ç–µ–∫—Å—Ç

        Returns:
            –†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç JSON
        """
        import re

        # –£–¥–∞–ª—è–µ–º —É–ø—Ä–∞–≤–ª—è—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –ª–æ–º–∞—é—Ç JSON
        # –†–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–µ —É–ø—Ä–∞–≤–ª—è—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã: \n, \r, \t, \", \\
        cleaned_text = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', text)

        # –ü—ã—Ç–∞–µ–º—Å—è –ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ –µ—Å—Ç—å
        try:
            return json.loads(cleaned_text)
        except json.JSONDecodeError:
            # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è, –ø—Ä–æ–±—É–µ–º –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –æ—á–∏—Å—Ç–∫—É
            # –ó–∞–º–µ–Ω—è–µ–º –Ω–µ—ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–∞ \\n
            # –¢–æ–ª—å–∫–æ –≤–Ω—É—Ç—Ä–∏ –∑–Ω–∞—á–µ–Ω–∏–π, –∞ –Ω–µ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ JSON
            cleaned_text = re.sub(r'(?<="[^"]*)\n(?=[^"]*"[,}\]])', '\\\\n', cleaned_text)
            return json.loads(cleaned_text)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∏–µ–Ω—Ç–∞
gemini_client = GeminiClient()

================================================================================

## –§–ê–ô–õ: src/shared/timeline_blocks.py
------------------------------------------------------------
"""
–ú–æ–¥—É–ª—å –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Å–µ—Ç–∫–∏ –ø–æ –Ω–µ–¥–µ–ª—è–º (–ë–õ–û–ö–ê–ú) —Å —É—á–µ—Ç–æ–º –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤ –†–§
–°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –Ω–µ–¥–µ–ª—å —Å –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∞ –ø–æ –ø—è—Ç–Ω–∏—Ü—É, –∏—Å–∫–ª—é—á–∞—è –ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–µ –¥–Ω–∏
"""

import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import logging
import holidays

# –ü–æ–ª—É—á–∞–µ–º –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∞–∑–¥–Ω–∏–∫–∏ –†–§ —á–µ—Ä–µ–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫—É holidays
def get_russian_holidays(year: int):
    """–ü–æ–ª—É—á–∞–µ—Ç –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∞–∑–¥–Ω–∏–∫–∏ –†–§ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –≥–æ–¥–∞"""
    return holidays.Russia(years=year)

class TimelineBlockGenerator:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self._holidays_cache = {}  # –ö—ç—à –¥–ª—è –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤ –ø–æ –≥–æ–¥–∞–º
        
    def generate_weekly_blocks(
        self, 
        start_date: str, 
        end_date: str, 
        max_workers_per_week: int = 15
    ) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏ (–Ω–µ–¥–µ–ª–∏) —Å –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∞ –ø–æ –ø—è—Ç–Ω–∏—Ü—É
        
        Args:
            start_date: –¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD
            end_date: –¥–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD
            max_workers_per_week: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—á–∏—Ö –≤ –Ω–µ–¥–µ–ª—é
            
        Returns:
            Dict —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ–µ–∫—Ç–∞ –∏ —Å–ø–∏—Å–∫–æ–º –±–ª–æ–∫–æ–≤
        """
        
        # –ü–∞—Ä—Å–∏–Ω–≥ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞—Ç (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –æ–±–∞ —Ñ–æ—Ä–º–∞—Ç–∞)
        try:
            start_dt = datetime.strptime(start_date, "%d.%m.%Y").date()
        except ValueError:
            start_dt = datetime.strptime(start_date, "%Y-%m-%d").date()
            
        try:
            end_dt = datetime.strptime(end_date, "%d.%m.%Y").date()
        except ValueError:
            end_dt = datetime.strptime(end_date, "%Y-%m-%d").date()
        
        if start_dt > end_dt:
            raise ValueError("–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–∑–∂–µ –¥–∞—Ç—ã –æ–∫–æ–Ω—á–∞–Ω–∏—è")
            
        blocks = []
        block_id = 1
        current_date = start_dt
        
        while current_date <= end_dt:
            # –ù–∞–π—Ç–∏ –Ω–∞—á–∞–ª–æ –Ω–µ–¥–µ–ª–∏ (–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫)
            monday = current_date - timedelta(days=current_date.weekday())
            # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤—ã–π –±–ª–æ–∫, –Ω–∞—á–∞—Ç—å —Å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –¥–∞—Ç—ã –Ω–∞—á–∞–ª–∞
            block_start = max(monday, start_dt)
            
            # –ù–∞–π—Ç–∏ –∫–æ–Ω–µ—Ü –Ω–µ–¥–µ–ª–∏ (–ø—è—Ç–Ω–∏—Ü–∞)
            friday = monday + timedelta(days=4)  # –ø—è—Ç–Ω–∏—Ü–∞ = –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫ + 4 –¥–Ω—è
            # –ï—Å–ª–∏ —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–ª–æ–∫, –∑–∞–∫–æ–Ω—á–∏—Ç—å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –¥–∞—Ç–æ–π –æ–∫–æ–Ω—á–∞–Ω–∏—è
            block_end = min(friday, end_dt)
            
            # –†–∞—Å—Å—á–∏—Ç–∞—Ç—å —Ä–∞–±–æ—á–∏–µ –¥–Ω–∏ —Å —É—á–µ—Ç–æ–º –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤
            working_days, excluded_holidays = self._calculate_working_days(
                block_start, block_end
            )
            
            # –°–æ–∑–¥–∞—Ç—å –±–ª–æ–∫ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ä–∞–±–æ—á–∏–µ –¥–Ω–∏
            if working_days > 0:
                block = {
                    "block_id": block_id,
                    "start_date": block_start.strftime("%Y-%m-%d"),
                    "end_date": block_end.strftime("%Y-%m-%d"),
                    "working_days": working_days,
                    "excluded_holidays": excluded_holidays,
                    "calendar_days": (block_end - block_start).days + 1,
                    "is_partial_start": block_start > monday,
                    "is_partial_end": block_end < friday
                }
                blocks.append(block)
                block_id += 1
            
            # –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–π –Ω–µ–¥–µ–ª–µ
            current_date = friday + timedelta(days=3)  # —Å–ª–µ–¥—É—é—â–∏–π –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫
            
        result = {
            "project_metadata": {
                "start_date": start_date,
                "end_date": end_date,
                "total_blocks": len(blocks),
                "max_workers_per_week": max_workers_per_week,
                "created_at": datetime.now().isoformat() + "Z"
            },
            "blocks": blocks
        }
        
        self.logger.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(blocks)} –±–ª–æ–∫–æ–≤ —Å {start_date} –ø–æ {end_date}")
        return result
    
    def _calculate_working_days(self, start_date, end_date) -> tuple[int, List[str]]:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π –∏—Å–∫–ª—é—á–∞—è –≤—ã—Ö–æ–¥–Ω—ã–µ –∏ –ø—Ä–∞–∑–¥–Ω–∏–∫–∏
        
        Returns:
            tuple: (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ä–∞–±–æ—á–∏—Ö_–¥–Ω–µ–π, —Å–ø–∏—Å–æ–∫_–∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö_–ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤)
        """
        working_days = 0
        excluded_holidays = []
        current = start_date
        
        while current <= end_date:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –≤—ã—Ö–æ–¥–Ω–æ–π –ª–∏ –¥–µ–Ω—å (—Å—É–±–±–æ—Ç–∞=5, –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ=6)
            if current.weekday() < 5:  # –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫=0, –ø—è—Ç–Ω–∏—Ü–∞=4
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø—Ä–∞–∑–¥–Ω–∏–∫ –ª–∏
                date_str = current.strftime("%Y-%m-%d")
                year = current.year
                
                # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∞–∑–¥–Ω–∏–∫–∏ –¥–ª—è –≥–æ–¥–∞ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
                if year not in self._holidays_cache:
                    self._holidays_cache[year] = get_russian_holidays(year)
                
                russian_holidays = self._holidays_cache[year]
                if current in russian_holidays:
                    excluded_holidays.append(date_str)
                else:
                    working_days += 1
            
            current += timedelta(days=1)
            
        return working_days, excluded_holidays
    
    def save_timeline_config(self, user_id: int, config: Dict[str, Any]) -> str:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Å–µ—Ç–∫–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Returns:
            str: –ø—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        sessions_dir = "/home/imort/Herzog_v2claude/data/sessions"
        os.makedirs(sessions_dir, exist_ok=True)
        
        filepath = f"{sessions_dir}/user_{user_id}_timeline.json"
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
            
        self.logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è timeline –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
        return filepath
    
    def load_timeline_config(self, user_id: int) -> Optional[Dict[str, Any]]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Å–µ—Ç–∫–∏
        
        Returns:
            Optional[Dict]: –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–ª–∏ None –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        filepath = f"/home/imort/Herzog_v2claude/data/sessions/user_{user_id}_timeline.json"
        
        if not os.path.exists(filepath):
            return None
            
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                config = json.load(f)
            self.logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è timeline –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
            return config
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
            return None
    
    def format_blocks_summary(self, timeline_config: Dict[str, Any]) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –±–ª–æ–∫–∏ –≤ —á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        
        Returns:
            str: –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –±–ª–æ–∫–æ–≤
        """
        blocks = timeline_config["blocks"]
        metadata = timeline_config["project_metadata"]
        
        summary = f"üìÖ *–ì—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–µ–∫—Ç–∞*\n"
        summary += f"–ü–µ—Ä–∏–æ–¥: {metadata['start_date']} ‚Äî {metadata['end_date']}\n"
        summary += f"–í—Å–µ–≥–æ –±–ª–æ–∫–æ–≤: {metadata['total_blocks']}\n"
        summary += f"–ú–∞–∫—Å. —Ä–∞–±–æ—á–∏—Ö –≤ –Ω–µ–¥–µ–ª—é: {metadata['max_workers_per_week']}\n\n"
        
        for block in blocks:
            start_formatted = datetime.strptime(block['start_date'], "%Y-%m-%d").strftime("%d %b %y")
            end_formatted = datetime.strptime(block['end_date'], "%Y-%m-%d").strftime("%d %b %y")
            
            summary += f"*–ë–ª–æ–∫ {block['block_id']}*: "
            summary += f"{start_formatted} ‚Äî {end_formatted}, "
            summary += f"{block['working_days']} —Ä–∞–±–æ—á–∏—Ö –¥–Ω"
            
            if block['excluded_holidays']:
                summary += f" (–ø—Ä–∞–∑–¥–Ω–∏–∫–∏: {', '.join([datetime.strptime(h, '%Y-%m-%d').strftime('%d.%m') for h in block['excluded_holidays']])})"
            
            summary += "\n"
        
        return summary

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è backward compatibility
def generate_weekly_blocks(start_date: str, end_date: str, max_workers_per_week: int = 15) -> Dict[str, Any]:
    """Wrapper —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
    generator = TimelineBlockGenerator()
    return generator.generate_weekly_blocks(start_date, end_date, max_workers_per_week)

def save_timeline_config(user_id: int, config: Dict[str, Any]) -> str:
    """Wrapper —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
    generator = TimelineBlockGenerator()
    return generator.save_timeline_config(user_id, config)

def load_timeline_config(user_id: int) -> Optional[Dict[str, Any]]:
    """Wrapper —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""  
    generator = TimelineBlockGenerator()
    return generator.load_timeline_config(user_id)

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª—è
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    generator = TimelineBlockGenerator()
    
    # –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä: 2 —Å–µ–Ω—Ç—è–±—Ä—è 2025 - 9 –æ–∫—Ç—è–±—Ä—è 2025
    test_config = generator.generate_weekly_blocks(
        start_date="2025-09-02",
        end_date="2025-10-09", 
        max_workers_per_week=15
    )
    
    print("–¢–µ—Å—Ç–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤:")
    print(json.dumps(test_config, ensure_ascii=False, indent=2))
    
    print("\n–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥:")
    print(generator.format_blocks_summary(test_config))

================================================================================

## –§–ê–ô–õ: src/shared/truth_initializer.py
------------------------------------------------------------
"""
–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ç–æ—Ä —Ñ–∞–π–ª–∞ true.json –¥–ª—è —Å–∏—Å—Ç–µ–º—ã HerZog v3.0
–°–æ–∑–¥–∞–µ—Ç –µ–¥–∏–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –ø—Ä–∞–≤–¥—ã –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞
"""

import json
import uuid
import os
from typing import Dict, List
from datetime import datetime

def create_true_json(project_path: str) -> bool:
    """
    –°–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª true.json –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞
    
    Args:
        project_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
        
    Returns:
        True –µ—Å–ª–∏ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ
    """
    try:
        # –ß–∏—Ç–∞–µ–º –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç–∞ (–æ–Ω–∏ —É–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –¥–∏—Ä–µ–∫—Ç–∏–≤—ã)
        project_data_path = os.path.join(project_path, "3_prepared", "project_data.json")
        if not os.path.exists(project_data_path):
            raise FileNotFoundError(f"–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª project_data: {project_data_path}")
        
        with open(project_data_path, 'r', encoding='utf-8') as f:
            project_data = json.load(f)
        
        # –î–∏—Ä–µ–∫—Ç–∏–≤—ã —É–∂–µ –≤–∫–ª—é—á–µ–Ω—ã –≤ project_data
        directives_data = project_data.get("directives", {})
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º project_id –∏–∑ –ø—É—Ç–∏ –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
        project_id = os.path.basename(project_path)
        
        # –°–æ–∑–¥–∞–µ–º true.json —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        truth_data = {
            "metadata": {
                "project_id": project_id,
                "project_name": directives_data.get("project_name", "–ë–µ–∑—ã–º—è–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç"),
                "source_file_name": directives_data.get("source_file_name", "estimate.xlsx"),
                "created_at": datetime.now().isoformat(),
                "pipeline_status": [
                    {"agent_name": "work_packager", "status": "pending"},
                    {"agent_name": "works_to_packages", "status": "pending"},
                    {"agent_name": "counter", "status": "pending"},
                    {"agent_name": "scheduler_and_staffer", "status": "pending"}
                ]
            },
            
            "project_inputs": {
                "target_work_package_count": directives_data.get("target_work_count", 15),
                "project_timeline": {
                    "start_date": directives_data.get("project_timeline", {}).get("start_date", "2025-09-01"),
                    "end_date": directives_data.get("project_timeline", {}).get("end_date", "2025-10-31")
                },
                "workforce_range": {
                    "min": directives_data.get("workforce_range", {}).get("min", 10),
                    "max": directives_data.get("workforce_range", {}).get("max", 20)
                },
                "agent_directives": directives_data.get("agent_directives", {
                    "work_packager": "",
                    "counter": "",
                    "scheduler_and_staffer": ""
                })
            },
            
            "timeline_blocks": project_data.get("timeline_blocks", []),
            
            "source_work_items": convert_work_items(project_data.get("work_items", [])),
            
            "results": {
                "work_packages": [],
                "schedule": {},
                "accounting": {},
                "staffing": {}
            }
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º true.json –≤ –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞
        truth_path = os.path.join(project_path, "true.json")
        with open(truth_path, 'w', encoding='utf-8') as f:
            json.dump(truth_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω true.json: {truth_path}")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è true.json: {e}")
        return False

def convert_work_items(old_work_items: List[Dict]) -> List[Dict]:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç work_items –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –≤ –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è true.json
    
    Args:
        old_work_items: –ú–∞—Å—Å–∏–≤ —Ä–∞–±–æ—Ç –≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        
    Returns:
        –ú–∞—Å—Å–∏–≤ —Ä–∞–±–æ—Ç –≤ –Ω–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    """
    converted_items = []
    
    for item in old_work_items:
        # –°–æ–∑–¥–∞–µ–º UUID –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        item_id = item.get("id", str(uuid.uuid4()))
        
        converted_item = {
            "id": item_id,
            "source_file": item.get("source_file", "estimate.xlsx"),
            "code": item.get("code", ""),
            "name": item.get("name", ""),
            "unit": item.get("unit", ""),
            "quantity": item.get("quantity", 0.0)
        }
        
        converted_items.append(converted_item)
    
    return converted_items

def update_pipeline_status(truth_path: str, agent_name: str, new_status: str) -> bool:
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –∞–≥–µ–Ω—Ç–∞ –≤ pipeline_status
    
    Args:
        truth_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É true.json
        agent_name: –ò–º—è –∞–≥–µ–Ω—Ç–∞
        new_status: –ù–æ–≤—ã–π —Å—Ç–∞—Ç—É—Å (pending/in_progress/completed)
        
    Returns:
        True –µ—Å–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ
    """
    try:
        # –ß–∏—Ç–∞–µ–º —Ç–µ–∫—É—â–∏–π true.json
        with open(truth_path, 'r', encoding='utf-8') as f:
            truth_data = json.load(f)
        
        # –ù–∞—Ö–æ–¥–∏–º –∏ –æ–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∞–≥–µ–Ω—Ç–∞
        updated = False
        for i, agent in enumerate(truth_data["metadata"]["pipeline_status"]):
            if agent["agent_name"] == agent_name:
                truth_data["metadata"]["pipeline_status"][i]["status"] = new_status
                
                if new_status == "in_progress":
                    truth_data["metadata"]["pipeline_status"][i]["started_at"] = datetime.now().isoformat()
                elif new_status == "completed":
                    truth_data["metadata"]["pipeline_status"][i]["completed_at"] = datetime.now().isoformat()
                    
                    # –°–ª–µ–¥—É—é—â–∏–π –∞–≥–µ–Ω—Ç –æ—Å—Ç–∞–µ—Ç—Å—è pending - –µ–≥–æ –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç main_pipeline
                    # –ù–µ –∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                
                updated = True
                break
        
        if updated:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            with open(truth_path, 'w', encoding='utf-8') as f:
                json.dump(truth_data, f, ensure_ascii=False, indent=2)
            return True
        else:
            print(f"‚ö†Ô∏è –ê–≥–µ–Ω—Ç {agent_name} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ pipeline_status")
            return False
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {e}")
        return False

def get_current_agent(truth_path: str) -> str:
    """
    –ù–∞—Ö–æ–¥–∏—Ç —Ç–µ–∫—É—â–µ–≥–æ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ (—Å–æ —Å—Ç–∞—Ç—É—Å–æ–º in_progress –∏–ª–∏ –ø–µ—Ä–≤–æ–≥–æ pending)
    
    Args:
        truth_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É true.json
        
    Returns:
        –ò–º—è —Ç–µ–∫—É—â–µ–≥–æ –∞–≥–µ–Ω—Ç–∞ –∏–ª–∏ None –µ—Å–ª–∏ –≤—Å–µ –∑–∞–≤–µ—Ä—à–µ–Ω—ã
    """
    try:
        with open(truth_path, 'r', encoding='utf-8') as f:
            truth_data = json.load(f)
        
        # –ò—â–µ–º –∞–≥–µ–Ω—Ç–∞ in_progress
        for agent in truth_data["metadata"]["pipeline_status"]:
            if agent["status"] == "in_progress":
                return agent["agent_name"]
        
        # –ï—Å–ª–∏ –Ω–µ—Ç in_progress, –∏—â–µ–º –ø–µ—Ä–≤–æ–≥–æ pending
        for agent in truth_data["metadata"]["pipeline_status"]:
            if agent["status"] == "pending":
                return agent["agent_name"]
        
        # –í—Å–µ –∞–≥–µ–Ω—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã
        return None
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ –∞–≥–µ–Ω—Ç–∞: {e}")
        return None

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ
    test_project_path = "/home/imort/Herzog_v3/projects/34975055/d19120ef"
    
    if os.path.exists(test_project_path):
        print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–∏—è true.json –¥–ª—è {test_project_path}")
        success = create_true_json(test_project_path)
        
        if success:
            truth_path = os.path.join(test_project_path, "true.json")
            current_agent = get_current_agent(truth_path)
            print(f"üéØ –¢–µ–∫—É—â–∏–π –∞–≥–µ–Ω—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞: {current_agent}")
        else:
            print("‚ùå –¢–µ—Å—Ç –Ω–µ –ø—Ä–æ—à–µ–ª")
    else:
        print(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {test_project_path}")

================================================================================

## –§–ê–ô–õ: src/shared/truth_structure_v2.py
------------------------------------------------------------
"""
–ù–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ true.json v2.0 –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
–ò–µ—Ä–∞—Ä—Ö–∏—á–Ω–∞—è, –ø–æ–Ω—è—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –ª—é–¥–µ–π –∏ –º–∞—à–∏–Ω
"""

import json
from typing import Dict, List, Any, Optional
from datetime import datetime


class TruthStructureV2:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã true.json v2.0
    
    –ü—Ä–∏–Ω—Ü–∏–ø—ã –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:
    1. –ß–µ—Ç–∫–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å–µ–∫—Ü–∏–π
    2. –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ—Å—Ç—å
    3. –ú–∞—à–∏–Ω–Ω–∞—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º–æ—Å—Ç—å  
    4. –ò–µ—Ä–∞—Ä—Ö–∏—á–Ω–æ—Å—Ç—å
    5. –ú–∏–Ω–∏–º–∞–ª–∏–∑–º (—Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ)
    """
    
    @staticmethod
    def create_empty_structure(project_id: str, project_name: str, source_file: str) -> Dict[str, Any]:
        """
        –°–æ–∑–¥–∞–µ—Ç –ø—É—Å—Ç—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É true.json v2.0
        """
        return {
            # üèóÔ∏è –ú–ï–¢–ê–ò–ù–§–û–†–ú–ê–¶–ò–Ø
            "meta": {
                "structure_version": "2.0",
                "project_id": project_id,
                "project_name": project_name,
                "source_file_name": source_file,
                "created_at": datetime.now().isoformat(),
                "last_updated": datetime.now().isoformat()
            },
            
            # üë§ –í–•–û–î–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø  
            "user_inputs": {
                "project_settings": {
                    "target_work_package_count": 10,
                    "timeline": {
                        "start_date": None,
                        "end_date": None
                    },
                    "workforce": {
                        "min_workers": 5,
                        "max_workers": 20
                    }
                },
                "agent_directives": {
                    "work_packager": "",
                    "works_to_packages": "",
                    "counter": "",
                    "scheduler_and_staffer": ""
                },
                "project_context": {
                    "project_type": "",
                    "building_type": "",
                    "location_type": "",
                    "season": "",
                    "special_conditions": []
                }
            },
            
            # ‚è±Ô∏è –í–†–ï–ú–ï–ù–ù–´–ï –ë–õ–û–ö–ò (–ù–ï–î–ï–õ–ò)
            "timeline_blocks": [],
            
            # üìã –ò–°–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï –ò–ó –°–ú–ï–¢–´
            "source_data": {
                "total_work_items": 0,
                "work_items": []
            },
            
            # üéØ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–†–ê–ë–û–¢–ö–ò –ê–ì–ï–ù–¢–ê–ú–ò
            "results": {
                "work_packages": [],
                "volume_summary": {},
                "schedule_summary": {},
                "staffing_summary": {}
            },
            
            # üîÑ –°–¢–ê–¢–£–° PIPELINE
            "pipeline": {
                "current_stage": "initialized",
                "agents_status": [],
                "last_successful_stage": None,
                "errors": []
            }
        }
    
    @staticmethod
    def restructure_old_format(old_truth: Dict[str, Any]) -> Dict[str, Any]:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç true.json –≤ –Ω–æ–≤—ã–π v2.0
        """
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
        old_meta = old_truth.get("metadata", {})
        old_inputs = old_truth.get("project_inputs", {})
        old_results = old_truth.get("results", {})
        old_timeline = old_truth.get("timeline_blocks", [])
        old_source = old_truth.get("source_work_items", [])
        old_pipeline = old_truth.get("metadata", {}).get("pipeline_status", [])
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        new_structure = {
            # üèóÔ∏è –ú–ï–¢–ê–ò–ù–§–û–†–ú–ê–¶–ò–Ø
            "meta": {
                "structure_version": "2.0",
                "project_id": old_meta.get("project_id", "unknown"),
                "project_name": old_inputs.get("project_name", "–ë–µ–∑—ã–º—è–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç"),
                "source_file_name": old_meta.get("source_file_name", "unknown.xlsx"),
                "created_at": old_meta.get("created_at", datetime.now().isoformat()),
                "last_updated": datetime.now().isoformat(),
                "migrated_from": "v1.0"
            },
            
            # üë§ –í–•–û–î–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø
            "user_inputs": {
                "project_settings": {
                    "target_work_package_count": old_inputs.get("target_work_package_count", 10),
                    "timeline": {
                        "start_date": old_inputs.get("project_timeline", {}).get("start_date"),
                        "end_date": old_inputs.get("project_timeline", {}).get("end_date")
                    },
                    "workforce": {
                        "min_workers": old_inputs.get("workforce_range", {}).get("min", 5),
                        "max_workers": old_inputs.get("workforce_range", {}).get("max", 20)
                    }
                },
                "agent_directives": old_inputs.get("agent_directives", {}),
                "project_context": {
                    "project_type": old_inputs.get("external_context", {}).get("object_characteristics", {}).get("project_type", ""),
                    "building_type": old_inputs.get("external_context", {}).get("object_characteristics", {}).get("building_type", ""),
                    "location_type": old_inputs.get("external_context", {}).get("site_conditions", {}).get("location_type", ""),
                    "season": old_inputs.get("external_context", {}).get("climate_factors", {}).get("season", ""),
                    "special_conditions": old_inputs.get("external_context", {}).get("site_conditions", {}).get("work_time_restrictions", [])
                }
            },
            
            # ‚è±Ô∏è –í–†–ï–ú–ï–ù–ù–´–ï –ë–õ–û–ö–ò (—É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
            "timeline_blocks": [
                {
                    "week_id": block.get("block_id", block.get("week_id", i+1)),
                    "start_date": block.get("start_date"),
                    "end_date": block.get("end_date"),
                    "working_days": block.get("working_days", 5),
                    "calendar_days": block.get("calendar_days", 7),
                    "holidays": block.get("excluded_holidays", [])
                }
                for i, block in enumerate(old_timeline)
            ],
            
            # üìã –ò–°–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï –ò–ó –°–ú–ï–¢–´ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ)
            "source_data": {
                "total_work_items": len(old_source),
                "extraction_summary": {
                    "total_rows_processed": len(old_source),
                    "work_items_identified": len([item for item in old_source if item.get("is_work", True)]),
                    "material_items_identified": len([item for item in old_source if not item.get("is_work", True)])
                },
                # –°–æ–∫—Ä–∞—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (—Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è)
                "work_items_summary": [
                    {
                        "id": item.get("id"),
                        "code": item.get("code"),
                        "name": item.get("name", "")[:50] + "..." if len(item.get("name", "")) > 50 else item.get("name", ""),
                        "unit": item.get("unit"),
                        "quantity": item.get("quantity"),
                        "assigned_package": item.get("package_id")
                    }
                    for item in old_source if item.get("is_work", True)
                ]
            },
            
            # üéØ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–†–ê–ë–û–¢–ö–ò –ê–ì–ï–ù–¢–ê–ú–ò
            "results": {
                "work_packages": old_results.get("work_packages", []),
                "volume_summary": old_results.get("volume_summary", {}),
                "schedule_summary": TruthStructureV2._extract_schedule_summary(old_results.get("work_packages", [])),
                "staffing_summary": TruthStructureV2._extract_staffing_summary(old_results.get("work_packages", []))
            },
            
            # üîÑ –°–¢–ê–¢–£–° PIPELINE
            "pipeline": {
                "current_stage": TruthStructureV2._determine_current_stage(old_pipeline),
                "agents_status": [
                    {
                        "agent": status.get("agent_name"),
                        "status": status.get("status"),
                        "started": status.get("started_at"),
                        "completed": status.get("completed_at"),
                        "duration": TruthStructureV2._calculate_duration(
                            status.get("started_at"), 
                            status.get("completed_at")
                        )
                    }
                    for status in old_pipeline
                ],
                "last_successful_stage": TruthStructureV2._find_last_successful(old_pipeline),
                "errors": [
                    status.get("agent_name") 
                    for status in old_pipeline 
                    if status.get("status") == "error"
                ]
            }
        }
        
        return new_structure
    
    @staticmethod
    def _extract_schedule_summary(work_packages: List[Dict]) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–º—É –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é"""
        if not work_packages:
            return {}
        
        scheduled_packages = [
            pkg for pkg in work_packages 
            if pkg.get("schedule_blocks") or pkg.get("progress_per_block")
        ]
        
        return {
            "total_packages": len(work_packages),
            "scheduled_packages": len(scheduled_packages),
            "scheduling_completeness": len(scheduled_packages) / len(work_packages) * 100 if work_packages else 0
        }
    
    @staticmethod
    def _extract_staffing_summary(work_packages: List[Dict]) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ –∫–∞–¥—Ä–æ–≤–æ–º—É –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é"""
        if not work_packages:
            return {}
        
        staffed_packages = [
            pkg for pkg in work_packages 
            if pkg.get("staffing_per_block")
        ]
        
        return {
            "total_packages": len(work_packages),
            "staffed_packages": len(staffed_packages),
            "staffing_completeness": len(staffed_packages) / len(work_packages) * 100 if work_packages else 0
        }
    
    @staticmethod
    def _determine_current_stage(pipeline_status: List[Dict]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–µ–∫—É—â—É—é —Å—Ç–∞–¥–∏—é pipeline"""
        if not pipeline_status:
            return "initialized"
        
        last_status = pipeline_status[-1]
        if last_status.get("status") == "error":
            return f"error_at_{last_status.get('agent_name', 'unknown')}"
        elif last_status.get("status") == "in_progress":
            return f"processing_{last_status.get('agent_name', 'unknown')}"
        elif last_status.get("status") == "completed":
            return f"completed_{last_status.get('agent_name', 'unknown')}"
        
        return "unknown"
    
    @staticmethod
    def _find_last_successful(pipeline_status: List[Dict]) -> Optional[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é —É—Å–ø–µ—à–Ω—É—é —Å—Ç–∞–¥–∏—é"""
        for status in reversed(pipeline_status):
            if status.get("status") == "completed":
                return status.get("agent_name")
        return None
    
    @staticmethod
    def _calculate_duration(start_time: Optional[str], end_time: Optional[str]) -> Optional[float]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö"""
        if not start_time or not end_time:
            return None
        
        try:
            start = datetime.fromisoformat(start_time.replace('Z', '+00:00'))
            end = datetime.fromisoformat(end_time.replace('Z', '+00:00'))
            return (end - start).total_seconds()
        except:
            return None

    @staticmethod
    def validate_structure(truth_data: Dict[str, Any]) -> List[str]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É true.json v2.0
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫ (–ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ = —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤–∞–ª–∏–¥–Ω–∞)
        """
        errors = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å–µ–∫—Ü–∏–∏
        required_sections = ["meta", "user_inputs", "timeline_blocks", "source_data", "results", "pipeline"]
        for section in required_sections:
            if section not in truth_data:
                errors.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è —Å–µ–∫—Ü–∏—è: {section}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Ä—Å–∏—é —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        if truth_data.get("meta", {}).get("structure_version") != "2.0":
            errors.append("–ù–µ–≤–µ—Ä–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–æ–∂–∏–¥–∞–µ—Ç—Å—è 2.0)")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        work_packages = truth_data.get("results", {}).get("work_packages", [])
        for pkg in work_packages:
            if not pkg.get("package_id"):
                errors.append(f"–ü–∞–∫–µ—Ç –±–µ–∑ package_id: {pkg.get('name', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π')}")
        
        return errors


def migrate_truth_file(old_file_path: str, new_file_path: str) -> bool:
    """
    –ú–∏–≥—Ä–∞—Ü–∏—è —Ñ–∞–π–ª–∞ true.json –∏–∑ v1.0 –≤ v2.0
    
    Args:
        old_file_path: –ü—É—Ç—å –∫ —Å—Ç–∞—Ä–æ–º—É —Ñ–∞–π–ª—É
        new_file_path: –ü—É—Ç—å –¥–ª—è –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
        
    Returns:
        True –µ—Å–ª–∏ –º–∏–≥—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
    """
    try:
        # –ß–∏—Ç–∞–µ–º —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª
        with open(old_file_path, 'r', encoding='utf-8') as f:
            old_data = json.load(f)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        new_data = TruthStructureV2.restructure_old_format(old_data)
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        errors = TruthStructureV2.validate_structure(new_data)
        if errors:
            print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –ø—Ä–∏ –º–∏–≥—Ä–∞—Ü–∏–∏: {errors}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–π —Ñ–∞–π–ª
        with open(new_file_path, 'w', encoding='utf-8') as f:
            json.dump(new_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {old_file_path} -> {new_file_path}")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏: {e}")
        return False


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º —Ñ–∞–π–ª–µ
    test_old_file = "/home/imort/Herzog_v3/projects/34975055/a61b42bf/true.json"
    test_new_file = "/tmp/true_v2_migrated.json"
    
    if migrate_truth_file(test_old_file, test_new_file):
        print("üß™ –¢–µ—Å—Ç–æ–≤–∞—è –º–∏–≥—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        import os
        old_size = os.path.getsize(test_old_file)
        new_size = os.path.getsize(test_new_file) 
        print(f"üìä –†–∞–∑–º–µ—Ä —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª–∞: {old_size:,} –±–∞–π—Ç")
        print(f"üìä –†–∞–∑–º–µ—Ä –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞: {new_size:,} –±–∞–π—Ç")
        print(f"üìä –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞: {((new_size - old_size) / old_size * 100):+.1f}%")
    else:
        print("‚ùå –¢–µ—Å—Ç–æ–≤–∞—è –º–∏–≥—Ä–∞—Ü–∏—è –ø—Ä–æ–≤–∞–ª–∏–ª–∞—Å—å")

================================================================================

## –§–ê–ô–õ: src/ai_agents/__init__.py
------------------------------------------------------------


================================================================================

## –§–ê–ô–õ: src/ai_agents/agent_runner.py
------------------------------------------------------------
"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä AI –∞–≥–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã HerZog v3.0
–£–ø—Ä–∞–≤–ª—è–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤ –ø–æ –µ–¥–∏–Ω–æ–π —Å—Ö–µ–º–µ
"""

import json
import logging
import os
import requests
from typing import Dict, Any
from dotenv import load_dotenv

# –°—Ç–∞—Ä—ã–µ –∏–º–ø–æ—Ä—Ç—ã —É–¥–∞–ª–µ–Ω—ã - –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É

load_dotenv()

def load_prompt_template(prompt_file: str) -> str:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —à–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞
    
    Args:
        prompt_file: –ò–º—è —Ñ–∞–π–ª–∞ –ø—Ä–æ–º–ø—Ç–∞
        
    Returns:
        –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø—Ä–æ–º–ø—Ç–∞
    """
    try:
        prompt_path = os.path.join(os.path.dirname(__file__), '../prompts', prompt_file)
        with open(prompt_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–º–ø—Ç–∞ {prompt_file}: {e}")
        raise

def call_gemini_api(prompt: str) -> str:
    """
    –í—ã–∑—ã–≤–∞–µ—Ç Gemini API —Å –ø—Ä–æ–º–ø—Ç–æ–º
    
    Args:
        prompt: –ì–æ—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
        
    Returns:
        –û—Ç–≤–µ—Ç –æ—Ç LLM
    """
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω API –∫–ª—é—á GEMINI_API_KEY")
    
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent?key={api_key}"
    
    headers = {'Content-Type': 'application/json'}
    
    payload = {
        "contents": [
            {
                "parts": [
                    {
                        "text": prompt
                    }
                ]
            }
        ],
        "generationConfig": {
            "temperature": 0.1,
            "maxOutputTokens": 8192
        }
    }
    
    try:
        response = requests.post(url, json=payload, headers=headers, timeout=120)
        
        if response.status_code == 200:
            data = response.json()
            return data['candidates'][0]['content']['parts'][0]['text']
        else:
            raise Exception(f"–û—à–∏–±–∫–∞ API Gemini: {response.status_code} - {response.text}")
            
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Gemini API: {e}")
        raise

def run_agent(agent_name: str, project_dir: str) -> bool:
    """
    –û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É true.json
    
    Args:
        agent_name: –ò–º—è –∞–≥–µ–Ω—Ç–∞ –∏–∑ agent_config
        project_dir: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
        
    Returns:
        True –µ—Å–ª–∏ –∞–≥–µ–Ω—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ
    """
    
    logging.warning(f"üîÑ DEPRECATED: –§—É–Ω–∫—Ü–∏—è run_agent —É—Å—Ç–∞—Ä–µ–ª–∞ –¥–ª—è –∞–≥–µ–Ω—Ç–∞ '{agent_name}'")
    logging.warning("üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ main_pipeline.py –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –Ω–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤")
    
    # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º False - –Ω–æ–≤—ã–µ –∞–≥–µ–Ω—Ç—ã –¥–æ–ª–∂–Ω—ã –∑–∞–ø—É—Å–∫–∞—Ç—å—Å—è —á–µ—Ä–µ–∑ main_pipeline
    return False

def run_pipeline(project_dir: str, start_from: str = "work_packager") -> bool:
    """
    DEPRECATED: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —á–µ—Ä–µ–∑ main_pipeline.py
    
    Args:
        project_dir: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
        start_from: –° –∫–∞–∫–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ –Ω–∞—á–∞—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
        
    Returns:
        True –µ—Å–ª–∏ –≤—Å–µ –∞–≥–µ–Ω—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ
    """
    
    logging.warning("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç–∞—Ä–µ–≤—à–∞—è —Ñ—É–Ω–∫—Ü–∏—è run_pipeline. –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ main_pipeline.py")
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ–≤—É—é –ª–æ–≥–∏–∫—É
    from ..main_pipeline import run_pipeline as new_run_pipeline
    import asyncio
    
    try:
        result = asyncio.run(new_run_pipeline(project_dir))
        return result.get('success', False)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≤ –Ω–æ–≤–æ–º –ø–∞–π–ø–ª–∞–π–Ω–µ: {e}")
        return False

if __name__ == "__main__":
    import sys
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    if len(sys.argv) == 3:
        # –ó–∞–ø—É—Å–∫ —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏: agent_name project_dir
        agent_name = sys.argv[1]
        project_dir = sys.argv[2]
        print(f"üöÄ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ '{agent_name}' –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ {project_dir}")
        success = run_agent(agent_name, project_dir)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {'‚úÖ –£—Å–ø–µ—Ö' if success else '‚ùå –û—à–∏–±–∫–∞'}")
    else:
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –ø—Ä–æ–µ–∫—Ç–µ
        test_project_dir = "/home/imort/Herzog_v3/projects/34975055/d19120ef"
        
        print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ agent_runner...")
        
        if os.path.exists(test_project_dir):
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
            success = run_agent("1.1_group_creator", test_project_dir)
            print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ—Å—Ç–∞: {'‚úÖ –£—Å–ø–µ—Ö' if success else '‚ùå –û—à–∏–±–∫–∞'}")
        else:
            print(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {test_project_dir}")

================================================================================

## –§–ê–ô–õ: src/ai_agents/counter.py
------------------------------------------------------------
"""
–ê–≥–µ–Ω—Ç 3: "–°–º–µ—Ç—á–∏–∫" (counter.py)
–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–µ –æ–±—ä–µ–º—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É–∫—Ä—É–ø–Ω–µ–Ω–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞ —Ä–∞–±–æ—Ç
"""

import json
import os
import asyncio
import logging
import uuid
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from collections import defaultdict

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –Ω–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã
from ..shared.gemini_client import gemini_client
from ..shared.truth_initializer import update_pipeline_status

logger = logging.getLogger(__name__)

class WorkVolumeCalculator:
    """
    –ê–≥–µ–Ω—Ç –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ –æ–±—ä–µ–º–æ–≤ –ø–æ —É–∫—Ä—É–ø–Ω–µ–Ω–Ω—ã–º –ø–∞–∫–µ—Ç–∞–º —Ä–∞–±–æ—Ç
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç –ª–æ–≥–∏–∫—É –∞–≥—Ä–µ–≥–∞—Ü–∏–∏: —Å–ª–æ–∂–µ–Ω–∏–µ –æ–¥–Ω–æ—Ç–∏–ø–Ω–æ–≥–æ, –º–∞–∫—Å–∏–º—É–º –¥–ª—è –ø–ª–æ—â–∞–¥–µ–π "–ø–∏—Ä–æ–≥–∞"
    """
    
    def __init__(self):
        self.agent_name = "counter"

    
    async def process(self, project_path: str) -> Dict[str, Any]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–∞—Å—á–µ—Ç–æ–≤ –æ–±—ä–µ–º–æ–≤
        
        Args:
            project_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        try:
            logger.info(f"üîÑ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ {self.agent_name}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º true.json
            truth_path = os.path.join(project_path, "true.json")
            if not os.path.exists(truth_path):
                raise FileNotFoundError(f"–§–∞–π–ª true.json –Ω–µ –Ω–∞–π–¥–µ–Ω: {truth_path}")
            
            with open(truth_path, 'r', encoding='utf-8') as f:
                truth_data = json.load(f)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∞–≥–µ–Ω—Ç–∞
            update_pipeline_status(truth_path, self.agent_name, "in_progress")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞
            agent_folder = os.path.join(project_path, "6_counter")
            os.makedirs(agent_folder, exist_ok=True)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            work_packages = truth_data.get('results', {}).get('work_packages', [])
            source_work_items = truth_data.get('source_work_items', [])
            agent_directives = truth_data.get('project_inputs', {}).get('agent_directives', {})
            user_directive = agent_directives.get('counter') or agent_directives.get('accountant', '')
            
            if not work_packages:
                raise Exception("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç. –°–Ω–∞—á–∞–ª–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–ø—É—â–µ–Ω work_packager")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–∞–±–æ—Ç—ã –∏–º–µ—é—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –∫ –ø–∞–∫–µ—Ç–∞–º
            works_with_packages = [w for w in source_work_items if w.get('package_id')]
            if not works_with_packages:
                raise Exception("–†–∞–±–æ—Ç—ã –Ω–µ –Ω–∞–∑–Ω–∞—á–µ–Ω—ã –∫ –ø–∞–∫–µ—Ç–∞–º. –°–Ω–∞—á–∞–ª–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–ø—É—â–µ–Ω works_to_packages")
            
            logger.info(f"üìä –†–∞—Å—á–µ—Ç –æ–±—ä–µ–º–æ–≤ –¥–ª—è {len(work_packages)} –ø–∞–∫–µ—Ç–æ–≤")
            logger.info(f"üìã –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(works_with_packages)} —Ä–∞–±–æ—Ç —Å –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è–º–∏")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç
            prompt_template = self._load_prompt()
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ä–∞–±–æ—Ç—ã –ø–æ –ø–∞–∫–µ—Ç–∞–º
            packages_with_works = self._group_works_by_packages(work_packages, works_with_packages)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ø–∞–∫–µ—Ç
            calculated_packages = []
            for package_data in packages_with_works:
                logger.info(f"üî¢ –†–∞—Å—á–µ—Ç –æ–±—ä–µ–º–æ–≤ –¥–ª—è –ø–∞–∫–µ—Ç–∞: {package_data['package']['name']}")
                
                calculated_package = await self._calculate_package_volumes(
                    package_data, user_directive, prompt_template, agent_folder
                )
                calculated_packages.append(calculated_package)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º true.json —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            self._update_truth_data(truth_data, calculated_packages, truth_path)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ
            update_pipeline_status(truth_path, self.agent_name, "completed")
            
            logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç {self.agent_name} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
            logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(calculated_packages)} –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç")
            
            return {
                'success': True,
                'packages_calculated': len(calculated_packages),
                'agent': self.agent_name
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≥–µ–Ω—Ç–∞ {self.agent_name}: {e}")
            # –ü—ã—Ç–∞–µ–º—Å—è –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –Ω–∞ –æ—à–∏–±–∫—É
            try:
                update_pipeline_status(truth_path, self.agent_name, "error")
            except:
                pass
            
            return {
                'success': False,
                'error': str(e),
                'agent': self.agent_name
            }
    
    def _group_works_by_packages(self, work_packages: List[Dict], 
                                source_work_items: List[Dict]) -> List[Dict]:
        """
        –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—ã –ø–æ –ø–∞–∫–µ—Ç–∞–º –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        packages_with_works = []
        
        for package in work_packages:
            package_id = package.get('package_id')
            
            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ä–∞–±–æ—Ç—ã —ç—Ç–æ–≥–æ –ø–∞–∫–µ—Ç–∞
            package_works = [
                work for work in source_work_items 
                if work.get('package_id') == package_id
            ]
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è AI
            works_for_ai = []
            for work in package_works:
                works_for_ai.append({
                    'id': work.get('id'),
                    'name': work.get('name', ''),
                    'code': work.get('code', ''),
                    'unit': work.get('unit', ''),
                    'quantity': work.get('quantity', 0.0)
                })
            
            packages_with_works.append({
                'package': package,
                'works': works_for_ai,
                'work_count': len(works_for_ai)
            })
        
        return packages_with_works
    
    async def _calculate_package_volumes(self, package_data: Dict, user_directive: str,
                                       prompt_template: str, agent_folder: str) -> Dict:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—ä–µ–º—ã –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞ —Ä–∞–±–æ—Ç
        """
        package = package_data['package']
        package_id = package.get('package_id')
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è AI
        input_data = {
            'package': package,
            'works': package_data['works'],
            'user_directive': user_directive
        }
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è LLM
        system_instruction, user_prompt = self._format_prompt(input_data, prompt_template)

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–ª—å –∫ —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è RECITATION
        salted_system_instruction = self._add_salt_to_prompt(system_instruction)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (–∫–∞–∫ –≤ work_packager)
        debug_data = {
            "system_instruction": salted_system_instruction,
            "user_prompt": user_prompt
        }
        input_path = os.path.join(agent_folder, f"{package_id}_input.json")
        with open(input_path, 'w', encoding='utf-8') as f:
            json.dump(debug_data, f, ensure_ascii=False, indent=2)

        # –í—ã–∑—ã–≤–∞–µ–º Gemini API —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
        logger.info(f"üì° –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–∞–∫–µ—Ç–∞ {package_id} –≤ Gemini (counter -> gemini-2.5-flash-lite)")
        gemini_response = await gemini_client.generate_response(
            prompt=user_prompt,
            system_instruction=salted_system_instruction,
            agent_name="counter"
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –æ—Ç LLM
        response_path = os.path.join(agent_folder, f"{package_id}_response.json")
        with open(response_path, 'w', encoding='utf-8') as f:
            json.dump(gemini_response, f, ensure_ascii=False, indent=2)
        
        if not gemini_response.get('success', False):
            logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê Gemini API –¥–ª—è –ø–∞–∫–µ—Ç–∞ {package_id}: {gemini_response.get('error')}")
            raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç Gemini –¥–ª—è –ø–∞–∫–µ—Ç–∞ {package_id}: {gemini_response.get('error')}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç
        calculation_result = self._process_calculation_response(
            gemini_response['response'], package, package_data['works']
        )
        
        return calculation_result
    
    def _load_prompt(self) -> str:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ–º–ø—Ç-—à–∞–±–ª–æ–Ω –¥–ª—è –∞–≥–µ–Ω—Ç–∞
        """
        prompt_path = os.path.join(
            os.path.dirname(__file__), "..", "prompts", "counter_prompt.txt"
        )
        
        try:
            with open(prompt_path, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            logger.warning(f"–ü—Ä–æ–º–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {prompt_path}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π")
            return self._get_default_prompt()
    
    def _get_default_prompt(self) -> str:
        """
        –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç, –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        return """
–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç-—Å–º–µ—Ç—á–∏–∫ –≤ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–µ. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –∏—Ç–æ–≥–æ–≤—ã–µ –æ–±—ä–µ–º—ã –¥–ª—è –ø–∞–∫–µ—Ç–∞ —Ä–∞–±–æ—Ç.

–ü–ê–ö–ï–¢ –†–ê–ë–û–¢:
{package}

–í–•–û–î–Ø–©–ò–ï –†–ê–ë–û–¢–´:
{works}

–î–ò–†–ï–ö–¢–ò–í–ê –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {user_directive}

–ü–†–ê–í–ò–õ–ê –†–ê–°–ß–ï–¢–ê –û–ë–™–ï–ú–û–í:
1. –°–õ–û–ñ–ï–ù–ò–ï: –û–¥–∏–Ω–∞–∫–æ–≤—ã–µ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è (–º¬≤, –º¬≥, —à—Ç) - —Å–∫–ª–∞–¥—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
2. –ú–ê–ö–°–ò–ú–£–ú: –î–ª—è "—Å–ª–æ–µ–Ω—ã—Ö" –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π (–ø–æ–ª, –ø–æ—Ç–æ–ª–æ–∫, —Å—Ç–µ–Ω—ã) - –±–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –ø–ª–æ—â–∞–¥—å
3. –õ–û–ì–ò–ö–ê: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–º—ã—Å–ª —Ä–∞–±–æ—Ç - —á—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –Ω—É–∂–Ω–æ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–∞–∫–µ—Ç–∞
4. –û–ö–†–£–ì–õ–ï–ù–ò–ï: –ò—Ç–æ–≥–æ–≤—ã–µ –æ–±—ä–µ–º—ã –æ–∫—Ä—É–≥–ª—è–π –¥–æ —Ä–∞–∑—É–º–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π

–ü–†–ò–ú–ï–†–´:
- –î–µ–º–æ–Ω—Ç–∞–∂ –ø–æ–ª–∞ (3 –≤–∏–¥–∞) ‚Üí –º–∞–∫—Å. –ø–ª–æ—â–∞–¥—å –ø–æ–ª–∞
- –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ–ª–∞ (—Å—Ç—è–∂–∫–∞ + –ø–æ–∫—Ä—ã—Ç–∏–µ) ‚Üí –ø–ª–æ—â–∞–¥—å –ø–æ–ª–∞ (–æ–¥–∏–Ω–∞–∫–æ–≤–∞—è)  
- –ú–æ–Ω—Ç–∞–∂ —Ç—Ä—É–± ‚Üí —Å—É–º–º–∞ –¥–ª–∏–Ω –≤—Å–µ—Ö —Ç—Ä—É–±
- –û–∫—Ä–∞—Å–∫–∞ —Å—Ç–µ–Ω (–≥—Ä—É–Ω—Ç + –∫—Ä–∞—Å–∫–∞) ‚Üí –ø–ª–æ—â–∞–¥—å —Å—Ç–µ–Ω (–æ–¥–∏–Ω–∞–∫–æ–≤–∞—è)

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –£–ß–ò–¢–´–í–ê–ô –î–ò–†–ï–ö–¢–ò–í–£: {user_directive}

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (—Å—Ç—Ä–æ–≥–æ JSON):
{{
    "calculation": {{
        "unit": "–º¬≤",
        "quantity": 150.0,
        "calculation_logic": "–í–∑—è—Ç–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å –ø–æ–ª–∞ –∏–∑ –≤—Å–µ—Ö —Ä–∞–±–æ—Ç –¥–µ–º–æ–Ω—Ç–∞–∂–∞",
        "component_analysis": [
            {{"work_name": "–î–µ–º–æ–Ω—Ç–∞–∂ –ª–∏–Ω–æ–ª–µ—É–º–∞", "unit": "–º¬≤", "quantity": 120.0}},
            {{"work_name": "–î–µ–º–æ–Ω—Ç–∞–∂ —Å—Ç—è–∂–∫–∏", "unit": "–º¬≤", "quantity": 150.0}}
        ]
    }}
}}

–í–ê–ñ–ù–û: 
- unit –∏ quantity - —ç—Ç–æ —Ç–æ, —á—Ç–æ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –∑–∞–∫–∞–∑—á–∏–∫—É –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤—Å–µ–≥–æ –ø–∞–∫–µ—Ç–∞
- calculation_logic - –æ–±—ä—è—Å–Ω–∏ —Å–≤–æ—é –ª–æ–≥–∏–∫—É —Ä–∞—Å—á–µ—Ç–∞
- –ï—Å–ª–∏ —Ä–∞–±–æ—Ç—ã —Ä–∞–∑–Ω–æ—Ä–æ–¥–Ω—ã–µ, –≤—ã–±–µ—Ä–∏ –Ω–∞–∏–±–æ–ª–µ–µ –∑–Ω–∞—á–∏–º—É—é –µ–¥–∏–Ω–∏—Ü—É –∏–∑–º–µ—Ä–µ–Ω–∏—è
"""
    
    def _add_salt_to_prompt(self, prompt: str) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—É—é —Å–æ–ª—å –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è RECITATION."""
        unique_id = str(uuid.uuid4())[:8]
        prefix = f"# ID: {unique_id} | –†–µ–∂–∏–º: JSON_STRICT\n"
        suffix = f"\n# –ö–æ–Ω—Ç—Ä–æ–ª—å: {unique_id}"
        return prefix + prompt + suffix

    def _format_prompt(self, input_data: Dict, prompt_template: str) -> Tuple[str, str]:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–º–ø—Ç —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ system_instruction –∏ user_prompt

        Returns:
            Tuple[str, str]: (system_instruction, user_prompt)
        """
        # System instruction - —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç –±–µ–∑ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤
        system_instruction = prompt_template

        # User prompt - JSON —Å –¥–∞–Ω–Ω—ã–º–∏
        user_prompt_data = {
            'package': input_data['package'],
            'works': input_data['works'],
            'user_directive': input_data['user_directive']
        }
        user_prompt = json.dumps(user_prompt_data, ensure_ascii=False, indent=2)

        return system_instruction, user_prompt

    def _clean_and_parse_json(self, response_text: str) -> Dict:
        """
        –û—á–∏—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç markdown –∏ –ø–∞—Ä—Å–∏—Ç JSON
        """
        try:
            # –£–±–∏—Ä–∞–µ–º markdown –±–ª–æ–∫ ```json ... ```
            import re

            # –ò—â–µ–º JSON –±–ª–æ–∫ –≤ markdown
            json_pattern = r'```(?:json)?\s*\n?(.*?)\n?```'
            match = re.search(json_pattern, response_text, re.DOTALL | re.IGNORECASE)

            if match:
                json_content = match.group(1).strip()
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç markdown –±–ª–æ–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—é —Å—Ç—Ä–æ–∫—É
                json_content = response_text.strip()

            # –ü–∞—Ä—Å–∏–º JSON
            return json.loads(json_content)

        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON: {e}")
            logger.error(f"–ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: {response_text[:200]}...")
            raise
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            raise
    
    def _process_calculation_response(self, llm_response: Any, package: Dict,
                                    works: List[Dict]) -> Dict:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç LLM —Å —Ä–∞—Å—á–µ—Ç–∞–º–∏
        """
        try:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º —Ç–æ–≥–æ, —á—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–π—Ç–∏ —Å—Ç—Ä–æ–∫–∞ —Å markdown
            if isinstance(llm_response, str):
                # –°—ã—Ä–∞—è —Å—Ç—Ä–æ–∫–∞, –≤–æ–∑–º–æ–∂–Ω–æ —Å markdown –±–ª–æ–∫–æ–º ```json
                response_data = self._clean_and_parse_json(llm_response)
            elif isinstance(llm_response, dict):
                # –£–∂–µ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç
                response_data = llm_response
            else:
                raise ValueError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø –æ—Ç–≤–µ—Ç–∞: {type(llm_response)}")

            calculation = response_data.get('calculation', {})
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            final_unit = calculation.get('unit', '—à—Ç')
            
            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
            raw_quantity = calculation.get('quantity', 0)
            try:
                if isinstance(raw_quantity, str):
                    final_quantity = float(raw_quantity)
                elif isinstance(raw_quantity, (int, float)):
                    final_quantity = float(raw_quantity)
                else:
                    final_quantity = 0.0
            except (ValueError, TypeError):
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å quantity –∫ —á–∏—Å–ª—É: {raw_quantity}, –∏—Å–ø–æ–ª—å–∑—É–µ–º 0")
                final_quantity = 0.0
                
            # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Å—Ç–∞—Ä—ã–π –∏ –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞
            calculation_logic = calculation.get('calculation_logic', '–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç')
            applied_rule = calculation.get('applied_rule', '–ù–ï–û–ü–†–ï–î–ï–õ–ï–ù–û')
            calculation_steps = calculation.get('calculation_steps', [])
            component_analysis = calculation.get('component_analysis', [])
            reasoning = calculation.get('reasoning', {})

            # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
            if applied_rule != '–ù–ï–û–ü–†–ï–î–ï–õ–ï–ù–û' and calculation_steps:
                calculation_logic = f"{applied_rule}: {', '.join(calculation_steps[:2])}"  # –ü–µ—Ä–≤—ã–µ 2 —à–∞–≥–∞ –∫–∞–∫ –ª–æ–≥–∏–∫–∞

            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = package.copy()
            result['calculations'] = {
                'unit': final_unit,
                'quantity': final_quantity,
                'calculation_logic': calculation_logic,
                'applied_rule': applied_rule,
                'calculation_steps': calculation_steps,
                'component_analysis': component_analysis,
                'reasoning': reasoning,
                'source_works_count': len(works),
                'calculated_at': datetime.now().isoformat()
            }
            
            return result
            
        except (json.JSONDecodeError, KeyError, AttributeError, ValueError) as e:
            logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ —Ä–∞—Å—á–µ—Ç–æ–≤: {e}")
            logger.error(f"–°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini: {llm_response}")
            raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç —Ä–∞—Å—á–µ—Ç–æ–≤ –æ—Ç Gemini: {e}")
    
    def _update_truth_data(self, truth_data: Dict, calculated_packages: List[Dict], truth_path: str):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç true.json —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ä–∞—Å—á–µ—Ç–æ–≤
        –î–æ–±–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è Excel –æ—Ç—á–µ—Ç–∞
        """
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ work_packages
        current_packages = truth_data.get('results', {}).get('work_packages', [])
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ package_id
        calculations_dict = {}
        for calc_package in calculated_packages:
            package_id = calc_package.get('package_id')
            calculations = calc_package.get('calculations', {})
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤–∫–ª—é—á–∞—è –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è –¥–ª—è –ü–¢–û
            calculations_dict[package_id] = {
                'unit': calculations.get('unit', '—à—Ç'),
                'quantity': calculations.get('quantity', 0),
                'calculation_logic': calculations.get('calculation_logic', '–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç'),
                'component_analysis': calculations.get('component_analysis', [])
            }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–∂–¥—ã–π –ø–∞–∫–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        for package in current_packages:
            package_id = package.get('package_id')
            if package_id in calculations_dict:
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å–∞–º–æ–µ –Ω—É–∂–Ω–æ–µ
                package['volume_data'] = calculations_dict[package_id]
        
        # –û–±–Ω–æ–≤–ª—è–µ–º work_packages –≤ true.json
        truth_data['results']['work_packages'] = current_packages
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        units_summary = defaultdict(float)
        for calc_data in calculations_dict.values():
            unit = calc_data['unit']
            quantity = calc_data['quantity']
            
            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
            try:
                if isinstance(quantity, str):
                    quantity = float(quantity)
                elif isinstance(quantity, (int, float)):
                    quantity = float(quantity)
                else:
                    quantity = 0.0
            except (ValueError, TypeError):
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫ —á–∏—Å–ª—É: {quantity}")
                quantity = 0.0
            
            if unit and quantity:
                units_summary[unit] += quantity
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        truth_data['results']['volume_summary'] = {
            'total_packages': len(calculated_packages),
            'units_breakdown': dict(units_summary),
            'calculated_at': datetime.now().isoformat()
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with open(truth_path, 'w', encoding='utf-8') as f:
            json.dump(truth_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω true.json —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è {len(calculated_packages)} –ø–∞–∫–µ—Ç–æ–≤")
        
        # –ö–æ–ø–∏—Ä—É–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π true.json –≤ –ø–∞–ø–∫—É –∞–≥–µ–Ω—Ç–∞
        agent_folder = os.path.join(os.path.dirname(truth_path), "6_counter")
        agent_truth_copy = os.path.join(agent_folder, "updated_true.json")
        
        with open(agent_truth_copy, 'w', encoding='utf-8') as f:
            json.dump(truth_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"üìÅ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π true.json –≤ {agent_truth_copy}")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–≥–µ–Ω—Ç–∞ –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ –∫–æ–¥–∞
async def run_counter(project_path: str) -> Dict[str, Any]:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –∞–≥–µ–Ω—Ç–∞ counter –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
    
    Args:
        project_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞
    """
    agent = WorkVolumeCalculator()
    return await agent.process(project_path)

if __name__ == "__main__":
    import sys
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) > 1:
        test_project_path = sys.argv[1]
    else:
        test_project_path = "/home/imort/Herzog_v3/projects/34975055/d490876a"
    
    if os.path.exists(test_project_path):
        print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ counter")
        result = asyncio.run(run_counter(test_project_path))
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
    else:
        print(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {test_project_path}")

================================================================================

## –§–ê–ô–õ: src/ai_agents/new_agent_runner.py
------------------------------------------------------------
"""
–ù–æ–≤—ã–π runner –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ HerZog v3.0
–ó–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–µ –∞–≥–µ–Ω—Ç—ã: work_packager, works_to_packages, counter, scheduler_and_staffer
"""

import json
import logging
import os
import asyncio
from typing import Dict, Any, Optional

# –ò–º–ø–æ—Ä—Ç –Ω–∞—à–∏—Ö –Ω–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
from .work_packager import run_work_packager
from .works_to_packages import run_works_to_packages
from .counter import run_counter
from .scheduler_and_staffer import run_scheduler_and_staffer

logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
NEW_AGENTS = {
    "work_packager": {
        "name": "–ê—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä - —Å–æ–∑–¥–∞–Ω–∏–µ –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç",
        "function": run_work_packager,
        "description": "–°–æ–∑–¥–∞–µ—Ç —É–∫—Ä—É–ø–Ω–µ–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç –∏–∑ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–∞–±–æ—Ç"
    },
    "works_to_packages": {
        "name": "–†–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–ª—å - –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ —Ä–∞–±–æ—Ç –∫ –ø–∞–∫–µ—Ç–∞–º", 
        "function": run_works_to_packages,
        "description": "–†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞–∂–¥—É—é —Ä–∞–±–æ—Ç—É –ø–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º –ø–∞–∫–µ—Ç–∞–º"
    },
    "counter": {
        "name": "–°–º–µ—Ç—á–∏–∫ - —Ä–∞—Å—á–µ—Ç –æ–±—ä–µ–º–æ–≤",
        "function": run_counter,
        "description": "–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–º—ã –¥–ª—è –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç"
    },
    "scheduler_and_staffer": {
        "name": "–°—É–ø–µ—Ä-–ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ - –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω",
        "function": run_scheduler_and_staffer,
        "description": "–°–æ–∑–¥–∞–µ—Ç –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∞"
    }
}

async def run_new_agent(agent_name: str, project_path: str) -> Dict[str, Any]:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–¥–∏–Ω –∏–∑ –Ω–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
    
    Args:
        agent_name: –ò–º—è –∞–≥–µ–Ω—Ç–∞ (work_packager, works_to_packages, counter, scheduler_and_staffer)
        project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞
    """
    
    if agent_name not in NEW_AGENTS:
        return {
            'success': False,
            'error': f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞–≥–µ–Ω—Ç: {agent_name}",
            'available_agents': list(NEW_AGENTS.keys())
        }
    
    agent_config = NEW_AGENTS[agent_name]
    
    logger.info(f"ü§ñ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞: {agent_config['name']}")
    logger.info(f"üìù {agent_config['description']}")
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≥–µ–Ω—Ç–∞
        result = await agent_config['function'](project_path)
        
        if result.get('success'):
            logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç {agent_name} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        else:
            logger.error(f"‚ùå –ê–≥–µ–Ω—Ç {agent_name} –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: {result.get('error')}")
        
        return result
        
    except Exception as e:
        error_result = {
            'success': False,
            'error': str(e),
            'agent': agent_name
        }
        logger.error(f"üí• –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –≤ –∞–≥–µ–Ω—Ç–µ {agent_name}: {e}")
        return error_result

async def run_new_pipeline(project_path: str, start_from: str = "work_packager") -> Dict[str, Any]:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –Ω–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
    
    Args:
        project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        start_from: –° –∫–∞–∫–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ –Ω–∞—á–∞—Ç—å
        
    Returns:
        –û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞–π–ø–ª–∞–π–Ω–∞
    """
    
    # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–æ–≤
    pipeline_sequence = [
        "work_packager",
        "works_to_packages", 
        "counter",
        "scheduler_and_staffer"
    ]
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å –∫–∞–∫–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ –Ω–∞—á–∏–Ω–∞—Ç—å
    try:
        start_index = pipeline_sequence.index(start_from)
        agents_to_run = pipeline_sequence[start_index:]
    except ValueError:
        return {
            'success': False,
            'error': f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å—Ç–∞—Ä—Ç–æ–≤—ã–π –∞–≥–µ–Ω—Ç: {start_from}",
            'available_agents': pipeline_sequence
        }
    
    logger.info(f"üèóÔ∏è –ó–∞–ø—É—Å–∫ –Ω–æ–≤–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ HerZog v3.0")
    logger.info(f"üìÇ –ü—Ä–æ–µ–∫—Ç: {project_path}")
    logger.info(f"üéØ –ê–≥–µ–Ω—Ç—ã: {' ‚Üí '.join(agents_to_run)}")
    
    pipeline_result = {
        'success': False,
        'project_path': project_path,
        'agents_completed': [],
        'agents_failed': [],
        'start_from': start_from,
        'total_agents': len(agents_to_run),
        'results': {}
    }
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≥–µ–Ω—Ç–æ–≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
    for agent_name in agents_to_run:
        logger.info(f"\n{'='*50}")
        logger.info(f"üöÄ –≠–¢–ê–ü: {agent_name.upper()}")
        logger.info(f"{'='*50}")
        
        agent_result = await run_new_agent(agent_name, project_path)
        pipeline_result['results'][agent_name] = agent_result
        
        if agent_result.get('success'):
            pipeline_result['agents_completed'].append(agent_name)
            logger.info(f"‚úÖ –≠—Ç–∞–ø {agent_name} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        else:
            pipeline_result['agents_failed'].append(agent_name)
            logger.error(f"‚ùå –≠—Ç–∞–ø {agent_name} –ø—Ä–æ–≤–∞–ª–µ–Ω: {agent_result.get('error')}")
            
            # –ü—Ä–µ—Ä—ã–≤–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω –ø—Ä–∏ –æ—à–∏–±–∫–µ
            pipeline_result['error'] = f"–ü–∞–π–ø–ª–∞–π–Ω –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ —ç—Ç–∞–ø–µ {agent_name}: {agent_result.get('error')}"
            return pipeline_result
    
    # –ï—Å–ª–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞ - –≤—Å–µ –∞–≥–µ–Ω—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ
    pipeline_result['success'] = True
    logger.info(f"\nüéâ –ü–ê–ô–ü–õ–ê–ô–ù –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
    logger.info(f"‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–æ –∞–≥–µ–Ω—Ç–æ–≤: {len(pipeline_result['agents_completed'])}")
    
    return pipeline_result

def run_new_agent_sync(agent_name: str, project_path: str) -> bool:
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–≥–µ–Ω—Ç–∞ (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ç–∞—Ä—ã–º –∫–æ–¥–æ–º)
    
    Args:
        agent_name: –ò–º—è –∞–≥–µ–Ω—Ç–∞
        project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        
    Returns:
        True –µ—Å–ª–∏ –∞–≥–µ–Ω—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ
    """
    try:
        result = asyncio.run(run_new_agent(agent_name, project_path))
        return result.get('success', False)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±–µ—Ä—Ç–∫–µ –¥–ª—è {agent_name}: {e}")
        return False

def get_new_agent_info(agent_name: Optional[str] = None) -> Dict[str, Any]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–æ–≤—ã—Ö –∞–≥–µ–Ω—Ç–∞—Ö
    
    Args:
        agent_name: –ò–º—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ –∏–ª–∏ None –¥–ª—è –≤—Å–µ—Ö
        
    Returns:
        –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–≥–µ–Ω—Ç–µ(–∞—Ö)
    """
    if agent_name:
        if agent_name in NEW_AGENTS:
            return NEW_AGENTS[agent_name]
        else:
            return {'error': f'–ê–≥–µ–Ω—Ç {agent_name} –Ω–µ –Ω–∞–π–¥–µ–Ω'}
    else:
        return NEW_AGENTS

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ runner'–∞
    import sys
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    if len(sys.argv) >= 3:
        # –ó–∞–ø—É—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞: python new_agent_runner.py work_packager /path/to/project
        agent_name = sys.argv[1]
        project_path = sys.argv[2]
        
        print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞: {agent_name}")
        print(f"üìÇ –ü—Ä–æ–µ–∫—Ç: {project_path}")
        
        result = asyncio.run(run_new_agent(agent_name, project_path))
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
    elif len(sys.argv) == 2:
        # –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞: python new_agent_runner.py /path/to/project  
        project_path = sys.argv[1]
        
        print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞")
        print(f"üìÇ –ü—Ä–æ–µ–∫—Ç: {project_path}")
        
        result = asyncio.run(run_new_pipeline(project_path))
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
    else:
        # –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞–≥–µ–Ω—Ç–∞—Ö
        print("ü§ñ –ù–æ–≤—ã–µ –∞–≥–µ–Ω—Ç—ã HerZog v3.0:")
        print("=" * 50)
        
        for agent_name, config in NEW_AGENTS.items():
            print(f"üì¶ {agent_name}:")
            print(f"   –ù–∞–∑–≤–∞–Ω–∏–µ: {config['name']}")
            print(f"   –û–ø–∏—Å–∞–Ω–∏–µ: {config['description']}")
            print()
        
        print("üí° –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
        print("   python new_agent_runner.py work_packager /path/to/project  # –æ–¥–∏–Ω –∞–≥–µ–Ω—Ç")
        print("   python new_agent_runner.py /path/to/project               # –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω")

================================================================================

## –§–ê–ô–õ: src/ai_agents/scheduler_and_staffer.py
------------------------------------------------------------
"""
–ê–≥–µ–Ω—Ç 4: "–°—É–ø–µ—Ä-–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫" (scheduler_and_staffer.py)
–°–æ–∑–¥–∞–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç: —Å—Ä–æ–∫–∏, –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª—é–¥–µ–π
"""

import json
import os
import asyncio
import logging
import math
import uuid
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from collections import defaultdict

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –Ω–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã
from ..shared.gemini_client import gemini_client
from ..shared.truth_initializer import update_pipeline_status

logger = logging.getLogger(__name__)

class SchedulerAndStaffer:
    """
    –ê–≥–µ–Ω—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∞
    –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–æ–±–ª—é–¥–µ–Ω–∏–µ –ª–∏–º–∏—Ç–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ä–∞–±–æ—á–∏—Ö
    """
    
    def __init__(self, batch_size: int = 12):
        self.agent_name = "scheduler_and_staffer"
        self.batch_size = batch_size

    
    async def process(self, project_path: str) -> Dict[str, Any]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ —Å–æ–∑–¥–∞–Ω–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∞
        
        Args:
            project_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        try:
            logger.info(f"üîÑ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ {self.agent_name}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º true.json
            truth_path = os.path.join(project_path, "true.json")
            if not os.path.exists(truth_path):
                raise FileNotFoundError(f"–§–∞–π–ª true.json –Ω–µ –Ω–∞–π–¥–µ–Ω: {truth_path}")
            
            with open(truth_path, 'r', encoding='utf-8') as f:
                truth_data = json.load(f)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∞–≥–µ–Ω—Ç–∞
            update_pipeline_status(truth_path, self.agent_name, "in_progress")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞
            agent_folder = os.path.join(project_path, "7_scheduler_and_staffer")
            os.makedirs(agent_folder, exist_ok=True)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            work_packages = truth_data.get('results', {}).get('work_packages', [])
            timeline_blocks = truth_data.get('timeline_blocks', [])
            project_inputs = truth_data.get('project_inputs', {})
            
            if not work_packages:
                raise Exception("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç —Å —Ä–∞—Å—á–µ—Ç–∞–º–∏. –°–Ω–∞—á–∞–ª–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–ø—É—â–µ–Ω counter")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–∞–∫–µ—Ç—ã –∏–º–µ—é—Ç volume_data
            packages_with_calcs = [p for p in work_packages if 'volume_data' in p]
            if not packages_with_calcs:
                raise Exception("–ü–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç –Ω–µ –∏–º–µ—é—Ç volume_data. –°–Ω–∞—á–∞–ª–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–ø—É—â–µ–Ω counter")
            
            logger.info(f"üìä –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –¥–ª—è {len(packages_with_calcs)} –ø–∞–∫–µ—Ç–æ–≤")
            logger.info(f"üìÖ –í—Ä–µ–º–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏: {len(timeline_blocks)} –Ω–µ–¥–µ–ª—å")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
            workforce_range = project_inputs.get('workforce_range', {'min': 10, 'max': 20})
            user_directives = project_inputs.get('agent_directives', {})
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∏—Ä–µ–∫—Ç–∏–≤—ã strategist + foreman –≤ –æ–¥–Ω—É
            scheduler_and_staffer_directive = (
                user_directives.get('scheduler_and_staffer') or
                f"{user_directives.get('strategist', '')} {user_directives.get('foreman', '')}".strip()
            )
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç
            prompt_template = self._load_prompt()
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –ø–∞–∫–µ—Ç–∞—Ö –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
            compact_packages = self._prepare_compact_packages(packages_with_calcs, project_path)

            # –†–∞–∑–±–∏–≤–∞–µ–º –ø–∞–∫–µ—Ç—ã –Ω–∞ –±–∞—Ç—á–∏ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
            scheduled_packages = []
            total_batches = math.ceil(len(compact_packages) / self.batch_size)

            for batch_num in range(total_batches):
                start_idx = batch_num * self.batch_size
                end_idx = min((batch_num + 1) * self.batch_size, len(compact_packages))
                batch_packages = compact_packages[start_idx:end_idx]

                logger.info(f"üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ {batch_num + 1}/{total_batches} ({len(batch_packages)} –ø–∞–∫–µ—Ç–æ–≤)")

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á
                batch_result = await self._process_batch(
                    batch_packages, timeline_blocks, workforce_range,
                    scheduler_and_staffer_directive, prompt_template,
                    batch_num, agent_folder
                )

                scheduled_packages.extend(batch_result)

            logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(scheduled_packages)} –ø–∞–∫–µ—Ç–æ–≤ –≤ {total_batches} –±–∞—Ç—á–∞—Ö")
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ –ø–µ—Ä—Å–æ–Ω–∞–ª—É
            validation_result = self._validate_workforce_constraints(
                scheduled_packages, timeline_blocks, workforce_range
            )
            
            if not validation_result['valid']:
                logger.warning(f"‚ö†Ô∏è –ù–∞—Ä—É—à–µ–Ω–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ –ø–µ—Ä—Å–æ–Ω–∞–ª—É: {validation_result['violations']}")
                # –ü—ã—Ç–∞–µ–º—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–∏—Ç—å
                scheduled_packages = self._fix_workforce_constraints(
                    scheduled_packages, timeline_blocks, workforce_range
                )
            
            # –û–±–Ω–æ–≤–ª—è–µ–º true.json —Å —Ñ–∏–Ω–∞–ª—å–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            self._update_truth_data(truth_data, scheduled_packages, truth_path)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ
            update_pipeline_status(truth_path, self.agent_name, "completed")
            
            logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç {self.agent_name} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
            logger.info(f"üìä –°–æ–∑–¥–∞–Ω –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω –¥–ª—è {len(scheduled_packages)} –ø–∞–∫–µ—Ç–æ–≤")
            
            return {
                'success': True,
                'packages_scheduled': len(scheduled_packages),
                'workforce_valid': validation_result['valid'],
                'agent': self.agent_name
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≥–µ–Ω—Ç–∞ {self.agent_name}: {e}")
            # –ü—ã—Ç–∞–µ–º—Å—è –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –Ω–∞ –æ—à–∏–±–∫—É
            try:
                update_pipeline_status(truth_path, self.agent_name, "error")
            except:
                pass
            
            return {
                'success': False,
                'error': str(e),
                'agent': self.agent_name
            }
    
    def _load_prompt(self) -> str:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ–º–ø—Ç-—à–∞–±–ª–æ–Ω –¥–ª—è –∞–≥–µ–Ω—Ç–∞
        """
        prompt_path = os.path.join(
            os.path.dirname(__file__), "..", "prompts", "scheduler_and_staffer_prompt.txt"
        )
        
        try:
            with open(prompt_path, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            logger.warning(f"–ü—Ä–æ–º–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {prompt_path}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π")
            return self._get_default_prompt()
    
    def _get_default_prompt(self) -> str:
        """
        –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç, –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        return """
# –†–û–õ–¨
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–º—É –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é.

# –ó–ê–î–ê–ß–ê
–°–æ–∑–¥–∞–π —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏–≤ –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç –ø–æ –Ω–µ–¥–µ–ª—è–º –∏ –Ω–∞–∑–Ω–∞—á–∏–≤ –ø–µ—Ä—Å–æ–Ω–∞–ª.

# –í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï
–í –∑–∞–ø—Ä–æ—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Ç—ã –ø–æ–ª—É—á–∏—à—å JSON-–æ–±—ä–µ–∫—Ç —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –∫–ª—é—á–∞–º–∏:
- "work_packages": –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç —Å –∏—Ö —Å–æ—Å—Ç–∞–≤–æ–º
- "timeline_blocks": –¥–æ—Å—Ç—É–ø–Ω—ã–µ –Ω–µ–¥–µ–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞
- "workforce_range": –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ –ø–µ—Ä—Å–æ–Ω–∞–ª—É
- "user_directive": –¥–∏—Ä–µ–∫—Ç–∏–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

# –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø
1. **–õ–∏–º–∏—Ç—ã –ø–µ—Ä—Å–æ–Ω–∞–ª–∞ (—Å—É–º–º–∞ –ø–æ –≤—Å–µ–º –ø–∞–∫–µ—Ç–∞–º –≤ –Ω–µ–¥–µ–ª—é):** –í –ø—Ä–µ–¥–µ–ª–∞—Ö –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ workforce_range.
2. **–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** –î–µ–º–æ–Ω—Ç–∞–∂ -> –ö–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ -> –ò–Ω–∂–µ–Ω–µ—Ä–Ω—ã–µ —Å–µ—Ç–∏ -> –û—Ç–¥–µ–ª–∫–∞.

# –§–û–†–ú–ê–¢ –í–´–í–û–î–ê (–°–¢–†–û–ì–û JSON)
{
    "scheduled_packages": [
        {
            "package_id": "pkg_001",
            "schedule_blocks": [1, 2],
            "progress_per_block": { "1": 60, "2": 40 },
            "staffing_per_block": { "1": 10, "2": 8 },
            "scheduling_reasoning": {
                "why_these_weeks": "–ö—Ä–∞—Ç–∫–æ.",
                "why_this_duration": "–ö—Ä–∞—Ç–∫–æ.",
                "why_this_sequence": "–ö—Ä–∞—Ç–∫–æ.",
                "why_this_staffing": "–ö—Ä–∞—Ç–∫–æ."
            }
        }
    ]
}

# –ü–†–û–í–ï–†–ö–ò –ü–ï–†–ï–î –û–¢–í–ï–¢–û–ú
1. **–õ–∏–º–∏—Ç—ã:** –°—É–º–º–∞ `staffing_per_block` –¥–ª—è –ö–ê–ñ–î–û–ô –Ω–µ–¥–µ–ª–∏ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ workforce_range.
2. **100%:** –°—É–º–º–∞ `progress_per_block` –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞–∫–µ—Ç–∞ —Ä–∞–≤–Ω–∞ 100.
3. **–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:** –ü–æ–ª—è `scheduling_reasoning` –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã.
"""
    
    def _add_salt_to_prompt(self, prompt: str) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—É—é —Å–æ–ª—å –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è RECITATION."""
        unique_id = str(uuid.uuid4())[:8]
        session_id = str(uuid.uuid4())[:12]
        prefix = f"# TASK_ID: {unique_id} | SESSION: {session_id} | MODE: STRICT_JSON_OUTPUT\n"
        prefix += f"# ANTI_RECITATION_SALT: {session_id}{unique_id}\n"
        suffix = f"\n# END_TASK: {unique_id} | VERIFY: {session_id}"
        return prefix + prompt + suffix

    def _format_prompt(self, input_data: Dict, prompt_template: str) -> Tuple[str, str]:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–º–ø—Ç —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ system_instruction –∏ user_prompt

        Returns:
            Tuple[str, str]: (system_instruction, user_prompt)
        """
        # System instruction - —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç –±–µ–∑ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤
        system_instruction = prompt_template

        # User prompt - JSON —Å –¥–∞–Ω–Ω—ã–º–∏ + –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–ª–µ–Ω–∏–µ –ø—Ä–æ—Ç–∏–≤ RECITATION
        anti_recitation_id = str(uuid.uuid4())[:10]
        user_prompt_data = {
            '_meta': {
                'task_type': 'schedule_planning',
                'session_id': anti_recitation_id,
                'timestamp': datetime.now().isoformat()
            },
            'work_packages': input_data['work_packages'],
            'timeline_blocks': input_data['timeline_blocks'],
            'workforce_range': input_data['workforce_range'],
            'user_directive': input_data['user_directive']
        }
        user_prompt = json.dumps(user_prompt_data, ensure_ascii=False, indent=2)

        return system_instruction, user_prompt

    async def _process_batch(self, batch_packages: List[Dict], timeline_blocks: List[Dict],
                           workforce_range: Dict, user_directive: str, prompt_template: str,
                           batch_num: int, agent_folder: str) -> List[Dict]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –±–∞—Ç—á –ø–∞–∫–µ—Ç–æ–≤ –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±–∞—Ç—á–∞
        input_data = {
            'work_packages': batch_packages,
            'timeline_blocks': timeline_blocks,
            'workforce_range': workforce_range,
            'user_directive': user_directive
        }

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è LLM
        system_instruction, user_prompt = self._format_prompt(input_data, prompt_template)

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–ª—å –∫ —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è RECITATION
        salted_system_instruction = self._add_salt_to_prompt(system_instruction)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (–∫–∞–∫ –≤ work_packager)
        debug_data = {
            "system_instruction": salted_system_instruction,
            "user_prompt": user_prompt
        }
        batch_input_path = os.path.join(agent_folder, f"batch_{batch_num+1:03d}_input.json")
        with open(batch_input_path, 'w', encoding='utf-8') as f:
            json.dump(debug_data, f, ensure_ascii=False, indent=2)

        # –í—ã–∑—ã–≤–∞–µ–º Gemini API —Å system_instruction –∏ user_prompt
        logger.info(f"üì° –û—Ç–ø—Ä–∞–≤–∫–∞ –±–∞—Ç—á–∞ {batch_num + 1} –≤ Gemini (scheduler_and_staffer -> gemini-2.5-pro)")
        gemini_response = await gemini_client.generate_response(
            prompt=user_prompt,
            system_instruction=salted_system_instruction,
            agent_name="scheduler_and_staffer"
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –æ—Ç LLM
        batch_response_path = os.path.join(agent_folder, f"batch_{batch_num+1:03d}_response.json")
        with open(batch_response_path, 'w', encoding='utf-8') as f:
            json.dump(gemini_response, f, ensure_ascii=False, indent=2)

        if not gemini_response.get('success', False):
            logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê Gemini API –¥–ª—è –±–∞—Ç—á–∞ {batch_num + 1}: {gemini_response.get('error')}")
            raise Exception(f"Gemini API –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –±–∞—Ç—á {batch_num + 1}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–æ–º–ø—Ç –∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ.")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç
        scheduled_batch = self._process_scheduling_response(
            gemini_response['response'], batch_packages, timeline_blocks, workforce_range
        )

        return scheduled_batch


    def _process_scheduling_response(self, llm_response: Any, original_packages: List[Dict],
                                   timeline_blocks: List[Dict], workforce_range: Dict) -> List[Dict]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç LLM —Å –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–º –ø–ª–∞–Ω–æ–º
        """
        try:
            if isinstance(llm_response, str):
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–ø—Ä—è–º—É—é –ø–∞—Ä—Å–∏—Ç—å
                response_data = json.loads(llm_response)
            else:
                response_data = llm_response
            
            scheduled_packages = response_data.get('scheduled_packages', [])
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∏ –æ–±–æ–≥–∞—â–∞–µ–º –∫–∞–∂–¥—ã–π –ø–∞–∫–µ—Ç
            validated_packages = []
            for pkg in scheduled_packages:
                validated_pkg = self._validate_and_fix_package_schedule(pkg, timeline_blocks)
                validated_packages.append(validated_pkg)
            
            logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(validated_packages)} –ø–∞–∫–µ—Ç–æ–≤ –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM")
            return validated_packages
            
        except (json.JSONDecodeError, KeyError, AttributeError) as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞: {e}")
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            if isinstance(llm_response, str):
                response_length = len(llm_response)
                lines_count = llm_response.count('\n')
                logger.error(f"üìè –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {response_length} —Å–∏–º–≤–æ–ª–æ–≤, —Å—Ç—Ä–æ–∫: {lines_count}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                tail = llm_response[-200:] if len(llm_response) > 200 else llm_response
                logger.error(f"üìÑ –ü–æ—Å–ª–µ–¥–Ω–∏–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞: ...{tail}")
                
                # –ü—Ä–æ–±—É–µ–º –ø–æ—á–∏–Ω–∏—Ç—å –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π JSON
                fixed_response = self._try_fix_truncated_json(llm_response)
                if fixed_response:
                    try:
                        response_data = json.loads(fixed_response)
                        scheduled_packages = response_data.get('scheduled_packages', [])
                        
                        validated_packages = []
                        for pkg in scheduled_packages:
                            validated_pkg = self._validate_and_fix_package_schedule(pkg, timeline_blocks)
                            validated_packages.append(validated_pkg)
                        
                        logger.info(f"üîß –£—Å–ø–µ—à–Ω–æ –ø–æ—á–∏–Ω–∏–ª–∏ JSON –∏ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∏ {len(validated_packages)} –ø–∞–∫–µ—Ç–æ–≤")
                        return validated_packages
                        
                    except Exception as fix_error:
                        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—á–∏–Ω–∏—Ç—å JSON: {fix_error}")
            
            logger.warning(f"üîÑ –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ fallback –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è {len(original_packages)} –ø–∞–∫–µ—Ç–æ–≤")
            return self._create_fallback_schedule(original_packages, timeline_blocks, workforce_range)
    
    def _try_fix_truncated_json(self, broken_json: str) -> Optional[str]:
        """
        –ü—ã—Ç–∞–µ—Ç—Å—è –ø–æ—á–∏–Ω–∏—Ç—å –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π JSON –æ—Ç–≤–µ—Ç –æ—Ç LLM
        """
        try:
            # –û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–æ—á–∏–Ω–∫–∏:
            
            # 1. –£–±–∏—Ä–∞–µ–º –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –∫–æ–Ω—Ü–µ
            lines = broken_json.split('\n')
            
            # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É —Å —Ñ–∏–≥—É—Ä–Ω–æ–π —Å–∫–æ–±–∫–æ–π –∏–ª–∏ –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ–π —Å–∫–æ–±–∫–æ–π
            fixed_lines = []
            for i, line in enumerate(lines):
                # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –∫–ª—é—á –±–µ–∑ –∑–Ω–∞—á–µ–Ω–∏—è - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è
                if '"unit":' in line and line.strip().endswith('"unit":'):
                    logger.info("üîß –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ —Å 'unit:', –æ–±—Ä–µ–∑–∞–µ–º")
                    break
                    
                # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–µ–ø–æ–ª–Ω–∞—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–µ –∑–∞–∫—Ä—ã—Ç–∞ –∫–∞–≤—ã—á–∫–∞) - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è  
                if line.strip() and not line.strip().endswith((',', '{', '}', '[', ']', '"')):
                    logger.info(f"üîß –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞: '{line.strip()}', –æ–±—Ä–µ–∑–∞–µ–º")
                    break
                    
                fixed_lines.append(line)
            
            # 2. –ù–∞—Ö–æ–¥–∏–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –º–µ—Å—Ç–æ –¥–ª—è –∑–∞–∫—Ä—ã—Ç–∏—è JSON
            fixed_content = '\n'.join(fixed_lines)
            
            # 3. –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Ç–∫—Ä—ã—Ç—ã–µ —Å–∫–æ–±–∫–∏ –∏ –∑–∞–∫—Ä—ã–≤–∞–µ–º –∏—Ö
            open_braces = fixed_content.count('{') - fixed_content.count('}')
            open_brackets = fixed_content.count('[') - fixed_content.count(']')
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–µ —Å–∫–æ–±–∫–∏
            closing = ''
            for _ in range(open_brackets):
                closing += '\n    ]'
            for _ in range(open_braces):
                closing += '\n  }'
            
            fixed_json = fixed_content + closing
            
            # 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–Ω—ã–π
            json.loads(fixed_json)  # –ï—Å–ª–∏ –Ω–µ –≤–∞–ª–∏–¥–Ω—ã–π - exception
            
            logger.info("üîß JSON —É—Å–ø–µ—à–Ω–æ –ø–æ—á–∏–Ω–µ–Ω")
            return fixed_json
            
        except Exception as e:
            logger.error(f"üîß –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –ø–æ—á–∏–Ω–∏—Ç—å JSON: {e}")
            return None
    
    def _validate_and_fix_package_schedule(self, package: Dict, timeline_blocks: List[Dict]) -> Dict:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω –¥–ª—è –ø–∞–∫–µ—Ç–∞
        """
        package_id = package.get('package_id', 'unknown')
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è schedule_blocks
        schedule_blocks = package.get('schedule_blocks', [])
        max_week = len(timeline_blocks)
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è schedule_blocks
        valid_blocks = []
        for week in schedule_blocks:
            try:
                week_num = int(week) if isinstance(week, str) else week
                if 1 <= week_num <= max_week:
                    valid_blocks.append(week_num)
            except (ValueError, TypeError):
                continue
        schedule_blocks = valid_blocks
        
        if not schedule_blocks:
            schedule_blocks = [1]  # fallback
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è progress_per_block
        progress_per_block = package.get('progress_per_block', {})
        total_progress = 0
        
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫–ª—é—á–∏ –∫ —Å—Ç—Ä–æ–∫–æ–≤–æ–º—É –≤–∏–¥—É –∏ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        normalized_progress = {}
        for week in schedule_blocks:
            week_str = str(week)
            progress = progress_per_block.get(week_str, progress_per_block.get(week, 0))
            normalized_progress[week_str] = max(0, min(100, progress))
            total_progress += normalized_progress[week_str]
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫ 100%
        if total_progress != 100 and total_progress > 0:
            scale_factor = 100.0 / total_progress
            for week_str in normalized_progress:
                normalized_progress[week_str] = round(normalized_progress[week_str] * scale_factor)
        elif total_progress == 0:
            # –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
            progress_per_week = round(100.0 / len(schedule_blocks))
            for week in schedule_blocks:
                normalized_progress[str(week)] = progress_per_week
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è staffing_per_block
        staffing_per_block = package.get('staffing_per_block', {})
        normalized_staffing = {}
        
        for week in schedule_blocks:
            week_str = str(week)
            staff = staffing_per_block.get(week_str, staffing_per_block.get(week, 1))
            normalized_staffing[week_str] = max(1, min(20, staff))  # –û—Ç 1 –¥–æ 20 —á–µ–ª–æ–≤–µ–∫
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        scheduling_reasoning = package.get('scheduling_reasoning', {})
        if not scheduling_reasoning:
            # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
            scheduling_reasoning = {
                'why_these_weeks': f'–ü–∞–∫–µ—Ç –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω –Ω–∞ –Ω–µ–¥–µ–ª–∏ {schedule_blocks} –ø–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏',
                'why_this_duration': f'–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å {len(schedule_blocks)} –Ω–µ–¥–µ–ª—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–±—ä–µ–º—É —Ä–∞–±–æ—Ç',
                'why_this_sequence': '–†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ –Ω–µ–¥–µ–ª—è–º',
                'why_this_staffing': f'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä—Å–æ–Ω–∞–ª–∞ –æ—Ç {min(normalized_staffing.values())} –¥–æ {max(normalized_staffing.values())} —á–µ–ª–æ–≤–µ–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞ —Ä–∞–±–æ—Ç'
            }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞–∫–µ—Ç
        package['schedule_blocks'] = schedule_blocks
        package['progress_per_block'] = normalized_progress
        package['staffing_per_block'] = normalized_staffing
        package['scheduling_reasoning'] = scheduling_reasoning
        
        return package
    
    def _validate_workforce_constraints(self, packages: List[Dict], 
                                      timeline_blocks: List[Dict], workforce_range: Dict) -> Dict:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–±–ª—é–¥–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ –ø–µ—Ä—Å–æ–Ω–∞–ª—É
        """
        max_workers = workforce_range['max']
        violations = []
        weekly_totals = {}
        
        # –°—á–∏—Ç–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª—é–¥–µ–π –ø–æ –Ω–µ–¥–µ–ª—è–º
        for week_num in range(1, len(timeline_blocks) + 1):
            week_str = str(week_num)
            total_workers = 0
            
            for package in packages:
                staffing = package.get('staffing_per_block', {})
                if week_str in staffing:
                    total_workers += staffing[week_str]
            
            weekly_totals[week_str] = total_workers
            
            if total_workers > max_workers:
                violations.append(f"–ù–µ–¥–µ–ª—è {week_num}: {total_workers} > {max_workers}")
        
        return {
            'valid': len(violations) == 0,
            'violations': violations,
            'weekly_totals': weekly_totals
        }
    
    def _fix_workforce_constraints(self, packages: List[Dict], 
                                 timeline_blocks: List[Dict], workforce_range: Dict) -> List[Dict]:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–∞—Ä—É—à–µ–Ω–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ –ø–µ—Ä—Å–æ–Ω–∞–ª—É
        """
        max_workers = workforce_range['max']
        
        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞: –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —É–º–µ–Ω—å—à–∞–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª –≤ –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –Ω–µ–¥–µ–ª–∏
        for week_num in range(1, len(timeline_blocks) + 1):
            week_str = str(week_num)
            
            # –°—á–∏—Ç–∞–µ–º —Ç–µ–∫—É—â–∏–π –ø–µ—Ä—Å–æ–Ω–∞–ª –≤ —ç—Ç—É –Ω–µ–¥–µ–ª—é
            current_workers = 0
            week_packages = []
            
            for package in packages:
                staffing = package.get('staffing_per_block', {})
                if week_str in staffing:
                    current_workers += staffing[week_str]
                    week_packages.append(package)
            
            # –ï—Å–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ - –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —É–º–µ–Ω—å—à–∞–µ–º
            if current_workers > max_workers:
                scale_factor = max_workers / current_workers
                
                for package in week_packages:
                    original_staff = package['staffing_per_block'][week_str]
                    new_staff = max(1, round(original_staff * scale_factor))
                    package['staffing_per_block'][week_str] = new_staff
        
        return packages
    
    def _create_fallback_schedule(self, packages: List[Dict], timeline_blocks: List[Dict],
                                workforce_range: Dict) -> List[Dict]:
        """
        –°–æ–∑–¥–∞–µ—Ç –±–∞–∑–æ–≤—ã–π –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω, –µ—Å–ª–∏ AI –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª
        """
        fallback_packages = []
        max_workers = workforce_range['max']
        workers_per_package = max(1, max_workers // len(packages))
        
        for i, package in enumerate(packages):
            # –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞–∫–µ—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏
            weeks_per_package = max(1, len(timeline_blocks) // len(packages))
            start_week = (i * weeks_per_package) + 1
            end_week = min(start_week + weeks_per_package - 1, len(timeline_blocks))
            
            schedule_blocks = list(range(start_week, end_week + 1))
            
            # –†–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å
            progress_per_week = round(100.0 / len(schedule_blocks))
            progress_per_block = {}
            staffing_per_block = {}
            
            for week in schedule_blocks:
                week_str = str(week)
                progress_per_block[week_str] = progress_per_week
                staffing_per_block[week_str] = workers_per_package
            
            fallback_package = package.copy()
            fallback_package['schedule_blocks'] = schedule_blocks
            fallback_package['progress_per_block'] = progress_per_block
            fallback_package['staffing_per_block'] = staffing_per_block
            
            fallback_packages.append(fallback_package)
        
        return fallback_packages
    
    def _update_truth_data(self, truth_data: Dict, scheduled_packages: List[Dict], truth_path: str):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç true.json —Å —Ñ–∏–Ω–∞–ª—å–Ω—ã–º –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–º –ø–ª–∞–Ω–æ–º
        –°–û–•–†–ê–ù–Ø–Ø volume_data –æ—Ç Counter –∞–≥–µ–Ω—Ç–∞
        """
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –û–±—ä–µ–¥–∏–Ω—è–µ–º scheduled_packages —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (volume_data)
        existing_packages = truth_data.get('results', {}).get('work_packages', [])
        existing_by_id = {pkg.get('package_id'): pkg for pkg in existing_packages}
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ: –±–µ—Ä–µ–º –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω –∏–∑ scheduled_packages + volume_data –∏–∑ existing
        merged_packages = []
        for scheduled_pkg in scheduled_packages:
            package_id = scheduled_pkg.get('package_id')
            existing_pkg = existing_by_id.get(package_id, {})
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º: scheduled (–∫–∞–ª–µ–Ω–¥–∞—Ä—å) + existing (volume_data)
            merged_pkg = scheduled_pkg.copy()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º volume_data –æ—Ç Counter –∞–≥–µ–Ω—Ç–∞, –µ—Å–ª–∏ –µ—Å—Ç—å
            if 'volume_data' in existing_pkg:
                merged_pkg['volume_data'] = existing_pkg['volume_data']
                
            merged_packages.append(merged_pkg)
        
        truth_data['results']['work_packages'] = merged_packages
        
        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–º –ø–ª–∞–Ω–µ
        schedule_summary = self._create_schedule_summary(scheduled_packages, truth_data.get('timeline_blocks', []))
        
        truth_data['results']['schedule'] = schedule_summary['schedule_info']
        truth_data['results']['staffing'] = schedule_summary['staffing_info']
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞
        truth_data['metadata']['pipeline_completed'] = True
        truth_data['metadata']['final_updated_at'] = datetime.now().isoformat()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with open(truth_path, 'w', encoding='utf-8') as f:
            json.dump(truth_data, f, ensure_ascii=False, indent=2)
    
    def _create_schedule_summary(self, packages: List[Dict], timeline_blocks: List[Dict]) -> Dict:
        """
        –°–æ–∑–¥–∞–µ—Ç —Å–≤–æ–¥–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–º –ø–ª–∞–Ω–µ
        """
        weekly_workload = {}
        total_packages = len(packages)
        
        for week_num in range(1, len(timeline_blocks) + 1):
            week_str = str(week_num)
            active_packages = 0
            total_workers = 0
            
            for package in packages:
                if week_str in package.get('staffing_per_block', {}):
                    active_packages += 1
                    total_workers += package['staffing_per_block'][week_str]
            
            weekly_workload[week_str] = {
                'active_packages': active_packages,
                'total_workers': total_workers
            }
        
        return {
            'schedule_info': {
                'total_packages': total_packages,
                'project_duration_weeks': len(timeline_blocks),
                'weekly_workload': weekly_workload,
                'created_at': datetime.now().isoformat()
            },
            'staffing_info': {
                'peak_workforce': max([w['total_workers'] for w in weekly_workload.values()]) if weekly_workload else 0,
                'average_workforce': (sum([w['total_workers'] for w in weekly_workload.values()]) / len(weekly_workload)) if weekly_workload else 0,
                'workforce_utilization': weekly_workload
            }
        }
    
    def _prepare_compact_packages(self, packages_with_calcs: List[Dict], project_path: str) -> List[Dict]:
        """
        –ì–æ—Ç–æ–≤–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –ø–∞–∫–µ—Ç–∞—Ö –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞.
        –ò–°–ü–†–ê–í–õ–ï–ù–û: –¢–µ–ø–µ—Ä—å –∏–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ volume_data, –≤–∫–ª—é—á–∞—è component_analysis
        """
        compact_packages = []

        for package in packages_with_calcs:
            package_id = package.get('package_id', 'unknown')
            package_name = package.get('name', package.get('package_name', f'–ü–∞–∫–µ—Ç {package_id}'))

            # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ volume_data –≤ true.json
            volume_data = package.get('volume_data', {})

            if not volume_data:
                logger.warning(f"‚ö†Ô∏è –ü–∞–∫–µ—Ç {package_id} –Ω–µ –∏–º–µ–µ—Ç volume_data, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ–±—ä–µ–º–∞
            final_quantity = volume_data.get('quantity', 0)
            final_unit = volume_data.get('unit', '—à—Ç')

            # –ò–∑–≤–ª–µ–∫–∞–µ–º component_analysis –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–æ—Å—Ç–∞–≤–µ
            component_analysis = volume_data.get('component_analysis', [])
            source_works_count = len(component_analysis)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç
            calculation_logic = volume_data.get('calculation_logic', '')
            complexity = self._determine_package_complexity(package_name, calculation_logic)

            # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
            compact_package = {
                'package_id': package_id,
                'package_name': package_name,
                'total_volume': {
                    'quantity': final_quantity,
                    'unit': final_unit
                },
                'source_works_count': source_works_count,
                'component_analysis': component_analysis,
                'complexity': complexity
            }

            compact_packages.append(compact_package)
            logger.info(f"üì¶ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –ø–∞–∫–µ—Ç: {package_name} ({final_quantity} {final_unit}, {source_works_count} —Ä–∞–±–æ—Ç, —Å–ª–æ–∂–Ω–æ—Å—Ç—å: {complexity})")

        return compact_packages
    
    def _determine_package_complexity(self, package_name: str, logic: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø–∞–∫–µ—Ç–∞ —Ä–∞–±–æ—Ç –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤
        """
        name_lower = package_name.lower()
        logic_lower = logic.lower()
        
        # –í—ã—Å–æ–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        if any(keyword in name_lower for keyword in ['–¥–µ–º–æ–Ω—Ç–∞–∂', '—Ä–∞–∑–±–æ—Ä–∫–∞', '—Å–Ω–æ—Å']):
            return 'high'
        if any(keyword in logic_lower for keyword in ['–±–µ—Ç–æ–Ω', '–∂–µ–ª–µ–∑–æ–±–µ—Ç–æ–Ω', '–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏']):
            return 'high'
            
        # –°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å  
        if any(keyword in name_lower for keyword in ['—É—Å—Ç–∞–Ω–æ–≤–∫–∞', '–º–æ–Ω—Ç–∞–∂', '—Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ']):
            return 'medium'
        if any(keyword in logic_lower for keyword in ['—Å—Ç–µ–Ω', '–ø–µ—Ä–µ–∫—Ä—ã', '–æ—Å–Ω–æ–≤–∞–Ω–∏']):
            return 'medium'
            
        # –ù–∏–∑–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        if any(keyword in name_lower for keyword in ['–æ—Ç–¥–µ–ª–∫', '–ø–æ–∫—Ä–∞—Å–∫', '—à—Ç—É–∫–∞—Ç—É—Ä–∫', '–ø–æ–¥–≥–æ—Ç–æ–≤–∫']):
            return 'low'
        if any(keyword in logic_lower for keyword in ['–ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç', '–∫—Ä–∞—Å–∫', '—à—Ç—É–∫–∞—Ç—É—Ä']):
            return 'low'
            
        return 'medium'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–≥–µ–Ω—Ç–∞ –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ –∫–æ–¥–∞
async def run_scheduler_and_staffer(project_path: str, batch_size: int = 12) -> Dict[str, Any]:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –∞–≥–µ–Ω—Ç–∞ scheduler_and_staffer –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞

    Args:
        project_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 12)

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞
    """
    agent = SchedulerAndStaffer(batch_size=batch_size)
    return await agent.process(project_path)

if __name__ == "__main__":
    import sys
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) > 1:
        test_project_path = sys.argv[1]
    else:
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        test_project_path = "/home/imort/Herzog_v3/projects/34975055/d490876a"
    
    if os.path.exists(test_project_path):
        print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ scheduler_and_staffer")
        result = asyncio.run(run_scheduler_and_staffer(test_project_path))
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
    else:
        print(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {test_project_path}")


================================================================================

## –§–ê–ô–õ: src/ai_agents/work_packager.py
------------------------------------------------------------
"""
–ê–≥–µ–Ω—Ç 1: "–ê—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä" (work_packager.py)
–°–æ–∑–¥–∞–µ—Ç —É–∫—Ä—É–ø–Ω–µ–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç –¥–ª—è —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
"""

import json
import os
import asyncio
import logging
import uuid
from typing import Dict, List, Any, Optional
from datetime import datetime

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –Ω–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã
from ..shared.gemini_client import gemini_client
from ..shared.truth_initializer import update_pipeline_status

logger = logging.getLogger(__name__)

class WorkPackager:
    """
    –ê–≥–µ–Ω—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É–∫—Ä—É–ø–Ω–µ–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–∞–±–æ—Ç—ã –∏ —Å–æ–∑–¥–∞–µ—Ç –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞
    """
    
    def __init__(self):
        self.agent_name = "work_packager"

    def _add_salt_to_prompt(self, prompt: str) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—É—é —Å–æ–ª—å –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è RECITATION."""
        unique_id = str(uuid.uuid4())[:8]
        prefix = f"# ID: {unique_id} | –†–µ–∂–∏–º: JSON_STRICT\n"
        suffix = f"\n# –ö–æ–Ω—Ç—Ä–æ–ª—å: {unique_id}"
        return prefix + prompt + suffix
    
    async def process(self, project_path: str) -> Dict[str, Any]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        
        Args:
            project_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        try:
            logger.info(f"üîÑ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ {self.agent_name}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º true.json
            truth_path = os.path.join(project_path, "true.json")
            if not os.path.exists(truth_path):
                raise FileNotFoundError(f"–§–∞–π–ª true.json –Ω–µ –Ω–∞–π–¥–µ–Ω: {truth_path}")
            
            with open(truth_path, 'r', encoding='utf-8') as f:
                truth_data = json.load(f)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∞–≥–µ–Ω—Ç–∞
            update_pipeline_status(truth_path, self.agent_name, "in_progress")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            input_data = self._extract_input_data(truth_data)
            
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –∞–≥–µ–Ω—Ç–∞
            llm_input_path = os.path.join(project_path, "4_work_packager")
            os.makedirs(llm_input_path, exist_ok=True)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç
            prompt_template = self._load_prompt()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
            system_instruction, user_prompt = self._format_prompt(input_data, prompt_template)

            # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–ª—å –∫ —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è RECITATION
            salted_system_instruction = self._add_salt_to_prompt(system_instruction)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            debug_data = {
                "system_instruction": salted_system_instruction,
                "user_prompt": user_prompt
            }
            with open(os.path.join(llm_input_path, "llm_input.json"), 'w', encoding='utf-8') as f:
                json.dump(debug_data, f, ensure_ascii=False, indent=2)

            # –í—ã–∑—ã–≤–∞–µ–º Gemini API —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏
            logger.info("üì° –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ Gemini —Å —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π (work_packager -> gemini-2.5-pro)")
            gemini_response = await gemini_client.generate_response(
                prompt=user_prompt,
                agent_name="work_packager",
                system_instruction=salted_system_instruction
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –æ—Ç LLM
            with open(os.path.join(llm_input_path, "llm_response.json"), 'w', encoding='utf-8') as f:
                json.dump(gemini_response, f, ensure_ascii=False, indent=2)
            
            if not gemini_response.get('success', False):
                raise Exception(f"–û—à–∏–±–∫–∞ Gemini API: {gemini_response.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç
            work_packages = self._process_llm_response(gemini_response['response'])
            
            # –û–±–Ω–æ–≤–ª—è–µ–º true.json
            truth_data['results']['work_packages'] = work_packages
            
            with open(truth_path, 'w', encoding='utf-8') as f:
                json.dump(truth_data, f, ensure_ascii=False, indent=2)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ
            update_pipeline_status(truth_path, self.agent_name, "completed")
            
            logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç {self.agent_name} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
            logger.info(f"üìä –°–æ–∑–¥–∞–Ω–æ {len(work_packages)} –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç")
            
            return {
                'success': True,
                'work_packages_created': len(work_packages),
                'agent': self.agent_name
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≥–µ–Ω—Ç–∞ {self.agent_name}: {e}")
            # –ü—ã—Ç–∞–µ–º—Å—è –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –Ω–∞ –æ—à–∏–±–∫—É
            try:
                update_pipeline_status(truth_path, self.agent_name, "error") 
            except:
                pass
            
            return {
                'success': False,
                'error': str(e),
                'agent': self.agent_name
            }
    
    def _extract_input_data(self, truth_data: Dict) -> Dict:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ true.json –¥–ª—è –∞–≥–µ–Ω—Ç–∞
        """
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ä–∞–±–æ—Ç—ã (—Ç–æ–ª—å–∫–æ –∏—Ö id –∏ name)
        source_work_items = truth_data.get('source_work_items', [])
        work_items_for_llm = []
        
        for item in source_work_items:
            work_items_for_llm.append({
                'id': item.get('id'),
                'name': item.get('name', ''),
                'code': item.get('code', '')
            })
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∏—Ä–µ–∫—Ç–∏–≤—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å–æ —Å—Ç–∞—Ä—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º)
        project_inputs = truth_data.get('project_inputs', {})
        target_count = project_inputs.get('target_work_package_count', 15)
        agent_directives = project_inputs.get('agent_directives', {})
        work_packager_directive = agent_directives.get('work_packager') or agent_directives.get('conceptualizer', '')
        
        return {
            'source_work_items': work_items_for_llm,
            'target_work_package_count': target_count,
            'user_directive': work_packager_directive,
            'total_work_items': len(work_items_for_llm)
        }
    
    def _load_prompt(self) -> str:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ–º–ø—Ç-—à–∞–±–ª–æ–Ω –¥–ª—è –∞–≥–µ–Ω—Ç–∞
        """
        prompt_path = os.path.join(
            os.path.dirname(__file__), "..", "prompts", "work_packager_prompt.txt"
        )
        
        try:
            with open(prompt_path, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            logger.warning(f"–ü—Ä–æ–º–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {prompt_path}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π")
            return self._get_default_prompt()
    
    def _get_default_prompt(self) -> str:
        """
        –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç, –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        return """
–¢—ã - –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–±–æ—Ç –∏ —Å–æ–∑–¥–∞—Ç—å —É–∫—Ä—É–ø–Ω–µ–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–æ–º.

–í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
- –°–ø–∏—Å–æ–∫ —Ä–∞–±–æ—Ç: {source_work_items}
- –¶–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤: {target_work_package_count}
- –î–∏—Ä–µ–∫—Ç–∏–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_directive}

–ó–ê–î–ê–ß–ê:
–°–æ–∑–¥–∞–π {target_work_package_count} —á–µ–ª–æ–≤–µ–∫–æ–ø–æ–Ω—è—Ç–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –¥–ª—è —É–∫—Ä—É–ø–Ω–µ–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç, –∫–æ—Ç–æ—Ä—ã–µ –ª–æ–≥–∏—á–µ—Å–∫–∏ –æ–±—ä–µ–¥–∏–Ω—è—é—Ç –ø–æ—Ö–æ–∂–∏–µ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–±–æ—Ç—ã.

–ö–∞–∂–¥—ã–π –ø–∞–∫–µ—Ç –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å:
- package_id: —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä "pkg_001")  
- name: –∫—Ä–∞—Ç–∫–æ–µ –ø–æ–Ω—è—Ç–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫ –∏ –ø–æ–ª–æ–≤")
- description: –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –ø–∞–∫–µ—Ç–∞

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –£—á–∏—Ç—ã–≤–∞–π —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—É—é –ª–æ–≥–∏–∫—É –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç
2. –ì—Ä—É–ø–ø–∏—Ä—É–π –ø–æ —Ç–∏–ø–∞–º —Ä–∞–±–æ—Ç (–¥–µ–º–æ–Ω—Ç–∞–∂, –º–æ–Ω—Ç–∞–∂, –æ—Ç–¥–µ–ª–∫–∞ –∏ —Ç.–¥.)
3. –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É—á–∏—Ç—ã–≤–∞–π –¥–∏—Ä–µ–∫—Ç–∏–≤—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_directive}
4. –ù–∞–∑–≤–∞–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ–Ω—è—Ç–Ω—ã–º–∏ –¥–ª—è –∑–∞–∫–∞–∑—á–∏–∫–∞

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (—Å—Ç—Ä–æ–≥–æ JSON):
{{
    "work_packages": [
        {{
            "package_id": "pkg_001",
            "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π", 
            "description": "–°–Ω–æ—Å –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫, –¥–µ–º–æ–Ω—Ç–∞–∂ –ø–æ–∫—Ä—ã—Ç–∏–π –ø–æ–ª–∞ –∏ –ø–æ—Ç–æ–ª–∫–∞"
        }}
    ]
}}
"""
    
    def _format_prompt(self, input_data: Dict, prompt_template: str) -> tuple[str, str]:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–º–ø—Ç, —Ä–∞–∑–¥–µ–ª—è—è —Å–∏—Å—Ç–µ–º–Ω—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ

        Returns:
            tuple[str, str]: (system_instruction, user_prompt)
        """
        # –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (—à–∞–±–ª–æ–Ω + –¥–∏—Ä–µ–∫—Ç–∏–≤—ã)
        system_instruction = prompt_template.format(
            target_work_package_count=input_data['target_work_package_count'],
            user_directive=input_data['user_directive'],
            total_work_items=input_data['total_work_items']
        )

        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (JSON)
        user_prompt = json.dumps(input_data['source_work_items'],
                                ensure_ascii=False, indent=2)

        return system_instruction, user_prompt
    
    def _process_llm_response(self, llm_response: Any) -> List[Dict]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç LLM –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç
        """
        try:
            if isinstance(llm_response, str):
                response_data = json.loads(llm_response)
            else:
                response_data = llm_response
                
            work_packages = response_data.get('work_packages', [])
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            validated_packages = []
            for i, package in enumerate(work_packages):
                package_id = package.get('package_id', f'pkg_{i+1:03d}')
                name = package.get('name', f'–ü–∞–∫–µ—Ç —Ä–∞–±–æ—Ç {i+1}')
                description = package.get('description', '')
                
                validated_packages.append({
                    'package_id': package_id,
                    'name': name,
                    'description': description,
                    'created_at': datetime.now().isoformat()
                })
            
            return validated_packages
            
        except (json.JSONDecodeError, KeyError, AttributeError) as e:
            logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ LLM: {e}")
            logger.error(f"–°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini: {llm_response}")
            raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç Gemini: {e}")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–≥–µ–Ω—Ç–∞ –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ –∫–æ–¥–∞
async def run_work_packager(project_path: str) -> Dict[str, Any]:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –∞–≥–µ–Ω—Ç–∞ work_packager –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
    
    Args:
        project_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞
    """
    agent = WorkPackager()
    return await agent.process(project_path)

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞
    test_project_path = "/home/imort/Herzog_v3/projects/34975055/d19120ef"
    
    if os.path.exists(test_project_path):
        print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ work_packager")
        result = asyncio.run(run_work_packager(test_project_path))
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
    else:
        print(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {test_project_path}")

================================================================================

## –§–ê–ô–õ: src/ai_agents/works_to_packages.py
------------------------------------------------------------
"""
–ê–≥–µ–Ω—Ç 2: "–†–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–ª—å" (works_to_packages.py)  
–ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç –∫–∞–∂–¥—É—é –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ä–∞–±–æ—Ç—É –æ–¥–Ω–æ–º—É –∏–∑ —É–∫—Ä—É–ø–Ω–µ–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –±–∞—Ç—á–∏–Ω–≥ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –¥–∞–Ω–Ω—ã—Ö
"""

import json
import os
import asyncio
import logging
import math
import uuid
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –Ω–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã
from ..shared.gemini_client import gemini_client
from ..shared.truth_initializer import update_pipeline_status

logger = logging.getLogger(__name__)

class WorksToPackagesAssigner:
    """
    –ê–≥–µ–Ω—Ç –¥–ª—è –ø—Ä–∏—Å–≤–æ–µ–Ω–∏—è —Ä–∞–±–æ—Ç –∫ —É–∫—Ä—É–ø–Ω–µ–Ω–Ω—ã–º –ø–∞–∫–µ—Ç–∞–º
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–æ–ª—å—à–∏–µ –æ–±—ä–µ–º—ã —Ä–∞–±–æ—Ç —á–µ—Ä–µ–∑ –±–∞—Ç—á–∏–Ω–≥
    """
    
    def __init__(self, batch_size: int = 50):
        self.agent_name = "works_to_packages"
        self.batch_size = batch_size

    
    async def process(self, project_path: str) -> Dict[str, Any]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –±–∞—Ç—á–∏–Ω–≥–∞
        
        Args:
            project_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        try:
            logger.info(f"üîÑ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ {self.agent_name}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º true.json
            truth_path = os.path.join(project_path, "true.json")
            if not os.path.exists(truth_path):
                raise FileNotFoundError(f"–§–∞–π–ª true.json –Ω–µ –Ω–∞–π–¥–µ–Ω: {truth_path}")
            
            with open(truth_path, 'r', encoding='utf-8') as f:
                truth_data = json.load(f)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∞–≥–µ–Ω—Ç–∞
            update_pipeline_status(truth_path, self.agent_name, "in_progress")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞
            agent_folder = os.path.join(project_path, "5_works_to_packages")
            os.makedirs(agent_folder, exist_ok=True)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            work_packages = truth_data.get('results', {}).get('work_packages', [])
            source_work_items = truth_data.get('source_work_items', [])
            
            if not work_packages:
                raise Exception("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç. –°–Ω–∞—á–∞–ª–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–ø—É—â–µ–Ω work_packager")
            
            logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(source_work_items)} —Ä–∞–±–æ—Ç –≤ {len(work_packages)} –ø–∞–∫–µ—Ç–æ–≤")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç
            prompt_template = self._load_prompt()
            
            # –†–∞–∑–±–∏–≤–∞–µ–º —Ä–∞–±–æ—Ç—ã –Ω–∞ –±–∞—Ç—á–∏ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
            assigned_works = []
            total_batches = math.ceil(len(source_work_items) / self.batch_size)
            
            for batch_num in range(total_batches):
                start_idx = batch_num * self.batch_size
                end_idx = min((batch_num + 1) * self.batch_size, len(source_work_items))
                batch_works = source_work_items[start_idx:end_idx]
                
                logger.info(f"üì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ {batch_num + 1}/{total_batches} ({len(batch_works)} —Ä–∞–±–æ—Ç)")
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á
                batch_result = await self._process_batch(
                    batch_works, work_packages, prompt_template, 
                    batch_num, agent_folder
                )
                
                assigned_works.extend(batch_result)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º true.json —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            self._update_truth_data(truth_data, assigned_works, truth_path)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ
            update_pipeline_status(truth_path, self.agent_name, "completed")
            
            logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç {self.agent_name} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
            logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(assigned_works)} —Ä–∞–±–æ—Ç")
            
            return {
                'success': True,
                'works_processed': len(assigned_works),
                'batches_processed': total_batches,
                'agent': self.agent_name
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≥–µ–Ω—Ç–∞ {self.agent_name}: {e}")
            # –ü—ã—Ç–∞–µ–º—Å—è –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –Ω–∞ –æ—à–∏–±–∫—É
            try:
                update_pipeline_status(truth_path, self.agent_name, "error")
            except:
                pass
            
            return {
                'success': False,
                'error': str(e),
                'agent': self.agent_name
            }
    
    async def _process_batch(self, batch_works: List[Dict], work_packages: List[Dict],
                           prompt_template: str, batch_num: int, agent_folder: str) -> List[Dict]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –±–∞—Ç—á —Ä–∞–±–æ—Ç
        """
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±–∞—Ç—á–∞
        input_data = {
            'batch_works': [
                {
                    'id': work.get('id'),
                    'name': work.get('name', ''),
                    'code': work.get('code', '')
                }
                for work in batch_works
            ],
            'work_packages': work_packages,
            'batch_number': batch_num + 1
        }
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è LLM
        system_instruction, user_prompt = self._format_prompt(input_data, prompt_template)

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–ª—å –∫ —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è RECITATION
        salted_system_instruction = self._add_salt_to_prompt(system_instruction)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (–∫–∞–∫ –≤ work_packager)
        debug_data = {
            "system_instruction": salted_system_instruction,
            "user_prompt": user_prompt
        }
        batch_input_path = os.path.join(agent_folder, f"batch_{batch_num+1:03d}_input.json")
        with open(batch_input_path, 'w', encoding='utf-8') as f:
            json.dump(debug_data, f, ensure_ascii=False, indent=2)

        # –í—ã–∑—ã–≤–∞–µ–º Gemini API —Å system_instruction –∏ user_prompt
        logger.info(f"üì° –û—Ç–ø—Ä–∞–≤–∫–∞ –±–∞—Ç—á–∞ {batch_num + 1} –≤ Gemini (works_to_packages -> gemini-2.5-flash-lite)")
        gemini_response = await gemini_client.generate_response(
            prompt=user_prompt,
            system_instruction=salted_system_instruction,
            agent_name="works_to_packages"
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –æ—Ç LLM
        batch_response_path = os.path.join(agent_folder, f"batch_{batch_num+1:03d}_response.json")
        with open(batch_response_path, 'w', encoding='utf-8') as f:
            json.dump(gemini_response, f, ensure_ascii=False, indent=2)
        
        if not gemini_response.get('success', False):
            logger.error(f"–û—à–∏–±–∫–∞ Gemini API –¥–ª—è –±–∞—Ç—á–∞ {batch_num + 1}: {gemini_response.get('error')}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–∞–±–æ—Ç—ã –±–µ–∑ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –ø–∞–∫–µ—Ç–æ–≤
            return batch_works
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç
        assignments = self._process_batch_response(gemini_response['response'], batch_works)
        
        return assignments
    
    def _load_prompt(self) -> str:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ–º–ø—Ç-—à–∞–±–ª–æ–Ω –¥–ª—è –∞–≥–µ–Ω—Ç–∞
        """
        prompt_path = os.path.join(
            os.path.dirname(__file__), "..", "prompts", "works_to_packages_prompt.txt"
        )
        
        try:
            with open(prompt_path, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            logger.warning(f"–ü—Ä–æ–º–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {prompt_path}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π")
            return self._get_default_prompt()
    
    def _get_default_prompt(self) -> str:
        """
        –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç, –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        return """
# –†–û–õ–¨
–¢—ã ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∏—Å–ø–µ—Ç—á–µ—Ä.

# –ó–ê–î–ê–ß–ê
–î–ª—è –ö–ê–ñ–î–û–ô —Ä–∞–±–æ—Ç—ã –∏–∑ —Å–ø–∏—Å–∫–∞ `–†–ê–ë–û–¢–´ –î–õ–Ø –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–Ø` –Ω–∞–∑–Ω–∞—á—å –û–î–ò–ù –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π `package_id` –∏–∑ `–î–û–°–¢–£–ü–ù–´–• –ü–ê–ö–ï–¢–û–í`.

# –í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï
–í –∑–∞–ø—Ä–æ—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Ç—ã –ø–æ–ª—É—á–∏—à—å JSON-–æ–±—ä–µ–∫—Ç —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –∫–ª—é—á–∞–º–∏:
- "work_packages": –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç
- "batch_works": —Ä–∞–±–æ—Ç—ã –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤ —Ç–µ–∫—É—â–µ–º –±–∞—Ç—á–µ
- "batch_number": –Ω–æ–º–µ—Ä —Ç–µ–∫—É—â–µ–≥–æ –±–∞—Ç—á–∞

# –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–ê–í–ò–õ–ê
1. **–ü–û–õ–ù–û–¢–ê –û–¢–í–ï–¢–ê:** –¢–≤–æ–π –æ—Ç–≤–µ—Ç –≤ –∫–ª—é—á–µ "assignments" –î–û–õ–ñ–ï–ù —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ä–æ–≤–Ω–æ —Å—Ç–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç–æ–≤, —Å–∫–æ–ª—å–∫–æ –±—ã–ª–æ –≤–æ –≤—Ö–æ–¥–Ω—ã—Ö "batch_works". –≠—Ç–æ —Å–∞–º–æ–µ –≥–ª–∞–≤–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ.
2. **–í–ê–õ–ò–î–ù–û–°–¢–¨ ID:** –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ `work_id` –∏ `package_id` –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–≤—ã–µ.
3. **–õ–û–ì–ò–ö–ê:** –í—ã–±–∏—Ä–∞–π –ø–∞–∫–µ—Ç, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –Ω–∞–∑–≤–∞–Ω–∏—é —Ä–∞–±–æ—Ç—ã.

# –§–û–†–ú–ê–¢ –í–´–í–û–î–ê (–°–¢–†–û–ì–û JSON)
{
    "assignments": [
        { "work_id": "id_—Ä–∞–±–æ—Ç—ã_1", "package_id": "pkg_003" }
    ]
}
"""
    
    def _add_salt_to_prompt(self, prompt: str) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—É—é —Å–æ–ª—å –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è RECITATION."""
        unique_id = str(uuid.uuid4())[:8]
        prefix = f"# ID: {unique_id} | –†–µ–∂–∏–º: JSON_STRICT\n"
        suffix = f"\n# –ö–æ–Ω—Ç—Ä–æ–ª—å: {unique_id}"
        return prefix + prompt + suffix

    def _format_prompt(self, input_data: Dict, prompt_template: str) -> Tuple[str, str]:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–º–ø—Ç —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ system_instruction –∏ user_prompt

        Returns:
            Tuple[str, str]: (system_instruction, user_prompt)
        """
        # System instruction - —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç –±–µ–∑ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤
        system_instruction = prompt_template

        # User prompt - —Ç–æ–ª—å–∫–æ JSON —Å —Ä–∞–±–æ—Ç–∞–º–∏
        user_prompt_data = {
            'work_packages': input_data['work_packages'],
            'batch_works': input_data['batch_works'],
            'batch_number': input_data['batch_number']
        }
        user_prompt = json.dumps(user_prompt_data, ensure_ascii=False, indent=2)

        return system_instruction, user_prompt
    
    def _process_batch_response(self, llm_response: Any, original_works: List[Dict]) -> List[Dict]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç LLM –¥–ª—è –±–∞—Ç—á–∞
        """
        try:
            if isinstance(llm_response, str):
                response_data = json.loads(llm_response)
            else:
                response_data = llm_response
            
            assignments = response_data.get('assignments', [])
            
            # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            assignment_dict = {assign['work_id']: assign['package_id'] for assign in assignments}
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–∞–±–æ—Ç—ã
            updated_works = []
            for work in original_works:
                work_copy = work.copy()
                work_id = work.get('id')
                
                if work_id in assignment_dict:
                    work_copy['package_id'] = assignment_dict[work_id]
                else:
                    # –ù–ò–ö–ê–ö–û–ì–û FALLBACK! –û—à–∏–±–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—à–∏–±–∫–æ–π!
                    logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Ä–∞–±–æ—Ç—ã {work_id}")
                    raise Exception(f"Gemini –Ω–µ –Ω–∞–∑–Ω–∞—á–∏–ª –ø–∞–∫–µ—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã {work_id}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–æ–º–ø—Ç –∏ –æ—Ç–≤–µ—Ç LLM.")
                
                updated_works.append(work_copy)
            
            return updated_works
            
        except (json.JSONDecodeError, KeyError, AttributeError) as e:
            logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ LLM –¥–ª—è –±–∞—Ç—á–∞: {e}")
            logger.error(f"–°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini: {llm_response}")
            raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç Gemini –¥–ª—è –±–∞—Ç—á–∞: {e}")
    
    def _update_truth_data(self, truth_data: Dict, assigned_works: List[Dict], truth_path: str):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç true.json —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–π
        """
        # –û–±–Ω–æ–≤–ª—è–µ–º source_work_items —Å package_id
        truth_data['source_work_items'] = assigned_works
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ results
        if 'results' not in truth_data:
            truth_data['results'] = {}
        
        # –°—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø–∞–∫–µ—Ç–∞–º
        package_stats = {}
        for work in assigned_works:
            package_id = work.get('package_id')
            if package_id:
                if package_id not in package_stats:
                    package_stats[package_id] = 0
                package_stats[package_id] += 1
        
        truth_data['results']['package_assignments'] = {
            'total_works': len(assigned_works),
            'works_per_package': package_stats,
            'assigned_at': datetime.now().isoformat()
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with open(truth_path, 'w', encoding='utf-8') as f:
            json.dump(truth_data, f, ensure_ascii=False, indent=2)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–≥–µ–Ω—Ç–∞ –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ –∫–æ–¥–∞
async def run_works_to_packages(project_path: str, batch_size: int = 50) -> Dict[str, Any]:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –∞–≥–µ–Ω—Ç–∞ works_to_packages –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
    
    Args:
        project_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞
    """
    agent = WorksToPackagesAssigner(batch_size=batch_size)
    return await agent.process(project_path)

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞
    test_project_path = "/home/imort/Herzog_v3/projects/34975055/d19120ef"
    
    if os.path.exists(test_project_path):
        print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ works_to_packages")
        result = asyncio.run(run_works_to_packages(test_project_path))
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
    else:
        print(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {test_project_path}")

================================================================================

## –§–ê–ô–õ: src/data_processing/__init__.py
------------------------------------------------------------


================================================================================

## –§–ê–ô–õ: src/data_processing/classifier.py
------------------------------------------------------------
"""
–ú–æ–¥—É–ª—å CLASSIFIER
–ó–∞–¥–∞—á–∞: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≥–∏–±—Ä–∏–¥–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ master_list,
–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∫–∞–∂–¥—É—é –ø–æ–∑–∏—Ü–∏—é –∏ –æ–±–æ–≥–∞—â–∞–µ—Ç –µ–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ API "–°–º–µ—Ç–Ω–æ–≥–æ –î–µ–ª–∞".
"""

import requests
import logging
import os
from typing import List, Dict, Optional
from dotenv import load_dotenv

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ—Å–ª–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–π –≤–Ω–∏–∑—É —Ñ–∞–π–ª–∞

load_dotenv()


def classify_locally(item: Dict) -> Optional[str]:
    """
    –õ–æ–∫–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –∂–µ—Å—Ç–∫–∏–º –ø—Ä–∞–≤–∏–ª–∞–º
    
    Args:
        item: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–æ–∑–∏—Ü–∏–∏
        
    Returns:
        "–†–∞–±–æ—Ç–∞", "–ú–∞—Ç–µ—Ä–∏–∞–ª", "–ò–Ω–æ–µ" –∏–ª–∏ None
    """
    code = item.get('code', '').upper().strip()
    name = item.get('name', '').lower().strip()
    
    # –®–∞–≥ 2.1: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —à–∏—Ñ—Ä—É
    work_prefixes = ['–ì–≠–°–ù', '–¢–ï–†', '–¢–ï–†–º', '–¢–ï–†—Ä', '–§–ï–†', '–ì–≠–°–ù–ú', '–ì–≠–°–ù–†', '–ì–≠–°–ù–ü', '–ì–≠–°–ù–ú–†']
    material_prefixes = ['–§–°–ë–¶', '–¢–°–°–¶', '–¢–¶', '–§–°–°–¶', '–§–°–°–¶–º', '–§–°–°–¶–æ']
    
    for prefix in work_prefixes:
        if code.startswith(prefix):
            return "–†–∞–±–æ—Ç–∞"
    
    for prefix in material_prefixes:
        if code.startswith(prefix):
            return "–ú–∞—Ç–µ—Ä–∏–∞–ª"
    
    # –®–∞–≥ 2.2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ "–ò–Ω–æ–µ" –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
    other_keywords = [
        '–Ω–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã', '—Å–º–µ—Ç–Ω–∞—è –ø—Ä–∏–±—ã–ª—å', '–≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã',
        '–Ω–∞ –∫–∞–∂–¥—ã–µ', '–∏—Ç–æ–≥–æ', '–≤—Å–µ–≥–æ', '—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç', '–¥–æ—Å—Ç–∞–≤–∫–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞'
    ]
    
    for keyword in other_keywords:
        if keyword in name:
            return "–ò–Ω–æ–µ"
    
    return None


def get_smetnoedelo_data(code: str, api_token: str) -> Optional[Dict]:
    """
    –í–†–ï–ú–ï–ù–ù–û –û–¢–ö–õ–Æ–ß–ï–ù–û - API —Ç–æ–∫–µ–Ω –∏—Å—á–µ—Ä–ø–∞–Ω
    """
    return None  # –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º API –ø–æ–∫–∞ –Ω–µ –ø–æ–ª—É—á–∏—Ç–µ –Ω–æ–≤—ã–π —Ç–æ–∫–µ–Ω

def get_smetnoedelo_data_ORIGINAL(code: str, api_token: str) -> Optional[Dict]:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ API "–°–º–µ—Ç–Ω–æ–≥–æ –î–µ–ª–∞"
    
    Args:
        code: –®–∏—Ñ—Ä —Ä–∞—Å—Ü–µ–Ω–∫–∏
        api_token: API —Ç–æ–∫–µ–Ω
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑—É –ø–æ –∫–æ–¥—É (—Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ API)
        code_upper = code.upper()
        
        base_mapping = {
            '–ì–≠–°–ù': 'gesn',
            '–ì–≠–°–ù–º': 'gesnm', 
            '–ì–≠–°–ù–º—Ä': 'gesnmr',
            '–ì–≠–°–ù–ø': 'gesnp',
            '–ì–≠–°–ù—Ä': 'gesnr',
            '–§–ï–†': 'fer',
            '–§–ï–†–º': 'ferm',
            '–§–ï–†–º—Ä': 'fermr', 
            '–§–ï–†–ø': 'ferp',
            '–§–ï–†—Ä': 'ferr',
            '–¢–ï–†': 'gesn',  # –¢–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Ä–∞—Å—Ü–µ–Ω–∫–∏ –æ–±—ã—á–Ω–æ –≤ –ì–≠–°–ù
            # –ú–∞—Ç–µ—Ä–∏–∞–ª—ã - –ø–æ–∫–∞ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç –≤ API
            '–§–°–ë–¶': 'fsbcm',
            '–§–°–°–¶–º': 'fsscm',
            '–§–°–°–¶–æ': 'fssco',
            '–§–°–≠–ú': 'fsem'
        }
        
        base = None
        for prefix, base_code in base_mapping.items():
            if code_upper.startswith(prefix):
                base = base_code
                break
        
        if not base:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –±–∞–∑—É –¥–ª—è –∫–æ–¥–∞ {code}")
            return None
        
        # –ó–∞–ø—Ä–æ—Å –∫ API (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–∑ test_api.py)
        url = "https://cs.smetnoedelo.ru/api/"
        params = {
            'token': api_token,
            'base': base,
            'code': code
        }
        
        response = requests.get(url, params=params, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—à–∏–±–∫–∏ –≤ –æ—Ç–≤–µ—Ç–µ
            if data.get('error'):
                logging.warning(f"API –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É –¥–ª—è –∫–æ–¥–∞ {code}: {data.get('error')}")
                return None
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–µ—Ä–∞—Ä—Ö–∏—é –∏–∑ TREE —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç API)
            hierarchy_parts = []
            tree_data = data.get('TREE', [])
            for item in tree_data:
                if 'NAME' in item:
                    hierarchy_parts.append(item['NAME'])
            
            result = {
                'official_name': data.get('BASE_NAME', '')  # –ò—Å–ø–æ–ª—å–∑—É–µ–º BASE_NAME –≤–º–µ—Å—Ç–æ NAME
            }
            
            
            logging.info(f"API —É—Å–ø–µ—à–Ω–æ –≤–µ—Ä–Ω—É–ª –¥–∞–Ω–Ω—ã–µ –¥–ª—è {code}: {result['official_name']}")
            return result
        
        elif response.status_code == 404:
            logging.warning(f"–ö–æ–¥ {code} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ API –°–º–µ—Ç–Ω–æ–≥–æ –î–µ–ª–∞")
            return None
        
        else:
            logging.error(f"–û—à–∏–±–∫–∞ API –°–º–µ—Ç–Ω–æ–≥–æ –î–µ–ª–∞: {response.status_code}")
            return None
            
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ API –°–º–µ—Ç–Ω–æ–≥–æ –î–µ–ª–∞ –¥–ª—è –∫–æ–¥–∞ {code}: {str(e)}")
        return None


async def classify_items(master_list: List[Dict], progress_callback=None, project_dir: str = None) -> List[Dict]:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –º–æ–¥—É–ª—è CLASSIFIER
    
    Args:
        master_list: –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –º–æ–¥—É–ª—è EXTRACTOR
        
    Returns:
        classified_list: –°–ø–∏—Å–æ–∫ —Å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–æ–∑–∏—Ü–∏—è–º–∏
    """
    classified_list = []
    api_token = os.getenv('SMETNOEDELO_API_KEY')
    
    if not api_token:
        logging.error("–ù–µ –Ω–∞–π–¥–µ–Ω API –∫–ª—é—á SMETNOEDELO_API_KEY")
        logging.info("–†–∞–±–æ—Ç–∞—é —Ç–æ–ª—å–∫–æ —Å –ª–æ–∫–∞–ª—å–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –±–µ–∑ API –æ–±–æ–≥–∞—â–µ–Ω–∏—è")
    
    # –ö—ç—à –¥–ª—è API –∑–∞–ø—Ä–æ—Å–æ–≤
    api_cache = {}
    total_items = len(master_list)
    
    for i, item in enumerate(master_list):
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é —ç–ª–µ–º–µ–Ω—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        classified_item = item.copy()
        
        # –®–∞–≥ 3.1: –õ–æ–∫–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        classification = classify_locally(item)
        
        if classification:
            classified_item['classification'] = classification
            
            # –®–∞–≥ 3.3: –û–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ API –¥–ª—è —Ä–∞–±–æ—Ç (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å API –∫–ª—é—á)
            if classification == "–†–∞–±–æ—Ç–∞" and api_token:
                code = item.get('code', '')
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
                if code in api_cache:
                    api_data = api_cache[code]
                else:
                    api_data = get_smetnoedelo_data(code, api_token)
                    api_cache[code] = api_data
                
                if api_data:
                    # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –µ—Å–ª–∏ –ø–æ–ª—É—á–µ–Ω–æ –∏–∑ API
                    if api_data['official_name']:
                        classified_item['name'] = api_data['official_name']
        
        else:
            # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –≥—Ä—É–ø–ø–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–µ—Ä–µ–∑ Gemini
            classified_item['classification'] = "–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ"
        
        classified_list.append(classified_item)
        
        # –í—ã–∑—ã–≤–∞–µ–º callback –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        if progress_callback and i % 5 == 0:  # –ö–∞–∂–¥—ã–µ 5 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            progress_callback(i + 1, total_items)
    
    # –®–∞–≥ 3.4: –ì—Ä—É–ø–ø–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π –ò "–ò–Ω–æ–µ" —á–µ—Ä–µ–∑ Gemini
    # –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Gemini –≤—Å—ë —á—Ç–æ –Ω–µ "–†–∞–±–æ—Ç–∞" –∏ –Ω–µ "–ú–∞—Ç–µ—Ä–∏–∞–ª"
    undefined_items = [item for item in classified_list if item['classification'] in ['–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ', '–ò–Ω–æ–µ']]
    
    if undefined_items:
        logging.info(f"–û—Ç–ø—Ä–∞–≤–ª—è—é {len(undefined_items)} –ø–æ–∑–∏—Ü–∏–π –≤ Gemini –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ ('–ò–Ω–æ–µ' + '–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ')")
        
        try:
            from .gemini_classifier import classify_with_gemini, convert_gemini_result
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è Gemini (—Ç–æ–ª—å–∫–æ –∫–æ–¥ –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ)
            gemini_input = []
            item_mapping = {}
            
            for i, item in enumerate(undefined_items):
                gemini_input.append({
                    'code': item.get('code', ''),
                    'name': item.get('name', '')
                })
                item_mapping[i] = item
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç Gemini
            gemini_results = await classify_with_gemini(gemini_input, project_dir)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π
            for item_uuid, gemini_result in gemini_results.items():
                # –ù–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —ç–ª–µ–º–µ–Ω—Ç –≤ classified_list
                original_item = gemini_result['original_item']
                
                for classified_item in classified_list:
                    if classified_item.get('id') == original_item.get('id'):
                        
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç Gemini
                        converted_result = convert_gemini_result(gemini_result)
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é (–∑–∞–º–µ–Ω—è–µ–º "–ò–Ω–æ–µ" –∏–ª–∏ "–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ" –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç Gemini)
                        classified_item.update(converted_result)
                        break
            
            logging.info(f"Gemini –æ–±—Ä–∞–±–æ—Ç–∞–ª {len(gemini_results)} –ø–æ–∑–∏—Ü–∏–π (–≤–∫–ª—é—á–∞—è '–ò–Ω–æ–µ' –∏ '–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ')")
            
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π —á–µ—Ä–µ–∑ Gemini: {e}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ Gemini)
    classifications = [item['classification'] for item in classified_list]
    work_count = classifications.count('–†–∞–±–æ—Ç–∞')
    material_count = classifications.count('–ú–∞—Ç–µ—Ä–∏–∞–ª')
    other_count = classifications.count('–ò–Ω–æ–µ')
    unknown_count = classifications.count('–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ')
    
    logging.info(f"–§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
    logging.info(f"  –†–∞–±–æ—Ç: {work_count}")
    logging.info(f"  –ú–∞—Ç–µ—Ä–∏–∞–ª–æ–≤: {material_count}")
    logging.info(f"  –ò–Ω–æ–µ: {other_count}")
    logging.info(f"  –ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö: {unknown_count}")
    
    return classified_list


async def classify_estimates(input_file: str) -> List[Dict]:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–∞–π–ø–ª–∞–π–Ω–∞ - –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    
    Args:
        input_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É raw_estimates.json
        
    Returns:
        –°–ø–∏—Å–æ–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
    """
    import json
    
    # –ß–∏—Ç–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
    with open(input_file, 'r', encoding='utf-8') as f:
        raw_data = json.load(f)
    
    logging.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(raw_data)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É –∏–∑ input_file
    project_dir = None
    if "projects/" in input_file:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—É—Ç—å –¥–æ –ø–∞–ø–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞
        parts = input_file.split("/")
        if "projects" in parts:
            project_idx = parts.index("projects")
            if project_idx + 2 < len(parts):  # projects/user_id/project_id
                project_dir = "/".join(parts[:project_idx + 3])
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    classified_data = await classify_items(raw_data, project_dir=project_dir)
    
    logging.info(f"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(classified_data)} –∑–∞–ø–∏—Å–µ–π")
    
    return classified_data


if __name__ == "__main__":
    import sys
    import json
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(level=logging.INFO)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) > 1:
        # –†–µ–∂–∏–º —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è - –∞—Ä–≥—É–º–µ–Ω—Ç = –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        project_dir = sys.argv[1]
        raw_estimates_file = os.path.join(project_dir, '1_extracted', 'raw_estimates.json')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if not os.path.exists(raw_estimates_file):
            logging.error(f"–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {raw_estimates_file}")
            sys.exit(1)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
        try:
            result = classify_estimates(raw_estimates_file)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            output_file = os.path.join(project_dir, '2_classified', 'classified_estimates.json')
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            logging.info(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
            print(f"–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ {len(result)} –ø–æ–∑–∏—Ü–∏–π")
            
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
            sys.exit(1)
    
    else:
        # –†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è - –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
        logging.info("–†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è classifier...")
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_data = [
            {
                'id': 'test-1',
                'source_file': 'test.xlsx',
                'position_num': '1',
                'code': '–ì–≠–°–ù46-02-009-02',
                'name': '–û—Ç–±–∏–≤–∫–∞ —à—Ç—É–∫–∞—Ç—É—Ä–∫–∏ —Å –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ–π',
                'unit': '100 –º2',
                'quantity': '7.77'
            },
            {
                'id': 'test-2',
                'source_file': 'test.xlsx',
                'position_num': '2',
                'code': '–§–°–ë–¶-14.4.01.02-0012',
                'name': '–°–º–µ—Å—å —Å—É—Ö–∞—è —à—Ç—É–∫–∞—Ç—É—Ä–Ω–∞—è',
                'unit': '–∫–≥',
                'quantity': '1000'
            }
        ]
        
        result = classify_items(test_data)
        
        print(f"–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ {len(result)} –ø–æ–∑–∏—Ü–∏–π")
        for item in result:
            print(f"–ü–æ–∑–∏—Ü–∏—è {item['position_num']}: {item['classification']}")


================================================================================

## –§–ê–ô–õ: src/data_processing/extractor.py
------------------------------------------------------------
"""
–ú–æ–¥—É–ª—å EXTRACTOR –¥–ª—è HerZog v3.0
–ó–∞–¥–∞—á–∞: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel-—Ñ–∞–π–ª–æ–≤ —Å–º–µ—Ç (–®–∞–≥ 1 –ø–∞–π–ø–ª–∞–π–Ω–∞)
"""

import pandas as pd
import uuid
import os
from typing import List, Dict, Optional
import logging


def find_table_header(df: pd.DataFrame) -> Optional[int]:
    """
    –ù–∞–π—Ç–∏ –Ω–∞—á–∞–ª–æ —Ç–∞–±–ª–∏—Ü—ã –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º "‚Ññ –ø/–ø" –∏ "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ"
    
    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ Excel
        
    Returns:
        –ù–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏-–∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
    """
    for i, row in df.iterrows():
        row_text = ' '.join([str(cell).lower() for cell in row if pd.notna(cell) and str(cell).strip()])
        
        if ('‚Ññ –ø/–ø' in row_text or '–ø/–ø' in row_text or '‚Ññ–ø/–ø' in row_text) and \
           ('–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ' in row_text) and \
           ('–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ' in row_text):
            return i
    
    return None


def is_valid_row(row: pd.Series, position_col_idx: int = 0) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Å—Ç—Ä–æ–∫–∏ –ø–æ —á–∏—Å–ª–æ–≤–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é –≤ –∫–æ–ª–æ–Ω–∫–µ "‚Ññ –ø/–ø"
    –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É –¥—Ä—É–≥–∏—Ö –∫–æ–ª–æ–Ω–æ–∫ (–∏—Å–∫–ª—é—á–∏—Ç—å –º—É—Å–æ—Ä–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏)
    
    Args:
        row: –°—Ç—Ä–æ–∫–∞ DataFrame
        position_col_idx: –ò–Ω–¥–µ–∫—Å –∫–æ–ª–æ–Ω–∫–∏ "‚Ññ –ø/–ø" (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0)
        
    Returns:
        True –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–ª–∏–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–º–µ—Ç—ã
    """
    if len(row) <= position_col_idx:
        return False
        
    position_value = row.iloc[position_col_idx]
    
    if pd.isna(position_value):
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —á–∏—Å–ª–æ
    try:
        num_value = float(str(position_value).replace(',', '.'))
    except (ValueError, TypeError):
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ç–æ—Ä–æ—é –∫–æ–ª–æ–Ω–∫—É - –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –Ω–µ –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ
    if len(row) > 1 and pd.notna(row.iloc[1]):
        code_value = str(row.iloc[1]).strip()
        
        # –ò—Å–∫–ª—é—á–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –≥–¥–µ –≤—Ç–æ—Ä–∞—è –∫–æ–ª–æ–Ω–∫–∞ - –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ
        try:
            float(code_value)
            # –ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ, –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ –¥—Ä—É–≥–∏—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
            if len(row) > 2 and pd.notna(row.iloc[2]):
                name_value = str(row.iloc[2]).strip()
                # –ï—Å–ª–∏ —Ç—Ä–µ—Ç—å—è –∫–æ–ª–æ–Ω–∫–∞ —Ç–æ–∂–µ –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ - —ç—Ç–æ –º—É—Å–æ—Ä–Ω–∞—è —Å—Ç—Ä–æ–∫–∞
                try:
                    float(name_value)
                    return False  # –°—Ç—Ä–æ–∫–∞ —Ç–∏–ø–∞ "1, 2, 3" - –º—É—Å–æ—Ä–Ω–∞—è
                except:
                    pass  # –¢—Ä–µ—Ç—å—è –∫–æ–ª–æ–Ω–∫–∞ –Ω–µ —á–∏—Å–ª–æ - —Ö–æ—Ä–æ—à–æ
        except:
            pass  # –í—Ç–æ—Ä–∞—è –∫–æ–ª–æ–Ω–∫–∞ –Ω–µ —á–∏—Å–ª–æ - —Ö–æ—Ä–æ—à–æ
    
    return True


def extract_from_file(file_path: str) -> List[Dict]:
    """
    –ò–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ–¥–Ω–æ–≥–æ XLSX —Ñ–∞–π–ª–∞
    
    Args:
        file_path: –ü—É—Ç—å –∫ XLSX —Ñ–∞–π–ª—É
        
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    """
    try:
        # –ß–∏—Ç–∞–µ–º –≤–µ—Å—å –ª–∏—Å—Ç
        df = pd.read_excel(file_path, header=None)
        
        # –ù–∞—Ö–æ–¥–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã
        header_row = find_table_header(df)
        
        if header_row is None:
            logging.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã –≤ —Ñ–∞–π–ª–µ {file_path}")
            return []
        
        # –†–∞–±–æ—Ç–∞–µ–º —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
        data_df = df.iloc[header_row + 1:]
        
        extracted_data = []
        file_name = os.path.basename(file_path)
        
        for idx, row in data_df.iterrows():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Å—Ç—Ä–æ–∫–∏
            if not is_valid_row(row):
                continue
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–æ–ª–æ–Ω–æ–∫ —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
            position_num = str(row.iloc[0]) if len(row) > 0 and pd.notna(row.iloc[0]) else ""
            code = str(row.iloc[1]) if len(row) > 1 and pd.notna(row.iloc[1]) else ""
            name = str(row.iloc[2]) if len(row) > 2 and pd.notna(row.iloc[2]) else ""
            unit = str(row.iloc[7]) if len(row) > 7 and pd.notna(row.iloc[7]) else ""
            quantity = str(row.iloc[8]) if len(row) > 8 and pd.notna(row.iloc[8]) else ""
            
            # –°–æ–∑–¥–∞–µ–º –ø–ª–æ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å —Å –µ–¥–∏–Ω—ã–º UUID
            record = {
                'id': str(uuid.uuid4()),
                'source_file': file_name,
                'position_num': position_num,
                'code': code,
                'name': name,
                'unit': unit,
                'quantity': quantity
            }
            
            extracted_data.append(record)
            
        logging.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(extracted_data)} –∑–∞–ø–∏—Å–µ–π –∏–∑ —Ñ–∞–π–ª–∞ {file_name}")
        return extracted_data
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {str(e)}")
        return []


def extract_from_files(file_paths: List[str]) -> List[Dict]:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –º–æ–¥—É–ª—è EXTRACTOR
    
    Args:
        file_paths: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ XLSX —Ñ–∞–π–ª–∞–º
        
    Returns:
        master_list: –ï–¥–∏–Ω—ã–π, –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
    """
    master_list = []
    
    for file_path in file_paths:
        if not os.path.exists(file_path):
            logging.warning(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            continue
            
        file_data = extract_from_file(file_path)
        master_list.extend(file_data)
    
    logging.info(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(master_list)}")
    return master_list


def extract_estimates(input_path: str) -> List[Dict]:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–∞–π–ø–ª–∞–π–Ω–∞ - –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≤—Å–µ—Ö Excel —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ
    
    Args:
        input_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ 0_input —Å Excel —Ñ–∞–π–ª–∞–º–∏
        
    Returns:
        –°–ø–∏—Å–æ–∫ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
    """
    excel_files = []
    
    # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö Excel —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ input
    for file_name in os.listdir(input_path):
        if file_name.endswith('.xlsx') and not file_name.startswith('~'):
            excel_files.append(os.path.join(input_path, file_name))
    
    if not excel_files:
        logging.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ Excel —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ: {input_path}")
        return []
    
    logging.info(f"–ù–∞–π–¥–µ–Ω–æ Excel —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(excel_files)}")
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    return extract_from_files(excel_files)


if __name__ == "__main__":
    import sys
    import json
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(level=logging.INFO)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) >= 3:
        # –†–µ–∂–∏–º —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è - –∞—Ä–≥—É–º–µ–Ω—Ç—ã: –ø—É—Ç—å –∫ Excel —Ñ–∞–π–ª—É –∏ –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        excel_file = sys.argv[1] 
        project_dir = sys.argv[2]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if not os.path.exists(excel_file):
            logging.error(f"–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {excel_file}")
            sys.exit(1)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ
        try:
            result = extract_from_files([excel_file])
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            output_file = os.path.join(project_dir, '1_extracted', 'raw_estimates.json')
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            logging.info(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
            print(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(result)} –∑–∞–ø–∏—Å–µ–π")
            if result:
                print("–ü—Ä–∏–º–µ—Ä –ø–µ—Ä–≤–æ–π –∑–∞–ø–∏—Å–∏:")
                for key, value in result[0].items():
                    print(f"  {key}: {value}")
            
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏: {e}")
            sys.exit(1)
    
    else:
        # –†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è - –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
        logging.info("–†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è extractor...")
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python -m src.data_processing.extractor <–ø—É—Ç—å_–∫_excel> <–ø—É—Ç—å_–∫_–ø—Ä–æ–µ–∫—Ç—É>")
        
        # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        test_files = ["/home/imort/Herzog_v2claude/income/tretiy/02_01_01_–°—Ç–µ–Ω—ã_–õ–°–†_–ø–æ_–ú–µ—Ç–æ–¥–∏–∫–µ_2020_–†–ò–ú1.xlsx"]
        
        if os.path.exists(test_files[0]):
            result = extract_from_files(test_files)
            
            print(f"–¢–µ—Å—Ç–æ–≤–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ: {len(result)} –∑–∞–ø–∏—Å–µ–π")
            if result:
                print("–ü—Ä–∏–º–µ—Ä –ø–µ—Ä–≤–æ–π –∑–∞–ø–∏—Å–∏:")
                for key, value in result[0].items():
                    print(f"  {key}: {value}")
        else:
            print("–¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ")

================================================================================

## –§–ê–ô–õ: src/data_processing/gemini_classifier.py
------------------------------------------------------------
"""
–ú–æ–¥—É–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–º–µ—Ç–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π —á–µ—Ä–µ–∑ Gemini 2.5 Pro
"""

import json
import logging
import os
import uuid
from typing import List, Dict, Optional
from dotenv import load_dotenv
from ..shared.gemini_client import gemini_client

load_dotenv()

def load_prompt_template() -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —à–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞"""
    try:
        prompt_path = os.path.join(os.path.dirname(__file__), '../prompts/gemini_classification_prompt.txt')
        with open(prompt_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–º–ø—Ç–∞: {e}")
        return ""

async def classify_with_gemini(items: List[Dict], project_dir: str = None) -> Dict[str, Dict]:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π —á–µ—Ä–µ–∑ Gemini 2.5 Pro
    
    Args:
        items: –°–ø–∏—Å–æ–∫ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π —Å –ø–æ–ª—è–º–∏ code, name
        project_dir: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è llm_input/response
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å {id: {"classification": str, "reasoning": str}}
    """
    if not items:
        return {}
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ ID –∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏ –≥–æ—Ç–æ–≤–∏–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    items_with_id = []
    id_mapping = {}
    
    for item in items:
        item_id = item.get('id', str(uuid.uuid4()))  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–π id –∏–ª–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –µ—Å–ª–∏ –Ω–µ—Ç
        id_mapping[item_id] = item
        
        items_with_id.append({
            "id": item_id,
            "full_name": f"{item.get('code', '')} {item.get('name', '')}"
        })
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –∑–∞–ø–æ–ª–Ω—è–µ–º —à–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞
    prompt_template = load_prompt_template()
    if not prompt_template:
        logging.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —à–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞")
        return {}
    
    # –†–∞–∑–¥–µ–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
    system_instruction = prompt_template.replace('{ITEMS_JSON}', "")  # –£–±–∏—Ä–∞–µ–º –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
    system_instruction = system_instruction.replace("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–µ –ø–æ–∑–∏—Ü–∏–∏:", "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º:")
    user_prompt = json.dumps(items_with_id, ensure_ascii=False, indent=2)

    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π gemini_client —Å —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π
        logging.info("üì° –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –≤ Gemini —Å —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π (classifier -> gemini-2.5-flash-lite)")
        gemini_response = await gemini_client.generate_response(
            prompt=user_prompt,
            agent_name="classifier",
            system_instruction=system_instruction
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º llm_input –∏ llm_response –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞ –ø–∞–ø–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞
        if project_dir:
            classified_dir = os.path.join(project_dir, "2_classified")
            os.makedirs(classified_dir, exist_ok=True)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            llm_input_path = os.path.join(classified_dir, "llm_input.json")
            llm_input_data = {
                "system_instruction": system_instruction,
                "user_prompt": user_prompt,
                "items": []
            }

            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ ID –∫ –∫–∞–∂–¥–æ–π –ø–æ–∑–∏—Ü–∏–∏
            for item in items:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º item_id –Ω–∞–ø—Ä—è–º—É—é - –æ–Ω —É–∂–µ –µ—Å—Ç—å –≤ id_mapping
                item_id = item.get('id')
                if item_id and item_id in id_mapping:
                    llm_input_data["items"].append({
                        "id": item_id,
                        "code": item.get('code', ''),
                        "name": item.get('name', '')
                    })

            with open(llm_input_path, 'w', encoding='utf-8') as f:
                json.dump(llm_input_data, f, ensure_ascii=False, indent=2)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –æ—Ç Gemini
            llm_response_path = os.path.join(classified_dir, "llm_response.json")
            with open(llm_response_path, 'w', encoding='utf-8') as f:
                json.dump(gemini_response, f, ensure_ascii=False, indent=2)

            logging.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω—ã llm_input.json –∏ llm_response.json –≤ {classified_dir}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞
        if not gemini_response.get('success', False):
            logging.error(f"–û—à–∏–±–∫–∞ Gemini API: {gemini_response.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
            return {}

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
        response_text = gemini_response.get('raw_text', '')
        logging.info(f"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç Gemini: {response_text[:200]}...")

        # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç –∏–∑ gemini_response['response'] (—É–∂–µ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω)
        classifications = gemini_response.get('response', [])

        if isinstance(classifications, list):
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å –ø–æ ID
            result = {}
            for classification in classifications:
                item_id = classification.get('id') or classification.get('uuid')  # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                if item_id in id_mapping:
                    result[item_id] = {
                        'classification': classification.get('classification', '–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ'),
                        'reasoning': classification.get('reasoning', ''),
                        'original_item': id_mapping[item_id]
                    }

            logging.info(f"Gemini —É—Å–ø–µ—à–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–ª {len(result)} –ø–æ–∑–∏—Ü–∏–π")
            return result
        else:
            logging.error("Gemini –≤–µ—Ä–Ω—É–ª –æ—Ç–≤–µ—Ç –Ω–µ –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–∞")
            return {}

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Gemini API: {str(e)}")
        return {}

def convert_gemini_result(gemini_result: Dict) -> Dict:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç Gemini –≤ —Ñ–æ—Ä–º–∞—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å –æ—Å–Ω–æ–≤–Ω—ã–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º
    
    Args:
        gemini_result: –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç classify_with_gemini
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –ø–æ–ª—è–º–∏ classification, reasoning
    """
    classification = gemini_result.get('classification', '–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ')
    
    return {
        'classification': classification,
        'gemini_confidence': 0.85,  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        'gemini_reasoning': gemini_result.get('reasoning', '')
    }

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª—è
    logging.basicConfig(level=logging.INFO)
    
    test_items = [
        {
            'code': '47-1',
            'name': '–ü–æ–≥—Ä—É–∑–∫–∞ –≤ –∞–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–µ —Å—Ä–µ–¥—Å—Ç–≤–æ: –º—É—Å–æ—Ä —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–π —Å –ø–æ–≥—Ä—É–∑–∫–æ–π –≤—Ä—É—á–Ω—É—é'
        },
        {
            'code': '–ö–ü',
            'name': '–†–∞–∑–º–µ—â–µ–Ω–∏–µ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–æ–≥–æ –º—É—Å–æ—Ä–∞ –Ω–∞ –ø–æ–ª–∏–≥–æ–Ω–µ –¢–ë–û'
        }
    ]
    
    result = classify_with_gemini(test_items)
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {result}")

================================================================================

## –§–ê–ô–õ: src/data_processing/pdf_exporter.py
------------------------------------------------------------
"""
PDF Exporter –¥–ª—è HerZog v3.0
–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç Excel –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –≤ PDF —Ñ–æ—Ä–º–∞—Ç
"""

import os
import logging
from typing import Optional, List, Dict, Any
import subprocess
import json
from datetime import datetime

logger = logging.getLogger(__name__)

class PDFExporter:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤ –≤ PDF
    """
    
    def __init__(self):
        self.supported_formats = ['pdf', 'png', 'jpg']
    
    def export_excel_to_pdf(self, excel_file: str, output_path: str, format: str = 'pdf') -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç Excel —Ñ–∞–π–ª –≤ PDF –∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        
        Args:
            excel_file: –ü—É—Ç—å –∫ Excel —Ñ–∞–π–ª—É
            output_path: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            format: –§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ ('pdf', 'png', 'jpg')
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        try:
            if format not in self.supported_formats:
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {format}. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {self.supported_formats}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ Excel —Ñ–∞–π–ª–∞
            if not os.path.exists(excel_file):
                raise FileNotFoundError(f"Excel —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {excel_file}")
            
            logger.info(f"üìÑ –≠–∫—Å–ø–æ—Ä—Ç Excel –≤ {format.upper()}: {excel_file}")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            base_name = os.path.splitext(os.path.basename(excel_file))[0]
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_file = os.path.join(output_path, f"{base_name}_export.{format}")
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
            success = False
            
            # –ú–µ—Ç–æ–¥ 1: LibreOffice (—Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π)
            if not success:
                success = self._convert_with_libreoffice(excel_file, output_file, format)
            
            # –ú–µ—Ç–æ–¥ 2: Python –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (—Ä–µ–∑–µ—Ä–≤–Ω—ã–π)
            if not success:
                success = self._convert_with_python_libs(excel_file, output_file, format)
            
            # –ú–µ—Ç–æ–¥ 3: –°–æ–∑–¥–∞–µ–º PDF-–æ—Ç—á–µ—Ç "–≤—Ä—É—á–Ω—É—é" –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö
            if not success:
                success = self._create_pdf_from_data(excel_file, output_file)
            
            if success:
                logger.info(f"‚úÖ PDF —ç–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω: {output_file}")
                return output_file
            else:
                raise Exception("–í—Å–µ –º–µ—Ç–æ–¥—ã –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ PDF –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏")
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ PDF: {e}")
            raise
    
    def _convert_with_libreoffice(self, excel_file: str, output_file: str, format: str) -> bool:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∏—Å–ø–æ–ª—å–∑—É—è LibreOffice"""
        try:
            logger.info("üîÑ –ü–æ–ø—ã—Ç–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ LibreOffice...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ LibreOffice
            result = subprocess.run(['which', 'libreoffice'], capture_output=True, text=True)
            if result.returncode != 0:
                logger.warning("‚ö†Ô∏è LibreOffice –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–∏—Å—Ç–µ–º–µ")
                return False
            
            # –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
            output_dir = os.path.dirname(output_file)
            if format == 'pdf':
                cmd = [
                    'libreoffice', '--headless', '--convert-to', 'pdf',
                    '--outdir', output_dir, excel_file
                ]
            else:
                logger.warning(f"‚ö†Ô∏è LibreOffice –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø—Ä—è–º—É—é –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é –≤ {format}")
                return False
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                # LibreOffice —Å–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª —Å –∏–º–µ–Ω–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ + .pdf
                expected_file = os.path.join(output_dir, os.path.splitext(os.path.basename(excel_file))[0] + '.pdf')
                if os.path.exists(expected_file):
                    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Ñ–∞–π–ª –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    if expected_file != output_file:
                        os.rename(expected_file, output_file)
                    return True
            
            logger.warning(f"‚ö†Ô∏è LibreOffice –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å: {result.stderr}")
            return False
            
        except subprocess.TimeoutExpired:
            logger.warning("‚ö†Ô∏è LibreOffice –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ —Ç–∞–π–º–∞—É—Ç—É")
            return False
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ LibreOffice –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
            return False
    
    def _convert_with_python_libs(self, excel_file: str, output_file: str, format: str) -> bool:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∏—Å–ø–æ–ª—å–∑—É—è Python –±–∏–±–ª–∏–æ—Ç–µ–∫–∏"""
        try:
            logger.info("üîÑ –ü–æ–ø—ã—Ç–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ Python –±–∏–±–ª–∏–æ—Ç–µ–∫–∏...")
            
            # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å reportlab –¥–ª—è PDF
            if format == 'pdf':
                return self._create_pdf_with_reportlab(excel_file, output_file)
            
            # –î–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å PIL + openpyxl
            elif format in ['png', 'jpg']:
                logger.warning("‚ö†Ô∏è –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Python –ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞")
                return False
            
            return False
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Python –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
            return False
    
    def _create_pdf_with_reportlab(self, excel_file: str, output_file: str) -> bool:
        """–°–æ–∑–¥–∞–µ—Ç PDF –∏—Å–ø–æ–ª—å–∑—É—è reportlab"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ reportlab
            try:
                from reportlab.lib.pagesizes import letter, A4
                from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
                from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
                from reportlab.lib import colors
                from reportlab.lib.units import cm
                from reportlab.pdfbase import pdfmetrics
                from reportlab.pdfbase.ttfonts import TTFont
            except ImportError:
                logger.warning("‚ö†Ô∏è reportlab –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                return False
            
            import openpyxl
            
            # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Excel
            wb = openpyxl.load_workbook(excel_file)
            
            # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —à—Ä–∏—Ñ—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
            try:
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Å–∏—Å—Ç–µ–º–Ω—ã–π —à—Ä–∏—Ñ—Ç —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π
                font_paths = [
                    '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf',  # Ubuntu/Debian
                    '/usr/share/fonts/TTF/DejaVuSans.ttf',            # Arch
                    '/System/Library/Fonts/Arial.ttf',               # macOS
                    'C:/Windows/Fonts/arial.ttf',                    # Windows
                    '/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf'  # Liberation
                ]
                
                font_registered = False
                for font_path in font_paths:
                    if os.path.exists(font_path):
                        pdfmetrics.registerFont(TTFont('CyrillicFont', font_path))
                        font_registered = True
                        logger.info(f"üìù –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω —à—Ä–∏—Ñ—Ç: {font_path}")
                        break
                
                if not font_registered:
                    logger.warning("‚ö†Ô∏è –®—Ä–∏—Ñ—Ç —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π")
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ —à—Ä–∏—Ñ—Ç–∞: {e}")

            # –°–æ–∑–¥–∞–µ–º PDF
            doc = SimpleDocTemplate(output_file, pagesize=A4)
            story = []
            styles = getSampleStyleSheet()
            
            # –°–æ–∑–¥–∞–µ–º —Å—Ç–∏–ª–∏ —Å –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–º —à—Ä–∏—Ñ—Ç–æ–º
            if font_registered:
                styles.add(ParagraphStyle('CyrillicHeading1',
                                        parent=styles['Heading1'],
                                        fontName='CyrillicFont',
                                        fontSize=16))
                styles.add(ParagraphStyle('CyrillicNormal',
                                        parent=styles['Normal'],
                                        fontName='CyrillicFont',
                                        fontSize=10))
                heading_style = 'CyrillicHeading1'
                normal_style = 'CyrillicNormal'
            else:
                heading_style = 'Heading1'
                normal_style = 'Normal'
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ª–∏—Å—Ç Excel
            for sheet_name in wb.sheetnames:
                ws = wb[sheet_name]
                
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ª–∏—Å—Ç–∞
                story.append(Paragraph(f"<b>{sheet_name}</b>", styles[heading_style]))
                story.append(Spacer(1, 0.5*cm))
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ª–∏—Å—Ç–∞ (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 20 —Å—Ç—Ä–æ–∫ –∏ 10 –∫–æ–ª–æ–Ω–æ–∫)
                max_rows = min(20, ws.max_row)
                max_cols = min(10, ws.max_column)
                
                data = []
                for row in range(1, max_rows + 1):
                    row_data = []
                    for col in range(1, max_cols + 1):
                        cell_value = ws.cell(row=row, column=col).value
                        if cell_value is None:
                            row_data.append("")
                        else:
                            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞
                            text = str(cell_value)
                            if len(text) > 30:
                                text = text[:27] + "..."
                            row_data.append(text)
                    data.append(row_data)
                
                # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
                if data:
                    table = Table(data)
                    
                    # –í—ã–±–∏—Ä–∞–µ–º —à—Ä–∏—Ñ—Ç –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã
                    table_font = 'CyrillicFont' if font_registered else 'Helvetica'
                    table_font_bold = 'CyrillicFont' if font_registered else 'Helvetica-Bold'
                    
                    table.setStyle(TableStyle([
                        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
                        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                        ('FONTNAME', (0, 0), (-1, 0), table_font_bold),
                        ('FONTNAME', (0, 1), (-1, -1), table_font),
                        ('FONTSIZE', (0, 0), (-1, 0), 8),
                        ('FONTSIZE', (0, 1), (-1, -1), 7),
                        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
                        ('GRID', (0, 0), (-1, -1), 1, colors.black)
                    ]))
                    story.append(table)
                
                story.append(Spacer(1, 1*cm))
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º PDF
            doc.build(story)
            logger.info("‚úÖ PDF —Å–æ–∑–¥–∞–Ω —á–µ—Ä–µ–∑ reportlab")
            return True
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è PDF —á–µ—Ä–µ–∑ reportlab: {e}")
            return False
    
    def _create_pdf_from_data(self, excel_file: str, output_file: str) -> bool:
        """–°–æ–∑–¥–∞–µ—Ç PDF –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö true.json"""
        try:
            logger.info("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ PDF –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            
            # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π true.json —Ñ–∞–π–ª
            project_dir = self._find_project_dir(excel_file)
            if not project_dir:
                logger.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–∞–ø–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞")
                return False
            
            truth_file = os.path.join(project_dir, "true.json")
            if not os.path.exists(truth_file):
                logger.warning("‚ö†Ô∏è –§–∞–π–ª true.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return False
            
            # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            with open(truth_file, 'r', encoding='utf-8') as f:
                truth_data = json.load(f)
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π PDF
            return self._create_simple_text_pdf(truth_data, output_file)
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è PDF –∏–∑ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return False
    
    def _find_project_dir(self, excel_file: str) -> Optional[str]:
        """–ò—â–µ—Ç –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞ –ø–æ Excel —Ñ–∞–π–ª—É"""
        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ Excel —Ñ–∞–π–ª —Å–æ–∑–¥–∞–µ—Ç—Å—è –≤ /tmp, –∞ –ø—Ä–æ–µ–∫—Ç –≤ /projects
        project_dirs = []
        
        # –ò—â–µ–º –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
        herzog_path = "/home/imort/Herzog_v3"
        if os.path.exists(herzog_path):
            projects_path = os.path.join(herzog_path, "projects")
            if os.path.exists(projects_path):
                # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∏–∑–º–µ–Ω–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞
                for user_dir in os.listdir(projects_path):
                    user_path = os.path.join(projects_path, user_dir)
                    if os.path.isdir(user_path):
                        for project_dir in os.listdir(user_path):
                            project_path = os.path.join(user_path, project_dir)
                            if os.path.isdir(project_path):
                                project_dirs.append((project_path, os.path.getmtime(project_path)))
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–∞–º—É—é —Å–≤–µ–∂—É—é –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞
        if project_dirs:
            project_dirs.sort(key=lambda x: x[1], reverse=True)
            return project_dirs[0][0]
        
        return None
    
    def _create_simple_text_pdf(self, truth_data: Dict, output_file: str) -> bool:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π PDF"""
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å weasyprint –¥–ª—è HTML->PDF
            try:
                import weasyprint
                return self._create_html_pdf(truth_data, output_file)
            except ImportError:
                pass
            
            # –†–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç: —Å–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –≤–º–µ—Å—Ç–æ PDF
            text_file = output_file.replace('.pdf', '.txt')
            
            with open(text_file, 'w', encoding='utf-8') as f:
                f.write("–ö–ê–õ–ï–ù–î–ê–†–ù–´–ô –ì–†–ê–§–ò–ö –ü–†–û–ò–ó–í–û–î–°–¢–í–ê –†–ê–ë–û–¢\n")
                f.write("="*50 + "\n\n")
                
                # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                project_name = truth_data.get('project_inputs', {}).get('project_name', '–ë–µ–∑—ã–º—è–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç')
                f.write(f"–ü—Ä–æ–µ–∫—Ç: {project_name}\n")
                f.write(f"–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {datetime.now().strftime('%d.%m.%Y %H:%M')}\n\n")
                
                # –ü–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç
                work_packages = truth_data.get('results', {}).get('work_packages', [])
                f.write(f"–ü–ê–ö–ï–¢–´ –†–ê–ë–û–¢ ({len(work_packages)} —à—Ç.):\n")
                f.write("-" * 30 + "\n")
                
                for i, package in enumerate(work_packages, 1):
                    name = package.get('name', '–ë–µ–∑—ã–º—è–Ω–Ω—ã–π –ø–∞–∫–µ—Ç')
                    volume_data = package.get('volume_data', {})
                    unit = volume_data.get('unit', '—à—Ç')
                    quantity = volume_data.get('quantity', 0)
                    
                    f.write(f"{i}. {name}\n")
                    f.write(f"   –û–±—ä–µ–º: {quantity} {unit}\n")
                    
                    # –ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω
                    schedule_blocks = package.get('schedule_blocks', [])
                    if schedule_blocks:
                        f.write(f"   –ù–µ–¥–µ–ª–∏: {', '.join(map(str, schedule_blocks))}\n")
                    
                    f.write("\n")
            
            # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –≤ .pdf –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            if os.path.exists(text_file):
                os.rename(text_file, output_file)
                logger.info("‚úÖ –°–æ–∑–¥–∞–Ω —Ç–µ–∫—Å—Ç–æ–≤—ã–π PDF (–∫–∞–∫ .txt)")
                return True
            
            return False
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ—Å—Ç–æ–≥–æ PDF: {e}")
            return False
    
    def _create_html_pdf(self, truth_data: Dict, output_file: str) -> bool:
        """–°–æ–∑–¥–∞–µ—Ç PDF —á–µ—Ä–µ–∑ HTML+CSS"""
        try:
            import weasyprint
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML
            html_content = self._generate_html_report(truth_data)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PDF
            weasyprint.HTML(string=html_content).write_pdf(output_file)
            logger.info("‚úÖ PDF —Å–æ–∑–¥–∞–Ω —á–µ—Ä–µ–∑ weasyprint")
            return True
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è HTML PDF: {e}")
            return False
    
    def _generate_html_report(self, truth_data: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML –æ—Ç—á–µ—Ç"""
        project_name = truth_data.get('project_inputs', {}).get('project_name', '–ë–µ–∑—ã–º—è–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç')
        work_packages = truth_data.get('results', {}).get('work_packages', [])
        
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>–ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ - {project_name}</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                h1 {{ color: #366092; text-align: center; }}
                table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
                th, td {{ border: 1px solid #ccc; padding: 8px; text-align: left; }}
                th {{ background-color: #366092; color: white; }}
                .center {{ text-align: center; }}
            </style>
        </head>
        <body>
            <h1>üìä –ö–ê–õ–ï–ù–î–ê–†–ù–´–ô –ì–†–ê–§–ò–ö –ü–†–û–ò–ó–í–û–î–°–¢–í–ê –†–ê–ë–û–¢</h1>
            <h2>{project_name}</h2>
            <p><strong>–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:</strong> {datetime.now().strftime('%d.%m.%Y %H:%M')}</p>
            
            <h3>–ü–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç</h3>
            <table>
                <tr>
                    <th>‚Ññ</th>
                    <th>–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ</th>
                    <th>–ï–¥–∏–Ω–∏—Ü–∞</th>
                    <th>–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ</th>
                    <th>–ù–µ–¥–µ–ª–∏</th>
                </tr>
        """
        
        for i, package in enumerate(work_packages, 1):
            name = package.get('name', '–ë–µ–∑—ã–º—è–Ω–Ω—ã–π –ø–∞–∫–µ—Ç')
            volume_data = package.get('volume_data', {})
            unit = volume_data.get('unit', '—à—Ç')
            quantity = volume_data.get('quantity', 0)
            schedule_blocks = package.get('schedule_blocks', [])
            weeks = ', '.join(map(str, schedule_blocks)) if schedule_blocks else '-'
            
            html += f"""
                <tr>
                    <td class="center">{i}</td>
                    <td>{name}</td>
                    <td class="center">{unit}</td>
                    <td class="center">{quantity}</td>
                    <td class="center">{weeks}</td>
                </tr>
            """
        
        html += """
            </table>
        </body>
        </html>
        """
        
        return html


def export_schedule_to_pdf(excel_file: str, output_path: str, format: str = 'pdf') -> str:
    """
    –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –≤ PDF
    
    Args:
        excel_file: –ü—É—Ç—å –∫ Excel —Ñ–∞–π–ª—É
        output_path: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        format: –§–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞ ('pdf', 'png', 'jpg')
        
    Returns:
        –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
    """
    exporter = PDFExporter()
    return exporter.export_excel_to_pdf(excel_file, output_path, format)


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–∫—Å–ø–æ—Ä—Ç–∞
    test_excel = "/tmp/–û—Ç—á–µ—Ç_–ü—Ä–æ–µ–∫—Ç_20250910_141641.xlsx"
    test_output = "/tmp"
    
    if os.path.exists(test_excel):
        print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ PDF...")
        try:
            pdf_file = export_schedule_to_pdf(test_excel, test_output)
            print(f"‚úÖ PDF —ç–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω: {pdf_file}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}")
            import traceback
            traceback.print_exc()
    else:
        print(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π Excel —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {test_excel}")

================================================================================

## –§–ê–ô–õ: src/data_processing/preparer.py
------------------------------------------------------------
"""
–ú–æ–¥—É–ª—å PREPARER –¥–ª—è HerZog v3.0
–ó–∞–¥–∞—á–∞: –û–†–ö–ï–°–¢–†–ê–¢–û–† - –≤—ã–∑—ã–≤–∞–µ—Ç classifier.py –∏ timeline_blocks.py, —Å–æ–±–∏—Ä–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–®–∞–≥ 3 –ø–∞–π–ø–ª–∞–π–Ω–∞)
"""

import json
import logging
from datetime import datetime
from typing import Dict, List, Any
import os

from ..shared.timeline_blocks import generate_weekly_blocks

logger = logging.getLogger(__name__)


def filter_works_from_classified(classified_data: List[Dict]) -> List[Dict]:
    """
    –ü—Ä–æ—Å—Ç–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç + –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è AI-–∞–≥–µ–Ω—Ç–æ–≤
    
    Args:
        classified_data: –†–µ–∑—É–ª—å—Ç–∞—Ç classifier.classify_estimates()
        
    Returns:
        –°–ø–∏—Å–æ–∫ —Ä–∞–±–æ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è AI-–∞–≥–µ–Ω—Ç–æ–≤
    """
    import uuid
    
    work_items = []
    
    for item in classified_data:
        if item.get('classification') == '–†–∞–±–æ—Ç–∞':
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –µ–¥–∏–Ω—ã–π ID –±–µ–∑ –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏ - –ø–ª–æ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
            work_item = {
                'id': item.get('id'),
                'source_file': item.get('source_file'),
                'position_num': item.get('position_num'),
                'code': item.get('code'),
                'name': item.get('name'),
                'unit': item.get('unit'),
                'quantity': item.get('quantity'),
                'classification': item.get('classification')
                # –ü–æ–ª—è group_id, group_name –¥–æ–±–∞–≤—è—Ç AI-–∞–≥–µ–Ω—Ç—ã –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
            }
            
            work_items.append(work_item)
    
    logger.info(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(work_items)} —Ä–∞–±–æ—á–∏—Ö –ø–æ–∑–∏—Ü–∏–π –∏–∑ {len(classified_data)}")
    return work_items


def prepare_project_data(raw_estimates_file: str, directives_file: str) -> Dict[str, Any]:
    """
    –û–†–ö–ï–°–¢–†–ê–¢–û–†: –í—ã–∑—ã–≤–∞–µ—Ç –º–æ–¥—É–ª–∏ –∏ —Å–æ–±–∏—Ä–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ project_data.json
    
    Args:
        raw_estimates_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É raw_estimates.json (–∏–∑ extractor)
        directives_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É directives.json
        
    Returns:
        –ï–¥–∏–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ–µ–∫—Ç–∞
    """
    
    logger.info("üé≠ PREPARER: –ù–∞—á–∏–Ω–∞—é –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—é –º–æ–¥—É–ª–µ–π...")
    
    # –®–ê–ì 1: –ß–∏—Ç–∞–µ–º —É–∂–µ –≥–æ—Ç–æ–≤—ã–µ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    logger.info("üìã –ß–∏—Ç–∞—é –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
    classified_file = raw_estimates_file.replace('1_extracted/raw_estimates.json', '2_classified/classified_estimates.json')
    
    with open(classified_file, 'r', encoding='utf-8') as f:
        classified_data = json.load(f)
    
    # –®–ê–ì 2: –ß–∏—Ç–∞–µ–º –¥–∏—Ä–µ–∫—Ç–∏–≤—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    with open(directives_file, 'r', encoding='utf-8') as f:
        directives = json.load(f)
    
    logger.info(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∏—Ä–µ–∫—Ç–∏–≤—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    
    # –®–ê–ì 3: –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—Ç—ã –¥–ª—è AI-–∞–≥–µ–Ω—Ç–æ–≤
    work_items = filter_works_from_classified(classified_data)
    
    # –®–ê–ì 4: –í—ã–∑—ã–≤–∞–µ–º TIMELINE_BLOCKS –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–µ–¥–µ–ª—å–Ω—ã—Ö –±–ª–æ–∫–æ–≤
    timeline = directives.get('project_timeline', {})
    start_date = timeline.get('start_date', '01.01.2024')
    end_date = timeline.get('end_date', '31.12.2024')
    
    logger.info(f"üìÖ –í—ã–∑—ã–≤–∞—é TIMELINE_BLOCKS –¥–ª—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞ {start_date} - {end_date}")
    timeline_result = generate_weekly_blocks(start_date, end_date)
    timeline_blocks = timeline_result['blocks']
    
    # –®–ê–ì 5: –°–æ–±–∏—Ä–∞–µ–º –µ–¥–∏–Ω—ã–π project_data.json
    project_data = {
        'meta': {
            'created_at': datetime.now().isoformat(),
            'total_work_items': len(work_items),
            'total_timeline_blocks': len(timeline_blocks),
            'project_duration_weeks': len(timeline_blocks)
        },
        'directives': directives,
        'timeline_blocks': timeline_blocks,
        'work_items': work_items,
        'processing_status': {
            'extraction': 'completed',
            'classification': 'completed', 
            'preparation': 'completed',
            'conceptualization': 'pending',
            'scheduling': 'pending',
            'accounting': 'pending',
            'staffing': 'pending',
            'reporting': 'pending'
        },
        'groups_data': {}
    }
    
    logger.info(f"‚úÖ PREPARER –∑–∞–≤–µ—Ä—à–µ–Ω: {len(work_items)} —Ä–∞–±–æ—Ç, {len(timeline_blocks)} –Ω–µ–¥–µ–ª—å")
    
    return project_data


def validate_project_data(project_data: Dict) -> bool:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞
    
    Args:
        project_data: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ–µ–∫—Ç–∞
        
    Returns:
        True –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –≤–∞–ª–∏–¥–Ω—ã
    """
    required_keys = ['meta', 'directives', 'timeline_blocks', 'work_items']
    
    for key in required_keys:
        if key not in project_data:
            logger.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ: {key}")
            return False
    
    if not project_data['work_items']:
        logger.error("–ù–µ—Ç —Ä–∞–±–æ—á–∏—Ö –ø–æ–∑–∏—Ü–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return False
    
    if not project_data['timeline_blocks']:
        logger.error("–ù–µ —Å–æ–∑–¥–∞–Ω—ã –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–∞–±–æ—á–∏—Ö –ø–æ–∑–∏—Ü–∏–π
    for item in project_data['work_items']:
        required_item_keys = ['id', 'source_file', 'code', 'name']
        for key in required_item_keys:
            if key not in item:
                logger.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ {key} –≤ —Ä–∞–±–æ—á–µ–π –ø–æ–∑–∏—Ü–∏–∏")
                return False
    
    logger.info("–í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–∞")
    return True


if __name__ == "__main__":
    import sys
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(level=logging.INFO)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) > 1:
        # –†–µ–∂–∏–º —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è - –∞—Ä–≥—É–º–µ–Ω—Ç = –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
        project_dir = sys.argv[1]
        raw_estimates_file = os.path.join(project_dir, '1_extracted', 'raw_estimates.json')
        directives_file = os.path.join(project_dir, '0_input', 'directives.json')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª—ã —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        if not os.path.exists(raw_estimates_file):
            logger.error(f"–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {raw_estimates_file}")
            sys.exit(1)
            
        if not os.path.exists(directives_file):
            logger.error(f"–ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {directives_file}")
            sys.exit(1)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
        try:
            result = prepare_project_data(raw_estimates_file, directives_file)
            is_valid = validate_project_data(result)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            output_file = os.path.join(project_dir, '3_prepared', 'project_data.json')
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            logger.info(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
            print(f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í–∞–ª–∏–¥–Ω–æ—Å—Ç—å: {is_valid}")
            print(f"–†–∞–±–æ—á–∏—Ö –ø–æ–∑–∏—Ü–∏–π: {len(result['work_items'])}")
            print(f"–í—Ä–µ–º–µ–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤: {len(result['timeline_blocks'])}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
            sys.exit(1)
    
    else:
        # –†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è - –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
        logger.info("–†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è preparer...")
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–∏–≤
        test_directives = {
            'target_work_count': 15,
            'project_timeline': {
                'start_date': '01.01.2024',
                'end_date': '30.06.2024'
            },
            'workforce_range': {'min': 10, 'max': 20}
        }
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_classified = [
            {
                'id': 'test-1',
                'classification': '–†–∞–±–æ—Ç–∞',
                'name': '–¢–µ—Å—Ç–æ–≤–∞—è —Ä–∞–±–æ—Ç–∞ 1',
                'code': '–ì–≠–°–ù-001',
                'quantity': '100',
                'source_file': 'test.xlsx',
                'position_num': '1',
                'unit': '–º2'
            },
            {
                'id': 'test-2', 
                'classification': '–ú–∞—Ç–µ—Ä–∏–∞–ª',
                'name': '–¢–µ—Å—Ç–æ–≤—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª',
                'code': '–§–°–°–¶-001',
                'source_file': 'test.xlsx',
                'position_num': '2',
                'unit': '–∫–≥',
                'quantity': '1000'
            }
        ]
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        import tempfile
        
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f1:
            json.dump(test_classified, f1, ensure_ascii=False)
            classified_file = f1.name
        
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f2:
            json.dump(test_directives, f2, ensure_ascii=False)
            directives_file = f2.name
        
        try:
            result = prepare_project_data(classified_file, directives_file)
            is_valid = validate_project_data(result)
            
            print(f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í–∞–ª–∏–¥–Ω–æ—Å—Ç—å: {is_valid}")
            print(f"–†–∞–±–æ—á–∏—Ö –ø–æ–∑–∏—Ü–∏–π: {len(result['work_items'])}")
            print(f"–í—Ä–µ–º–µ–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤: {len(result['timeline_blocks'])}")
            
        finally:
            # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            os.unlink(classified_file)
            os.unlink(directives_file)

================================================================================

## –§–ê–ô–õ: src/data_processing/reporter_v3.py
------------------------------------------------------------
"""
–ù–û–í–´–ô –ú–æ–¥—É–ª—å REPORTER v3 –¥–ª—è HerZog v3.0
–°–æ–∑–¥–∞–Ω–∏–µ –ú–ù–û–ì–û–°–¢–†–ê–ù–ò–ß–ù–û–ì–û Excel –æ—Ç—á–µ—Ç–∞ —Å –ª–∏—Å—Ç–∞–º–∏:
- üìä –ì—Ä–∞—Ñ–∏–∫ (–∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω Gantt)
- üìã –ü–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç (–¥–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è)
- üßÆ –õ–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–æ–≤ (—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è)
"""

import json
import logging
import os
from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Border, Side, Alignment, NamedStyle
from openpyxl.formatting.rule import CellIsRule
from openpyxl.utils import get_column_letter
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Any

logger = logging.getLogger(__name__)

class MultiPageScheduleGenerator:
    """
    –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –º–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ–≥–æ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞ –≤ —Å—Ç–∏–ª–µ HerZog v3.0
    """
    
    def __init__(self):
        # –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—Ç–∏–ª–∏ –¥–ª—è Excel
        self.header_fill = PatternFill(start_color="2E4057", end_color="2E4057", fill_type="solid")  # –¢–µ–º–Ω–æ-—Å–∏–Ω–∏–π
        self.header_font = Font(color="FFFFFF", bold=True, size=11)
        self.subheader_fill = PatternFill(start_color="4A628A", end_color="4A628A", fill_type="solid")  # –°—Ä–µ–¥–Ω–∏–π —Å–∏–Ω–∏–π
        self.subheader_font = Font(color="FFFFFF", bold=True, size=10)
        
        # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä—ã —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏
        self.progress_high = PatternFill(start_color="4CAF50", end_color="4CAF50", fill_type="solid")  # –ó–µ–ª–µ–Ω—ã–π
        self.progress_medium = PatternFill(start_color="FF9800", end_color="FF9800", fill_type="solid")  # –û—Ä–∞–Ω–∂–µ–≤—ã–π
        self.progress_low = PatternFill(start_color="F44336", end_color="F44336", fill_type="solid")  # –ö—Ä–∞—Å–Ω—ã–π
        
        # –ê–∫—Ü–µ–Ω—Ç–Ω—ã–µ —Ü–≤–µ—Ç–∞
        self.info_fill = PatternFill(start_color="E3F2FD", end_color="E3F2FD", fill_type="solid")  # –°–≤–µ—Ç–ª–æ-–≥–æ–ª—É–±–æ–π
        self.logic_fill = PatternFill(start_color="F1F8E9", end_color="F1F8E9", fill_type="solid")  # –°–≤–µ—Ç–ª–æ-–∑–µ–ª–µ–Ω—ã–π
        self.reasoning_fill = PatternFill(start_color="FFF3E0", end_color="FFF3E0", fill_type="solid")  # –°–≤–µ—Ç–ª–æ-–æ—Ä–∞–Ω–∂–µ–≤—ã–π
        self.warning_fill = PatternFill(start_color="FFEBEE", end_color="FFEBEE", fill_type="solid")  # –°–≤–µ—Ç–ª–æ-–∫—Ä–∞—Å–Ω—ã–π
        
        # –ì—Ä–∞–Ω–∏—Ü—ã
        self.border = Border(
            left=Side(style='thin', color='CCCCCC'), 
            right=Side(style='thin', color='CCCCCC'),
            top=Side(style='thin', color='CCCCCC'), 
            bottom=Side(style='thin', color='CCCCCC')
        )
        self.thick_border = Border(
            left=Side(style='medium', color='2E4057'), 
            right=Side(style='medium', color='2E4057'),
            top=Side(style='medium', color='2E4057'), 
            bottom=Side(style='medium', color='2E4057')
        )
        
        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ
        self.center_align = Alignment(horizontal='center', vertical='center', wrap_text=True)
        self.left_align = Alignment(horizontal='left', vertical='center', wrap_text=True)
        self.right_align = Alignment(horizontal='right', vertical='center')
        self.top_left_align = Alignment(horizontal='left', vertical='top', wrap_text=True)
    
    def generate_multipage_excel(self, input_file: str, output_path: str) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ–≥–æ Excel –æ—Ç—á–µ—Ç–∞ –∏–∑ true.json
        
        Args:
            input_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É true.json
            output_path: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        try:
            # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ true.json
            with open(input_file, 'r', encoding='utf-8') as f:
                truth_data = json.load(f)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–µ—Ä—Å–∏—é —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            structure_version = truth_data.get('meta', {}).get('structure_version', '1.0')
            logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ true.json –≤–µ—Ä—Å–∏–∏ {structure_version}")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–µ—Ä—Å–∏–∏
            if structure_version == "2.0":
                extracted_data = self._extract_data_v2(truth_data)
            else:
                extracted_data = self._extract_data_v1(truth_data)
            
            work_packages = extracted_data['work_packages']
            timeline_blocks = extracted_data['timeline_blocks']
            project_info = extracted_data['project_info']
            
            if not work_packages:
                raise Exception("–ù–µ—Ç –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞")
            
            if not timeline_blocks:
                raise Exception("–ù–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –¥–ª—è –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞")
            
            logger.info(f"üìä –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –¥–ª—è {len(work_packages)} –ø–∞–∫–µ—Ç–æ–≤ –Ω–∞ {len(timeline_blocks)} –Ω–µ–¥–µ–ª—å")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º scheduling_reasoning –¥–∞–Ω–Ω—ã–µ
            scheduling_data = self._load_scheduling_reasoning(input_file)
            
            # –°–æ–∑–¥–∞–µ–º Excel —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ª–∏—Å—Ç–∞–º–∏
            wb = Workbook()
            
            # –õ–∏—Å—Ç 1: üìä –ì—Ä–∞—Ñ–∏–∫ (Gantt)
            ws_schedule = wb.active
            ws_schedule.title = "üìä –ì—Ä–∞—Ñ–∏–∫"
            self._create_schedule_sheet(ws_schedule, work_packages, timeline_blocks, project_info, scheduling_data)
            
            # –õ–∏—Å—Ç 2: üìÖ –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è (–ù–û–í–´–ô!)
            ws_reasoning = wb.create_sheet("üìÖ –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ")
            self._create_reasoning_sheet(ws_reasoning, work_packages, timeline_blocks, project_info, scheduling_data)
            
            # –õ–∏—Å—Ç 3: üìã –ü–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç
            ws_packages = wb.create_sheet("üìã –ü–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç")
            self._create_packages_sheet(ws_packages, work_packages, project_info)
            
            # –õ–∏—Å—Ç 4: üßÆ –õ–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–æ–≤  
            ws_logic = wb.create_sheet("üßÆ –õ–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–æ–≤")
            self._create_logic_sheet(ws_logic, work_packages, project_info, extracted_data)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            project_name = project_info.get('project_name', 'project').replace(' ', '_')
            filename = f"–û—Ç—á–µ—Ç_{project_name}_{timestamp}.xlsx"
            output_file = os.path.join(output_path, filename)
            
            wb.save(output_file)
            logger.info(f"‚úÖ –ú–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
            
            return output_file
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –º–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞: {e}")
            import traceback
            logger.error(f"üìã –ü–æ–ª–Ω–∞—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ –æ—à–∏–±–∫–∏:\\n{traceback.format_exc()}")
            raise
    
    def _load_scheduling_reasoning(self, input_file: str) -> Dict[str, Any]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ scheduling_reasoning –∏–∑ –ø–∞–ø–∫–∏ scheduler_and_staffer
        """
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ scheduler_and_staffer
            project_folder = os.path.dirname(input_file)
            scheduler_response_path = os.path.join(project_folder, "7_scheduler_and_staffer", "llm_response.json")
            
            if not os.path.exists(scheduler_response_path):
                logger.warning(f"–§–∞–π–ª scheduling_reasoning –Ω–µ –Ω–∞–π–¥–µ–Ω: {scheduler_response_path}")
                return {}
            
            with open(scheduler_response_path, 'r', encoding='utf-8') as f:
                scheduler_data = json.load(f)
            
            if not scheduler_data.get('success', False):
                logger.warning("Scheduler response –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —É—Å–ø–µ—à–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")
                return {}
            
            # –ü–∞—Ä—Å–∏–º JSON –∏–∑ response
            raw_response = scheduler_data.get('raw_text', scheduler_data.get('response', ''))
            if isinstance(raw_response, str):
                try:
                    # –û—á–∏—â–∞–µ–º –æ—Ç markdown –µ—Å–ª–∏ –µ—Å—Ç—å
                    if raw_response.strip().startswith('```'):
                        # –£–±–∏—Ä–∞–µ–º ```json –≤ –Ω–∞—á–∞–ª–µ –∏ ``` –≤ –∫–æ–Ω—Ü–µ
                        lines = raw_response.strip().split('\n')
                        if lines[0].startswith('```'):
                            lines = lines[1:]
                        if lines[-1].strip() == '```':
                            lines = lines[:-1]
                        raw_response = '\n'.join(lines)
                    
                    parsed_response = json.loads(raw_response)
                except json.JSONDecodeError as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å scheduler response JSON: {e}")
                    logger.warning(f"Raw response sample: {raw_response[:200]}...")
                    return {}
            else:
                parsed_response = raw_response
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º scheduled_packages —Å reasoning
            scheduled_packages = parsed_response.get('scheduled_packages', [])
            
            # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            reasoning_dict = {}
            for package in scheduled_packages:
                package_id = package.get('package_id')
                if package_id and 'scheduling_reasoning' in package:
                    reasoning_dict[package_id] = {
                        'scheduling_reasoning': package['scheduling_reasoning'],
                        'schedule_blocks': package.get('schedule_blocks', []),
                        'progress_per_block': package.get('progress_per_block', {}),
                        'staffing_per_block': package.get('staffing_per_block', {})
                    }
            
            logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–π –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è {len(reasoning_dict)} –ø–∞–∫–µ—Ç–æ–≤")
            return reasoning_dict
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ scheduling_reasoning: {e}")
            return {}
    
    def _extract_data_v2(self, truth_data: Dict) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã v2.0"""
        return {
            'work_packages': truth_data.get('results', {}).get('work_packages', []),
            'timeline_blocks': truth_data.get('timeline_blocks', []),
            'project_info': {
                'project_name': truth_data.get('meta', {}).get('project_name', '–ü—Ä–æ–µ–∫—Ç'),
                'created_at': truth_data.get('meta', {}).get('created_at'),
                'structure_version': '2.0'
            },
            'user_inputs': truth_data.get('user_inputs', {}),
            'pipeline_status': truth_data.get('pipeline', {})
        }
    
    def _extract_data_v1(self, truth_data: Dict) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã v1.0"""
        return {
            'work_packages': truth_data.get('results', {}).get('work_packages', []),
            'timeline_blocks': truth_data.get('timeline_blocks', []),
            'project_info': {
                'project_name': truth_data.get('project_inputs', {}).get('project_name', '–ü—Ä–æ–µ–∫—Ç'),
                'created_at': truth_data.get('metadata', {}).get('created_at'),
                'structure_version': '1.0'
            },
            'user_inputs': truth_data.get('project_inputs', {}),
            'pipeline_status': truth_data.get('metadata', {}).get('pipeline_status', [])
        }
    
    def _create_schedule_sheet(self, ws, work_packages: List[Dict], timeline_blocks: List[Dict], project_info: Dict, scheduling_data: Dict = {}):
        """–°–æ–∑–¥–∞–µ—Ç –ª–∏—Å—Ç —Å –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–º –≥—Ä–∞—Ñ–∏–∫–æ–º (Gantt)"""
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        ws['A1'] = "üìä –ö–ê–õ–ï–ù–î–ê–†–ù–´–ô –ì–†–ê–§–ò–ö –ü–†–û–ò–ó–í–û–î–°–¢–í–ê –†–ê–ë–û–¢"
        ws.merge_cells('A1:G1')
        ws['A1'].font = Font(bold=True, size=16, color="366092")
        ws['A1'].alignment = self.center_align
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–µ–∫—Ç–µ
        ws['A2'] = f"–ü—Ä–æ–µ–∫—Ç: {project_info.get('project_name', '–ë–µ–∑—ã–º—è–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç')}"
        ws.merge_cells('A2:G2')
        ws['A2'].font = Font(bold=True, size=12)
        ws['A2'].alignment = self.center_align
        
        ws['A3'] = f"–°–æ–∑–¥–∞–Ω: {self._format_datetime(project_info.get('created_at'))}"
        ws.merge_cells('A3:G3')
        ws['A3'].font = Font(size=10)
        ws['A3'].alignment = self.center_align
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –∫–æ–ª–æ–Ω–æ–∫ (—Å—Ç—Ä–æ–∫–∞ 5)
        headers = [
            "‚Ññ –ø/–ø",
            "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –≤–∏–¥–∞ —Ä–∞–±–æ—Ç", 
            "–ï–¥. –∏–∑–º.",
            "–ö–æ–ª-–≤–æ",
            "–ù–∞—á–∞–ª–æ",
            "–û–∫–æ–Ω—á–∞–Ω–∏–µ",
            "–ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω –ø–æ –Ω–µ–¥–µ–ª—è–º"
        ]
        
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=5, column=col, value=header)
            cell.font = self.header_font
            cell.fill = self.header_fill
            cell.alignment = self.center_align
            cell.border = self.border
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º "–ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω" –Ω–∞ –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ª–æ–Ω–æ–∫
        timeline_cols = len(timeline_blocks)
        if timeline_cols > 1:
            ws.merge_cells(f'G5:{get_column_letter(6 + timeline_cols)}5')
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –Ω–µ–¥–µ–ª—å (—Å—Ç—Ä–æ–∫–∞ 6)
        for i, block in enumerate(timeline_blocks, 7):
            week_id = block.get('week_id', block.get('block_id', i-6))
            start_date = datetime.fromisoformat(block['start_date']).strftime('%d.%m')
            end_date = datetime.fromisoformat(block['end_date']).strftime('%d.%m')
            
            cell = ws.cell(row=6, column=i, value=f"–ù–µ–¥.{week_id}\n{start_date}-{end_date}")
            cell.font = Font(size=8, bold=True)
            cell.fill = self.info_fill
            cell.alignment = self.center_align
            cell.border = self.border

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—ã—Å–æ—Ç—É —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –Ω–µ–¥–µ–ª—å
        ws.row_dimensions[6].height = 30

        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç
        current_row = 7
        for i, package in enumerate(work_packages, 1):
            package_id = package.get('package_id', '')
            
            # –ù–æ–º–µ—Ä –ø/–ø
            ws.cell(row=current_row, column=1, value=i).alignment = self.center_align
            
            # –ù–∞–∑–≤–∞–Ω–∏–µ –ø–∞–∫–µ—Ç–∞
            package_name = package.get('name', '–ë–µ–∑—ã–º—è–Ω–Ω—ã–π –ø–∞–∫–µ—Ç')
            ws.cell(row=current_row, column=2, value=package_name).alignment = self.left_align
            
            # –ï–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞
            volume_data = package.get('volume_data', {})
            calculations = package.get('calculations', {})
            
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: volume_data -> calculations -> –¥–µ—Ñ–æ–ª—Ç
            unit = (volume_data.get('final_unit') or 
                   volume_data.get('unit') or 
                   calculations.get('final_unit') or 
                   calculations.get('unit') or '—à—Ç')
                   
            quantity = (volume_data.get('final_quantity') or 
                       volume_data.get('quantity') or 
                       calculations.get('final_quantity') or 
                       calculations.get('quantity') or 0)
            
            ws.cell(row=current_row, column=3, value=unit).alignment = self.center_align
            ws.cell(row=current_row, column=4, value=str(quantity)).alignment = self.center_align
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ scheduling_data (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) –∏–ª–∏ –∏–∑ package
            schedule_info = scheduling_data.get(package_id, {})
            schedule_blocks = schedule_info.get('schedule_blocks', package.get('schedule_blocks', []))
            progress_per_block = schedule_info.get('progress_per_block', package.get('progress_per_block', {}))
            staffing_per_block = schedule_info.get('staffing_per_block', package.get('staffing_per_block', {}))
            
            # –î–∞—Ç—ã –Ω–∞—á–∞–ª–∞ –∏ –æ–∫–æ–Ω—á–∞–Ω–∏—è
            if schedule_blocks:
                start_date = self._get_package_start_date(schedule_blocks, timeline_blocks)
                end_date = self._get_package_end_date(schedule_blocks, timeline_blocks)
                ws.cell(row=current_row, column=5, value=start_date).alignment = self.center_align
                ws.cell(row=current_row, column=6, value=end_date).alignment = self.center_align
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ –Ω–µ–¥–µ–ª—è–º —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
            for j, block in enumerate(timeline_blocks, 7):
                week_id = block.get('week_id', block.get('block_id'))
                week_str = str(week_id)
                
                if week_id in schedule_blocks and week_str in progress_per_block:
                    progress = progress_per_block[week_str]
                    staffing = staffing_per_block.get(week_str, 0)
                    
                    # –§–æ—Ä–º–∞—Ç: "50%/3—á–µ–ª"
                    cell_value = f"{progress}%/{staffing}—á–µ–ª"
                    cell = ws.cell(row=current_row, column=j, value=cell_value)
                    cell.alignment = self.center_align
                    
                    # –¶–≤–µ—Ç–æ–≤–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –ø—Ä–æ–≥—Ä–µ—Å—Å—É
                    if progress >= 70:
                        cell.fill = self.progress_high
                        cell.font = Font(color="FFFFFF", bold=True)
                    elif progress >= 30:
                        cell.fill = self.progress_medium
                        cell.font = Font(color="FFFFFF", bold=True)
                    else:
                        cell.fill = self.progress_low
                        cell.font = Font(color="FFFFFF", bold=True)
                    
                    cell.border = self.border
                else:
                    # –ü—É—Å—Ç–∞—è —è—á–µ–π–∫–∞ —Å –≥—Ä–∞–Ω–∏—Ü–∞–º–∏
                    cell = ws.cell(row=current_row, column=j, value="")
                    cell.border = self.border
            
            current_row += 1
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        self._format_schedule_sheet(ws, timeline_cols)
    
    def _create_reasoning_sheet(self, ws, work_packages: List[Dict], timeline_blocks: List[Dict], project_info: Dict, scheduling_data: Dict):
        """–°–æ–∑–¥–∞–µ—Ç –ª–∏—Å—Ç —Å –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è–º–∏"""
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        ws['A1'] = "üìÖ –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï –ò –û–ë–û–°–ù–û–í–ê–ù–ò–Ø –†–ï–®–ï–ù–ò–ô"
        ws.merge_cells('A1:F1')
        ws['A1'].font = Font(bold=True, size=16, color="2E4057")
        ws['A1'].alignment = self.center_align
        ws['A1'].fill = self.reasoning_fill
        
        # –ü–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫
        ws['A2'] = "–î–µ—Ç–∞–ª—å–Ω—ã–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–∞–±–æ—Ç –ø–æ –ø–∞–∫–µ—Ç–∞–º"
        ws.merge_cells('A2:F2')
        ws['A2'].font = Font(bold=True, size=12, color="4A628A")
        ws['A2'].alignment = self.center_align
        
        current_row = 4
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–∞–∫–µ—Ç—ã, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å scheduling_reasoning
        scheduled_packages = []
        for package in work_packages:
            package_id = package.get('package_id', '')
            if package_id in scheduling_data:
                scheduled_packages.append(package)
        
        if not scheduled_packages:
            ws.cell(row=current_row, column=1, value="‚ö†Ô∏è –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã").font = Font(bold=True, color="F44336")
            return
        
        for i, package in enumerate(scheduled_packages, 1):
            package_id = package.get('package_id', '')
            schedule_info = scheduling_data.get(package_id, {})
            reasoning = schedule_info.get('scheduling_reasoning', {})
            
            if not reasoning:
                continue
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø–∞–∫–µ—Ç–∞
            package_header = f"üì¶ –ü–ê–ö–ï–¢ {i}: {package.get('name', '–ë–µ–∑—ã–º—è–Ω–Ω—ã–π –ø–∞–∫–µ—Ç')}"
            ws.cell(row=current_row, column=1, value=package_header)
            ws.cell(row=current_row, column=1).font = Font(bold=True, size=14, color="2E4057")
            ws.cell(row=current_row, column=1).fill = self.subheader_fill
            ws.merge_cells(f'A{current_row}:F{current_row}')
            current_row += 1
            
            # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            schedule_blocks = schedule_info.get('schedule_blocks', [])
            progress_per_block = schedule_info.get('progress_per_block', {})
            staffing_per_block = schedule_info.get('staffing_per_block', {})
            
            info_items = [
                ("üìÖ ID –ø–∞–∫–µ—Ç–∞:", package_id),
                ("‚è±Ô∏è –ù–µ–¥–µ–ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:", f"{min(schedule_blocks)}-{max(schedule_blocks)}" if schedule_blocks else "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ"),
                ("üë• –û–±—â–∞—è —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç—å:", f"{sum(staffing_per_block.values())} —á–µ–ª¬∑–Ω–µ–¥" if staffing_per_block else "0"),
                ("üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞:", " | ".join([f"–ù–µ–¥.{k}: {v}%" for k, v in progress_per_block.items()]) if progress_per_block else "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ")
            ]
            
            for label, value in info_items:
                ws.cell(row=current_row, column=1, value=label).font = Font(bold=True, size=10)
                ws.cell(row=current_row, column=2, value=str(value))
                ws.cell(row=current_row, column=1).fill = self.info_fill
                ws.cell(row=current_row, column=2).fill = self.info_fill
                current_row += 1
            
            current_row += 1
            
            # –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
            reasoning_items = [
                ("üóìÔ∏è –ü–û–ß–ï–ú–£ –ò–ú–ï–ù–ù–û –≠–¢–ò –ù–ï–î–ï–õ–ò:", reasoning.get('why_these_weeks', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')),
                ("‚è≥ –ü–û–ß–ï–ú–£ –ò–ú–ï–ù–ù–û –¢–ê–ö–ê–Ø –ü–†–û–î–û–õ–ñ–ò–¢–ï–õ–¨–ù–û–°–¢–¨:", reasoning.get('why_this_duration', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')),
                ("üìä –ü–û–ß–ï–ú–£ –ò–ú–ï–ù–ù–û –¢–ê–ö–ê–Ø –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–¨:", reasoning.get('why_this_sequence', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')),
                ("üë∑ –ü–û–ß–ï–ú–£ –ò–ú–ï–ù–ù–û –¢–ê–ö–û–ï –ö–û–õ–ò–ß–ï–°–¢–í–û –õ–Æ–î–ï–ô:", reasoning.get('why_this_staffing', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'))
            ]
            
            for j, (label, explanation) in enumerate(reasoning_items):
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
                ws.cell(row=current_row, column=1, value=label)
                ws.cell(row=current_row, column=1).font = Font(bold=True, size=11, color="FF6F00")
                ws.cell(row=current_row, column=1).fill = self.reasoning_fill
                ws.merge_cells(f'A{current_row}:F{current_row}')
                current_row += 1
                
                # –¢–µ–∫—Å—Ç –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
                ws.cell(row=current_row, column=1, value=explanation)
                ws.cell(row=current_row, column=1).alignment = self.top_left_align
                ws.cell(row=current_row, column=1).font = Font(size=10)
                ws.merge_cells(f'A{current_row}:F{current_row}')
                
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—ã—Å–æ—Ç—É —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
                ws.row_dimensions[current_row].height = max(20, len(explanation) // 100 * 15)
                
                current_row += 2
            
            current_row += 2  # –ü—Ä–æ–ø—É—Å–∫ –º–µ–∂–¥—É –ø–∞–∫–µ—Ç–∞–º–∏
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        self._format_reasoning_sheet(ws)
    
    def _create_packages_sheet(self, ws, work_packages: List[Dict], project_info: Dict):
        """–°–æ–∑–¥–∞–µ—Ç –ª–∏—Å—Ç —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –ø–æ –ø–∞–∫–µ—Ç–∞–º —Ä–∞–±–æ—Ç"""
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        ws['A1'] = "üìã –ü–ê–ö–ï–¢–´ –†–ê–ë–û–¢ - –î–ï–¢–ê–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø"
        ws.merge_cells('A1:H1')
        ws['A1'].font = Font(bold=True, size=16, color="366092")
        ws['A1'].alignment = self.center_align
        
        current_row = 3
        
        # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞–∫–µ—Ç–∞
        for i, package in enumerate(work_packages, 1):
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø–∞–∫–µ—Ç–∞
            package_header = f"üì¶ –ü–ê–ö–ï–¢ {i}: {package.get('name', '–ë–µ–∑—ã–º—è–Ω–Ω—ã–π –ø–∞–∫–µ—Ç')}"
            ws.cell(row=current_row, column=1, value=package_header).font = Font(bold=True, size=14, color="366092")
            ws.merge_cells(f'A{current_row}:H{current_row}')
            current_row += 1
            
            # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–∞–∫–µ—Ç–∞
            volume_data = package.get('volume_data', {})
            calculations = package.get('calculations', {})
            
            unit = (volume_data.get('final_unit') or volume_data.get('unit') or 
                   calculations.get('final_unit') or calculations.get('unit') or '—à—Ç')
            quantity = (volume_data.get('final_quantity') or volume_data.get('quantity') or 
                       calculations.get('final_quantity') or calculations.get('quantity') or 0)
            
            # –î–µ—Ç–∞–ª–∏ –ø–∞–∫–µ—Ç–∞
            package_details = [
                ("ID –ø–∞–∫–µ—Ç–∞:", package.get('package_id', 'N/A')),
                ("–ï–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è:", unit),
                ("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ:", str(quantity)),
                ("–û–ø–∏—Å–∞–Ω–∏–µ:", package.get('description', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'))
            ]
            
            for label, value in package_details:
                ws.cell(row=current_row, column=1, value=label).font = Font(bold=True)
                ws.cell(row=current_row, column=2, value=value)
                current_row += 1
            
            # –õ–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
            logic = (volume_data.get('calculation_logic') or 
                    calculations.get('calculation_logic') or 
                    '–õ–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞')
            
            ws.cell(row=current_row, column=1, value="–õ–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–∞:").font = Font(bold=True)
            ws.cell(row=current_row, column=2, value=logic[:200] + "..." if len(logic) > 200 else logic)
            current_row += 1
            
            # –ü–æ–¥—Ä–æ–±–Ω—ã–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
            reasoning = volume_data.get('reasoning', {})
            if reasoning:
                current_row += 1
                ws.cell(row=current_row, column=1, value="üìù –û–ë–û–°–ù–û–í–ê–ù–ò–Ø –†–ê–°–ß–ï–¢–û–í:").font = Font(bold=True, size=11, color="2F5233")
                current_row += 1
                
                # –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
                why_quantity = reasoning.get('why_this_quantity', '')
                if why_quantity:
                    ws.cell(row=current_row, column=1, value="‚Ä¢ –ü–æ—á–µ–º—É —ç—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ:").font = Font(bold=True)
                    ws.merge_cells(f'B{current_row}:H{current_row}')
                    ws.cell(row=current_row, column=2, value=why_quantity).alignment = self.left_align
                    current_row += 1
                
                # –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
                why_unit = reasoning.get('why_this_unit', '')
                if why_unit:
                    ws.cell(row=current_row, column=1, value="‚Ä¢ –ü–æ—á–µ–º—É —ç—Ç–∞ –µ–¥–∏–Ω–∏—Ü–∞:").font = Font(bold=True)
                    ws.merge_cells(f'B{current_row}:H{current_row}')
                    ws.cell(row=current_row, column=2, value=why_unit).alignment = self.left_align
                    current_row += 1
                
                # –ü–æ–¥—Ö–æ–¥ –∫ —Ä–∞—Å—á–µ—Ç—É
                calc_approach = reasoning.get('calculation_approach', '')
                if calc_approach:
                    ws.cell(row=current_row, column=1, value="‚Ä¢ –ü–æ–¥—Ö–æ–¥ –∫ —Ä–∞—Å—á–µ—Ç—É:").font = Font(bold=True)
                    ws.merge_cells(f'B{current_row}:H{current_row}')
                    ws.cell(row=current_row, column=2, value=calc_approach).alignment = self.left_align
                    current_row += 1
            
            # –°–ø–∏—Å–æ–∫ —Ä–∞–±–æ—Ç –≤ –ø–∞–∫–µ—Ç–µ
            current_row += 1
            ws.cell(row=current_row, column=1, value="üìã –í–•–û–î–Ø–©–ò–ï –†–ê–ë–û–¢–´:").font = Font(bold=True, size=12, color="2F5233")
            current_row += 1
            
            # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è —Ä–∞–±–æ—Ç
            work_headers = ["‚Ññ", "–ö–æ–¥ —Ä–∞–±–æ—Ç—ã", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç—ã", "–ï–¥–∏–Ω–∏—Ü–∞", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", "–†–æ–ª—å", "–£—á–∞—Å—Ç–∏–µ"]
            for col, header in enumerate(work_headers, 1):
                cell = ws.cell(row=current_row, column=col, value=header)
                cell.font = Font(bold=True)
                cell.fill = self.info_fill
                cell.alignment = self.center_align
                cell.border = self.border
            current_row += 1
            
            # –ù–∞–π–¥–µ–º —Ä–∞–±–æ—Ç—ã —ç—Ç–æ–≥–æ –ø–∞–∫–µ—Ç–∞
            package_works = self._get_package_works(package.get('package_id'), work_packages, project_info)
            
            for j, work in enumerate(package_works, 1):
                ws.cell(row=current_row, column=1, value=j).alignment = self.center_align
                ws.cell(row=current_row, column=2, value=work.get('code', 'N/A'))
                ws.cell(row=current_row, column=3, value=work.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'))
                ws.cell(row=current_row, column=4, value=work.get('unit', '—à—Ç')).alignment = self.center_align
                ws.cell(row=current_row, column=5, value=str(work.get('quantity', 0))).alignment = self.right_align
                ws.cell(row=current_row, column=6, value=work.get('role', '–æ—Å–Ω–æ–≤–Ω–∞—è')).alignment = self.center_align
                ws.cell(row=current_row, column=7, value=work.get('included', '–ø–æ–ª–Ω–∞—è')).alignment = self.center_align
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã
                for col in range(1, 8):
                    ws.cell(row=current_row, column=col).border = self.border
                    
                current_row += 1
            
            current_row += 2  # –ü—Ä–æ–ø—É—Å–∫ –º–µ–∂–¥—É –ø–∞–∫–µ—Ç–∞–º–∏
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        self._format_packages_sheet(ws)
    
    def _get_package_works(self, package_id, work_packages, project_info):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ä–∞–±–æ—Ç –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞"""
        works = []
        
        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ source_work_items
        source_works = project_info.get('source_work_items', [])
        for work in source_works:
            if work.get('package_id') == package_id:
                works.append({
                    'code': work.get('code', 'N/A'),
                    'name': work.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'),
                    'unit': work.get('unit', '—à—Ç'),
                    'quantity': work.get('quantity', 0),
                    'role': '–∏—Å—Ö–æ–¥–Ω–∞—è —Ä–∞–±–æ—Ç–∞'
                })
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ source_work_items, –∏—â–µ–º –≤ volume_data –ø–∞–∫–µ—Ç–∞
        if not works:
            for pkg in work_packages:
                if pkg.get('package_id') == package_id:
                    volume_data = pkg.get('volume_data', {})
                    component_analysis = volume_data.get('component_analysis', [])
                    
                    for component in component_analysis:
                        works.append({
                            'code': component.get('code', 'N/A'),
                            'name': component.get('work_name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'),
                            'unit': component.get('unit', '—à—Ç'),
                            'quantity': component.get('quantity', 0),
                            'role': self._translate_role(component.get('role', 'unknown')),
                            'included': self._translate_included(component.get('included', 'full'))
                        })
                    break
        
        return works
    
    def _translate_role(self, role):
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ä–æ–ª—å —Ä–∞–±–æ—Ç—ã –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫"""
        role_translations = {
            'base_surface': '–±–∞–∑–æ–≤–∞—è –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å',
            'finish_layer': '—Ñ–∏–Ω–∏—à–Ω—ã–π —Å–ª–æ–π', 
            'adjustment': '–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞',
            'preparation': '–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞',
            'base_element': '–±–∞–∑–æ–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç',
            'safety_element': '—ç–ª–µ–º–µ–Ω—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏',
            'separate_work': '–æ—Ç–¥–µ–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞',
            'full': '–ø–æ–ª–Ω–∞—è',
            'excluded': '–∏—Å–∫–ª—é—á–µ–Ω–∞',
            'reference': '—Å–ø—Ä–∞–≤–æ—á–Ω–∞—è'
        }
        return role_translations.get(role, role)
    
    def _translate_included(self, included):
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–∏–ø —É—á–∞—Å—Ç–∏—è —Ä–∞–±–æ—Ç—ã –≤ —Ä–∞—Å—á–µ—Ç–∞—Ö –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫"""
        included_translations = {
            'full': '–ø–æ–ª–Ω–∞—è',
            'excluded': '–∏—Å–∫–ª—é—á–µ–Ω–∞',
            'reference': '—Å–ø—Ä–∞–≤–æ—á–Ω–∞—è',
            'partial': '—á–∞—Å—Ç–∏—á–Ω–∞—è'
        }
        return included_translations.get(included, included)
    
    def _create_logic_sheet(self, ws, work_packages: List[Dict], project_info: Dict, extracted_data: Dict):
        """–°–æ–∑–¥–∞–µ—Ç –ª–∏—Å—Ç —Å –ª–æ–≥–∏–∫–æ–π —Ä–∞—Å—á–µ—Ç–æ–≤ –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        ws['A1'] = "üßÆ –õ–û–ì–ò–ö–ê –†–ê–°–ß–ï–¢–û–í –ò –¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø"
        ws.merge_cells('A1:E1')
        ws['A1'].font = Font(bold=True, size=16, color="366092")
        ws['A1'].alignment = self.center_align
        
        current_row = 3
        
        # –ë–ª–æ–∫ 1: –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–µ–∫—Ç–µ
        ws.cell(row=current_row, column=1, value="üìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ü–†–û–ï–ö–¢–ï").font = Font(bold=True, size=12)
        current_row += 1
        
        project_details = [
            ("–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞:", project_info.get('project_name', '–ë–µ–∑—ã–º—è–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç')),
            ("–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:", project_info.get('structure_version', '1.0')),
            ("–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:", self._format_datetime(project_info.get('created_at'))),
            ("–í—Å–µ–≥–æ –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç:", len(work_packages)),
            ("–í—Å–µ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤:", len(extracted_data.get('timeline_blocks', [])))
        ]
        
        for label, value in project_details:
            ws.cell(row=current_row, column=1, value=label).font = Font(bold=True)
            ws.cell(row=current_row, column=2, value=str(value))
            current_row += 1
        
        current_row += 2
        
        # –ë–ª–æ–∫ 2: –õ–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞–∫–µ—Ç–∞
        ws.cell(row=current_row, column=1, value="üßÆ –î–ï–¢–ê–õ–¨–ù–ê–Ø –õ–û–ì–ò–ö–ê –†–ê–°–ß–ï–¢–û–í").font = Font(bold=True, size=12)
        current_row += 1
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
        calc_headers = ["–ü–∞–∫–µ—Ç", "–ï–¥–∏–Ω–∏—Ü–∞", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", "–õ–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–∞"]
        for col, header in enumerate(calc_headers, 1):
            cell = ws.cell(row=current_row, column=col, value=header)
            cell.font = self.header_font
            cell.fill = self.logic_fill
            cell.alignment = self.center_align
            cell.border = self.border
        current_row += 1
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ª–æ–≥–∏–∫—É —Ä–∞—Å—á–µ—Ç–æ–≤
        for package in work_packages:
            package_name = package.get('name', '–ë–µ–∑—ã–º—è–Ω–Ω—ã–π –ø–∞–∫–µ—Ç')
            
            # –î–∞–Ω–Ω—ã–µ —Ä–∞—Å—á–µ—Ç–æ–≤ - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞
            volume_data = package.get('volume_data', {})
            calculations = package.get('calculations', {})
            
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: volume_data -> calculations -> –¥–µ—Ñ–æ–ª—Ç
            unit = (volume_data.get('final_unit') or 
                   volume_data.get('unit') or 
                   calculations.get('final_unit') or 
                   calculations.get('unit') or '—à—Ç')
                   
            quantity = (volume_data.get('final_quantity') or 
                       volume_data.get('quantity') or 
                       calculations.get('final_quantity') or 
                       calculations.get('quantity') or 0)
            
            # –õ–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
            logic = (volume_data.get('calculation_logic') or 
                    calculations.get('calculation_logic') or 
                    calculations.get('calculation_summary') or 
                    '–õ–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞')
                    
            reasoning = volume_data.get('reasoning', {})
            
            # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è–º–∏ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å volume_data)
            if reasoning and volume_data:
                why_quantity = reasoning.get('why_this_quantity', '')
                why_unit = reasoning.get('why_this_unit', '')
                approach = reasoning.get('calculation_approach', '')
                
                if why_quantity or why_unit or approach:
                    extended_logic = f"{logic}\n\n–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞: {why_quantity}\n–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü—ã: {why_unit}\n–ü–æ–¥—Ö–æ–¥ –∫ —Ä–∞—Å—á–µ—Ç—É: {approach}"
                    logic = extended_logic[:400] + "..." if len(extended_logic) > 400 else extended_logic
            
            ws.cell(row=current_row, column=1, value=package_name).alignment = self.left_align
            ws.cell(row=current_row, column=2, value=unit).alignment = self.center_align
            ws.cell(row=current_row, column=3, value=str(quantity)).alignment = self.right_align
            ws.cell(row=current_row, column=4, value=logic).alignment = self.left_align
            
            current_row += 1
        
        current_row += 2
        
        # –ë–ª–æ–∫ 3: –°—Ç–∞—Ç—É—Å pipeline
        pipeline_status = extracted_data.get('pipeline_status', {})
        if pipeline_status:
            ws.cell(row=current_row, column=1, value="üîÑ –°–¢–ê–¢–£–° –û–ë–†–ê–ë–û–¢–ö–ò").font = Font(bold=True, size=12)
            current_row += 1
            
            # –î–ª—è v2.0
            if isinstance(pipeline_status, dict):
                agents = pipeline_status.get('agents_status', [])
                current_stage = pipeline_status.get('current_stage', 'unknown')
                
                ws.cell(row=current_row, column=1, value="–¢–µ–∫—É—â–∞—è —Å—Ç–∞–¥–∏—è:").font = Font(bold=True)
                ws.cell(row=current_row, column=2, value=current_stage)
                current_row += 1
                
                for agent in agents:
                    agent_name = agent.get('agent', 'unknown')
                    status = agent.get('status', 'unknown')
                    duration = agent.get('duration', 'N/A')
                    
                    ws.cell(row=current_row, column=1, value=f"{agent_name}:")
                    ws.cell(row=current_row, column=2, value=status)
                    ws.cell(row=current_row, column=3, value=f"{duration}s" if duration and duration != 'N/A' else 'N/A')
                    current_row += 1
            
            # –î–ª—è v1.0
            elif isinstance(pipeline_status, list):
                for status in pipeline_status:
                    agent_name = status.get('agent_name', 'unknown')
                    agent_status = status.get('status', 'unknown')
                    
                    ws.cell(row=current_row, column=1, value=f"{agent_name}:")
                    ws.cell(row=current_row, column=2, value=agent_status)
                    current_row += 1
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        self._format_logic_sheet(ws)
    
    def _get_package_start_date(self, schedule_blocks: List[int], timeline_blocks: List[Dict]) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞—Ç—É –Ω–∞—á–∞–ª–∞ –ø–∞–∫–µ—Ç–∞ —Ä–∞–±–æ—Ç"""
        if not schedule_blocks:
            return ""
        
        min_week = min(schedule_blocks)
        for block in timeline_blocks:
            block_id = block.get('week_id', block.get('block_id'))
            if block_id == min_week:
                date = datetime.fromisoformat(block['start_date'])
                return date.strftime('%d.%m.%Y')
        return ""
    
    def _get_package_end_date(self, schedule_blocks: List[int], timeline_blocks: List[Dict]) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞—Ç—É –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–∞–∫–µ—Ç–∞ —Ä–∞–±–æ—Ç"""
        if not schedule_blocks:
            return ""
        
        max_week = max(schedule_blocks)
        for block in timeline_blocks:
            block_id = block.get('week_id', block.get('block_id'))
            if block_id == max_week:
                date = datetime.fromisoformat(block['end_date'])
                return date.strftime('%d.%m.%Y')
        return ""
    
    def _format_datetime(self, datetime_str: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç datetime –≤ —á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥"""
        if not datetime_str:
            return "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
        try:
            dt = datetime.fromisoformat(datetime_str.replace('Z', '+00:00'))
            return dt.strftime('%d.%m.%Y %H:%M')
        except:
            return str(datetime_str)
    
    def _format_schedule_sheet(self, ws, timeline_cols: int):
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫ –ª–∏—Å—Ç—É –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞"""
        
        # –®–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
        ws.column_dimensions['A'].width = 5   # ‚Ññ
        ws.column_dimensions['B'].width = 40  # –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç
        ws.column_dimensions['C'].width = 8   # –ï–¥.–∏–∑–º
        ws.column_dimensions['D'].width = 10  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ
        ws.column_dimensions['E'].width = 12  # –ù–∞—á–∞–ª–æ
        ws.column_dimensions['F'].width = 12  # –û–∫–æ–Ω—á–∞–Ω–∏–µ
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        for i in range(7, 7 + timeline_cols):
            col_letter = get_column_letter(i)
            ws.column_dimensions[col_letter].width = 10
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã –∫–æ –≤—Å–µ–º —è—á–µ–π–∫–∞–º —Å –¥–∞–Ω–Ω—ã–º–∏
        max_row = ws.max_row
        max_col = 6 + timeline_cols
        
        for row in range(5, max_row + 1):
            for col in range(1, max_col + 1):
                cell = ws.cell(row=row, column=col)
                cell.border = self.border
    
    def _format_packages_sheet(self, ws):
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫ –ª–∏—Å—Ç—É –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç"""
        
        # –®–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
        ws.column_dimensions['A'].width = 5   # ‚Ññ
        ws.column_dimensions['B'].width = 20  # –ö–æ–¥ —Ä–∞–±–æ—Ç—ã
        ws.column_dimensions['C'].width = 50  # –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç—ã
        ws.column_dimensions['D'].width = 12  # –ï–¥–∏–Ω–∏—Ü–∞
        ws.column_dimensions['E'].width = 12  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ
        ws.column_dimensions['F'].width = 18  # –†–æ–ª—å
        ws.column_dimensions['G'].width = 12  # –£—á–∞—Å—Ç–∏–µ
        ws.column_dimensions['H'].width = 15  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞
        
        # –ì—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –≤—Å–µ—Ö —è—á–µ–µ–∫
        max_row = ws.max_row
        for row in range(3, max_row + 1):
            for col in range(1, 9):
                ws.cell(row=row, column=col).border = self.border
    
    def _format_reasoning_sheet(self, ws):
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫ –ª–∏—Å—Ç—É –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–π"""
        
        # –®–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
        ws.column_dimensions['A'].width = 80  # –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
        ws.column_dimensions['B'].width = 25  # –ó–Ω–∞—á–µ–Ω–∏—è
        ws.column_dimensions['C'].width = 15  # –î–æ–ø. –∫–æ–ª–æ–Ω–∫–∏
        ws.column_dimensions['D'].width = 15
        ws.column_dimensions['E'].width = 15
        ws.column_dimensions['F'].width = 15
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã –∫ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–º —è—á–µ–π–∫–∞–º
        max_row = ws.max_row
        for row in range(1, max_row + 1):
            for col in range(1, 7):
                cell = ws.cell(row=row, column=col)
                if cell.value:
                    cell.border = self.border
    
    def _format_logic_sheet(self, ws):
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫ –ª–∏—Å—Ç—É –ª–æ–≥–∏–∫–∏ —Ä–∞—Å—á–µ—Ç–æ–≤"""
        
        # –®–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
        ws.column_dimensions['A'].width = 30  # –ü–∞–∫–µ—Ç
        ws.column_dimensions['B'].width = 12  # –ï–¥–∏–Ω–∏—Ü–∞
        ws.column_dimensions['C'].width = 10  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ
        ws.column_dimensions['D'].width = 80  # –õ–æ–≥–∏–∫–∞
        ws.column_dimensions['E'].width = 15  # –î–æ–ø. –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è


# –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ
def generate_multipage_excel_report(input_file: str, output_path: str) -> str:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ–≥–æ Excel –æ—Ç—á–µ—Ç–∞ –≤ –Ω–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    
    Args:
        input_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É true.json
        output_path: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        
    Returns:
        –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
    """
    generator = MultiPageScheduleGenerator()
    return generator.generate_multipage_excel(input_file, output_path)


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    test_input = "/home/imort/Herzog_v3/projects/34975055/d490876a/true.json"
    test_output = "/tmp"
    
    if os.path.exists(test_input):
        print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –º–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ —Å scheduling_reasoning...")
        try:
            result_file = generate_multipage_excel_report(test_input, test_output)
            print(f"‚úÖ –ú–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {result_file}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    else:
        print(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {test_input}")

================================================================================

## –§–ê–ô–õ: test_results/README.md
------------------------------------------------------------
# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–µ–∞–ª—å–Ω—ã—Ö API —Ç–µ—Å—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã HerZog v3.0

–ó–¥–µ—Å—å —Ö—Ä–∞–Ω—è—Ç—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –Ω–∞—Å—Ç–æ—è—â–∏–º–∏ –≤—ã–∑–æ–≤–∞–º–∏ Gemini API.

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫

### `real_api_test_result/`
**–ü–æ–ª–Ω—ã–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç** —Å —Ä–µ–∞–ª—å–Ω—ã–º Gemini API (—á–∞—Å—Ç–∏—á–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω)
- ‚úÖ –≠—Ç–∞–ø 1: work_packager - –£–°–ü–ï–®–ù–û (12 –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç)  
- ‚úÖ –≠—Ç–∞–ø 2: works_to_packages - –£–°–ü–ï–®–ù–û (71 —Ä–∞–±–æ—Ç–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∞)
- ‚úÖ –≠—Ç–∞–ø 3: counter - –£–°–ü–ï–®–ù–û (–æ–±—ä–µ–º—ã —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã)
- ‚ùå –≠—Ç–∞–ø 4: scheduler_and_staffer - –ü–†–ï–†–í–ê–ù (–∫–≤–æ—Ç–∞ API –∏—Å—á–µ—Ä–ø–∞–Ω–∞)

**–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:**
- –ü—Ä–æ–µ–∫—Ç: –ö–∞–ø–∏—Ç–∞–ª—å–Ω—ã–π —Ä–µ–º–æ–Ω—Ç 3-–∫–æ–º–Ω–∞—Ç–Ω–æ–π –∫–≤–∞—Ä—Ç–∏—Ä—ã 85 –º¬≤
- –†–∞–±–æ—Ç: 71 –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞
- –í—Ä–µ–º–µ–Ω–Ω–æ–π –ø–ª–∞–Ω: 12 –Ω–µ–¥–µ–ª—å (–º–∞—Ä—Ç-–º–∞–π 2024)
- –õ–∏–º–∏—Ç—ã –ø–µ—Ä—Å–æ–Ω–∞–ª–∞: 6-18 —á–µ–ª–æ–≤–µ–∫

**–î–∏—Ä–µ–∫—Ç–∏–≤—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:**
- conceptualizer: "–¥–µ–º–æ–Ω—Ç–∞–∂ –æ—Ç–¥–µ–ª—å–Ω–æ –æ—Ç –º–æ–Ω—Ç–∞–∂–∞, –≤—Å—é —ç–ª–µ–∫—Ç—Ä–∏–∫—É –∏ —Å–ª–∞–±–æ—Ç–æ—á–∫—É –≤ –æ–¥–∏–Ω –ø–∞–∫–µ—Ç, —Å–∞–Ω—Ç–µ—Ö–Ω–∏–∫—É –≤ –æ–¥–∏–Ω –±–ª–æ–∫, –æ—Ç–¥–µ–ª–∫—É —Ä–∞–∑–±–∏—Ç—å –ø–æ —Ç–∏–ø–∞–º —Ä–∞–±–æ—Ç"
- strategist: "–¥–µ–º–æ–Ω—Ç–∞–∂ –≤ –ø–µ—Ä–≤—ã–µ 2 –Ω–µ–¥–µ–ª–∏, –ø–æ—Ç–æ–º –æ–±—â–µ—Å—Ç—Ä–æ–π–∫–∞, –∏–Ω–∂–µ–Ω–µ—Ä–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ, –æ—Ç–¥–µ–ª–∫–∞ –≤ –∫–æ–Ω—Ü–µ"
- accountant: "–ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ –ø–ª–æ—â–∞–¥–Ω—ã—Ö —Ä–∞–±–æ—Ç –±–µ—Ä–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –ø–ª–æ—â–∞–¥—å, –ø—Ä–∏ –ª–∏–Ω–µ–π–Ω—ã—Ö - —Å—É–º–º–∏—Ä—É–π"
- foreman: "–Ω–∞ –æ—Ç–¥–µ–ª–æ—á–Ω—ã–µ —Ä–∞–±–æ—Ç—ã –º–∞–∫—Å–∏–º—É–º –ª—é–¥–µ–π, –Ω–∞ –¥–µ–º–æ–Ω—Ç–∞–∂ –∏ —ç–ª–µ–∫—Ç—Ä–∏–∫—É –ø–æ–º–µ–Ω—å—à–µ"

### `work_packager_only/`
**–û—Ç–¥–µ–ª—å–Ω—ã–π —Ç–µ—Å—Ç work_packager** —Å —Ä–µ–∞–ª—å–Ω—ã–º Gemini API - –£–°–ü–ï–®–ù–û
- –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: 40 —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–±–æ—Ç
- –†–µ–∑—É–ª—å—Ç–∞—Ç: 10 –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç
- API –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: 3524 —Ç–æ–∫–µ–Ω–∞ (2919 –ø—Ä–æ–º–ø—Ç + 605 –æ—Ç–≤–µ—Ç)

## –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–π–ª—ã –≤ –∫–∞–∂–¥–æ–π –ø–∞–ø–∫–µ

### `true.json`
–û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª —Å –ø—Ä–æ–µ–∫—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:
- `project_inputs` - –∏—Å—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –¥–∏—Ä–µ–∫—Ç–∏–≤—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- `source_work_items` - –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–±–æ—Ç—ã  
- `timeline_blocks` - –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ –±–ª–æ–∫–∏ (–Ω–µ–¥–µ–ª–∏)
- `results.work_packages` - —Å–æ–∑–¥–∞–Ω–Ω—ã–µ AI –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç —Å —Ä–∞—Å—á–µ—Ç–∞–º–∏

### –ü–∞–ø–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤:
- `4_work_packager/` - –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –æ—Ç–≤–µ—Ç AI –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞–∫–µ—Ç–æ–≤
- `5_works_to_packages/` - –±–∞—Ç—á–∏ –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–±–æ—Ç –ø–æ –ø–∞–∫–µ—Ç–∞–º
- `6_counter/` - —Ä–∞—Å—á–µ—Ç—ã –æ–±—ä–µ–º–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞–∫–µ—Ç–∞
- `7_scheduler_and_staffer/` - –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ (–µ—Å–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ)

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–æ–≤ AI:
- `llm_input.json` - —á—Ç–æ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–æ—Å—å –≤ Gemini API
- `llm_response.json` - –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini (–≤–∫–ª—é—á–∞—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)

## –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### ‚úÖ –†–∞–±–æ—Ç–∞—é—â–∏–µ –∞–≥–µ–Ω—Ç—ã:
1. **work_packager** - –æ—Ç–ª–∏—á–Ω–æ —Å–æ–∑–¥–∞–µ—Ç –ª–æ–≥–∏—á–Ω—ã–µ –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç
2. **works_to_packages** - –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–∞–±–æ—Ç—ã –ø–æ –ø–∞–∫–µ—Ç–∞–º —Å –±–∞—Ç—á–∏–Ω–≥–æ–º
3. **counter** - —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–º—ã

### ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:
- **–ö–≤–æ—Ç—ã API**: Gemini –∏–º–µ–µ—Ç –ª–∏–º–∏—Ç 10 –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–∏–Ω—É—Ç—É
- **scheduler_and_staffer** —Ç—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ –≤—ã–∑–æ–≤–æ–≤ (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ –∫–∞–∂–¥—ã–π –ø–∞–∫–µ—Ç)

### üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∞—Ç—á–∏–Ω–≥ –¥–ª—è scheduler_and_staffer
2. –î–æ–±–∞–≤–∏—Ç—å retry –ª–æ–≥–∏–∫—É —Å –∑–∞–¥–µ—Ä–∂–∫–∞–º–∏ –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –∫–≤–æ—Ç
3. –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ –º–æ–¥–µ–ª—å —Å –±–æ–ª—å—à–∏–º–∏ –ª–∏–º–∏—Ç–∞–º–∏

## –ö–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ AI

Gemini —Å–æ–∑–¥–∞–ª **–≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã**:
- –ü—Ä–∞–≤–∏–ª—å–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞–ª —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é
- –£—á–µ–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –¥–∏—Ä–µ–∫—Ç–∏–≤—ã
- –°–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–ª —Ä–∞–±–æ—Ç—ã –ª–æ–≥–∏—á–Ω–æ (–¥–µ–º–æ–Ω—Ç–∞–∂ –æ—Ç–¥–µ–ª—å–Ω–æ, —ç–ª–µ–∫—Ç—Ä–∏–∫–∞ –≤ –±–ª–æ–∫)
- –°–æ–∑–¥–∞–ª –ø–æ–Ω—è—Ç–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∏ –æ–ø–∏—Å–∞–Ω–∏—è –ø–∞–∫–µ—Ç–æ–≤

**–ü—Ä–∏–º–µ—Ä —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞:**
```json
{
  "package_id": "pkg_004",
  "name": "–≠–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã", 
  "description": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–∞–±–µ–ª–µ–π, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ–¥—Ä–æ–∑–µ—Ç–Ω–∏–∫–æ–≤ –∏ —Ä–∞—Å–ø–∞—è—á–Ω—ã—Ö –∫–æ—Ä–æ–±–æ–∫, –º–æ–Ω—Ç–∞–∂ —Ä–æ–∑–µ—Ç–æ–∫, –≤—ã–∫–ª—é—á–∞—Ç–µ–ª–µ–π, —Å–≤–µ—Ç–∏–ª—å–Ω–∏–∫–æ–≤ –∏ —ç–ª–µ–∫—Ç—Ä–æ—â–∏—Ç–∫–∞, –ø—É—Å–∫–æ–Ω–∞–ª–∞–¥–∫–∞."
}
```

## –í—ã–≤–æ–¥

üéâ **–°–∏—Å—Ç–µ–º–∞ HerZog v3.0 —É—Å–ø–µ—à–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º Gemini AI!**

–¢—Ä–∏ –∏–∑ —á–µ—Ç—ã—Ä–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã. –ß–µ—Ç–≤–µ—Ä—Ç—ã–π —Ç—Ä–µ–±—É–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ —Ä–∞–º–∫–∞—Ö –∫–≤–æ—Ç API.

================================================================================

## –§–ê–ô–õ: examples/add_new_agent_example.py
------------------------------------------------------------
"""
–ü–†–ò–ú–ï–†: –ö–∞–∫ –ª–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ –≤ —Å–∏—Å—Ç–µ–º—É HerZog v3.0

–≠—Ç–æ—Ç –ø—Ä–∏–º–µ—Ä –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞–∫ –¥–æ–±–∞–≤–∏—Ç—å –∞–≥–µ–Ω—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
–º–µ–∂–¥—É –≥—Ä—É–ø–ø–∏—Ä–æ–≤—â–∏–∫–æ–º –∏ –Ω–∞–∑–Ω–∞—á–∞—Ç–µ–ª–µ–º –≥—Ä—É–ø–ø
"""

import os
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from ai_agents.agent_config_v2 import registry, add_agent_after
from ai_agents.agent_logic_v2 import processor

def create_quality_checker_agent():
    """
    –°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ —Ä–∞–±–æ—Ç
    –ë—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –º–µ–∂–¥—É 1.1_group_creator –∏ 1.2_group_assigner
    """
    
    print("üîß –î–æ–±–∞–≤–ª—è–µ–º –∞–≥–µ–Ω—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞...")
    
    # 1. –î–æ–±–∞–≤–ª—è–µ–º –∞–≥–µ–Ω—Ç–∞ –≤ —Å–∏—Å—Ç–µ–º—É
    new_agent_id = add_agent_after(
        after_agent_id="1.1_group_creator",
        new_agent_id="quality_checker", 
        name="–ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä –∫–∞—á–µ—Å—Ç–≤–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏",
        description="–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –≥—Ä—É–ø–ø —Ä–∞–±–æ—Ç –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è",
        prompt_file="agent_1.1.5_quality_checker_prompt.txt"
    )
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω –∞–≥–µ–Ω—Ç: {new_agent_id}")
    
    # 2. –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –Ω–æ–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
    prompt_content = '''–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–æ–º—É –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é –∏ –∫–æ–Ω—Ç—Ä–æ–ª—é –∫–∞—á–µ—Å—Ç–≤–∞.

–¢–í–û–Ø –ó–ê–î–ê–ß–ê:
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –≥—Ä—É–ø–ø—ã —Ä–∞–±–æ—Ç –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Ö –∫–∞—á–µ—Å—Ç–≤–æ:

1. –ü—Ä–æ–≤–µ—Ä—å –ª–æ–≥–∏—á–Ω–æ—Å—Ç—å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏:
   - –°–≤—è–∑–∞–Ω–Ω—ã–µ —Ä–∞–±–æ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –æ–¥–Ω–æ–π –≥—Ä—É–ø–ø–µ
   - –†–∞–∑–Ω–æ—Ç–∏–ø–Ω—ã–µ —Ä–∞–±–æ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–∞–∑–¥–µ–ª–µ–Ω—ã
   - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥—Ä—É–ø–ø –¥–æ–ª–∂–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∞—Ç—å —Ü–µ–ª–∏

2. –ù–∞–π–¥–∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –æ—à–∏–±–∫–∏:
   - –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ –∏–ª–∏ –º–∞–ª–µ–Ω—å–∫–∏–µ –≥—Ä—É–ø–ø—ã
   - –ù–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Ä–∞–±–æ—Ç—ã –≤ –æ–¥–Ω–æ–π –≥—Ä—É–ø–ø–µ
   - –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É —Ä–∞–±–æ—Ç–∞–º–∏

3. –ü—Ä–µ–¥–ª–æ–∂–∏ —É–ª—É—á—à–µ–Ω–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–æ

–í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
{DATA_JSON}

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (—Ç–æ–ª—å–∫–æ JSON):
{
  "quality_check": {
    "overall_score": 8.5,
    "issues_found": [
      {
        "group_id": "group_1",
        "issue": "–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ä–∞–∑–Ω–æ—Ç–∏–ø–Ω—ã—Ö —Ä–∞–±–æ—Ç",
        "severity": "medium",
        "suggestion": "–†–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞ –ø–æ–¥–≥—Ä—É–ø–ø—ã –ø–æ —Ç–∏–ø—É —Ä–∞–±–æ—Ç"
      }
    ],
    "approved": true,
    "recommendations": [
      "–û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≥—Ä—É–ø–ø—ã —ç–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂–Ω—ã—Ö —Ä–∞–±–æ—Ç",
      "–†–∞–∑–¥–µ–ª–∏—Ç—å –æ—Ç–¥–µ–ª–æ—á–Ω—ã–µ —Ä–∞–±–æ—Ç—ã –ø–æ –ø–æ–º–µ—â–µ–Ω–∏—è–º"
    ]
  }
}

–î–ò–†–ï–ö–¢–ò–í–´: {DIRECTIVE}
'''
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –ø—Ä–æ–º–ø—Ç–∞
    prompt_dir = os.path.join(os.path.dirname(__file__), '..', 'src', 'prompts')
    prompt_file_path = os.path.join(prompt_dir, "agent_1.1.5_quality_checker_prompt.txt")
    
    with open(prompt_file_path, 'w', encoding='utf-8') as f:
        f.write(prompt_content)
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω –ø—Ä–æ–º–ø—Ç: {prompt_file_path}")
    
    # 3. –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –ª–æ–≥–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –Ω–æ–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
    def extract_for_quality_checker(project_data):
        """–≠–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–∞ –∫–∞—á–µ—Å—Ç–≤–∞"""
        return {
            'work_groups': project_data.get('work_groups', []),
            'work_items': [item for item in project_data.get('work_items', []) 
                          if item.get('classification') == '–†–∞–±–æ—Ç–∞'],
            'directives': project_data.get('directives', {}),
            'target_work_count': project_data.get('directives', {}).get('target_work_count', 15)
        }
    
    def process_quality_checker_output(llm_response, project_data):
        """–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –≤—ã—Ö–æ–¥–∞ –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–∞ –∫–∞—á–µ—Å—Ç–≤–∞"""
        updated_data = project_data.copy()
        
        # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç LLM
        import json
        try:
            if "```json" in llm_response:
                start_idx = llm_response.find("```json") + 7
                end_idx = llm_response.find("```", start_idx)
                json_str = llm_response[start_idx:end_idx].strip()
            else:
                start_idx = max(llm_response.find('['), llm_response.find('{'))
                end_idx = max(llm_response.rfind(']'), llm_response.rfind('}'))
                json_str = llm_response[start_idx:end_idx+1]
            
            parsed_response = json.loads(json_str)
        except:
            # –ï—Å–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è, –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
            parsed_response = {
                "quality_check": {
                    "overall_score": 7.0,
                    "approved": True,
                    "issues_found": [],
                    "recommendations": []
                }
            }
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫ –¥–∞–Ω–Ω—ã–º
        updated_data['quality_check'] = parsed_response.get('quality_check', {})
        
        return updated_data
    
    def format_quality_checker_prompt(input_data, prompt_template):
        """–§–æ—Ä–º–∞—Ç—Ç–µ—Ä –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–∞ –∫–∞—á–µ—Å—Ç–≤–∞"""
        import json
        
        data_json = json.dumps(input_data, ensure_ascii=False, indent=2)
        prompt = prompt_template.replace('{DATA_JSON}', data_json)
        
        directive_text = input_data.get('directives', {}).get('conceptualizer', '–ü—Ä–æ–≤–µ—Ä—è—Ç—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ')
        prompt = prompt.replace('{DIRECTIVE}', directive_text)
        
        return prompt
    
    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    processor.register_input_extractor(new_agent_id, extract_for_quality_checker)
    processor.register_output_processor(new_agent_id, process_quality_checker_output) 
    processor.register_prompt_formatter(new_agent_id, format_quality_checker_prompt)
    
    print(f"‚úÖ –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –¥–ª—è {new_agent_id}")
    
    return new_agent_id

def demonstrate_flexible_system():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≥–∏–±–∫–æ–π —Å–∏—Å—Ç–µ–º—ã –∞–≥–µ–Ω—Ç–æ–≤"""
    
    print("üöÄ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ì–ò–ë–ö–û–ô –°–ò–°–¢–ï–ú–´ –ê–ì–ï–ù–¢–û–í")
    print("=" * 50)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â—É—é —Å–∏—Å—Ç–µ–º—É
    print("\nüìã –ò—Å—Ö–æ–¥–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–æ–≤:")
    for agent_id in registry.get_pipeline_sequence():
        config = registry.get_agent(agent_id)
        print(f"  {agent_id}: {config['name']}")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
    print(f"\nüîß –î–æ–±–∞–≤–ª—è–µ–º –∞–≥–µ–Ω—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞...")
    new_agent_id = create_quality_checker_agent()
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É
    print(f"\nüìã –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–æ–≤:")
    for agent_id in registry.get_pipeline_sequence():
        config = registry.get_agent(agent_id)
        mark = "üÜï" if agent_id == new_agent_id else "  "
        print(f"{mark} {agent_id}: {config['name']}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≥—Ä—É–ø–ø–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    print(f"\nüèóÔ∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ –≥—Ä—É–ø–ø–∞–º:")
    for group_num in range(1, 5):
        group_agents = registry.get_agents_by_group(group_num)
        if group_agents:
            print(f"  –ì—Ä—É–ø–ø–∞ {group_num}:")
            for agent in group_agents:
                mark = "üÜï" if agent['agent_id'] == new_agent_id else "    "
                print(f"{mark} {agent['agent_id']}: {agent['name']}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏
    print(f"\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞:")
    errors = registry.validate_pipeline()
    if errors:
        print(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã –æ—à–∏–±–∫–∏:")
        for error in errors:
            print(f"   - {error}")
    else:
        print("‚úÖ –ü–∞–π–ø–ª–∞–π–Ω –≤–∞–ª–∏–¥–µ–Ω!")
    
    print(f"\nüéâ –ì–û–¢–û–í–û! –°–∏—Å—Ç–µ–º–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–µ–≥–∫–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤!")

def example_add_cost_optimizer():
    """
    –ü—Ä–∏–º–µ—Ä –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –ø–æ—Å–ª–µ –±—É—Ö–≥–∞–ª—Ç–µ—Ä–∞
    """
    
    print(f"\nüí∞ –î–æ–±–∞–≤–ª—è–µ–º –∞–≥–µ–Ω—Ç–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏...")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –≥—Ä—É–ø–ø—É 3 (—É—á–µ—Ç) –ø–æ—Å–ª–µ –±—É—Ö–≥–∞–ª—Ç–µ—Ä–∞
    cost_optimizer_id = registry.add_agent_to_group(
        group=3,
        agent_id="cost_optimizer",
        name="–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å—Ç–æ–∏–º–æ—Å—Ç–∏",
        description="–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç—å —Ä–∞–±–æ—Ç –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç—ã —ç–∫–æ–Ω–æ–º–∏–∏",
        prompt_file="agent_3.5_cost_optimizer_prompt.txt",
        input_dependencies=["3_accountant"]
    )
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω –∞–≥–µ–Ω—Ç: {cost_optimizer_id}")
    
    return cost_optimizer_id

def example_add_safety_planner():
    """
    –ü—Ä–∏–º–µ—Ä –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –≤ –≥—Ä—É–ø–ø—É 2
    """
    
    print(f"\nü¶∫ –î–æ–±–∞–≤–ª—è–µ–º –∞–≥–µ–Ω—Ç–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏...")
    
    safety_planner_id = registry.add_agent_to_group(
        group=2,
        agent_id="safety_planner", 
        name="–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏",
        description="–ü–ª–∞–Ω–∏—Ä—É–µ—Ç –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –ø–æ —Ç–µ—Ö–Ω–∏–∫–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏",
        prompt_file="agent_2.5_safety_planner_prompt.txt",
        input_dependencies=["2_strategist"]
    )
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω –∞–≥–µ–Ω—Ç: {safety_planner_id}")
    
    return safety_planner_id

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    demonstrate_flexible_system()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –µ—â–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    example_add_cost_optimizer()
    example_add_safety_planner()
    
    print(f"\nüìã –§–ò–ù–ê–õ–¨–ù–ê–Ø –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–æ–≤:")
    for i, agent_id in enumerate(registry.get_pipeline_sequence(), 1):
        config = registry.get_agent(agent_id)
        print(f"  {i:2d}. {agent_id}: {config['name']}")
    
    print(f"\nüéØ –ò–¢–û–ì–û: {len(registry.agents)} –∞–≥–µ–Ω—Ç–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–µ")
    print("üöÄ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é!")

================================================================================

## –§–ê–ô–õ: tests/mock_gemini_client.py
------------------------------------------------------------
"""
–ú–æ–∫-–∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤ Gemini API
"""

import json
import logging
from typing import Dict, Any

logger = logging.getLogger(__name__)

class MockGeminiClient:
    """
    –ú–æ–∫-–∫–ª–∏–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –∏–º–∏—Ç–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç—ã Gemini API –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    """
    
    def __init__(self):
        self.call_count = 0
        
    async def generate_response(self, prompt: str) -> Dict[str, Any]:
        """
        –ò–º–∏—Ç–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç Gemini API —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        """
        self.call_count += 1
        
        logger.info(f"ü§ñ MockGemini –≤—ã–∑–æ–≤ #{self.call_count}, –ø—Ä–æ–º—Ç: {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞ –ø–æ –ø—Ä–æ–º–ø—Ç—É –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –æ—Ç–≤–µ—Ç–∞
        if "work_packages" in prompt and "package_id" in prompt:
            # –≠—Ç–æ work_packager
            mock_response = {
                "work_packages": [
                    {
                        "package_id": "pkg_001",
                        "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π",
                        "description": "–°–Ω–æ—Å –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫, –¥–µ–º–æ–Ω—Ç–∞–∂ –ø–æ–∫—Ä—ã—Ç–∏–π –ø–æ–ª–∞ –∏ –ø–æ—Ç–æ–ª–∫–∞"
                    },
                    {
                        "package_id": "pkg_002", 
                        "name": "–≠–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã",
                        "description": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–∞–±–µ–ª–µ–π, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–æ–∑–µ—Ç–æ–∫ –∏ –≤—ã–∫–ª—é—á–∞—Ç–µ–ª–µ–π"
                    },
                    {
                        "package_id": "pkg_003",
                        "name": "–û—Ç–¥–µ–ª–æ—á–Ω—ã–µ —Ä–∞–±–æ—Ç—ã —Å—Ç–µ–Ω",
                        "description": "–®—Ç—É–∫–∞—Ç—É—Ä–∫–∞ –∏ –ø–æ–∫—Ä–∞—Å–∫–∞ —Å—Ç–µ–Ω –ø–æ–º–µ—â–µ–Ω–∏–π"
                    },
                    {
                        "package_id": "pkg_004",
                        "name": "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ–ª–æ–≤",
                        "description": "–°—Ç—è–∂–∫–∞ –∏ —É–∫–ª–∞–¥–∫–∞ –Ω–∞–ø–æ–ª—å–Ω—ã—Ö –ø–æ–∫—Ä—ã—Ç–∏–π"
                    },
                    {
                        "package_id": "pkg_005",
                        "name": "–†–∞–±–æ—Ç—ã –ø–æ –ø–æ—Ç–æ–ª–∫–∞–º",
                        "description": "–ú–æ–Ω—Ç–∞–∂ –ø–æ–¥–≤–µ—Å–Ω—ã—Ö –∏ –Ω–∞—Ç—è–∂–Ω—ã—Ö –ø–æ—Ç–æ–ª–∫–æ–≤"
                    },
                    {
                        "package_id": "pkg_006",
                        "name": "–°–∞–Ω—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ä–∞–±–æ—Ç—ã",
                        "description": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ —Ç—Ä—É–± –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∞–Ω—Ç–µ—Ö–Ω–∏–∫–∏"
                    }
                ]
            }
            
        elif "assignments" in prompt and "work_id" in prompt:
            # –≠—Ç–æ works_to_packages
            mock_response = {
                "assignments": [
                    {"work_id": "work_001", "package_id": "pkg_001"},
                    {"work_id": "work_002", "package_id": "pkg_001"}, 
                    {"work_id": "work_003", "package_id": "pkg_002"},
                    {"work_id": "work_004", "package_id": "pkg_002"},
                    {"work_id": "work_005", "package_id": "pkg_002"},
                    {"work_id": "work_006", "package_id": "pkg_003"},
                    {"work_id": "work_007", "package_id": "pkg_003"},
                    {"work_id": "work_008", "package_id": "pkg_004"},
                    {"work_id": "work_009", "package_id": "pkg_004"},
                    {"work_id": "work_010", "package_id": "pkg_005"},
                    {"work_id": "work_011", "package_id": "pkg_006"},
                    {"work_id": "work_012", "package_id": "pkg_006"}
                ]
            }
            
        elif "calculation" in prompt and "final_unit" in prompt:
            # –≠—Ç–æ counter  
            mock_response = {
                "calculation": {
                    "final_unit": "–º¬≤",
                    "final_quantity": 120.0,
                    "calculation_logic": "–ü—Ä–∏–º–µ–Ω–µ–Ω–æ –ø—Ä–∞–≤–∏–ª–æ –º–∞–∫—Å–∏–º—É–º–∞ –¥–ª—è –ø–ª–æ—â–∞–¥–Ω—ã—Ö —Ä–∞–±–æ—Ç",
                    "component_analysis": [
                        {
                            "work_name": "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫",
                            "unit": "–º¬≤", 
                            "quantity": 80.0,
                            "included": "full",
                            "role": "base_surface"
                        }
                    ]
                }
            }
            
        elif "scheduled_packages" in prompt and "schedule_blocks" in prompt:
            # –≠—Ç–æ scheduler_and_staffer
            mock_response = {
                "scheduled_packages": [
                    {
                        "package_id": "pkg_001",
                        "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π",
                        "calculations": {"unit": "–º¬≤", "quantity": 100.0},
                        "schedule_blocks": [1, 2],
                        "progress_per_block": {"1": 60, "2": 40},
                        "staffing_per_block": {"1": 8, "2": 6}
                    },
                    {
                        "package_id": "pkg_002",
                        "name": "–≠–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã", 
                        "calculations": {"unit": "–º", "quantity": 200.0},
                        "schedule_blocks": [3, 4],
                        "progress_per_block": {"3": 70, "4": 30},
                        "staffing_per_block": {"3": 4, "4": 3}
                    }
                ]
            }
            
        else:
            # –û–±—â–∏–π –æ—Ç–≤–µ—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            mock_response = {
                "result": "mock_response",
                "message": "–¢–µ—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –æ—Ç MockGemini"
            }
        
        return {
            'success': True,
            'response': mock_response,
            'json_parse_success': True,
            'raw_text': json.dumps(mock_response, ensure_ascii=False),
            'prompt_feedback': None,
            'usage_metadata': {
                'prompt_token_count': len(prompt) // 4,  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
                'candidates_token_count': 100,
                'total_token_count': len(prompt) // 4 + 100
            }
        }

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –º–æ–∫-—ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è —Ç–µ—Å—Ç–æ–≤
mock_gemini_client = MockGeminiClient()

================================================================================

## –§–ê–ô–õ: tests/run_all_tests.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã HerZog v3.0
–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≤—Å–µ —á–µ—Ç—ã—Ä–µ –∞–≥–µ–Ω—Ç–∞ –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ
"""

import asyncio
import subprocess
import sys
import time
from pathlib import Path

def run_test_file(test_file):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–¥–∏–Ω —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç"""
    
    print(f"\n{'='*60}")
    print(f"üß™ –ó–ê–ü–£–°–ö –¢–ï–°–¢–ê: {test_file}")
    print(f"{'='*60}")
    
    start_time = time.time()
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç –∫–∞–∫ subprocess
        result = subprocess.run([
            sys.executable, test_file
        ], capture_output=True, text=True, timeout=60)
        
        duration = time.time() - start_time
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        print(result.stdout)
        
        if result.stderr:
            print("STDERR:", result.stderr)
        
        success = result.returncode == 0
        
        print(f"\n‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.1f}—Å")
        
        if success:
            print(f"‚úÖ –¢–ï–°–¢ {test_file} –ü–†–û–ô–î–ï–ù")
        else:
            print(f"‚ùå –¢–ï–°–¢ {test_file} –ü–†–û–í–ê–õ–ï–ù (–∫–æ–¥ –≤–æ–∑–≤—Ä–∞—Ç–∞: {result.returncode})")
        
        return success, duration
        
    except subprocess.TimeoutExpired:
        duration = time.time() - start_time
        print(f"‚è∞ –¢–ï–°–¢ {test_file} –ü–†–ï–í–´–°–ò–õ –õ–ò–ú–ò–¢ –í–†–ï–ú–ï–ù–ò ({duration:.1f}—Å)")
        return False, duration
        
    except Exception as e:
        duration = time.time() - start_time
        print(f"üí• –û–®–ò–ë–ö–ê –ó–ê–ü–£–°–ö–ê –¢–ï–°–¢–ê {test_file}: {e}")
        return False, duration

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    
    print("üöÄ –ó–ê–ü–£–°–ö –í–°–ï–• –¢–ï–°–¢–û–í –°–ò–°–¢–ï–ú–´ HERZOG v3.0")
    print("=" * 60)
    
    tests_dir = Path(__file__).parent
    
    # –°–ø–∏—Å–æ–∫ —Ç–µ—Å—Ç–æ–≤ –≤ –ø–æ—Ä—è–¥–∫–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    test_files = [
        "test_work_packager.py",
        "test_works_to_packages.py", 
        "test_counter.py",
        "test_scheduler_and_staffer.py",
        "test_full_pipeline.py"
    ]
    
    results = []
    total_start_time = time.time()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–∞–∂–¥—ã–π —Ç–µ—Å—Ç
    for test_file in test_files:
        test_path = tests_dir / test_file
        
        if not test_path.exists():
            print(f"‚ö†Ô∏è –¢–ï–°–¢ –ù–ï –ù–ê–ô–î–ï–ù: {test_file}")
            results.append((test_file, False, 0))
            continue
        
        success, duration = run_test_file(str(test_path))
        results.append((test_file, success, duration))
    
    total_duration = time.time() - total_start_time
    
    # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\n" + "=" * 60)
    print("üìä –ò–¢–û–ì–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
    print("=" * 60)
    
    passed = 0
    failed = 0
    
    for test_file, success, duration in results:
        status = "‚úÖ –ü–†–û–ô–î–ï–ù" if success else "‚ùå –ü–†–û–í–ê–õ–ï–ù"
        print(f"  {test_file:<30} {status} ({duration:.1f}—Å)")
        
        if success:
            passed += 1
        else:
            failed += 1
    
    print(f"\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"  ‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {passed}")
    print(f"  ‚ùå –ü—Ä–æ–≤–∞–ª–∏–≤—à–∏—Ö—Å—è —Ç–µ—Å—Ç–æ–≤: {failed}")
    print(f"  üìä –í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {len(results)}")
    print(f"  ‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_duration:.1f}—Å")
    
    success_rate = (passed / len(results)) * 100 if results else 0
    print(f"  üéØ –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏: {success_rate:.1f}%")
    
    if passed == len(results):
        print(f"\nüéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        print(f"‚úÖ –°–∏—Å—Ç–µ–º–∞ HerZog v3.0 –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
        sys.exit(0)
    else:
        print(f"\n‚ö†Ô∏è –ï–°–¢–¨ –ü–†–û–í–ê–õ–ò–í–®–ò–ï–°–Ø –¢–ï–°–¢–´!")
        print(f"üîß –¢—Ä–µ–±—É–µ—Ç—Å—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º")
        sys.exit(1)

if __name__ == "__main__":
    main()

================================================================================

## –§–ê–ô–õ: tests/test_agents.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–ñ–µ–ª–µ–∑–æ–±–µ—Ç–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è –≤—Å–µ—Ö AI –∞–≥–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã HerZog
–ò—Å–ø–æ–ª—å–∑—É—é—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
"""

import asyncio
import sys
import os
import json
import logging
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –æ—Å–Ω–æ–≤–Ω–æ–º—É –∫–æ–¥—É
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.ai_agents.work_packager import WorkPackager
from src.ai_agents.works_to_packages import WorksToPackagesAssigner
from src.ai_agents.counter import WorkVolumeCalculator
from src.ai_agents.scheduler_and_staffer import SchedulerAndStaffer

logger = logging.getLogger(__name__)

class AgentTester:
    """–ö–ª–∞—Å—Å –¥–ª—è –∂–µ–ª–µ–∑–æ–±–µ—Ç–æ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤"""

    def __init__(self, test_project_path: str):
        self.test_project_path = test_project_path
        self.results = {}

    async def test_work_packager(self):
        """–¢–µ—Å—Ç –∞–≥–µ–Ω—Ç–∞ work_packager"""
        logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ work_packager")

        agent = WorkPackager()
        result = await agent.process(self.test_project_path)

        self.results['work_packager'] = {
            'success': result.get('success', False),
            'packages_created': result.get('packages_created', 0),
            'error': result.get('error')
        }

        if result.get('success'):
            logger.info(f"‚úÖ work_packager: –°–æ–∑–¥–∞–Ω–æ {result.get('packages_created', 0)} –ø–∞–∫–µ—Ç–æ–≤")
        else:
            logger.error(f"‚ùå work_packager: {result.get('error')}")

    async def test_works_to_packages(self):
        """–¢–µ—Å—Ç –∞–≥–µ–Ω—Ç–∞ works_to_packages"""
        logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ works_to_packages")

        agent = WorksToPackagesAssigner(batch_size=25)  # –ú–µ–Ω—å—à–∏–π –±–∞—Ç—á –¥–ª—è —Ç–µ—Å—Ç–æ–≤
        result = await agent.process(self.test_project_path)

        self.results['works_to_packages'] = {
            'success': result.get('success', False),
            'works_processed': result.get('works_processed', 0),
            'batches_processed': result.get('batches_processed', 0),
            'error': result.get('error')
        }

        if result.get('success'):
            logger.info(f"‚úÖ works_to_packages: –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {result.get('works_processed', 0)} —Ä–∞–±–æ—Ç –≤ {result.get('batches_processed', 0)} –±–∞—Ç—á–∞—Ö")
        else:
            logger.error(f"‚ùå works_to_packages: {result.get('error')}")

    async def test_counter(self):
        """–¢–µ—Å—Ç –∞–≥–µ–Ω—Ç–∞ counter"""
        logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ counter")

        agent = WorkVolumeCalculator()
        result = await agent.process(self.test_project_path)

        self.results['counter'] = {
            'success': result.get('success', False),
            'packages_calculated': result.get('packages_calculated', 0),
            'error': result.get('error')
        }

        if result.get('success'):
            logger.info(f"‚úÖ counter: –†–∞—Å—Å—á–∏—Ç–∞–Ω–æ {result.get('packages_calculated', 0)} –ø–∞–∫–µ—Ç–æ–≤")
        else:
            logger.error(f"‚ùå counter: {result.get('error')}")

    async def test_scheduler_and_staffer(self):
        """–¢–µ—Å—Ç –∞–≥–µ–Ω—Ç–∞ scheduler_and_staffer"""
        logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ scheduler_and_staffer")

        agent = SchedulerAndStaffer(batch_size=8)  # –ú–µ–Ω—å—à–∏–π –±–∞—Ç—á –¥–ª—è —Ç–µ—Å—Ç–æ–≤
        result = await agent.process(self.test_project_path)

        self.results['scheduler_and_staffer'] = {
            'success': result.get('success', False),
            'packages_scheduled': result.get('packages_scheduled', 0),
            'workforce_valid': result.get('workforce_valid', False),
            'error': result.get('error')
        }

        if result.get('success'):
            logger.info(f"‚úÖ scheduler_and_staffer: –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ {result.get('packages_scheduled', 0)} –ø–∞–∫–µ—Ç–æ–≤, –ø–µ—Ä—Å–æ–Ω–∞–ª –≤–∞–ª–∏–¥–µ–Ω: {result.get('workforce_valid')}")
        else:
            logger.error(f"‚ùå scheduler_and_staffer: {result.get('error')}")

    async def run_all_tests(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ —Ç–µ—Å—Ç—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ"""
        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ –∂–µ–ª–µ–∑–æ–±–µ—Ç–æ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤ –Ω–∞ –ø—Ä–æ–µ–∫—Ç–µ: {self.test_project_path}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø—Ä–æ–µ–∫—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if not os.path.exists(self.test_project_path):
            logger.error(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.test_project_path}")
            return self.results

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º true.json
        true_json_path = os.path.join(self.test_project_path, "true.json")
        if not os.path.exists(true_json_path):
            logger.error(f"‚ùå –§–∞–π–ª true.json –Ω–µ –Ω–∞–π–¥–µ–Ω: {true_json_path}")
            return self.results

        try:
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–≥–µ–Ω—Ç—ã –ø–æ –ø–æ—Ä—è–¥–∫—É
            await self.test_work_packager()
            await self.test_works_to_packages()
            await self.test_counter()
            await self.test_scheduler_and_staffer()

        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
            self.results['critical_error'] = str(e)

        # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—É—é —Å–≤–æ–¥–∫—É
        self._print_summary()

        return self.results

    def _print_summary(self):
        """–í—ã–≤–æ–¥–∏—Ç –∏—Ç–æ–≥–æ–≤—É—é —Å–≤–æ–¥–∫—É —Ç–µ—Å—Ç–æ–≤"""
        logger.info("üìä === –ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê –¢–ï–°–¢–û–í ===")

        total_tests = 0
        passed_tests = 0

        for agent_name, result in self.results.items():
            if agent_name == 'critical_error':
                continue

            total_tests += 1
            status = "‚úÖ –ü–†–û–®–ï–õ" if result.get('success') else "‚ùå –ü–†–û–í–ê–õ–ï–ù"
            error_msg = f" ({result.get('error')})" if result.get('error') else ""

            logger.info(f"  {agent_name}: {status}{error_msg}")

            if result.get('success'):
                passed_tests += 1

        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        logger.info(f"üìà –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {passed_tests}/{total_tests} ({success_rate:.1f}%)")

        if 'critical_error' in self.results:
            logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {self.results['critical_error']}")

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–æ–≤"""

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # –ü—É—Ç—å –∫ —Ç–µ—Å—Ç–æ–≤–æ–º—É –ø—Ä–æ–µ–∫—Ç—É
    test_project_path = "/home/imort/Herzog_v3/projects/34975055/841377b4"

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–µ—Ä –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    tester = AgentTester(test_project_path)
    results = await tester.run_all_tests()

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞
    success_count = sum(1 for r in results.values() if isinstance(r, dict) and r.get('success'))
    total_count = len([r for r in results.values() if isinstance(r, dict) and 'success' in r])

    return 0 if success_count == total_count else 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)

================================================================================

## –§–ê–ô–õ: tests/test_agents_full.py
------------------------------------------------------------
"""
–ü–æ–ª–Ω—ã–π —Ç–µ—Å—Ç –≤—Å–µ—Ö AI-–∞–≥–µ–Ω—Ç–æ–≤ HerZog v3.0 —Å –º–æ–∫-–¥–∞–Ω–Ω—ã–º–∏
"""

import asyncio
import json
import os
import shutil
import tempfile
import logging
from datetime import datetime

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–æ–≤
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞
TEST_PROJECT_DATA = {
    "meta": {
        "created_at": datetime.now().isoformat(),
        "total_work_items": 6,
        "total_timeline_blocks": 12,
        "project_duration_weeks": 12
    },
    "directives": {
        "target_work_count": 15,
        "project_timeline": {
            "start_date": "01.01.2024",
            "end_date": "31.03.2024"
        },
        "workforce_range": {"min": 8, "max": 15},
        "directives": {
            "conceptualizer": "–≤—Å—é —ç–ª–µ–∫—Ç—Ä–∏–∫—É –≤ –æ–¥–∏–Ω –±–ª–æ–∫, –∞ —Å–∞–Ω—Ç–µ—Ö–Ω–∏–∫—É –æ—Ç–¥–µ–ª—å–Ω–æ",
            "strategist": "–¥–µ–º–æ–Ω—Ç–∞–∂ –Ω–∞ –ø–µ—Ä–≤–æ–π –Ω–µ–¥–µ–ª–µ",
            "accountant": "–ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ —Å—á–∏—Ç–∞–π –ø–ª–æ—â–∞–¥—å –≤ –º¬≤",
            "foreman": "–Ω–∞ –æ—Ç–¥–µ–ª–∫—É –±–æ–ª—å—à–µ –ª—é–¥–µ–π"
        }
    },
    "timeline_blocks": [
        {"week_id": 1, "start_date": "01.01.2024", "end_date": "07.01.2024", "days": 7},
        {"week_id": 2, "start_date": "08.01.2024", "end_date": "14.01.2024", "days": 7},
        {"week_id": 3, "start_date": "15.01.2024", "end_date": "21.01.2024", "days": 7},
        {"week_id": 4, "start_date": "22.01.2024", "end_date": "28.01.2024", "days": 7},
        {"week_id": 5, "start_date": "29.01.2024", "end_date": "04.02.2024", "days": 7},
        {"week_id": 6, "start_date": "05.02.2024", "end_date": "11.02.2024", "days": 7},
        {"week_id": 7, "start_date": "12.02.2024", "end_date": "18.02.2024", "days": 7},
        {"week_id": 8, "start_date": "19.02.2024", "end_date": "25.02.2024", "days": 7},
        {"week_id": 9, "start_date": "26.02.2024", "end_date": "04.03.2024", "days": 7},
        {"week_id": 10, "start_date": "05.03.2024", "end_date": "11.03.2024", "days": 7},
        {"week_id": 11, "start_date": "12.03.2024", "end_date": "18.03.2024", "days": 7},
        {"week_id": 12, "start_date": "19.03.2024", "end_date": "25.03.2024", "days": 7}
    ],
    "work_items": [
        {
            "id": "work_001",
            "original_data": {
                "internal_id": "pos_001",
                "source_file": "test_smeta.xlsx",
                "position_num": "1",
                "code": "–ì–≠–°–ù46-02-009-02",
                "name": "–î–µ–º–æ–Ω—Ç–∞–∂ —à—Ç—É–∫–∞—Ç—É—Ä–∫–∏ —Å –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ–π —Å—Ç–µ–Ω",
                "unit": "100 –º2",
                "quantity": "2.5",
                "classification": "–†–∞–±–æ—Ç–∞"
            },
            "group_id": None,
            "group_name": None,
            "schedule_phases": [],
            "worker_counts": []
        },
        {
            "id": "work_002", 
            "original_data": {
                "internal_id": "pos_002",
                "source_file": "test_smeta.xlsx",
                "position_num": "2",
                "code": "–ì–≠–°–ù15-04-015-01",
                "name": "–ö–ª–∞–¥–∫–∞ —Å—Ç–µ–Ω –∏–∑ –∫–∏—Ä–ø–∏—á–∞ –∫–µ—Ä–∞–º–∏—á–µ—Å–∫–æ–≥–æ –æ–±—ã–∫–Ω–æ–≤–µ–Ω–Ω–æ–≥–æ",
                "unit": "–º3",
                "quantity": "15.8",
                "classification": "–†–∞–±–æ—Ç–∞"
            },
            "group_id": None,
            "group_name": None,
            "schedule_phases": [],
            "worker_counts": []
        },
        {
            "id": "work_003",
            "original_data": {
                "internal_id": "pos_003",
                "source_file": "test_smeta.xlsx",
                "position_num": "3", 
                "code": "–ì–≠–°–ù23-03-003-01",
                "name": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–∞–±–µ–ª—è —Å–∏–ª–æ–≤–æ–≥–æ –≤ —Ç—Ä—É–±–∞—Ö",
                "unit": "–º",
                "quantity": "120",
                "classification": "–†–∞–±–æ—Ç–∞"
            },
            "group_id": None,
            "group_name": None,
            "schedule_phases": [],
            "worker_counts": []
        },
        {
            "id": "work_004",
            "original_data": {
                "internal_id": "pos_004",
                "source_file": "test_smeta.xlsx",
                "position_num": "4",
                "code": "–ì–≠–°–ù24-01-015-02",
                "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—Ç–æ—è–∫–æ–≤ –≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥–Ω—ã—Ö —Å—Ç–∞–ª—å–Ω—ã—Ö",
                "unit": "–º",
                "quantity": "25",
                "classification": "–†–∞–±–æ—Ç–∞"
            },
            "group_id": None,
            "group_name": None,
            "schedule_phases": [],
            "worker_counts": []
        },
        {
            "id": "work_005",
            "original_data": {
                "internal_id": "pos_005",
                "source_file": "test_smeta.xlsx",
                "position_num": "5",
                "code": "–ì–≠–°–ù15-01-052-01",
                "name": "–®—Ç—É–∫–∞—Ç—É—Ä–∫–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ–π —Å—Ç–µ–Ω —Ü–µ–º–µ–Ω—Ç–Ω–æ-–∏–∑–≤–µ—Å—Ç–∫–æ–≤—ã–º —Ä–∞—Å—Ç–≤–æ—Ä–æ–º",
                "unit": "100 –º2",
                "quantity": "3.2",
                "classification": "–†–∞–±–æ—Ç–∞"
            },
            "group_id": None,
            "group_name": None,
            "schedule_phases": [],
            "worker_counts": []
        },
        {
            "id": "work_006",
            "original_data": {
                "internal_id": "pos_006",
                "source_file": "test_smeta.xlsx",
                "position_num": "6",
                "code": "–ì–≠–°–ù15-01-055-03",
                "name": "–û–∫—Ä–∞—Å–∫–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ–π —Å—Ç–µ–Ω –∏ –ø–æ—Ç–æ–ª–∫–æ–≤",
                "unit": "100 –º2", 
                "quantity": "4.1",
                "classification": "–†–∞–±–æ—Ç–∞"
            },
            "group_id": None,
            "group_name": None,
            "schedule_phases": [],
            "worker_counts": []
        }
    ],
    "processing_status": {
        "extraction": "completed",
        "classification": "completed", 
        "preparation": "completed",
        "conceptualization": "pending",
        "scheduling": "pending",
        "accounting": "pending",
        "staffing": "pending",
        "reporting": "pending"
    }
}


async def test_agents_pipeline():
    """
    –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤
    """
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è —Ç–µ—Å—Ç–æ–≤
    with tempfile.TemporaryDirectory() as temp_dir:
        logger.info(f"–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ –≤ –ø–∞–ø–∫–µ: {temp_dir}")
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ –∫–∞–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ
        paths = {
            3: f"{temp_dir}/3_prepared",
            4: f"{temp_dir}/4_conceptualized", 
            5: f"{temp_dir}/5_scheduled",
            6: f"{temp_dir}/6_accounted",
            7: f"{temp_dir}/7_staffed",
            8: f"{temp_dir}/8_output"
        }
        
        for path in paths.values():
            os.makedirs(path, exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        initial_data = TEST_PROJECT_DATA.copy()
        with open(f"{paths[3]}/project_data.json", 'w', encoding='utf-8') as f:
            json.dump(initial_data, f, ensure_ascii=False, indent=2)
        
        logger.info("‚úÖ –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã")
        
        # –¢–µ—Å—Ç 1: –ê–≥–µ–Ω—Ç –ö–æ–Ω—Ü–µ–ø—Ç—É–∞–ª–∏–∑–∞—Ç–æ—Ä
        logger.info("üéØ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ê–≥–µ–Ω—Ç 1: –ö–æ–Ω—Ü–µ–ø—Ç—É–∞–ª–∏–∑–∞—Ç–æ—Ä")
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∞–≥–µ–Ω—Ç–∞ (—Å —É—á–µ—Ç–æ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—É—Ç–µ–π)
            import sys
            sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
            
            from src.ai_agents.agent_1_conceptualizer import run_agent as run_agent_1
            
            result_1 = await run_agent_1(paths[3], paths[4])
            logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç 1 –∑–∞–≤–µ—Ä—à–µ–Ω: {result_1}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            with open(f"{paths[4]}/project_data.json", 'r', encoding='utf-8') as f:
                data_after_1 = json.load(f)
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≥—Ä—É–ø–ø—ã –Ω–∞–∑–Ω–∞—á–µ–Ω—ã
            grouped_count = sum(1 for item in data_after_1['work_items'] if item.get('group_id') is not None)
            logger.info(f"–°–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–æ —Ä–∞–±–æ—Ç: {grouped_count}/6")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            assert os.path.exists(f"{paths[4]}/llm_input.json"), "–§–∞–π–ª llm_input.json –Ω–µ —Å–æ–∑–¥–∞–Ω"
            assert os.path.exists(f"{paths[4]}/llm_response.json"), "–§–∞–π–ª llm_response.json –Ω–µ —Å–æ–∑–¥–∞–Ω"
            
            logger.info("‚úÖ –ê–≥–µ–Ω—Ç 1 –ø—Ä–æ—à–µ–ª —Ç–µ—Å—Ç")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∞–≥–µ–Ω—Ç–µ 1: {e}")
            return False
        
        # –¢–µ—Å—Ç 2: –ê–≥–µ–Ω—Ç –°—Ç—Ä–∞—Ç–µ–≥  
        logger.info("üìã –¢–µ—Å—Ç–∏—Ä—É–µ–º –ê–≥–µ–Ω—Ç 2: –°—Ç—Ä–∞—Ç–µ–≥")
        try:
            from src.ai_agents.agent_2_strategist import run_agent as run_agent_2
            
            result_2 = await run_agent_2(paths[4], paths[5])
            logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç 2 –∑–∞–≤–µ—Ä—à–µ–Ω: {result_2}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            with open(f"{paths[5]}/project_data.json", 'r', encoding='utf-8') as f:
                data_after_2 = json.load(f)
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–∑—ã –Ω–∞–∑–Ω–∞—á–µ–Ω—ã
            scheduled_count = sum(1 for item in data_after_2['work_items'] if item.get('schedule_phases'))
            logger.info(f"–ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ —Ä–∞–±–æ—Ç: {scheduled_count}/6")
            
            logger.info("‚úÖ –ê–≥–µ–Ω—Ç 2 –ø—Ä–æ—à–µ–ª —Ç–µ—Å—Ç")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∞–≥–µ–Ω—Ç–µ 2: {e}")
            return False
        
        # –¢–µ—Å—Ç 3: –ê–≥–µ–Ω—Ç –ë—É—Ö–≥–∞–ª—Ç–µ—Ä
        logger.info("üí∞ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ê–≥–µ–Ω—Ç 3: –ë—É—Ö–≥–∞–ª—Ç–µ—Ä")
        try:
            from src.ai_agents.agent_3_accountant import run_agent as run_agent_3
            
            result_3 = await run_agent_3(paths[5], paths[6])
            logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç 3 –∑–∞–≤–µ—Ä—à–µ–Ω: {result_3}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            with open(f"{paths[6]}/project_data.json", 'r', encoding='utf-8') as f:
                data_after_3 = json.load(f)
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–æ–∑–¥–∞–Ω—ã –∏—Ç–æ–≥–∏ –ø–æ –≥—Ä—É–ø–ø–∞–º
            group_summary = data_after_3.get('group_summary', {})
            logger.info(f"–°–æ–∑–¥–∞–Ω–æ —Å–≤–æ–¥–æ–∫ –ø–æ –≥—Ä—É–ø–ø–∞–º: {len(group_summary)}")
            
            logger.info("‚úÖ –ê–≥–µ–Ω—Ç 3 –ø—Ä–æ—à–µ–ª —Ç–µ—Å—Ç")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∞–≥–µ–Ω—Ç–µ 3: {e}")
            return False
        
        # –¢–µ—Å—Ç 4: –ê–≥–µ–Ω—Ç –ü—Ä–æ—Ä–∞–±
        logger.info("‚ö° –¢–µ—Å—Ç–∏—Ä—É–µ–º –ê–≥–µ–Ω—Ç 4: –ü—Ä–æ—Ä–∞–±")
        try:
            from src.ai_agents.agent_4_foreman import run_agent as run_agent_4
            
            result_4 = await run_agent_4(paths[6], paths[7])
            logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç 4 –∑–∞–≤–µ—Ä—à–µ–Ω: {result_4}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç  
            with open(f"{paths[7]}/project_data.json", 'r', encoding='utf-8') as f:
                data_after_4 = json.load(f)
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–∞–±–æ—á–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω—ã
            staffed_count = sum(1 for item in data_after_4['work_items'] if item.get('worker_counts'))
            logger.info(f"–£–∫–æ–º–ø–ª–µ–∫—Ç–æ–≤–∞–Ω–æ —Ä–∞–±–æ—Ç: {staffed_count}/6")
            
            logger.info("‚úÖ –ê–≥–µ–Ω—Ç 4 –ø—Ä–æ—à–µ–ª —Ç–µ—Å—Ç")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∞–≥–µ–Ω—Ç–µ 4: {e}")
            return False
        
        # –¢–µ—Å—Ç 5: –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        logger.info("üìä –¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞")
        try:
            from src.data_processing.reporter import generate_excel_report
            
            final_input = f"{paths[7]}/project_data.json"
            excel_file = generate_excel_report(final_input, paths[8])
            
            assert os.path.exists(excel_file), "Excel —Ñ–∞–π–ª –Ω–µ —Å–æ–∑–¥–∞–Ω"
            logger.info(f"‚úÖ Excel –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {excel_file}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
            return False
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        logger.info("üîç –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–∏—è project_data.json")
        
        with open(f"{paths[7]}/project_data.json", 'r', encoding='utf-8') as f:
            final_data = json.load(f)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –ø–æ–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ
        for item in final_data['work_items']:
            assert item.get('group_id') is not None, f"group_id –Ω–µ –∑–∞–ø–æ–ª–Ω–µ–Ω –¥–ª—è {item['id']}"
            assert item.get('group_name') is not None, f"group_name –Ω–µ –∑–∞–ø–æ–ª–Ω–µ–Ω –¥–ª—è {item['id']}"
            # schedule_phases –∏ worker_counts –º–æ–≥—É—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º–∏ –º–∞—Å—Å–∏–≤–∞–º–∏ - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
        status = final_data['processing_status']
        assert status['conceptualization'] == 'completed', "–°—Ç–∞—Ç—É—Å –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–µ completed"
        assert status['scheduling'] == 'completed', "–°—Ç–∞—Ç—É—Å –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ completed" 
        assert status['accounting'] == 'completed', "–°—Ç–∞—Ç—É—Å –±—É—Ö–≥–∞–ª—Ç–µ—Ä–∏–∏ –Ω–µ completed"
        assert status['staffing'] == 'completed', "–°—Ç–∞—Ç—É—Å —É–∫–æ–º–ø–ª–µ–∫—Ç–æ–≤–∞–Ω–∏—è –Ω–µ completed"
        
        logger.info("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        
        # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        groups = set(item.get('group_id') for item in final_data['work_items'] if item.get('group_id'))
        logger.info(f"üìà –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        logger.info(f"   –°–æ–∑–¥–∞–Ω–æ –≥—Ä—É–ø–ø: {len(groups)}")
        logger.info(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ä–∞–±–æ—Ç: {len(final_data['work_items'])}")
        logger.info(f"   –ù–µ–¥–µ–ª—å –≤ –ø—Ä–æ–µ–∫—Ç–µ: {len(final_data['timeline_blocks'])}")
        if 'group_summary' in final_data:
            logger.info(f"   –°–≤–æ–¥–æ–∫ –ø–æ –≥—Ä—É–ø–ø–∞–º: {len(final_data['group_summary'])}")
        
        return True


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    result = asyncio.run(test_agents_pipeline())
    if result:
        print("\nüéØ –í—Å–µ –∞–≥–µ–Ω—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!")
        print("üîÑ –û–±–æ–≥–∞—â–µ–Ω–∏–µ project_data.json –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ")
        print("üìÅ –í—Å–µ —Ñ–∞–π–ª—ã –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–∑–¥–∞—é—Ç—Å—è")
    else:
        print("\n‚ùå –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –æ—à–∏–±–∫–∏ –≤ —Ä–∞–±–æ—Ç–µ –∞–≥–µ–Ω—Ç–æ–≤")
        exit(1)

================================================================================

## –§–ê–ô–õ: tests/test_clean_structure.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç —á—Ç–æ –≤ project_data.json –Ω–µ—Ç –ª–∏—à–Ω–∏—Ö –ø–æ–ª–µ–π group_id, group_name
"""

import json
import tempfile
import os
import sys
sys.path.append('/home/imort/Herzog_v3')

from src.data_processing.preparer import prepare_project_data

def test_clean_structure():
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ—Ç –ª–∏—à–Ω–∏—Ö null –ø–æ–ª–µ–π"""
    
    test_raw_estimates = [
        {
            'internal_id': 'work-1',
            'source_file': 'test.xlsx',
            'position_num': '1',
            'code': '–ì–≠–°–ù46-02-009-02',
            'name': '–û—Ç–±–∏–≤–∫–∞ —à—Ç—É–∫–∞—Ç—É—Ä–∫–∏',
            'unit': '100 –º2',
            'quantity': '7.77'
        }
    ]
    
    test_directives = {
        'target_work_count': 10,
        'project_timeline': {
            'start_date': '01.01.2024',
            'end_date': '07.01.2024'
        },
        'workforce_range': {'min': 5, 'max': 15}
    }
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f1:
        json.dump(test_raw_estimates, f1, ensure_ascii=False)
        raw_estimates_file = f1.name
    
    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f2:
        json.dump(test_directives, f2, ensure_ascii=False)
        directives_file = f2.name
    
    try:
        result = prepare_project_data(raw_estimates_file, directives_file)
        
        work_items = result.get('work_items', [])
        print(f"üìã –ü—Ä–æ–≤–µ—Ä—è—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–∞–±–æ—Ç...")
        
        for i, work_item in enumerate(work_items):
            print(f"   Work {i+1}:")
            for key, value in work_item.items():
                print(f"     {key}: {type(value).__name__}")
                if key == 'original_data':
                    for subkey, subvalue in value.items():
                        print(f"       {subkey}: {subvalue}")
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ—Ç group_id –∏ group_name
            if 'group_id' in work_item:
                print(f"‚ùå –ù–ê–ô–î–ï–ù–û –î–ï–†–¨–ú–û: group_id = {work_item['group_id']}")
                return False
            if 'group_name' in work_item:
                print(f"‚ùå –ù–ê–ô–î–ï–ù–û –î–ï–†–¨–ú–û: group_name = {work_item['group_name']}")
                return False
        
        print("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —á–∏—Å—Ç–∞—è - –Ω–µ—Ç –ª–∏—à–Ω–∏—Ö null –ø–æ–ª–µ–π!")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return False
    finally:
        try:
            os.unlink(raw_estimates_file)
            os.unlink(directives_file)
        except:
            pass

if __name__ == "__main__":
    success = test_clean_structure()
    if success:
        print("\nüéâ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —á–∏—Å—Ç–∞—è!")
    else:
        print("\nüí© –ï—Å—Ç—å –ª–∏—à–Ω–∏–µ –ø–æ–ª—è!")
        sys.exit(1)

================================================================================

## –§–ê–ô–õ: tests/test_copy_project.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞ –¥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —ç—Ç–∞–ø–∞
"""

import os
import sys
import shutil
import tempfile

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º Herzog
sys.path.append('/home/imort/Herzog_v3')

from src.telegram_bot.handlers import _copy_project_files_up_to_stage

def test_copy_function():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞"""
    
    source_project = "/home/imort/Herzog_v3/projects/34975055/da1ac471"
    
    print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞ –∏–∑: {source_project}")
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    with tempfile.TemporaryDirectory() as temp_dir:
        target_project = os.path.join(temp_dir, "test_project")
        os.makedirs(target_project, exist_ok=True)
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ —ç—Ç–∞–ø—ã
        test_stages = ["0", "3", "5", "6", "8"]
        
        for stage in test_stages:
            print(f"\nüîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —ç—Ç–∞–ø–∞ {stage}...")
            
            # –û—á–∏—â–∞–µ–º –ø–∞–ø–∫—É –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
            if os.path.exists(target_project):
                shutil.rmtree(target_project)
            os.makedirs(target_project)
            
            # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
            success = _copy_project_files_up_to_stage(source_project, target_project, stage)
            
            if success:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–ª–æ—Å—å
                copied_folders = []
                for item in os.listdir(target_project):
                    if os.path.isdir(os.path.join(target_project, item)):
                        copied_folders.append(item)
                
                copied_folders.sort()
                print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã –ø–∞–ø–∫–∏: {copied_folders}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º true.json
                truth_file = os.path.join(target_project, "true.json")
                if os.path.exists(truth_file):
                    file_size = os.path.getsize(truth_file)
                    print(f"   üìÑ true.json —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω: {file_size} –±–∞–π—Ç")
                else:
                    print("   ‚ö†Ô∏è true.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    
            else:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è —ç—Ç–∞–ø–∞ {stage}")
    
    print(f"\nüéØ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

if __name__ == "__main__":
    test_copy_function()

================================================================================

## –§–ê–ô–õ: tests/test_counter.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∞–≥–µ–Ω—Ç–∞ counter.py
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç –æ–±—ä–µ–º–æ–≤ –¥–ª—è –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç
"""

import json
import os
import sys
import asyncio
import tempfile
import shutil
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.ai_agents.counter import WorkVolumeCalculator
from tests.mock_gemini_client import mock_gemini_client

# –ü–æ–¥–º–µ–Ω—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–π gemini_client –Ω–∞ –º–æ–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
import src.ai_agents.counter
src.ai_agents.counter.gemini_client = mock_gemini_client

class TestCounter:
    
    def __init__(self):
        self.test_project_path = None
    
    def setup_test_project(self):
        """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç —Å mock –¥–∞–Ω–Ω—ã–º–∏"""
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        self.test_project_path = tempfile.mkdtemp(prefix='test_herzog_')
        
        # –°–æ–∑–¥–∞–µ–º mock true.json —Å –ø–∞–∫–µ—Ç–∞–º–∏ —Ä–∞–±–æ—Ç –∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—ã–º–∏ —Ä–∞–±–æ—Ç–∞–º–∏
        mock_truth_data = {
            "metadata": {
                "project_id": "test_project",
                "project_name": "–¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç",
                "pipeline_status": [
                    {"agent_name": "work_packager", "status": "completed"},
                    {"agent_name": "works_to_packages", "status": "completed"},
                    {"agent_name": "counter", "status": "pending"}
                ]
            },
            "project_inputs": {
                "target_work_package_count": 6,
                "agent_directives": {
                    "accountant": "–ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ –ø–æ–ª–æ–≤ —Å—á–∏—Ç–∞–π —Ç–æ–ª—å–∫–æ –ø–ª–æ—â–∞–¥—å"
                }
            },
            "source_work_items": [
                {
                    "id": "work_001",
                    "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫ –∫–∏—Ä–ø–∏—á–Ω—ã—Ö",
                    "code": "08.01.001",
                    "unit": "–º¬≤",
                    "quantity": 80.5,
                    "package_id": "pkg_001"
                },
                {
                    "id": "work_002",
                    "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–æ–∫—Ä—ã—Ç–∏—è –ø–æ–ª–∞ –ª–∏–Ω–æ–ª–µ—É–º",
                    "code": "08.02.015",
                    "unit": "–º¬≤",
                    "quantity": 120.0,
                    "package_id": "pkg_001"
                },
                {
                    "id": "work_003",
                    "name": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–∞–±–µ–ª—è –í–í–ì 3—Ö2.5",
                    "code": "19.03.012",
                    "unit": "–º",
                    "quantity": 250.0,
                    "package_id": "pkg_002"
                },
                {
                    "id": "work_004",
                    "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–æ–∑–µ—Ç–æ–∫ —Å–∫—Ä—ã—Ç—ã—Ö",
                    "code": "19.05.001",
                    "unit": "—à—Ç",
                    "quantity": 12.0,
                    "package_id": "pkg_002"
                },
                {
                    "id": "work_005",
                    "name": "–ú–æ–Ω—Ç–∞–∂ –≤—ã–∫–ª—é—á–∞—Ç–µ–ª–µ–π",
                    "code": "19.05.003",
                    "unit": "—à—Ç",
                    "quantity": 8.0,
                    "package_id": "pkg_002"
                },
                {
                    "id": "work_006",
                    "name": "–®—Ç—É–∫–∞—Ç—É—Ä–∫–∞ —Å—Ç–µ–Ω —Ü–µ–º–µ–Ω—Ç–Ω—ã–º —Ä–∞—Å—Ç–≤–æ—Ä–æ–º",
                    "code": "15.01.001",
                    "unit": "–º¬≤",
                    "quantity": 180.0,
                    "package_id": "pkg_003"
                },
                {
                    "id": "work_007",
                    "name": "–ü–æ–∫—Ä–∞—Å–∫–∞ —Å—Ç–µ–Ω –≤–æ–¥–æ—ç–º—É–ª—å—Å–∏–æ–Ω–Ω–æ–π –∫—Ä–∞—Å–∫–æ–π",
                    "code": "15.06.001",
                    "unit": "–º¬≤",
                    "quantity": 175.0,
                    "package_id": "pkg_003"
                },
                {
                    "id": "work_008",
                    "name": "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Å—Ç—è–∂–∫–∏ —Ü–µ–º–µ–Ω—Ç–Ω–æ–π",
                    "code": "11.01.001",
                    "unit": "–º¬≤",
                    "quantity": 95.0,
                    "package_id": "pkg_004"
                },
                {
                    "id": "work_009",
                    "name": "–£–∫–ª–∞–¥–∫–∞ –ª–∞–º–∏–Ω–∞—Ç–∞",
                    "code": "11.04.001",
                    "unit": "–º¬≤",
                    "quantity": 90.0,
                    "package_id": "pkg_004"
                }
            ],
            "results": {
                "work_packages": [
                    {
                        "package_id": "pkg_001",
                        "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π",
                        "description": "–°–Ω–æ—Å –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫, –¥–µ–º–æ–Ω—Ç–∞–∂ –ø–æ–∫—Ä—ã—Ç–∏–π –ø–æ–ª–∞ –∏ –ø–æ—Ç–æ–ª–∫–∞"
                    },
                    {
                        "package_id": "pkg_002",
                        "name": "–≠–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã",
                        "description": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–∞–±–µ–ª–µ–π, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–æ–∑–µ—Ç–æ–∫ –∏ –≤—ã–∫–ª—é—á–∞—Ç–µ–ª–µ–π"
                    },
                    {
                        "package_id": "pkg_003",
                        "name": "–û—Ç–¥–µ–ª–æ—á–Ω—ã–µ —Ä–∞–±–æ—Ç—ã —Å—Ç–µ–Ω",
                        "description": "–®—Ç—É–∫–∞—Ç—É—Ä–∫–∞ –∏ –ø–æ–∫—Ä–∞—Å–∫–∞ —Å—Ç–µ–Ω –ø–æ–º–µ—â–µ–Ω–∏–π"
                    },
                    {
                        "package_id": "pkg_004",
                        "name": "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ–ª–æ–≤",
                        "description": "–°—Ç—è–∂–∫–∞ –∏ —É–∫–ª–∞–¥–∫–∞ –Ω–∞–ø–æ–ª—å–Ω—ã—Ö –ø–æ–∫—Ä—ã—Ç–∏–π"
                    }
                ]
            }
        }
        
        truth_path = os.path.join(self.test_project_path, "true.json")
        with open(truth_path, 'w', encoding='utf-8') as f:
            json.dump(mock_truth_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç: {self.test_project_path}")
        return self.test_project_path
    
    async def test_counter_full_process(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Ä–∞—Å—á–µ—Ç–∞ –æ–±—ä–µ–º–æ–≤"""
        
        print("üß™ === –¢–ï–°–¢ COUNTER –ü–û–õ–ù–´–ô –ü–†–û–¶–ï–°–° ===")
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç
        project_path = self.setup_test_project()
        
        try:
            # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞
            agent = WorkVolumeCalculator()
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
            print("üîÑ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ counter...")
            result = await agent.process(project_path)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if result.get('success'):
                print("‚úÖ –ê–≥–µ–Ω—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–∞–∫–µ—Ç–æ–≤: {result.get('packages_calculated', 0)}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π true.json
                truth_path = os.path.join(project_path, "true.json")
                with open(truth_path, 'r', encoding='utf-8') as f:
                    updated_truth = json.load(f)
                
                work_packages = updated_truth.get('results', {}).get('work_packages', [])
                
                print(f"üìã –†–∞—Å—á–µ—Ç—ã –æ–±—ä–µ–º–æ–≤ –ø–æ –ø–∞–∫–µ—Ç–∞–º:")
                for pkg in work_packages:
                    calculations = pkg.get('calculations', {})
                    unit = calculations.get('unit', '–Ω/–¥')
                    quantity = calculations.get('quantity', 0)
                    logic = calculations.get('calculation_logic', '–Ω/–¥')
                    
                    print(f"  {pkg['package_id']}: {pkg['name']}")
                    print(f"    –ò—Ç–æ–≥–æ–≤—ã–π –æ–±—ä–µ–º: {quantity} {unit}")
                    print(f"    –õ–æ–≥–∏–∫–∞: {logic[:60]}...")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–ø–∫—É –∞–≥–µ–Ω—Ç–∞
                agent_folder = os.path.join(project_path, "6_counter")
                if os.path.exists(agent_folder):
                    files = os.listdir(agent_folder)
                    pkg_files = [f for f in files if f.startswith('pkg_')]
                    print(f"üìÅ –°–æ–∑–¥–∞–Ω—ã —Ñ–∞–π–ª—ã –ø–∞–∫–µ—Ç–æ–≤: {len(pkg_files)} —Ñ–∞–π–ª–æ–≤")
                
                # –ë–∞–∑–æ–≤—ã–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                assert len(work_packages) == 4, "–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ"
                
                for pkg in work_packages:
                    assert 'calculations' in pkg, f"–ü–∞–∫–µ—Ç {pkg['package_id']} –Ω–µ –∏–º–µ–µ—Ç —Ä–∞—Å—á–µ—Ç–æ–≤"
                    calc = pkg['calculations']
                    assert 'unit' in calc, f"–ü–∞–∫–µ—Ç {pkg['package_id']} –Ω–µ –∏–º–µ–µ—Ç –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è"
                    assert 'quantity' in calc, f"–ü–∞–∫–µ—Ç {pkg['package_id']} –Ω–µ –∏–º–µ–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞"
                    assert calc['quantity'] > 0, f"–ü–∞–∫–µ—Ç {pkg['package_id']} –∏–º–µ–µ—Ç –Ω—É–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ"
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                volume_stats = updated_truth.get('results', {}).get('volume_calculations', {})
                assert 'packages_calculated' in volume_stats, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–æ–≤"
                
                print("‚úÖ –í—Å–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–æ–π–¥–µ–Ω—ã")
                return True
                
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∞–≥–µ–Ω—Ç–∞: {result.get('error')}")
                return False
                
        except Exception as e:
            print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –≤ —Ç–µ—Å—Ç–µ: {e}")
            return False
        
        finally:
            # –û—á–∏—â–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            if self.test_project_path and os.path.exists(self.test_project_path):
                shutil.rmtree(self.test_project_path)
                print(f"üßπ –£–¥–∞–ª–µ–Ω —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç: {self.test_project_path}")
    
    async def test_data_grouping(self):
        """–¢–µ—Å—Ç –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ —Ä–∞–±–æ—Ç –ø–æ –ø–∞–∫–µ—Ç–∞–º"""
        
        print("üß™ === –¢–ï–°–¢ –ì–†–£–ü–ü–ò–†–û–í–ö–ò –î–ê–ù–ù–´–• ===")
        
        project_path = self.setup_test_project()
        
        try:
            agent = WorkVolumeCalculator()
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º true.json
            truth_path = os.path.join(project_path, "true.json")
            with open(truth_path, 'r', encoding='utf-8') as f:
                truth_data = json.load(f)
            
            work_packages = truth_data.get('results', {}).get('work_packages', [])
            source_work_items = truth_data.get('source_work_items', [])
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É
            packages_with_works = agent._group_works_by_packages(work_packages, source_work_items)
            
            print("üìä –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Ä–∞–±–æ—Ç –ø–æ –ø–∞–∫–µ—Ç–∞–º:")
            for pkg_data in packages_with_works:
                pkg = pkg_data['package']
                works = pkg_data['works']
                print(f"  {pkg['package_id']}: {len(works)} —Ä–∞–±–æ—Ç")
                for work in works:
                    print(f"    - {work['name'][:40]}... ({work['quantity']} {work['unit']})")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏–∏
            assert len(packages_with_works) == 4, "–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥—Ä—É–ø–ø"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ —Ä–∞–±–æ—Ç—ã —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω—ã
            total_works = sum(len(pkg_data['works']) for pkg_data in packages_with_works)
            assert total_works == 9, "–ù–µ –≤—Å–µ —Ä–∞–±–æ—Ç—ã —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω—ã"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —É –∫–∞–∂–¥–æ–π —Ä–∞–±–æ—Ç—ã –µ—Å—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è
            for pkg_data in packages_with_works:
                for work in pkg_data['works']:
                    assert 'id' in work, "–†–∞–±–æ—Ç–∞ –Ω–µ –∏–º–µ–µ—Ç id"
                    assert 'unit' in work, "–†–∞–±–æ—Ç–∞ –Ω–µ –∏–º–µ–µ—Ç –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è"
                    assert 'quantity' in work, "–†–∞–±–æ—Ç–∞ –Ω–µ –∏–º–µ–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞"
            
            print("‚úÖ –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏: {e}")
            return False
            
        finally:
            if self.test_project_path and os.path.exists(self.test_project_path):
                shutil.rmtree(self.test_project_path)
    
    async def test_fallback_calculation(self):
        """–¢–µ—Å—Ç fallback —Ä–∞—Å—á–µ—Ç–æ–≤"""
        
        print("üß™ === –¢–ï–°–¢ FALLBACK –†–ê–°–ß–ï–¢–û–í ===")
        
        project_path = self.setup_test_project()
        
        try:
            agent = WorkVolumeCalculator()
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º fallback —Ä–∞—Å—á–µ—Ç
            test_package = {
                "package_id": "pkg_test",
                "name": "–¢–µ—Å—Ç–æ–≤—ã–π –ø–∞–∫–µ—Ç"
            }
            
            test_works = [
                {"name": "–†–∞–±–æ—Ç–∞ 1", "unit": "–º¬≤", "quantity": 100.0},
                {"name": "–†–∞–±–æ—Ç–∞ 2", "unit": "–º¬≤", "quantity": 150.0},
                {"name": "–†–∞–±–æ—Ç–∞ 3", "unit": "—à—Ç", "quantity": 5.0}
            ]
            
            result = agent._create_fallback_calculation(test_package, test_works)
            
            print(f"üìä Fallback —Ä–∞—Å—á–µ—Ç:")
            calc = result.get('calculations', {})
            print(f"  –ï–¥–∏–Ω–∏—Ü–∞: {calc.get('unit')}")
            print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {calc.get('quantity')}")
            print(f"  –õ–æ–≥–∏–∫–∞: {calc.get('calculation_logic')}")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏–∏
            assert 'calculations' in result, "–†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–∞—Å—á–µ—Ç—ã"
            assert calc.get('unit') == '–º¬≤', "–ù–µ–≤–µ—Ä–Ω–∞—è –µ–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤ fallback"
            assert calc.get('quantity') == 150.0, "–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ fallback (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–∞–∫—Å–∏–º—É–º)"
            
            print("‚úÖ Fallback —Ä–∞—Å—á–µ—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è fallback: {e}")
            return False
            
        finally:
            if self.test_project_path and os.path.exists(self.test_project_path):
                shutil.rmtree(self.test_project_path)
    
    async def test_error_handling(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫"""
        
        print("üß™ === –¢–ï–°–¢ –û–ë–†–ê–ë–û–¢–ö–ò –û–®–ò–ë–û–ö ===")
        
        project_path = self.setup_test_project()
        
        try:
            # –£–¥–∞–ª—è–µ–º –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –ø–∞–∫–µ—Ç–æ–≤ —É —Ä–∞–±–æ—Ç
            truth_path = os.path.join(project_path, "true.json")
            with open(truth_path, 'r', encoding='utf-8') as f:
                truth_data = json.load(f)
            
            # –£–±–∏—Ä–∞–µ–º package_id —É –≤—Å–µ—Ö —Ä–∞–±–æ—Ç
            for work in truth_data['source_work_items']:
                if 'package_id' in work:
                    del work['package_id']
            
            with open(truth_path, 'w', encoding='utf-8') as f:
                json.dump(truth_data, f, ensure_ascii=False, indent=2)
            
            agent = WorkVolumeCalculator()
            
            print("üîÑ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ –±–µ–∑ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–π –∫ –ø–∞–∫–µ—Ç–∞–º...")
            result = await agent.process(project_path)
            
            # –û–∂–∏–¥–∞–µ–º –æ—à–∏–±–∫—É
            if not result.get('success'):
                print(f"‚úÖ –û—à–∏–±–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞: {result.get('error')}")
                assert "–Ω–µ –Ω–∞–∑–Ω–∞—á–µ–Ω—ã –∫ –ø–∞–∫–µ—Ç–∞–º" in result.get('error', ''), "–ù–µ–≤–µ—Ä–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ"
                return True
            else:
                print("‚ùå –û–∂–∏–¥–∞–ª–∞—Å—å –æ—à–∏–±–∫–∞, –Ω–æ –∞–≥–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —É—Å–ø–µ—à–Ω–æ")
                return False
                
        except Exception as e:
            print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–µ: {e}")
            return False
            
        finally:
            if self.test_project_path and os.path.exists(self.test_project_path):
                shutil.rmtree(self.test_project_path)

async def run_all_tests():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    
    print("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ counter.py")
    print("=" * 50)
    
    tester = TestCounter()
    
    tests = [
        ("–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø–∞–∫–µ—Ç–∞–º", tester.test_data_grouping),
        ("Fallback —Ä–∞—Å—á–µ—Ç—ã", tester.test_fallback_calculation),
        ("–ü–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å —Ä–∞—Å—á–µ—Ç–∞ –æ–±—ä–µ–º–æ–≤", tester.test_counter_full_process),
        ("–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫", tester.test_error_handling)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\nüß™ –¢–µ—Å—Ç: {test_name}")
        print("-" * 30)
        
        try:
            success = await test_func()
            results.append((test_name, success))
            
            if success:
                print(f"‚úÖ {test_name}: –ü–†–û–ô–î–ï–ù")
            else:
                print(f"‚ùå {test_name}: –ü–†–û–í–ê–õ–ï–ù")
                
        except Exception as e:
            print(f"üí• {test_name}: –û–®–ò–ë–ö–ê - {e}")
            results.append((test_name, False))
    
    print("\n" + "=" * 50)
    print("üìä –ò–¢–û–ì–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    
    passed = 0
    for test_name, success in results:
        status = "‚úÖ –ü–†–û–ô–î–ï–ù" if success else "‚ùå –ü–†–û–í–ê–õ–ï–ù"
        print(f"  {test_name}: {status}")
        if success:
            passed += 1
    
    print(f"\nüéØ –†–µ–∑—É–ª—å—Ç–∞—Ç: {passed}/{len(results)} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ")
    
    if passed == len(results):
        print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        return True
    else:
        print("‚ö†Ô∏è –ï—Å—Ç—å –Ω–µ—É–¥–∞—á–Ω—ã–µ —Ç–µ—Å—Ç—ã!")
        return False

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
    asyncio.run(run_all_tests())

================================================================================

## –§–ê–ô–õ: tests/test_final_structure.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è–º–∏
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞–∫ —Ç–µ–ø–µ—Ä—å –≤—ã–≥–ª—è–¥–∏—Ç true.json —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è–º–∏ –æ—Ç –∫–∞–∂–¥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
"""

# –ü—Ä–∏–º–µ—Ä —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ true.json —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è–º–∏
final_structure_example = {
    "metadata": {
        "project_id": "test_001",
        "project_name": "–¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è–º–∏",
        "created_at": "2025-09-10T15:30:00.000000",
        "pipeline_completed": True
    },
    
    "project_inputs": {
        "target_work_package_count": 4,
        "project_timeline": {
            "start_date": "01.01.2025",
            "end_date": "28.02.2025"
        },
        "workforce_range": {
            "min": 5,
            "max": 15
        },
        "agent_directives": {
            "conceptualizer": "–≤—Å—é —ç–ª–µ–∫—Ç—Ä–∏–∫—É –≤ –æ–¥–∏–Ω –±–ª–æ–∫",
            "strategist": "—Ä–∞—Å—Ç—è–Ω–∏ –¥–µ–º–æ–Ω—Ç–∞–∂ –Ω–∞ –ø–µ—Ä–≤—ã–π –º–µ—Å—è—Ü", 
            "accountant": "–ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ –ø–æ–ª–æ–≤ —Å—á–∏—Ç–∞–π —Ç–æ–ª—å–∫–æ –ø–ª–æ—â–∞–¥—å",
            "foreman": "–Ω–∞ –æ—Ç–¥–µ–ª–∫—É –º–∞–∫—Å–∏–º—É–º –ª—é–¥–µ–π"
        }
    },
    
    "timeline_blocks": [
        {"week_id": 1, "start_date": "2025-01-01", "end_date": "2025-01-07"},
        {"week_id": 2, "start_date": "2025-01-08", "end_date": "2025-01-14"},
        {"week_id": 3, "start_date": "2025-01-15", "end_date": "2025-01-21"},
        {"week_id": 4, "start_date": "2025-01-22", "end_date": "2025-01-28"}
    ],
    
    "results": {
        "work_packages": [
            {
                # –î–∞–Ω–Ω—ã–µ –æ—Ç work_packager (–∞–≥–µ–Ω—Ç 1) - –ë–ï–ó –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–π
                "package_id": "pkg_001",
                "name": "–î–µ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã",
                "description": "–°–Ω–æ—Å –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫ –∏ –ø–æ–∫—Ä—ã—Ç–∏–π",
                "created_at": "2025-09-10T15:28:50.117839",
                
                # works_to_packages (–∞–≥–µ–Ω—Ç 2) –ø—Ä–∏—Å–≤–æ–∏–ª package_id –≤—Å–µ–º —Ä–∞–±–æ—Ç–∞–º
                # –ù–∏–∫–∞–∫–∏—Ö –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π –≤ –ø–∞–∫–µ—Ç–µ - –ë–ï–ó –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–π
                
                # –î–∞–Ω–Ω—ã–µ –æ—Ç counter (–∞–≥–µ–Ω—Ç 3) - –° –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è–º–∏! 
                "volume_data": {
                    "quantity": 150.0,
                    "unit": "–º¬≤",
                    "calculation_logic": "–ü—Ä–∏–º–µ–Ω–µ–Ω–æ –ø—Ä–∞–≤–∏–ª–æ –º–∞–∫—Å–∏–º—É–º–∞: –≤–∑—è—Ç–∞ –Ω–∞–∏–±–æ–ª—å—à–∞—è –ø–ª–æ—â–∞–¥—å –∏–∑ –≤—Å–µ—Ö —Ä–∞–±–æ—Ç –¥–µ–º–æ–Ω—Ç–∞–∂–∞",
                    "component_analysis": [
                        {
                            "work_name": "–î–µ–º–æ–Ω—Ç–∞–∂ –≥–∏–ø—Å–æ–∫–∞—Ä—Ç–æ–Ω–∞", 
                            "unit": "–º¬≤", 
                            "quantity": 120.0, 
                            "included": "full",
                            "role": "base_surface"
                        },
                        {
                            "work_name": "–°–Ω—è—Ç–∏–µ –ª–∏–Ω–æ–ª–µ—É–º–∞",
                            "unit": "–º¬≤", 
                            "quantity": 150.0, 
                            "included": "reference", 
                            "role": "floor_covering"
                        }
                    ],
                    # –ù–û–í–û–ï - –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è –¥–ª—è –ü–¢–û!
                    "reasoning": {
                        "why_this_quantity": "150 –º¬≤ - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å –¥–µ–º–æ–Ω—Ç–∏—Ä—É–µ–º—ã—Ö –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ–π, –≤—Å–µ —Ä–∞–±–æ—Ç—ã –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –Ω–∞ –æ–¥–Ω–æ–π –ø–ª–æ—â–∞–¥–∏",
                        "why_this_unit": "–º¬≤ –≤—ã–±—Ä–∞–Ω–∞ –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–∞—è –µ–¥–∏–Ω–∏—Ü–∞ –¥–ª—è –ø–ª–æ—â–∞–¥–Ω—ã—Ö —Ä–∞–±–æ—Ç –¥–µ–º–æ–Ω—Ç–∞–∂–∞",
                        "calculation_approach": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –ø—Ä–∏–Ω—Ü–∏–ø –º–∞–∫—Å–∏–º—É–º–∞ –¥–ª—è —Å–ª–æ–µ–Ω—ã—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π - –≤—Å–µ —Ä–∞–±–æ—Ç—ã –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –Ω–∞ –æ–¥–Ω–æ–π –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏"
                    }
                },
                
                # –î–∞–Ω–Ω—ã–µ –æ—Ç scheduler_and_staffer (–∞–≥–µ–Ω—Ç 4) - –° –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è–º–∏!
                "schedule_blocks": [1, 2],
                "progress_per_block": {
                    "1": 60,
                    "2": 40
                },
                "staffing_per_block": {
                    "1": 10,
                    "2": 8
                },
                # –ù–û–í–û–ï - –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –ü–¢–û!
                "scheduling_reasoning": {
                    "why_these_weeks": "–î–µ–º–æ–Ω—Ç–∞–∂ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ –ø—Ä–æ–µ–∫—Ç–∞ –ø–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –∫–∞–∫ —É–∫–∞–∑–∞–Ω–æ –≤ –¥–∏—Ä–µ–∫—Ç–∏–≤–µ",
                    "why_this_duration": "2 –Ω–µ–¥–µ–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –¥–µ–º–æ–Ω—Ç–∞–∂–∞ 150–º¬≤ —Å —É—á–µ—Ç–æ–º –¥–∏—Ä–µ–∫—Ç–∏–≤—ã –æ —Ä–∞—Å—Ç—è–≥–∏–≤–∞–Ω–∏–∏ –Ω–∞ –ø–µ—Ä–≤—ã–π –º–µ—Å—è—Ü",
                    "why_this_sequence": "60% –≤ –ø–µ—Ä–≤—É—é –Ω–µ–¥–µ–ª—é (–æ—Å–Ω–æ–≤–Ω–æ–π –¥–µ–º–æ–Ω—Ç–∞–∂), 40% –≤–æ –≤—Ç–æ—Ä—É—é (–¥–æ–≤–æ–¥–∫–∞ –∏ —É–±–æ—Ä–∫–∞ –º—É—Å–æ—Ä–∞)",
                    "why_this_staffing": "10 —á–µ–ª–æ–≤–µ–∫ –≤ –ø–µ—Ä–≤—É—é –Ω–µ–¥–µ–ª—é –¥–ª—è –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ–≥–æ –¥–µ–º–æ–Ω—Ç–∞–∂–∞, 8 –≤–æ –≤—Ç–æ—Ä—É—é –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ä–∞–±–æ—Ç"
                }
            },
            
            {
                # –í—Ç–æ—Ä–æ–π –ø–∞–∫–µ—Ç - –≠–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã
                "package_id": "pkg_002", 
                "name": "–≠–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã",
                "description": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–∞–±–µ–ª–µ–π –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è",
                "created_at": "2025-09-10T15:28:50.117839",
                
                "volume_data": {
                    "quantity": 250.0,
                    "unit": "–º",
                    "calculation_logic": "–°–ª–æ–∂–µ–Ω–∏–µ –¥–ª–∏–Ω –≤—Å–µ—Ö –∫–∞–±–µ–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π –ø–æ –ø—Ä–∏–Ω—Ü–∏–ø—É —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ–¥–Ω–æ—Ç–∏–ø–Ω—ã—Ö —Ä–∞–±–æ—Ç",
                    "component_analysis": [
                        {
                            "work_name": "–ö–∞–±–µ–ª—å –í–í–ì 3x2.5",
                            "unit": "–º",
                            "quantity": 150.0,
                            "included": "full",
                            "role": "main_cable"
                        },
                        {
                            "work_name": "–ö–∞–±–µ–ª—å –í–í–ì 3x1.5", 
                            "unit": "–º",
                            "quantity": 100.0,
                            "included": "full", 
                            "role": "lighting_cable"
                        }
                    ],
                    "reasoning": {
                        "why_this_quantity": "250 –º - —Å—É–º–º–∞—Ä–Ω–∞—è –¥–ª–∏–Ω–∞ –≤—Å–µ—Ö –∫–∞–±–µ–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π, —Å–æ–≥–ª–∞—Å–Ω–æ –¥–∏—Ä–µ–∫—Ç–∏–≤–µ –æ–± –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ —ç–ª–µ–∫—Ç—Ä–∏–∫–∏",
                        "why_this_unit": "–º –≤—ã–±—Ä–∞–Ω–∞ –∫–∞–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –µ–¥–∏–Ω–∏—Ü–∞ –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö —ç–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂–Ω—ã—Ö —Ä–∞–±–æ—Ç",
                        "calculation_approach": "–ü—Ä–∏–Ω—Ü–∏–ø —Å–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –æ–¥–Ω–æ—Ç–∏–ø–Ω—ã—Ö —Ä–∞–±–æ—Ç - –∫–∞–±–µ–ª–∏ –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è —Ñ–∏–∑–∏—á–µ—Å–∫–∏"
                    }
                },
                
                "schedule_blocks": [3, 4],
                "progress_per_block": {
                    "3": 70,
                    "4": 30
                },
                "staffing_per_block": {
                    "3": 4,
                    "4": 2
                },
                "scheduling_reasoning": {
                    "why_these_weeks": "–≠–ª–µ–∫—Ç—Ä–∏–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –¥–µ–º–æ–Ω—Ç–∞–∂–∞, –Ω–∞ 3-4 –Ω–µ–¥–µ–ª–µ —Å–æ–≥–ª–∞—Å–Ω–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
                    "why_this_duration": "2 –Ω–µ–¥–µ–ª–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è –ø—Ä–æ–∫–ª–∞–¥–∫–∏ 250–º –∫–∞–±–µ–ª–µ–π –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è",
                    "why_this_sequence": "70% –≤ –ø–µ—Ä–≤—É—é –Ω–µ–¥–µ–ª—é (–ø—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–∞–±–µ–ª–µ–π), 30% –≤–æ –≤—Ç–æ—Ä—É—é (–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è)",
                    "why_this_staffing": "4 —ç–ª–µ–∫—Ç—Ä–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–º —ç—Ç–∞–ø–µ, 2 –¥–ª—è –∑–∞–≤–µ—Ä—à–∞—é—â–∏—Ö —Ä–∞–±–æ—Ç"
                }
            }
        ]
    },
    
    "source_work_items": [
        # –ó–¥–µ—Å—å –≤—Å–µ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–∞–±–æ—Ç—ã —Å –ø—Ä–∏—Å–≤–æ–µ–Ω–Ω—ã–º–∏ package_id
        {
            "id": "work_001",
            "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –≥–∏–ø—Å–æ–∫–∞—Ä—Ç–æ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫",
            "code": "07-01-002-1",
            "unit": "–º¬≤",
            "quantity": 120.0,
            "package_id": "pkg_001"  # –ü—Ä–∏—Å–≤–æ–µ–Ω–æ –∞–≥–µ–Ω—Ç–æ–º works_to_packages
        },
        {
            "id": "work_002", 
            "name": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–∞–±–µ–ª—è –í–í–ì 3x2.5",
            "code": "08-01-001-1",
            "unit": "–º",
            "quantity": 150.0,
            "package_id": "pkg_002"  # –ü—Ä–∏—Å–≤–æ–µ–Ω–æ –∞–≥–µ–Ω—Ç–æ–º works_to_packages
        }
        # ... –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ –¥–ª—è –≤—Å–µ—Ö —Ä–∞–±–æ—Ç
    ]
}

print("üéØ –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–†–£–ö–¢–£–†–ê true.json –° –û–ë–û–°–ù–û–í–ê–ù–ò–Ø–ú–ò:")
print("\nüìã –ê–ì–ï–ù–¢–´ –ò –ò–• –í–ö–õ–ê–î–´:")
print("1. work_packager - —Å–æ–∑–¥–∞–µ—Ç –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç (–ë–ï–ó –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–π)")
print("2. works_to_packages - –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç —Ä–∞–±–æ—Ç—ã –∫ –ø–∞–∫–µ—Ç–∞–º (–ë–ï–ó –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–π)")
print("3. counter - —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—ä–µ–º—ã + –¥–æ–±–∞–≤–ª—è–µ—Ç volume_data.reasoning")
print("4. scheduler_and_staffer - –ø–ª–∞–Ω–∏—Ä—É–µ—Ç –≥—Ä–∞—Ñ–∏–∫ + –¥–æ–±–∞–≤–ª—è–µ—Ç scheduling_reasoning")

print("\nüìä –ù–û–í–´–ï –ü–û–õ–Ø –î–õ–Ø –ü–¢–û:")
print("‚Ä¢ volume_data.reasoning - –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è —Ä–∞—Å—á–µ—Ç–∞ –æ–±—ä–µ–º–æ–≤")
print("‚Ä¢ scheduling_reasoning - –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è")

print("\nüìã EXCEL –õ–ò–°–¢–´ –° –û–ë–û–°–ù–û–í–ê–ù–ò–Ø–ú–ò:")
print("‚Ä¢ '–ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫' - –æ—Å–Ω–æ–≤–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ –ì–∞–Ω—Ç–∞")
print("‚Ä¢ '–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è –æ–±—ä–µ–º–æ–≤' - –ø–æ—á–µ–º—É —Ç–∞–∫–∏–µ –æ–±—ä–µ–º—ã –∏ –µ–¥–∏–Ω–∏—Ü—ã")
print("‚Ä¢ '–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è' - –ø–æ—á–µ–º—É —Ç–∞–∫–∏–µ —Å—Ä–æ–∫–∏ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª") 
print("‚Ä¢ '–°–≤–æ–¥–∫–∞ –ø–æ –ø—Ä–æ–µ–∫—Ç—É' - –æ–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")

print("\n‚úÖ –í—Å–µ –≥–æ—Ç–æ–≤–æ! –°–∏—Å—Ç–µ–º–∞ —Ç–µ–ø–µ—Ä—å –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è –¥–ª—è –ü–¢–û")

================================================================================

## –§–ê–ô–õ: tests/test_fixed_classifier.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π —á–µ—Ä–µ–∑ Gemini
"""

import sys
import os
import logging

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append('/home/imort/Herzog_v3')

from src.data_processing.classifier import classify_estimates

def test_classifier():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏  
    input_file = "/home/imort/Herzog_v3/projects/34975055/d19120ef/1_extracted/raw_estimates.json"
    
    print("üß™ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞...")
    print(f"üìÅ –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {input_file}")
    
    try:
        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        classified_data = classify_estimates(input_file)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        classifications = [item['classification'] for item in classified_data]
        work_count = classifications.count('–†–∞–±–æ—Ç–∞')
        material_count = classifications.count('–ú–∞—Ç–µ—Ä–∏–∞–ª')
        other_count = classifications.count('–ò–Ω–æ–µ')
        unknown_count = classifications.count('–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ')
        
        print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
        print(f"  –†–∞–±–æ—Ç: {work_count}")
        print(f"  –ú–∞—Ç–µ—Ä–∏–∞–ª–æ–≤: {material_count}")
        print(f"  –ò–Ω–æ–µ: {other_count}")
        print(f"  –ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö: {unknown_count}")
        print(f"  –í—Å–µ–≥–æ: {len(classified_data)}")
        
        if unknown_count == 0:
            print("‚úÖ –í—Å–µ –ø–æ–∑–∏—Ü–∏–∏ —É—Å–ø–µ—à–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã!")
        else:
            print(f"‚ö†Ô∏è  –û—Å—Ç–∞–ª–æ—Å—å {unknown_count} –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π")
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–∑–¥–∞–Ω—ã –ª–∏ llm —Ñ–∞–π–ª—ã
        project_dir = "/home/imort/Herzog_v3/projects/34975055/d19120ef"
        llm_input_path = f"{project_dir}/2_classified/llm_input.json"
        llm_response_path = f"{project_dir}/2_classified/llm_response.json"
        
        if os.path.exists(llm_input_path):
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω llm_input.json")
        else:
            print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω llm_input.json")
            
        if os.path.exists(llm_response_path):
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω llm_response.json")
        else:
            print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω llm_response.json")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_classifier()
    sys.exit(0 if success else 1)

================================================================================

## –§–ê–ô–õ: tests/test_fixed_work_packager.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ work_packager –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ
"""

import asyncio
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º Herzog
sys.path.append('/home/imort/Herzog_v3')

from src.ai_agents.work_packager import run_work_packager

async def test_fixed_work_packager():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π work_packager"""
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ work_packager...")
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø—Ä–æ–µ–∫—Ç 
    project_path = "/home/imort/Herzog_v3/projects/34975055/d490876a"
    
    if not os.path.exists(project_path):
        print(f"‚ùå –ü—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {project_path}")
        return False
    
    try:
        print(f"üîÑ –ó–∞–ø—É—Å–∫ work_packager –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞: {project_path}")
        
        result = await run_work_packager(project_path)
        
        if result['success']:
            packages_created = result.get('packages_created', 0)
            print(f"‚úÖ Work_packager –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            print(f"üìä –°–æ–∑–¥–∞–Ω–æ –ø–∞–∫–µ—Ç–æ–≤: {packages_created}")
            
            # –ß–∏—Ç–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π true.json —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –ø–∞–∫–µ—Ç—ã
            import json
            truth_path = os.path.join(project_path, "true.json")
            if os.path.exists(truth_path):
                with open(truth_path, 'r', encoding='utf-8') as f:
                    truth_data = json.load(f)
                
                work_packages = truth_data.get('results', {}).get('work_packages', [])
                print(f"üìã –ù–∞–π–¥–µ–Ω–æ –ø–∞–∫–µ—Ç–æ–≤ –≤ true.json: {len(work_packages)}")
                
                for pkg in work_packages[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                    print(f"   - {pkg.get('package_id')}: {pkg.get('name')}")
            
            return True
            
        else:
            print(f"‚ùå Work_packager –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: {result.get('error')}")
            return False
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    asyncio.run(test_fixed_work_packager())

================================================================================

## –§–ê–ô–õ: tests/test_flat_structure.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –ø–ª–æ—Å–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞ ID
"""

import sys
import os
import json
import tempfile
import uuid
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.append('/home/imort/Herzog_v3')

from src.data_processing.extractor import extract_from_files
from src.data_processing.classifier import classify_items
from src.data_processing.preparer import filter_works_from_classified


def test_flat_structure():
    """
    –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω —Å –ø–ª–æ—Å–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
    """
    print("üß™ –¢–ï–°–¢: –ü–ª–æ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö")
    print("=" * 50)
    
    # –®–∞–≥ 1: –¢–µ—Å—Ç–∏—Ä—É–µ–º extractor - –¥–æ–ª–∂–µ–Ω —Å–æ–∑–¥–∞–≤–∞—Ç—å –µ–¥–∏–Ω—ã–π id –±–µ–∑ –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏
    print("\n1Ô∏è‚É£ –¢–µ—Å—Ç EXTRACTOR...")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π Excel —Ñ–∞–π–ª –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    import pandas as pd
    
    test_data = {
        'A': ['‚Ññ –ø/–ø', '1', '2'],
        'B': ['–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ', '–ì–≠–°–ù46-02-009', '–§–°–ë–¶-14.4.01.02'],
        'C': ['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç', '–û—Ç–±–∏–≤–∫–∞ —à—Ç—É–∫–∞—Ç—É—Ä–∫–∏', '–°–º–µ—Å—å —Å—É—Ö–∞—è'],
        'H': ['–ï–¥.–∏–∑–º.', '–º2', '–∫–≥'],
        'I': ['–ö–æ–ª-–≤–æ', '100', '500']
    }
    
    df = pd.DataFrame(test_data)
    
    with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as tmp:
        df.to_excel(tmp.name, index=False, header=False)
        tmp_excel = tmp.name
    
    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        extracted_data = extract_from_files([tmp_excel])
        
        print(f"   ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(extracted_data)} –∑–∞–ø–∏—Å–µ–π")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        if extracted_data:
            first_item = extracted_data[0]
            print(f"   üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–µ—Ä–≤–æ–π –∑–∞–ø–∏—Å–∏:")
            for key, value in first_item.items():
                print(f"      {key}: {value}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å –µ–¥–∏–Ω—ã–π id
            assert 'id' in first_item, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ 'id'"
            assert 'internal_id' not in first_item, "–ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ä–æ–µ –ø–æ–ª–µ 'internal_id'"
            print("   ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ extractor –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞")
        
        # –®–∞–≥ 2: –¢–µ—Å—Ç–∏—Ä—É–µ–º classifier
        print("\n2Ô∏è‚É£ –¢–µ—Å—Ç CLASSIFIER...")
        
        classified_data = classify_items(extracted_data)
        print(f"   ‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ {len(classified_data)} –∑–∞–ø–∏—Å–µ–π")
        
        if classified_data:
            first_classified = classified_data[0]
            print(f"   üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏:")
            for key, value in first_classified.items():
                print(f"      {key}: {value}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ id —Å–æ—Ö—Ä–∞–Ω–∏–ª—Å—è
            assert 'id' in first_classified, "–ü–æ—Ç–µ—Ä—è–Ω id –ø–æ—Å–ª–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"
            assert first_classified['id'] == first_item['id'], "ID –∏–∑–º–µ–Ω–∏–ª—Å—è –ø–æ—Å–ª–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"
            print("   ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ classifier –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞")
        
        # –®–∞–≥ 3: –¢–µ—Å—Ç–∏—Ä—É–µ–º preparer
        print("\n3Ô∏è‚É£ –¢–µ—Å—Ç PREPARER...")
        
        work_items = filter_works_from_classified(classified_data)
        print(f"   ‚úÖ –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(work_items)} —Ä–∞–±–æ—Ç")
        
        if work_items:
            first_work = work_items[0]
            print(f"   üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–∞–±–æ—Ç—ã:")
            for key, value in first_work.items():
                print(f"      {key}: {value}")
            
            # –ì–ª–∞–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –Ω–∏–∫–∞–∫–æ–π –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏ original_data!
            assert 'original_data' not in first_work, "–ù–∞–π–¥–µ–Ω–∞ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω–∞—è –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å 'original_data'"
            assert 'id' in first_work, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç id –≤ —Ä–∞–±–æ—Ç–µ"
            assert 'source_file' in first_work, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç source_file –≤ —Ä–∞–±–æ—Ç–µ"
            assert 'code' in first_work, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç code –≤ —Ä–∞–±–æ—Ç–µ"
            assert 'name' in first_work, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç name –≤ —Ä–∞–±–æ—Ç–µ"
            
            print("   ‚úÖ –ü–ª–æ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–∞–±–æ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞!")
            print("   üéâ –ù–ï–¢ –í–õ–û–ñ–ï–ù–ù–û–°–¢–ò original_data - —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–ª–æ—Å–∫–∞—è!")
        
        print("\n" + "=" * 50)
        print("‚úÖ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´!")
        print("üéØ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö —Ç–µ–ø–µ—Ä—å –ø–ª–æ—Å–∫–∞—è —Å –µ–¥–∏–Ω—ã–º ID")
        print("üìã –û–¥–∏–Ω ID –ø—É—Ç–µ—à–µ—Å—Ç–≤—É–µ—Ç —á–µ—Ä–µ–∑ –≤—Å–µ —ç—Ç–∞–ø—ã –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π")
        
    finally:
        # –û—á–∏—Å—Ç–∫–∞
        os.unlink(tmp_excel)


if __name__ == "__main__":
    test_flat_structure()

================================================================================

## –§–ê–ô–õ: tests/test_full_pipeline.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏
"""

import asyncio
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º Herzog
sys.path.append('/home/imort/Herzog_v3')

from src.ai_agents.counter import run_counter
from src.ai_agents.scheduler_and_staffer import run_scheduler_and_staffer
from src.data_processing.reporter_v3 import generate_multipage_excel_report

async def test_counter_and_scheduler():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º counter –∏ scheduler_and_staffer —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏"""
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ counter –∏ scheduler_and_staffer —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏...")
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø—Ä–æ–µ–∫—Ç 
    project_path = "/home/imort/Herzog_v3/projects/34975055/d490876a"
    
    if not os.path.exists(project_path):
        print(f"‚ùå –ü—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {project_path}")
        return False
    
    try:
        # –®–∞–≥ 1: –ó–∞–ø—É—Å–∫–∞–µ–º counter —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –ª–∏–º–∏—Ç–∞–º–∏ —Ç–æ–∫–µ–Ω–æ–≤
        print(f"üîÑ –ó–∞–ø—É—Å–∫ counter –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞: {project_path}")
        counter_result = await run_counter(project_path)
        
        if not counter_result['success']:
            print(f"‚ùå Counter –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: {counter_result.get('error')}")
            return False
        
        print(f"‚úÖ Counter –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–∞–∫–µ—Ç–æ–≤: {counter_result.get('packages_processed', 0)}")
        
        # –®–∞–≥ 2: –ó–∞–ø—É—Å–∫–∞–µ–º scheduler_and_staffer —Å –æ–±—Ö–æ–¥–æ–º RECITATION
        print(f"üîÑ –ó–∞–ø—É—Å–∫ scheduler_and_staffer –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞: {project_path}")
        scheduler_result = await run_scheduler_and_staffer(project_path)
        
        if not scheduler_result['success']:
            print(f"‚ùå Scheduler_and_staffer –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: {scheduler_result.get('error')}")
            return False
            
        print(f"‚úÖ Scheduler_and_staffer –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–∞–∫–µ—Ç–æ–≤: {scheduler_result.get('packages_scheduled', 0)}")
        
        # –®–∞–≥ 3: –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º Excel –æ—Ç—á–µ—Ç
        print(f"üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Excel –æ—Ç—á–µ—Ç–∞...")
        try:
            truth_file = os.path.join(project_path, "true.json")
            output_folder = os.path.join(project_path, "8_output")
            os.makedirs(output_folder, exist_ok=True)
            
            excel_file = generate_multipage_excel_report(truth_file, output_folder)
            print(f"‚úÖ Excel –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {excel_file}")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Excel: {e}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Ç–æ–≥–æ–≤—ã–µ —Ñ–∞–π–ª—ã
        output_folder = os.path.join(project_path, "8_output")
        if os.path.exists(output_folder):
            print(f"\nüìÅ –§–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ 8_output:")
            for file in os.listdir(output_folder):
                file_path = os.path.join(output_folder, file)
                if os.path.isfile(file_path):
                    size = os.path.getsize(file_path)
                    print(f"   üìÑ {file} ({size} –±–∞–π—Ç)")
        
        return True
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    asyncio.run(test_counter_and_scheduler())

================================================================================

## –§–ê–ô–õ: tests/test_gemini_client.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ Gemini –∫–ª–∏–µ–Ω—Ç–∞ —Å retry –ª–æ–≥–∏–∫–æ–π
"""

import asyncio
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º Herzog
sys.path.append('/home/imort/Herzog_v3')

from src.shared.gemini_client import gemini_client

async def test_gemini_client():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç Gemini"""
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ Gemini –∫–ª–∏–µ–Ω—Ç–∞...")
    print(f"üìã –ú–æ–¥–µ–ª—å: {gemini_client.model.model_name}")
    
    # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    test_prompt = '''
–¢—ã - –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–±–æ—Ç. –û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:

{
    "test": "ok",
    "model": "gemini-1.5-pro",
    "message": "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—à–ª–æ —É—Å–ø–µ—à–Ω–æ!"
}

–î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
- –£–∫–ª–∞–¥–∫–∞ –ø–ª–∏—Ç–∫–∏: 100 –º2
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏—è: 100 –º2
'''

    try:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        print("\nüîÑ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å...")
        result = await gemini_client.generate_response(test_prompt)
        
        if result['success']:
            print(f"‚úÖ –ó–∞–ø—Ä–æ—Å —É—Å–ø–µ—à–µ–Ω!")
            print(f"üìä –¢–æ–∫–µ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {result['usage_metadata']['total_token_count']}")
            print(f"üéØ –ü–æ–ø—ã—Ç–∫–∞: {result.get('attempt', 1)}")
            print(f"üìÑ JSON –ø–∞—Ä—Å–∏–Ω–≥: {'—É—Å–ø–µ—à–µ–Ω' if result['json_parse_success'] else '–Ω–µ—É—Å–ø–µ—à–µ–Ω'}")
            
            if result['json_parse_success']:
                response = result['response']
                print(f"üí¨ –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {response.get('message', '–Ω–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è')}")
            else:
                print(f"üí¨ –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç: {result['raw_text'][:200]}...")
                
        else:
            print(f"‚ùå –ó–∞–ø—Ä–æ—Å –Ω–µ—É—Å–ø–µ—à–µ–Ω: {result['error']}")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_gemini_client())

================================================================================

## –§–ê–ô–õ: tests/test_json_recovery.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω–æ–≥–æ JSON
"""

import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º Herzog
sys.path.append('/home/imort/Herzog_v3')

from src.shared.gemini_client import gemini_client
from src.ai_agents.work_packager import WorkPackager

def test_json_recovery():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω–æ–≥–æ JSON"""
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω–æ–≥–æ JSON...")
    
    # –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ (–æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π)
    broken_json = """{
  "work_packages": [
    {
      "package_id": "pkg_001",
      "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –∫—Ä–æ–≤–ª–∏ –∏ —Å—Ç—Ä–æ–ø–∏–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã",
      "description": "–†–∞–∑–±–æ—Ä–∫–∞ –∫—Ä–æ–≤–µ–ª—å–Ω–æ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è –∏–∑ —Ö—Ä–∏–∑–æ—Ç–∏–ª—Ü–µ–º–µ–Ω—Ç–Ω—ã—Ö –ª–∏—Å—Ç–æ–≤, –æ–±—Ä–µ—à–µ—Ç–∫–∏ –∏ –¥–µ—Ä–µ–≤—è–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∫—Ä—ã—à."
    },
    {
      "package_id": "pkg_002",
      "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π",
      "description": "–†–∞–∑–±–æ—Ä–∫–∞ –∫–∏—Ä–ø–∏—á–Ω—ã—Ö —Å—Ç–µ–Ω –∏ –∂–µ–ª–µ–∑–æ–±–µ—Ç–æ–Ω–Ω—ã—Ö —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–æ–≤ –≤–Ω—É—Ç—Ä–∏ –∑–¥–∞–Ω–∏—è."
    },
    {
      "package_id": "pkg_003",
      "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–æ–ª–æ–≤ –∏ –æ—Å–Ω–æ–≤–∞–Ω–∏–π",
      "description": "–†–∞–∑–±–æ—Ä–∫–∞ –ø–æ–∫—Ä—ã—Ç–∏–π –ø–æ–ª–æ–≤ (–ø–ª–∏—Ç–∫–∞, —Ü–µ–º–µ–Ω—Ç, –ª–∏–Ω–æ–ª–µ—É–º, –¥–æ—Å–∫–∏), –æ—Å–Ω–æ–≤–∞–Ω–∏–π, –ª–∞–≥, —Å—Ç–æ–ª–±–∏–∫–æ–≤ –∏ –ø–ª–∏–Ω—Ç—É—Å–æ–≤."
    },
    {
      "package_id": "pkg_015",
      "name": "–û—Ç–¥–µ–ª–∫–∞ –ø–æ—Ç–æ–ª–∫–æ–≤",
      "description" """
    
    print("üîß –¢–µ—Å—Ç–∏—Ä—É—é _try_fix_broken_json...")
    
    try:
        fixed = gemini_client._try_fix_broken_json(broken_json)
        print(f"‚úÖ JSON –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω! –ù–∞–π–¥–µ–Ω–æ –ø–∞–∫–µ—Ç–æ–≤: {len(fixed.get('work_packages', []))}")
        
        for pkg in fixed.get('work_packages', [])[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
            print(f"   - {pkg.get('package_id')}: {pkg.get('name')}")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è JSON: {e}")
    
    print("\nüîß –¢–µ—Å—Ç–∏—Ä—É—é _extract_packages_from_raw_response...")
    
    try:
        packager = WorkPackager()
        packages = packager._extract_packages_from_raw_response(broken_json)
        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ –ø–∞–∫–µ—Ç–æ–≤ –∏–∑ —Å—ã—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {len(packages)}")
        
        for pkg in packages[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
            print(f"   - {pkg.get('package_id')}: {pkg.get('name')}")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞–∫–µ—Ç–æ–≤: {e}")
    
    print("\nüîß –¢–µ—Å—Ç–∏—Ä—É—é —Å–æ–∑–¥–∞–Ω–∏–µ fallback –ø–∞–∫–µ—Ç–æ–≤...")
    
    try:
        packager = WorkPackager()
        fallback = packager._create_basic_fallback_packages()
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ fallback –ø–∞–∫–µ—Ç–æ–≤: {len(fallback)}")
        
        for pkg in fallback:
            print(f"   - {pkg.get('package_id')}: {pkg.get('name')}")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è fallback: {e}")

if __name__ == "__main__":
    test_json_recovery()

================================================================================

## –§–ê–ô–õ: tests/test_multi_model_system.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã —Å —Ä–∞–∑–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
"""

import asyncio
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º Herzog
sys.path.append('/home/imort/Herzog_v3')

from src.shared.gemini_client import gemini_client

async def test_multi_model_system():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É —Å —Ä–∞–∑–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞"""
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º—É–ª—å—Ç–∏–º–æ–¥–µ–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã Gemini...")
    print(f"üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤:")
    for agent, model in gemini_client.agent_models.items():
        print(f"   {agent}: {model}")
    
    print()
    
    # –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º—Ç
    test_prompt = '''
{
    "test": "multi_model",
    "agent": "current_agent",
    "message": "–ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!"
}
'''

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
    agents_to_test = ['work_packager', 'works_to_packages', 'counter', 'scheduler_and_staffer']
    
    for agent_name in agents_to_test:
        try:
            print(f"üîÑ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–≥–µ–Ω—Ç–∞: {agent_name}")
            
            result = await gemini_client.generate_response(
                test_prompt, 
                agent_name=agent_name
            )
            
            if result['success']:
                model_used = result.get('model_used', 'unknown')
                tokens = result['usage_metadata']['total_token_count']
                attempt = result.get('attempt', 1)
                
                print(f"   ‚úÖ –£—Å–ø–µ—Ö: {model_used} | –¢–æ–∫–µ–Ω–æ–≤: {tokens} | –ü–æ–ø—ã—Ç–∫–∞: {attempt}")
                
                if result['json_parse_success']:
                    response = result['response']
                    print(f"   üí¨ –û—Ç–≤–µ—Ç: {response.get('message', '–Ω–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è')}")
                else:
                    print(f"   ‚ö†Ô∏è  JSON –Ω–µ –ø–∞—Ä—Å–∏—Ç—Å—è, —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç: {result['raw_text'][:100]}...")
            else:
                print(f"   ‚ùå –û—à–∏–±–∫–∞: {result['error']}")
                
        except Exception as e:
            print(f"   üí• –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}")
        
        print()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –≤—ã–∑–æ–≤ (–±–µ–∑ –∞–≥–µ–Ω—Ç–∞)
    print("üîÑ –¢–µ—Å—Ç–∏—Ä—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –≤—ã–∑–æ–≤ (–±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–∞)...")
    try:
        result = await gemini_client.generate_response(test_prompt)
        
        if result['success']:
            model_used = result.get('model_used', 'unknown')
            tokens = result['usage_metadata']['total_token_count']
            
            print(f"   ‚úÖ –£—Å–ø–µ—Ö: {model_used} | –¢–æ–∫–µ–Ω–æ–≤: {tokens}")
        else:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {result['error']}")
            
    except Exception as e:
        print(f"   üí• –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}")
    
    print("\nüéØ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º—É–ª—å—Ç–∏–º–æ–¥–µ–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

if __name__ == "__main__":
    asyncio.run(test_multi_model_system())

================================================================================

## –§–ê–ô–õ: tests/test_new_agent_system.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –Ω–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –∞–≥–µ–Ω—Ç–æ–≤ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ group_creator –∏ group_assigner
"""

import sys
import os
import json
import logging

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append('/home/imort/Herzog_v3')

from src.ai_agents.agent_runner import run_agent, run_pipeline

def create_test_project_data():
    """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–π project_data.json –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    # –ß–∏—Ç–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    classified_file = "/home/imort/Herzog_v3/projects/34975055/d19120ef/2_classified/classified_estimates.json"
    with open(classified_file, 'r', encoding='utf-8') as f:
        classified_data = json.load(f)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –¢–û–õ–¨–ö–û —Ä–∞–±–æ—Ç—ã –¥–ª—è project_data.json
    work_items_only = [item for item in classified_data if item.get('classification') == '–†–∞–±–æ—Ç–∞']
    print(f"üìã –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(work_items_only)} —Ä–∞–±–æ—Ç –∏–∑ {len(classified_data)} –ø–æ–∑–∏—Ü–∏–π")
    
    # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π project_data.json
    project_data = {
        "meta": {
            "user_id": "34975055",
            "project_id": "d19120ef", 
            "created_at": "2025-09-04",
            "source_files": ["–ö–† - –õ–°–† –ø–æ –ú–µ—Ç–æ–¥–∏–∫–µ 2020 (–†–ú)1.xlsx"]
        },
        "directives": {
            "target_work_count": 15,
            "project_timeline": {
                "start_date": "2024-01-01",
                "end_date": "2024-06-30"
            },
            "workforce_range": {"min": 10, "max": 20},
            "conceptualizer": "–≤—Å—é —ç–ª–µ–∫—Ç—Ä–∏–∫—É –≤ –æ–¥–∏–Ω –±–ª–æ–∫, –¥–µ–º–æ–Ω—Ç–∞–∂ –æ—Ç–¥–µ–ª—å–Ω–æ",
            "strategist": "—Ä–∞—Å—Ç—è–Ω–∏ –¥–µ–º–æ–Ω—Ç–∞–∂ –Ω–∞ –≤–µ—Å—å –ø–µ—Ä–≤—ã–π –º–µ—Å—è—Ü",
            "accountant": "–ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ —Å—á–∏—Ç–∞–π —Ç–æ—á–Ω–æ",
            "foreman": "–Ω–∞ –æ—Ç–¥–µ–ª–∫—É –∫–∏–Ω—å –º–∞–∫—Å–∏–º—É–º –ª—é–¥–µ–π"
        },
        "timeline_blocks": [],  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –ø–æ–∑–∂–µ
        "work_items": work_items_only
    }
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–µ–¥–µ–ª—å–Ω—ã–µ –±–ª–æ–∫–∏ (26 –Ω–µ–¥–µ–ª—å –¥–ª—è –ø–æ–ª—É–≥–æ–¥–∞)
    from datetime import datetime, timedelta
    start_date = datetime(2024, 1, 1)
    
    for week_num in range(1, 27):
        week_start = start_date + timedelta(weeks=week_num-1)
        week_end = week_start + timedelta(days=6)
        
        project_data["timeline_blocks"].append({
            "week_id": week_num,
            "start_date": week_start.strftime("%Y-%m-%d"),
            "end_date": week_end.strftime("%Y-%m-%d"),
            "calendar_week": week_start.isocalendar()[1]
        })
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–ø–∫—É 3_prepared
    prepared_dir = "/home/imort/Herzog_v3/projects/34975055/d19120ef/3_prepared"
    os.makedirs(prepared_dir, exist_ok=True)
    
    output_file = os.path.join(prepared_dir, "project_data.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(project_data, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ç–µ—Å—Ç–æ–≤—ã–π project_data.json: {output_file}")
    return output_file

def test_group_creator():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∞–≥–µ–Ω—Ç–∞ group_creator"""
    project_dir = "/home/imort/Herzog_v3/projects/34975055/d19120ef"
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ group_creator...")
    
    success = run_agent("group_creator", project_dir)
    
    if success:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result_file = os.path.join(project_dir, "4.1_grouped", "project_data.json")
        if os.path.exists(result_file):
            with open(result_file, 'r', encoding='utf-8') as f:
                result_data = json.load(f)
            
            work_groups = result_data.get('work_groups', [])
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(work_groups)} –≥—Ä—É–ø–ø —Ä–∞–±–æ—Ç:")
            for group in work_groups:
                print(f"  - {group.get('name')} (UUID: {group.get('uuid', 'N/A')})")
        
        return True
    else:
        print("‚ùå –û—à–∏–±–∫–∞ –≤ —Ä–∞–±–æ—Ç–µ group_creator")
        return False

def test_group_assigner():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∞–≥–µ–Ω—Ç–∞ group_assigner"""
    project_dir = "/home/imort/Herzog_v3/projects/34975055/d19120ef"
    
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ group_assigner...")
    
    success = run_agent("group_assigner", project_dir)
    
    if success:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result_file = os.path.join(project_dir, "4_conceptualized", "project_data.json")
        if os.path.exists(result_file):
            with open(result_file, 'r', encoding='utf-8') as f:
                result_data = json.load(f)
            
            work_items = result_data.get('work_items', [])
            assigned_works = [item for item in work_items 
                            if item.get('classification') == '–†–∞–±–æ—Ç–∞' and 'group_uuid' in item]
            
            print(f"‚úÖ –ù–∞–∑–Ω–∞—á–µ–Ω—ã –≥—Ä—É–ø–ø—ã –¥–ª—è {len(assigned_works)} —Ä–∞–±–æ—Ç")
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ UUID –≥—Ä—É–ø–ø
            group_assignments = {}
            for work in assigned_works:
                group_uuid = work.get('group_uuid')
                if group_uuid not in group_assignments:
                    group_assignments[group_uuid] = []
                group_assignments[group_uuid].append(work.get('name', 'N/A'))
            
            print(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≥—Ä—É–ø–ø–∞–º:")
            for group_uuid, works in group_assignments.items():
                print(f"  - {group_uuid[:8]}...: {len(works)} —Ä–∞–±–æ—Ç")
        
        return True
    else:
        print("‚ùå –û—à–∏–±–∫–∞ –≤ —Ä–∞–±–æ—Ç–µ group_assigner")
        return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ –Ω–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –∞–≥–µ–Ω—Ç–æ–≤")
    
    try:
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        create_test_project_data()
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
        success1 = test_group_creator()
        
        if success1:
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—Ç–æ—Ä–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
            success2 = test_group_assigner()
            
            if success2:
                print("\nüéâ –û–±–∞ –∞–≥–µ–Ω—Ç–∞ —Ä–∞–±–æ—Ç–∞—é—Ç —É—Å–ø–µ—à–Ω–æ!")
                return True
        
        print("\nüí• –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–∞–ª–µ–Ω–æ")
        return False
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

================================================================================

## –§–ê–ô–õ: tests/test_new_test_command.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–°–∏–º—É–ª—è—Ü–∏—è –∫–æ–º–∞–Ω–¥—ã /test —Å —ç—Ç–∞–ø–∞ 6 (counter)
"""

import os
import sys
import shutil
import tempfile

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º Herzog
sys.path.append('/home/imort/Herzog_v3')

from src.telegram_bot.handlers import _copy_project_files_up_to_stage

def simulate_test_stage_6():
    """–°–∏–º—É–ª–∏—Ä—É–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ —Å —ç—Ç–∞–ø–∞ 6"""
    
    source_project = "/home/imort/Herzog_v3/projects/34975055/da1ac471"
    
    print("üß™ –°–∏–º—É–ª—è—Ü–∏—è –∫–æ–º–∞–Ω–¥—ã /test —Å —ç—Ç–∞–ø–æ–º 6 (counter)...")
    print(f"üìÅ –ò—Å—Ç–æ—á–Ω–∏–∫: {source_project}")
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –∫–∞–∫ –µ—Å–ª–∏ –±—ã —Å–æ–∑–¥–∞–ª questionnaire.create_project_structure
    with tempfile.TemporaryDirectory() as temp_dir:
        target_project = os.path.join(temp_dir, "test_project")
        os.makedirs(target_project, exist_ok=True)
        
        print(f"üìÅ –¶–µ–ª—å: {target_project}")
        
        # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –¥–æ —ç—Ç–∞–ø–∞ 6 (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ)
        print("üîÑ –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤...")
        success = _copy_project_files_up_to_stage(source_project, target_project, "6")
        
        if success:
            print("‚úÖ –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ!")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–ª–æ—Å—å
            copied_folders = []
            for item in os.listdir(target_project):
                if os.path.isdir(os.path.join(target_project, item)):
                    copied_folders.append(item)
                    
            copied_folders.sort()
            print(f"üìã –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞–ø–∫–∏: {copied_folders}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º true.json
            truth_file = os.path.join(target_project, "true.json")
            if os.path.exists(truth_file):
                file_size = os.path.getsize(truth_file)
                print(f"üìÑ true.json: {file_size} –±–∞–π—Ç")
                
                # –ü—Ä–æ–≤–µ—Ä–∏–º —Å–∫–æ–ª—å–∫–æ –ø–∞–∫–µ—Ç–æ–≤ —É–∂–µ –∏–º–µ—é—Ç volume_data
                import json
                with open(truth_file, 'r', encoding='utf-8') as f:
                    truth_data = json.load(f)
                
                work_packages = truth_data.get('results', {}).get('work_packages', [])
                packages_with_volume = [pkg for pkg in work_packages if 'volume_data' in pkg]
                
                print(f"üìä –ü–∞–∫–µ—Ç–æ–≤ –≤—Å–µ–≥–æ: {len(work_packages)}")
                print(f"‚úÖ –° volume_data: {len(packages_with_volume)}")
                print(f"‚è≥ –û—Å—Ç–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å: {len(work_packages) - len(packages_with_volume)}")
                
                # –ü—Ä–æ–≤–µ—Ä–∏–º –ø–∞–ø–∫—É 6_counter
                counter_folder = os.path.join(target_project, "6_counter")
                if os.path.exists(counter_folder):
                    counter_files = os.listdir(counter_folder)
                    response_files = [f for f in counter_files if f.endswith('_response.json')]
                    print(f"üìÅ –§–∞–π–ª–æ–≤ –≤ 6_counter: {len(counter_files)}")
                    print(f"üìã Response —Ñ–∞–π–ª–æ–≤: {len(response_files)}")
                    
                    # –ù–∞–π–¥–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∏ –ø–µ—Ä–≤—ã–π —Å –æ—à–∏–±–∫–æ–π
                    success_responses = []
                    error_responses = []
                    
                    for resp_file in response_files:
                        resp_path = os.path.join(counter_folder, resp_file)
                        try:
                            with open(resp_path, 'r', encoding='utf-8') as f:
                                resp_data = json.load(f)
                                if resp_data.get('success'):
                                    success_responses.append(resp_file)
                                else:
                                    error_responses.append(resp_file)
                        except:
                            pass
                    
                    print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤: {len(success_responses)}")
                    print(f"‚ùå –û—à–∏–±–æ–∫: {len(error_responses)}")
                    
                    if error_responses:
                        print(f"üö® –ü–µ—Ä–≤–∞—è –æ—à–∏–±–∫–∞ –≤: {sorted(error_responses)[0]}")
            
            print(f"\nüéØ –†–µ–∑—É–ª—å—Ç–∞—Ç:")
            print(f"   –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç –≥–æ—Ç–æ–≤ –∫ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—é –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            print(f"   –ú–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å pipeline —Å —ç—Ç–∞–ø–∞ 7 (scheduler_and_staffer)")
            print(f"   Counter —á–∞—Å—Ç–∏—á–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–ª –ø–∞–∫–µ—Ç—ã, –º–æ–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å")
                
        else:
            print("‚ùå –û—à–∏–±–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è!")

if __name__ == "__main__":
    simulate_test_stage_6()

================================================================================

## –§–ê–ô–õ: tests/test_pdf_cyrillic.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã –≤ PDF —ç–∫—Å–ø–æ—Ä—Ç–µ
"""

import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º Herzog
sys.path.append('/home/imort/Herzog_v3')

from src.data_processing.pdf_exporter import PDFExporter

def test_pdf_cyrillic():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º PDF —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π"""
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ PDF —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π...")
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π Excel —Ñ–∞–π–ª —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π
    import openpyxl
    from datetime import datetime
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π Excel —Ñ–∞–π–ª
    test_excel_path = '/tmp/test_cyrillic.xlsx'
    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "–ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫"
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º –¥–∞–Ω–Ω—ã–º–∏ —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π
    ws['A1'] = "‚Ññ"
    ws['B1'] = "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç"
    ws['C1'] = "–ï–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è" 
    ws['D1'] = "–û–±—ä–µ–º"
    
    ws['A2'] = 1
    ws['B2'] = "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫"
    ws['C2'] = "–º¬≤"
    ws['D2'] = 150.5
    
    ws['A3'] = 2
    ws['B3'] = "–ú–æ–Ω—Ç–∞–∂ —Å—Ç—è–∂–∫–∏ –ø–æ–ª–∞"
    ws['C3'] = "–º¬≤"  
    ws['D3'] = 85.2
    
    ws['A4'] = 3
    ws['B4'] = "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —á–∏—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è"
    ws['C4'] = "–º¬≤"
    ws['D4'] = 85.2
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º Excel
    wb.save(test_excel_path)
    print(f"üìÑ –°–æ–∑–¥–∞–Ω —Ç–µ—Å—Ç–æ–≤—ã–π Excel: {test_excel_path}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º PDF —ç–∫—Å–ø–æ—Ä—Ç
    try:
        exporter = PDFExporter()
        pdf_path = exporter.export_excel_to_pdf(test_excel_path, '/tmp', 'pdf')
        
        if os.path.exists(pdf_path):
            file_size = os.path.getsize(pdf_path)
            print(f"‚úÖ PDF —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ: {pdf_path}")
            print(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ PDF (–ø—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
            with open(pdf_path, 'rb') as f:
                content = f.read()
                if b'PDF' in content[:10]:
                    print("‚úÖ –§–∞–π–ª —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º PDF")
                else:
                    print("‚ö†Ô∏è –§–∞–π–ª –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω")
                    
        else:
            print("‚ùå PDF —Ñ–∞–π–ª –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è PDF: {e}")
        import traceback
        traceback.print_exc()
    
    # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    try:
        if os.path.exists(test_excel_path):
            os.remove(test_excel_path)
    except:
        pass

if __name__ == "__main__":
    test_pdf_cyrillic()

================================================================================

## –§–ê–ô–õ: tests/test_pipeline_fix.py
------------------------------------------------------------
#!/usr/bin/env python3

import asyncio
import os
from src.main_pipeline import HerzogPipeline

async def test_pipeline():
    project_path = 'projects/34975055/fdebae37'
    
    if not os.path.exists(project_path):
        print(f'‚ùå –ü—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {project_path}')
        return
    
    print(f'‚úÖ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞: {project_path}')
    
    pipeline = HerzogPipeline(project_path)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —ç—Ç–∞–ø –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª–∏–∑–∞—Ü–∏–∏ (—à–∞–≥ 4)
    print('üéØ –ó–∞–ø—É—Å–∫–∞–µ–º —ç—Ç–∞–ø –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª–∏–∑–∞—Ü–∏–∏...')
    result = await pipeline.run_ai_agent(4)
    
    print('üìä –†–µ–∑—É–ª—å—Ç–∞—Ç:')
    print(result)
    
    if result.get('success'):
        print('‚úÖ –ö–æ–Ω—Ü–µ–ø—Ç—É–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!')
    else:
        print('‚ùå –û—à–∏–±–∫–∞ –≤ –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª–∏–∑–∞—Ü–∏–∏:', result.get('error'))

if __name__ == '__main__':
    asyncio.run(test_pipeline())

================================================================================

## –§–ê–ô–õ: tests/test_preparer_filtering.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –≤ preparer.py
–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤ project_data.json –ø–æ–ø–∞–¥–∞—é—Ç —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—Ç—ã
"""

import json
import tempfile
import os
import sys
sys.path.append('/home/imort/Herzog_v3')

from src.data_processing.preparer import prepare_project_data

def test_preparer_filtering():
    """–¢–µ—Å—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—Ç—ã –¥–æ–ª–∂–Ω—ã –ø–æ–ø–∞—Å—Ç—å –≤ project_data.json"""
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å —Ä–∞–±–æ—Ç–∞–º–∏, –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏ –∏ "–∏–Ω–æ–µ"
    test_classified_data = [
        {
            'internal_id': 'work-1',
            'classification': '–†–∞–±–æ—Ç–∞',
            'source_file': 'test.xlsx',
            'position_num': '1',
            'code': '–ì–≠–°–ù46-02-009-02',
            'name': '–û—Ç–±–∏–≤–∫–∞ —à—Ç—É–∫–∞—Ç—É—Ä–∫–∏',
            'unit': '100 –º2',
            'quantity': '7.77'
        },
        {
            'internal_id': 'material-1',
            'classification': '–ú–∞—Ç–µ—Ä–∏–∞–ª', 
            'source_file': 'test.xlsx',
            'position_num': '2',
            'code': '–§–°–ë–¶-14.4.01.02-0012',
            'name': '–°–º–µ—Å—å —Å—É—Ö–∞—è —à—Ç—É–∫–∞—Ç—É—Ä–Ω–∞—è',
            'unit': '–∫–≥',
            'quantity': '1000'
        },
        {
            'internal_id': 'work-2',
            'classification': '–†–∞–±–æ—Ç–∞',
            'source_file': 'test.xlsx', 
            'position_num': '3',
            'code': '–ì–≠–°–ù46-01-001-01',
            'name': '–î–µ–º–æ–Ω—Ç–∞–∂ –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫',
            'unit': '100 –º2',
            'quantity': '5.5'
        },
        {
            'internal_id': 'other-1',
            'classification': '–ò–Ω–æ–µ',
            'source_file': 'test.xlsx',
            'position_num': '4', 
            'code': '–ù–†-001',
            'name': '–ù–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã',
            'unit': '%',
            'quantity': '15'
        }
    ]
    
    test_directives = {
        'target_work_count': 15,
        'project_timeline': {
            'start_date': '01.01.2024',
            'end_date': '31.01.2024'
        },
        'workforce_range': {'min': 10, 'max': 20}
    }
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f1:
        json.dump(test_classified_data, f1, ensure_ascii=False, indent=2)
        classified_file = f1.name
    
    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f2:
        json.dump(test_directives, f2, ensure_ascii=False, indent=2)
        directives_file = f2.name
    
    try:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º preparer
        result = prepare_project_data(classified_file, directives_file)
        
        print(f"üìä –ò—Å—Ö–æ–¥–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π –≤—Å–µ–≥–æ: {len(test_classified_data)}")
        print(f"   - –†–∞–±–æ—Ç: {len([x for x in test_classified_data if x['classification'] == '–†–∞–±–æ—Ç–∞'])}")
        print(f"   - –ú–∞—Ç–µ—Ä–∏–∞–ª–æ–≤: {len([x for x in test_classified_data if x['classification'] == '–ú–∞—Ç–µ—Ä–∏–∞–ª'])}")
        print(f"   - –ò–Ω–æ–µ: {len([x for x in test_classified_data if x['classification'] == '–ò–Ω–æ–µ'])}")
        
        work_items = result.get('work_items', [])
        print(f"\nüéØ –í project_data.json –ø–æ–ø–∞–ª–æ –ø–æ–∑–∏—Ü–∏–π: {len(work_items)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –ø–æ–∑–∏—Ü–∏–∏ - —Ä–∞–±–æ—Ç—ã
        for i, item in enumerate(work_items):
            original = item.get('original_data', {})
            classification = original.get('classification')
            name = original.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
            print(f"   {i+1}. {name} - {classification}")
            
            if classification != '–†–∞–±–æ—Ç–∞':
                print(f"‚ùå –û–®–ò–ë–ö–ê: –ø–æ–∑–∏—Ü–∏—è {i+1} –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Ä–∞–±–æ—Ç–æ–π!")
                return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç–∞-–¥–∞–Ω–Ω—ã–µ
        meta = result.get('meta', {})
        total_work_items = meta.get('total_work_items', 0)
        
        print(f"\nüìã –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:")
        print(f"   total_work_items: {total_work_items}")
        print(f"   timeline_blocks: {meta.get('total_timeline_blocks', 0)}")
        
        if total_work_items == 2:  # –û–∂–∏–¥–∞–µ–º 2 —Ä–∞–±–æ—Ç—ã
            print("‚úÖ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ!")
            return True
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: –æ–∂–∏–¥–∞–ª–∏ 2 —Ä–∞–±–æ—Ç—ã, –ø–æ–ª—É—á–∏–ª–∏ {total_work_items}")
            return False
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        return False
        
    finally:
        # –ß–∏—Å—Ç–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        try:
            os.unlink(classified_file)
            os.unlink(directives_file)
        except:
            pass

if __name__ == "__main__":
    success = test_preparer_filtering()
    if success:
        print("\nüéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã!")
    else:
        print("\nüí• –ï—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π!")
        sys.exit(1)

================================================================================

## –§–ê–ô–õ: tests/test_preparer_orchestrator.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —á—Ç–æ preparer.py –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä
–ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã–∑–æ–≤—ã classifier.py –∏ timeline_blocks.py
"""

import json
import tempfile
import os
import sys
sys.path.append('/home/imort/Herzog_v3')

from src.data_processing.preparer import prepare_project_data

def test_preparer_orchestrator():
    """–¢–µ—Å—Ç —á—Ç–æ preparer –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤—ã–∑—ã–≤–∞–µ—Ç –¥—Ä—É–≥–∏–µ –º–æ–¥—É–ª–∏"""
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ raw_estimates.json (–∫–∞–∫ –ø–æ—Å–ª–µ extractor)
    test_raw_estimates = [
        {
            'internal_id': 'work-1',
            'source_file': 'test.xlsx',
            'position_num': '1',
            'code': '–ì–≠–°–ù46-02-009-02',
            'name': '–û—Ç–±–∏–≤–∫–∞ —à—Ç—É–∫–∞—Ç—É—Ä–∫–∏',
            'unit': '100 –º2',
            'quantity': '7.77'
        },
        {
            'internal_id': 'material-1',
            'source_file': 'test.xlsx',
            'position_num': '2',
            'code': '–§–°–ë–¶-14.4.01.02-0012',
            'name': '–°–º–µ—Å—å —Å—É—Ö–∞—è —à—Ç—É–∫–∞—Ç—É—Ä–Ω–∞—è',
            'unit': '–∫–≥',
            'quantity': '1000'
        },
        {
            'internal_id': 'work-2',
            'source_file': 'test.xlsx', 
            'position_num': '3',
            'code': '–ì–≠–°–ù46-01-001-01',
            'name': '–î–µ–º–æ–Ω—Ç–∞–∂ –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫',
            'unit': '100 –º2',
            'quantity': '5.5'
        }
    ]
    
    test_directives = {
        'target_work_count': 10,
        'project_timeline': {
            'start_date': '01.02.2024',
            'end_date': '29.02.2024'  # –û–¥–∏–Ω –º–µ—Å—è—Ü = 4 –Ω–µ–¥–µ–ª–∏
        },
        'workforce_range': {'min': 5, 'max': 15},
        'directives': {
            'conceptualizer': '–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –ª–æ–≥–∏—á–Ω–æ',
            'strategist': '–ü–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ'
        }
    }
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f1:
        json.dump(test_raw_estimates, f1, ensure_ascii=False, indent=2)
        raw_estimates_file = f1.name
    
    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f2:
        json.dump(test_directives, f2, ensure_ascii=False, indent=2)
        directives_file = f2.name
    
    try:
        print("üé≠ –¢–µ—Å—Ç–∏—Ä—É—é preparer –∫–∞–∫ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä...")
        print(f"üìÑ Raw estimates: {len(test_raw_estimates)} –ø–æ–∑–∏—Ü–∏–π")
        print(f"üìÖ –î–∏–∞–ø–∞–∑–æ–Ω: 01.02.2024 - 29.02.2024")
        
        # –í—ã–∑—ã–≤–∞–µ–º –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä
        result = prepare_project_data(raw_estimates_file, directives_file)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏:")
        print(f"   Work items: {len(result.get('work_items', []))}")
        print(f"   Timeline blocks: {len(result.get('timeline_blocks', []))}")
        print(f"   Meta total_work_items: {result.get('meta', {}).get('total_work_items', 0)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ classifier —Å—Ä–∞–±–æ—Ç–∞–ª –ø—Ä–∞–≤–∏–ª—å–Ω–æ
        work_items = result.get('work_items', [])
        for i, item in enumerate(work_items):
            original = item.get('original_data', {})
            classification = original.get('classification')
            name = original.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
            print(f"   {i+1}. {name} - {classification}")
            
            if classification != '–†–∞–±–æ—Ç–∞':
                print(f"‚ùå –û–®–ò–ë–ö–ê: classifier –Ω–µ –æ—Ç—Ä–∞–±–æ—Ç–∞–ª - –ø–æ–∑–∏—Ü–∏—è –Ω–µ —Ä–∞–±–æ—Ç–∞!")
                return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ timeline_blocks —Å—Ä–∞–±–æ—Ç–∞–ª –ø—Ä–∞–≤–∏–ª—å–Ω–æ
        timeline_blocks = result.get('timeline_blocks', [])
        if len(timeline_blocks) != 4:  # –§–µ–≤—Ä–∞–ª—å 2024 = 4 –Ω–µ–¥–µ–ª–∏
            print(f"‚ùå –û–®–ò–ë–ö–ê: timeline_blocks –≤–µ—Ä–Ω—É–ª {len(timeline_blocks)} –Ω–µ–¥–µ–ª—å, –æ–∂–∏–¥–∞–ª–∏ 4")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É project_data
        required_keys = ['meta', 'directives', 'timeline_blocks', 'work_items', 'processing_status', 'groups_data']
        for key in required_keys:
            if key not in result:
                print(f"‚ùå –û–®–ò–ë–ö–ê: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á {key} –≤ project_data")
                return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–∞–±–æ—Ç –∏–º–µ–Ω–Ω–æ 2 (–æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã –º–∞—Ç–µ—Ä–∏–∞–ª—ã)
        expected_works = 2
        actual_works = len(work_items)
        
        if actual_works == expected_works:
            print(f"‚úÖ –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ!")
            print(f"   - –í—ã–∑–≤–∞–ª classifier.py ‚úì")
            print(f"   - –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–ª —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—Ç—ã ({actual_works} –∏–∑ {len(test_raw_estimates)}) ‚úì")
            print(f"   - –í—ã–∑–≤–∞–ª timeline_blocks.py ({len(timeline_blocks)} –Ω–µ–¥–µ–ª—å) ‚úì")
            print(f"   - –°–æ–±—Ä–∞–ª project_data.json —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π ‚úì")
            return True
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —Ä–∞–±–æ—Ç: –æ–∂–∏–¥–∞–ª–∏ {expected_works}, –ø–æ–ª—É—á–∏–ª–∏ {actual_works}")
            return False
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞: {e}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        # –ß–∏—Å—Ç–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        try:
            os.unlink(raw_estimates_file)
            os.unlink(directives_file)
        except:
            pass

if __name__ == "__main__":
    success = test_preparer_orchestrator()
    if success:
        print("\nüéâ PREPARER-–û–†–ö–ï–°–¢–†–ê–¢–û–† —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ!")
    else:
        print("\nüí• –ï—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º!")
        sys.exit(1)

================================================================================

## –§–ê–ô–õ: tests/test_real_data_pipeline.py
------------------------------------------------------------
"""
–¢–µ—Å—Ç —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –ø–∞–π–ø–ª–∞–π–Ω —Å fallback –º–µ—Ç–æ–¥–∞–º–∏ (–±–µ–∑ LLM)
"""

import asyncio
import json
import os
import shutil
import logging

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def test_real_pipeline():
    """
    –ü—Ä–æ–≥–æ–Ω—è–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω
    """
    # –ü—É—Ç—å –∫ —Ä–µ–∞–ª—å–Ω—ã–º –¥–∞–Ω–Ω—ã–º
    base_path = "/home/imort/Herzog_v3/projects/test/test"
    input_path = f"{base_path}/3_prepared"
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–æ–≤
    paths = {
        4: f"{base_path}/4_conceptualized",
        5: f"{base_path}/5_scheduled", 
        6: f"{base_path}/6_accounted",
        7: f"{base_path}/7_staffed",
        8: f"{base_path}/8_output"
    }
    
    for path in paths.values():
        os.makedirs(path, exist_ok=True)
    
    # –ß–∏—Ç–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    with open(f"{input_path}/project_data.json", 'r', encoding='utf-8') as f:
        initial_data = json.load(f)
    
    logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Ç–µ—Å—Ç —Å {initial_data['meta']['total_work_items']} —Ä–∞–±–æ—Ç–∞–º–∏")
    logger.info(f"üìÖ –ü—Ä–æ–µ–∫—Ç –Ω–∞ {initial_data['meta']['total_timeline_blocks']} –Ω–µ–¥–µ–ª—å")
    
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∞–≥–µ–Ω—Ç–æ–≤
    import sys
    sys.path.append('/home/imort/Herzog_v3')
    
    try:
        # –ê–≥–µ–Ω—Ç 1: –ö–æ–Ω—Ü–µ–ø—Ç—É–∞–ª–∏–∑–∞—Ç–æ—Ä (—Å fallback)
        logger.info("üéØ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ê–≥–µ–Ω—Ç 1: –ö–æ–Ω—Ü–µ–ø—Ç—É–∞–ª–∏–∑–∞—Ç–æ—Ä")
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å—Ç—É—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É
        data_step_1 = initial_data.copy()
        work_items = data_step_1['work_items']
        
        # –ü—Ä–æ—Å—Ç–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (fallback –º–µ—Ç–æ–¥)
        group_keywords = {
            'group_1': {
                'name': '–î–µ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã',
                'keywords': ['–¥–µ–º–æ–Ω—Ç–∞–∂', '—Å–Ω–æ—Å', '—Ä–∞–∑–±–æ—Ä–∫–∞', '–æ—Ç–±–∏–≤–∫–∞', '–æ—á–∏—Å—Ç–∫–∞']
            },
            'group_2': {
                'name': '–ó–µ–º–ª—è–Ω—ã–µ —Ä–∞–±–æ—Ç—ã', 
                'keywords': ['–∑–µ–º–ª—è', '–≥—Ä—É–Ω—Ç', '–∫–æ–ø–∫–∞', '—Ä—ã—Ç—å–µ', '—Ç—Ä–∞–Ω—à–µ—è', '–∫–æ—Ç–ª–æ–≤–∞–Ω']
            },
            'group_3': {
                'name': '–§—É–Ω–¥–∞–º–µ–Ω—Ç–Ω—ã–µ —Ä–∞–±–æ—Ç—ã',
                'keywords': ['—Ñ—É–Ω–¥–∞–º–µ–Ω—Ç', '–æ—Å–Ω–æ–≤–∞–Ω–∏–µ', '–±–µ—Ç–æ–Ω', '–∞—Ä–º–∞—Ç—É—Ä–∞', '–∫–∞—Ä–∫–∞—Å']
            },
            'group_4': {
                'name': '–ö–ª–∞–¥–æ—á–Ω—ã–µ —Ä–∞–±–æ—Ç—ã',
                'keywords': ['–∫–ª–∞–¥–∫–∞', '–∫–∏—Ä–ø–∏—á', '–±–ª–æ–∫', '—Å—Ç–µ–Ω–∞', '–ø–µ—Ä–µ–≥–æ—Ä–æ–¥–∫–∞']
            },
            'group_5': {
                'name': '–ö—Ä–æ–≤–µ–ª—å–Ω—ã–µ —Ä–∞–±–æ—Ç—ã',
                'keywords': ['–∫—Ä–æ–≤–ª—è', '–∫—Ä—ã—à–∞', '–ø–æ–∫—Ä—ã—Ç–∏–µ', '—á–µ—Ä–µ–ø–∏—Ü–∞', '–ø—Ä–æ—Ñ–ª–∏—Å—Ç']
            },
            'group_6': {
                'name': '–û—Ç–¥–µ–ª–æ—á–Ω—ã–µ —Ä–∞–±–æ—Ç—ã',
                'keywords': ['—à—Ç—É–∫–∞—Ç—É—Ä–∫–∞', '–ø–æ–∫—Ä–∞—Å–∫–∞', '–æ–±–ª–∏—Ü–æ–≤–∫–∞', '–ø–ª–∏—Ç–∫–∞', '–æ–±–æ–∏', '—à–ø–∞—Ç–ª–µ–≤–∫–∞']
            },
            'group_7': {
                'name': '–≠–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã',
                'keywords': ['—ç–ª–µ–∫—Ç—Ä', '–ø—Ä–æ–≤–æ–¥', '–∫–∞–±–µ–ª—å', '—Ä–æ–∑–µ—Ç–∫–∞', '–≤—ã–∫–ª—é—á–∞—Ç–µ–ª—å', '—â–∏—Ç']
            },
            'group_8': {
                'name': '–°–∞–Ω—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ä–∞–±–æ—Ç—ã', 
                'keywords': ['—Å–∞–Ω—Ç–µ—Ö–Ω–∏–∫', '—Ç—Ä—É–±–∞', '–≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥', '–∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏—è', '–æ—Ç–æ–ø–ª–µ–Ω–∏–µ']
            }
        }
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É
        groups_data = {}
        for item in work_items:
            work_name = item.get('original_data', {}).get('name', '').lower()
            
            # –ò—â–µ–º –ø–æ–¥—Ö–æ–¥—è—â—É—é –≥—Ä—É–ø–ø—É
            assigned = False
            for group_id, group_info in group_keywords.items():
                if any(keyword in work_name for keyword in group_info['keywords']):
                    item['group_id'] = group_id
                    item['group_name'] = group_info['name']
                    assigned = True
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ groups_data
                    if group_id not in groups_data:
                        groups_data[group_id] = {
                            'group_name': group_info['name'],
                            'work_ids': [],
                            'schedule_phases': [],
                            'total_quantity': 0,
                            'common_unit': '',
                            'worker_counts': []
                        }
                    groups_data[group_id]['work_ids'].append(item['id'])
                    break
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≥—Ä—É–ø–ø—É - –æ–±—â–∏–µ —Ä–∞–±–æ—Ç—ã
            if not assigned:
                item['group_id'] = 'group_other'
                item['group_name'] = '–ü—Ä–æ—á–∏–µ —Ä–∞–±–æ—Ç—ã'
                if 'group_other' not in groups_data:
                    groups_data['group_other'] = {
                        'group_name': '–ü—Ä–æ—á–∏–µ —Ä–∞–±–æ—Ç—ã',
                        'work_ids': [],
                        'schedule_phases': [],
                        'total_quantity': 0,
                        'common_unit': '',
                        'worker_counts': []
                    }
                groups_data['group_other']['work_ids'].append(item['id'])
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        data_step_1['groups_data'] = groups_data
        data_step_1['processing_status']['conceptualization'] = 'completed'
        data_step_1['processing_status']['scheduling'] = 'pending'
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ê–≥–µ–Ω—Ç–∞ 1
        with open(f"{paths[4]}/project_data.json", 'w', encoding='utf-8') as f:
            json.dump(data_step_1, f, ensure_ascii=False, indent=2)
        
        # –ò–º–∏—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        with open(f"{paths[4]}/llm_input.json", 'w', encoding='utf-8') as f:
            json.dump({"status": "fallback_grouping", "groups_created": len(groups_data)}, f)
        
        with open(f"{paths[4]}/llm_response.json", 'w', encoding='utf-8') as f:
            json.dump({"status": "fallback_completed", "method": "keyword_matching"}, f)
        
        logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç 1: –°–æ–∑–¥–∞–Ω–æ {len(groups_data)} –≥—Ä—É–ø–ø")
        for gid, gdata in groups_data.items():
            logger.info(f"   {gid}: {gdata['group_name']} ({len(gdata['work_ids'])} —Ä–∞–±–æ—Ç)")
        
        # –ê–≥–µ–Ω—Ç 2: –°—Ç—Ä–∞—Ç–µ–≥ (–ø—Ä–æ—Å—Ç–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ)
        logger.info("üìã –¢–µ—Å—Ç–∏—Ä—É–µ–º –ê–≥–µ–Ω—Ç 2: –°—Ç—Ä–∞—Ç–µ–≥")
        
        data_step_2 = data_step_1.copy()
        timeline_blocks = data_step_2['timeline_blocks']
        groups_data = data_step_2['groups_data']
        
        # –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –Ω–µ–¥–µ–ª—è–º
        week_assignments = {
            'group_1': [1, 2],              # –î–µ–º–æ–Ω—Ç–∞–∂ - –ø–µ—Ä–≤—ã–µ –Ω–µ–¥–µ–ª–∏
            'group_2': [3, 4, 5],           # –ó–µ–º–ª—è–Ω—ã–µ - –ø–æ—Å–ª–µ –¥–µ–º–æ–Ω—Ç–∞–∂–∞
            'group_3': [6, 7, 8, 9],        # –§—É–Ω–¥–∞–º–µ–Ω—Ç - –ø–æ—Å–ª–µ –∑–µ–º–ª—è–Ω—ã—Ö
            'group_4': [10, 11, 12, 13],    # –ö–ª–∞–¥–æ—á–Ω—ã–µ - –ø–æ—Å–ª–µ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞
            'group_5': [14, 15, 16],        # –ö—Ä–æ–≤–µ–ª—å–Ω—ã–µ - –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å –∫–ª–∞–¥–æ—á–Ω—ã–º–∏
            'group_7': [17, 18, 19, 20],    # –≠–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂ - –ø–æ—Å–ª–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ä–∞–±–æ—Ç
            'group_8': [21, 22, 23, 24],    # –°–∞–Ω—Ç–µ—Ö–Ω–∏–∫–∞ - –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å —ç–ª–µ–∫—Ç—Ä–∏–∫–æ–π
            'group_6': [25, 26, 27, 28],    # –û—Ç–¥–µ–ª–∫–∞ - –≤ –∫–æ–Ω—Ü–µ
            'group_other': [29, 30]         # –ü—Ä–æ—á–∏–µ - –≤ –∫–æ–Ω—Ü–µ
        }
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∫ –≥—Ä—É–ø–ø–∞–º
        for group_id, group_data in groups_data.items():
            if group_id in week_assignments:
                weeks = week_assignments[group_id]
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ–¥–µ–ª–∏ –Ω–µ –≤—ã—Ö–æ–¥—è—Ç –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã –ø—Ä–æ–µ–∫—Ç–∞
                max_week = len(timeline_blocks)
                valid_weeks = [w for w in weeks if w <= max_week]
                group_data['schedule_phases'] = valid_weeks
            else:
                # –î–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –≥—Ä—É–ø–ø - –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–µ–¥–µ–ª–∏
                group_data['schedule_phases'] = [max(1, len(timeline_blocks) - 2), len(timeline_blocks) - 1]
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        data_step_2['processing_status']['scheduling'] = 'completed'
        data_step_2['processing_status']['accounting'] = 'pending'
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ê–≥–µ–Ω—Ç–∞ 2
        with open(f"{paths[5]}/project_data.json", 'w', encoding='utf-8') as f:
            json.dump(data_step_2, f, ensure_ascii=False, indent=2)
        
        with open(f"{paths[5]}/llm_input.json", 'w', encoding='utf-8') as f:
            json.dump({"status": "fallback_scheduling"}, f)
        
        with open(f"{paths[5]}/llm_response.json", 'w', encoding='utf-8') as f:
            json.dump({"status": "fallback_completed"}, f)
        
        scheduled_groups = sum(1 for g in groups_data.values() if g['schedule_phases'])
        logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç 2: –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ {scheduled_groups} –≥—Ä—É–ø–ø")
        for gid, gdata in groups_data.items():
            if gdata['schedule_phases']:
                logger.info(f"   {gid}: –Ω–µ–¥–µ–ª–∏ {gdata['schedule_phases']}")
        
        # –ê–≥–µ–Ω—Ç 3: –ë—É—Ö–≥–∞–ª—Ç–µ—Ä (–ø–æ–¥—Å—á–µ—Ç –æ–±—ä–µ–º–æ–≤ –ø–æ –≥—Ä—É–ø–ø–∞–º)
        logger.info("üí∞ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ê–≥–µ–Ω—Ç 3: –ë—É—Ö–≥–∞–ª—Ç–µ—Ä")
        
        data_step_3 = data_step_2.copy()
        work_items = data_step_3['work_items']
        groups_data = data_step_3['groups_data']
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ä–∞–±–æ—Ç—ã –∏ —Å—á–∏—Ç–∞–µ–º –æ–±—ä–µ–º—ã
        for group_id, group_data in groups_data.items():
            work_ids = group_data['work_ids']
            
            # –ù–∞—Ö–æ–¥–∏–º —Ä–∞–±–æ—Ç—ã —ç—Ç–æ–π –≥—Ä—É–ø–ø—ã
            group_works = [item for item in work_items if item['id'] in work_ids]
            
            # –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—É—é –µ–¥–∏–Ω–∏—Ü—É –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤ –≥—Ä—É–ø–ø–µ
            units = [item.get('original_data', {}).get('unit', '—à—Ç') for item in group_works]
            if units:
                common_unit = max(set(units), key=units.count)
            else:
                common_unit = '—à—Ç'
            
            # –°—É–º–º–∏—Ä—É–µ–º –æ–±—ä–µ–º—ã
            total_qty = 0
            for item in group_works:
                qty_str = str(item.get('original_data', {}).get('quantity', '0'))
                try:
                    qty = float(qty_str.replace(',', '.'))
                    total_qty += qty
                except:
                    total_qty += 1
            
            # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –≥—Ä—É–ø–ø–µ –æ–±—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            group_data['total_quantity'] = total_qty
            group_data['common_unit'] = common_unit
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        data_step_3['processing_status']['accounting'] = 'completed'
        data_step_3['processing_status']['staffing'] = 'pending'
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ê–≥–µ–Ω—Ç–∞ 3
        with open(f"{paths[6]}/project_data.json", 'w', encoding='utf-8') as f:
            json.dump(data_step_3, f, ensure_ascii=False, indent=2)
        
        with open(f"{paths[6]}/llm_input.json", 'w', encoding='utf-8') as f:
            json.dump({"status": "fallback_accounting"}, f)
        
        with open(f"{paths[6]}/llm_response.json", 'w', encoding='utf-8') as f:
            json.dump({"status": "fallback_completed"}, f)
        
        logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç 3: –ü–æ–¥—Å—á–∏—Ç–∞–Ω–æ –æ–±—ä–µ–º–æ–≤ –¥–ª—è {len(groups_data)} –≥—Ä—É–ø–ø")
        for gid, gdata in groups_data.items():
            logger.info(f"   {gid}: {gdata['total_quantity']} {gdata['common_unit']}")
        
        # –ê–≥–µ–Ω—Ç 4: –ü—Ä–æ—Ä–∞–± (—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–±–æ—á–∏—Ö)
        logger.info("‚ö° –¢–µ—Å—Ç–∏—Ä—É–µ–º –ê–≥–µ–Ω—Ç 4: –ü—Ä–æ—Ä–∞–±")
        
        data_step_4 = data_step_3.copy()
        groups_data = data_step_4['groups_data']
        workforce_range = data_step_4['directives']['workforce_range']
        
        # –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–±–æ—á–∏—Ö –ø–æ –≥—Ä—É–ø–ø–∞–º
        for group_id, group_data in groups_data.items():
            schedule_phases = group_data.get('schedule_phases', [])
            if schedule_phases:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—á–∏—Ö –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –≥—Ä—É–ø–ø—ã
                if 'group_1' in group_id:  # –î–µ–º–æ–Ω—Ç–∞–∂
                    base_workers = 3
                elif 'group_2' in group_id:  # –ó–µ–º–ª—è–Ω—ã–µ
                    base_workers = 5
                elif 'group_3' in group_id:  # –§—É–Ω–¥–∞–º–µ–Ω—Ç
                    base_workers = 6
                elif 'group_4' in group_id:  # –ö–ª–∞–¥–æ—á–Ω—ã–µ
                    base_workers = 4
                elif 'group_6' in group_id:  # –û—Ç–¥–µ–ª–∫–∞
                    base_workers = 5
                else:  # –ü—Ä–æ—á–∏–µ
                    base_workers = (workforce_range['min'] + workforce_range['max']) // 2
                
                # –°–æ–∑–¥–∞–µ–º –º–∞—Å—Å–∏–≤ —Ä–∞–±–æ—á–∏—Ö –¥–ª—è –∫–∞–∂–¥–æ–π –Ω–µ–¥–µ–ª–∏
                workers_per_week = [base_workers] * len(schedule_phases)
                group_data['worker_counts'] = workers_per_week
            else:
                group_data['worker_counts'] = []
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        data_step_4['processing_status']['staffing'] = 'completed' 
        data_step_4['processing_status']['reporting'] = 'pending'
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ê–≥–µ–Ω—Ç–∞ 4
        with open(f"{paths[7]}/project_data.json", 'w', encoding='utf-8') as f:
            json.dump(data_step_4, f, ensure_ascii=False, indent=2)
        
        with open(f"{paths[7]}/llm_input.json", 'w', encoding='utf-8') as f:
            json.dump({"status": "fallback_staffing"}, f)
        
        with open(f"{paths[7]}/llm_response.json", 'w', encoding='utf-8') as f:
            json.dump({"status": "fallback_completed"}, f)
        
        staffed_groups = sum(1 for g in groups_data.values() if g['worker_counts'])
        logger.info(f"‚úÖ –ê–≥–µ–Ω—Ç 4: –£–∫–æ–º–ø–ª–µ–∫—Ç–æ–≤–∞–Ω–æ {staffed_groups} –≥—Ä—É–ø–ø")
        for gid, gdata in groups_data.items():
            if gdata['worker_counts']:
                logger.info(f"   {gid}: —Ä–∞–±–æ—á–∏–µ {gdata['worker_counts']}")
        
        # –®–∞–≥ 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Excel –æ—Ç—á–µ—Ç–∞
        logger.info("üìä –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π Excel –æ—Ç—á–µ—Ç")
        
        from src.data_processing.reporter import generate_excel_report
        
        final_input = f"{paths[7]}/project_data.json"
        excel_file = generate_excel_report(final_input, paths[8])
        
        logger.info(f"‚úÖ Excel –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {excel_file}")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        logger.info("üéâ –¢–ï–°–¢ –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
        logger.info(f"üìà –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        logger.info(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ä–∞–±–æ—Ç: {len(work_items)}")
        logger.info(f"   –°–æ–∑–¥–∞–Ω–æ –≥—Ä—É–ø–ø: {len(groups_data)}")
        logger.info(f"   –ù–µ–¥–µ–ª—å –≤ –ø—Ä–æ–µ–∫—Ç–µ: {len(timeline_blocks)}")
        logger.info(f"   –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {base_path}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–µ: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    result = asyncio.run(test_real_pipeline())
    if result:
        print("\nüéØ –¢–µ—Å—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print("üìÅ –ü—Ä–æ–≤–µ—Ä—å –ø–∞–ø–∫–∏ 4_conceptualized, 5_scheduled, 6_accounted, 7_staffed, 8_output")
        print("üìä –ü–æ—Å–º–æ—Ç—Ä–∏ –∫–∞–∫ –∏–∑–º–µ–Ω—è–ª—Å—è project_data.json –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ")
    else:
        print("\n‚ùå –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–∞–º–∏")
        exit(1)

================================================================================

## –§–ê–ô–õ: tests/test_reporter_v4.py
------------------------------------------------------------
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ reporter_v4.py
—Å —É–ª—É—á—à–µ–Ω–Ω—ã–º UI/UX –∏ scheduling_reasoning –¥–∞–Ω–Ω—ã–º–∏
"""

import os
import sys
import logging

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—é
sys.path.append('/home/imort/Herzog_v3/src/data_processing')

from reporter_v4 import generate_professional_excel_report

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

def test_professional_reporter():
    """
    –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ reporter_v4
    """
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–û–ì–û REPORTER V4")
    print("=" * 60)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –ø—É—Ç–∏
    test_cases = [
        "/home/imort/Herzog_v3/projects/test/b4338a45/true.json",  # –° scheduling_reasoning
        "/home/imort/Herzog_v3/projects/test/d3f0a7a1/true.json",  # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π
        "/home/imort/Herzog_v3/projects/test/9d778a7f/true.json"   # –†–µ–∑–µ—Ä–≤–Ω—ã–π
    ]
    
    output_dir = "/tmp"
    
    for i, test_input in enumerate(test_cases, 1):
        print(f"\nüìä –¢–ï–°–¢ {i}: {os.path.basename(os.path.dirname(test_input))}")
        print("-" * 40)
        
        if not os.path.exists(test_input):
            print(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {test_input}")
            continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ scheduler –¥–∞–Ω–Ω—ã—Ö
        scheduler_path = os.path.join(os.path.dirname(test_input), '7_scheduler_and_staffer', 'llm_response.json')
        has_scheduler_data = os.path.exists(scheduler_path)
        print(f"üìÖ –î–∞–Ω–Ω—ã–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {'‚úÖ –ù–∞–π–¥–µ–Ω—ã' if has_scheduler_data else '‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç'}")
        
        if has_scheduler_data:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É scheduler –¥–∞–Ω–Ω—ã—Ö
            try:
                import json
                with open(scheduler_path, 'r', encoding='utf-8') as f:
                    scheduler_data = json.load(f)
                    
                success = scheduler_data.get('success', False)
                packages = scheduler_data.get('response', {}).get('scheduled_packages', [])
                
                print(f"üìä –°—Ç–∞—Ç—É—Å –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {'‚úÖ –£—Å–ø–µ—à–Ω–æ' if success else '‚ùå –û—à–∏–±–∫–∞'}")
                print(f"üì¶ –ü–∞–∫–µ—Ç–æ–≤ —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è–º–∏: {len(packages)}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ reasoning
                reasoning_count = 0
                for pkg in packages:
                    if pkg.get('scheduling_reasoning'):
                        reasoning_count += 1
                
                print(f"üß† –ü–∞–∫–µ—Ç–æ–≤ —Å reasoning: {reasoning_count}")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç—á–µ—Ç–∞
        try:
            print(f"üöÄ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞...")
            result_file = generate_professional_excel_report(test_input, output_dir)
            
            if os.path.exists(result_file):
                file_size = os.path.getsize(result_file) // 1024  # KB
                print(f"‚úÖ –£–°–ü–ï–•! –û—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {result_file}")
                print(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} KB")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª–∞
                try:
                    from openpyxl import load_workbook
                    wb = load_workbook(result_file)
                    sheet_names = wb.sheetnames
                    
                    print(f"üìã –õ–∏—Å—Ç—ã –≤ —Ñ–∞–π–ª–µ ({len(sheet_names)}):")
                    for sheet in sheet_names:
                        ws = wb[sheet]
                        rows = ws.max_row
                        cols = ws.max_column
                        print(f"  ‚Ä¢ {sheet}: {rows} —Å—Ç—Ä–æ–∫, {cols} –∫–æ–ª–æ–Ω–æ–∫")
                        
                        # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –ª–∏—Å—Ç–∞ "–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è"
                        if "–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ" in sheet and has_scheduler_data:
                            print(f"    üéØ –ù–æ–≤—ã–π –ª–∏—Å—Ç —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è–º–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω!")
                    
                    wb.close()
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–∞: {e}")
                
                print(f"üéâ –¢–ï–°–¢ {i} –ü–†–û–ô–î–ï–ù!")
                
            else:
                print(f"‚ùå –¢–ï–°–¢ {i} –ü–†–û–í–ê–õ–ï–ù: –§–∞–π–ª –Ω–µ —Å–æ–∑–¥–∞–Ω")
                
        except Exception as e:
            print(f"‚ùå –¢–ï–°–¢ {i} –ü–†–û–í–ê–õ–ï–ù: {e}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "=" * 60)
    print("üìä –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")

def analyze_test_data():
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    """
    print("\nüîç –ê–ù–ê–õ–ò–ó –î–û–°–¢–£–ü–ù–´–• –¢–ï–°–¢–û–í–´–• –î–ê–ù–ù–´–•")
    print("=" * 60)
    
    projects_dir = "/home/imort/Herzog_v3/projects"
    
    if not os.path.exists(projects_dir):
        print("‚ùå –ü–∞–ø–∫–∞ projects –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return
    
    # –ù–∞–π–¥–µ–º –≤—Å–µ true.json —Ñ–∞–π–ª—ã
    true_json_files = []
    for root, dirs, files in os.walk(projects_dir):
        if 'true.json' in files:
            true_json_files.append(os.path.join(root, 'true.json'))
    
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ true.json: {len(true_json_files)}")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
    for i, filepath in enumerate(true_json_files[:5], 1):  # –û–≥—Ä–∞–Ω–∏—á–∏–º –¥–æ 5 –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏
        project_id = os.path.basename(os.path.dirname(filepath))
        print(f"\nüìÅ –ü–†–û–ï–ö–¢ {i}: {project_id}")
        print("-" * 30)
        
        try:
            import json
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            meta = data.get('meta', {})
            results = data.get('results', {})
            work_packages = results.get('work_packages', [])
            timeline_blocks = data.get('timeline_blocks', [])
            
            print(f"üìä –ü–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç: {len(work_packages)}")
            print(f"‚è∞ –í—Ä–µ–º–µ–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤: {len(timeline_blocks)}")
            print(f"üìÖ –í–µ—Ä—Å–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: {meta.get('structure_version', '1.0')}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º scheduler –¥–∞–Ω–Ω—ã–µ
            scheduler_path = os.path.join(os.path.dirname(filepath), '7_scheduler_and_staffer', 'llm_response.json')
            if os.path.exists(scheduler_path):
                with open(scheduler_path, 'r', encoding='utf-8') as f:
                    scheduler_data = json.load(f)
                
                success = scheduler_data.get('success', False)
                scheduled_packages = scheduler_data.get('response', {}).get('scheduled_packages', [])
                
                reasoning_count = sum(1 for pkg in scheduled_packages if pkg.get('scheduling_reasoning'))
                
                print(f"üß† –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: {'‚úÖ –î–∞' if success else '‚ùå –ù–µ—Ç'}")
                print(f"üí≠ –° –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è–º–∏: {reasoning_count}/{len(scheduled_packages)} –ø–∞–∫–µ—Ç–æ–≤")
                
                if reasoning_count > 0:
                    print(f"üéØ –ü–û–î–•–û–î–ò–¢ –î–õ–Ø –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø!")
            else:
                print("üß† –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: ‚ùå –î–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")

if __name__ == "__main__":
    print("üöÄ –ó–ê–ü–£–°–ö –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø REPORTER V4")
    print("–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π Excel –æ—Ç—á–µ—Ç —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º UI/UX")
    print("–í–∫–ª—é—á–∞–µ—Ç scheduling_reasoning –¥–∞–Ω–Ω—ã–µ –∏–∑ AI-–∞–≥–µ–Ω—Ç–∞")
    
    # –°–Ω–∞—á–∞–ª–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    analyze_test_data()
    
    # –ó–∞—Ç–µ–º –∑–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    test_professional_reporter()
    
    print("\n‚ú® –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ /tmp")

================================================================================

## –§–ê–ô–õ: tests/test_scheduler_and_staffer.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∞–≥–µ–Ω—Ç–∞ scheduler_and_staffer.py
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª–∞
"""

import json
import os
import sys
import asyncio
import tempfile
import shutil
from datetime import datetime, timedelta

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.ai_agents.scheduler_and_staffer import SchedulerAndStaffer
from tests.mock_gemini_client import mock_gemini_client

# –ü–æ–¥–º–µ–Ω—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–π gemini_client –Ω–∞ –º–æ–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
import src.ai_agents.scheduler_and_staffer
src.ai_agents.scheduler_and_staffer.gemini_client = mock_gemini_client

class TestSchedulerAndStaffer:
    
    def __init__(self):
        self.test_project_path = None
    
    def setup_test_project(self):
        """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç —Å mock –¥–∞–Ω–Ω—ã–º–∏"""
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        self.test_project_path = tempfile.mkdtemp(prefix='test_herzog_')
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏ (4 –Ω–µ–¥–µ–ª–∏)
        start_date = datetime(2024, 1, 1)
        timeline_blocks = []
        
        for week in range(1, 5):
            week_start = start_date + timedelta(weeks=week-1)
            week_end = week_start + timedelta(days=6)
            
            timeline_blocks.append({
                "week_id": week,
                "start_date": week_start.strftime("%Y-%m-%d"),
                "end_date": week_end.strftime("%Y-%m-%d")
            })
        
        # –°–æ–∑–¥–∞–µ–º mock true.json —Å –ø–æ–ª–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        mock_truth_data = {
            "metadata": {
                "project_id": "test_project",
                "project_name": "–¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç",
                "pipeline_status": [
                    {"agent_name": "work_packager", "status": "completed"},
                    {"agent_name": "works_to_packages", "status": "completed"},
                    {"agent_name": "counter", "status": "completed"},
                    {"agent_name": "scheduler_and_staffer", "status": "pending"}
                ]
            },
            "project_inputs": {
                "target_work_package_count": 4,
                "workforce_range": {
                    "min": 5,
                    "max": 15
                },
                "agent_directives": {
                    "strategist": "—Ä–∞—Å—Ç—è–Ω–∏ –¥–µ–º–æ–Ω—Ç–∞–∂ –Ω–∞ –ø–µ—Ä–≤—ã–µ –¥–≤–µ –Ω–µ–¥–µ–ª–∏",
                    "foreman": "–Ω–∞ —ç–ª–µ–∫—Ç—Ä–∏–∫—É –≤—ã–¥–µ–ª–∏ –º–∞–∫—Å–∏–º—É–º 4 —á–µ–ª–æ–≤–µ–∫–∞"
                }
            },
            "timeline_blocks": timeline_blocks,
            "source_work_items": [
                {
                    "id": "work_001",
                    "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫ –∫–∏—Ä–ø–∏—á–Ω—ã—Ö",
                    "code": "08.01.001",
                    "package_id": "pkg_001"
                },
                {
                    "id": "work_002",
                    "name": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–∞–±–µ–ª—è –í–í–ì 3—Ö2.5",
                    "code": "19.03.012",
                    "package_id": "pkg_002"
                }
            ],
            "results": {
                "work_packages": [
                    {
                        "package_id": "pkg_001",
                        "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π",
                        "description": "–°–Ω–æ—Å –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫, –¥–µ–º–æ–Ω—Ç–∞–∂ –ø–æ–∫—Ä—ã—Ç–∏–π –ø–æ–ª–∞ –∏ –ø–æ—Ç–æ–ª–∫–∞",
                        "calculations": {
                            "unit": "–º¬≤",
                            "quantity": 120.0,
                            "calculation_logic": "–ü—Ä–∏–º–µ–Ω–µ–Ω–æ –ø—Ä–∞–≤–∏–ª–æ –º–∞–∫—Å–∏–º—É–º–∞",
                            "source_works_count": 2
                        }
                    },
                    {
                        "package_id": "pkg_002",
                        "name": "–≠–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã",
                        "description": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–∞–±–µ–ª–µ–π, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–æ–∑–µ—Ç–æ–∫ –∏ –≤—ã–∫–ª—é—á–∞—Ç–µ–ª–µ–π",
                        "calculations": {
                            "unit": "–º",
                            "quantity": 250.0,
                            "calculation_logic": "–°—É–º–º–∞ –≤—Å–µ—Ö –∫–∞–±–µ–ª—å–Ω—ã—Ö –ª–∏–Ω–∏–π",
                            "source_works_count": 3
                        }
                    }
                ]
            }
        }
        
        truth_path = os.path.join(self.test_project_path, "true.json")
        with open(truth_path, 'w', encoding='utf-8') as f:
            json.dump(mock_truth_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç: {self.test_project_path}")
        return self.test_project_path
    
    async def test_scheduler_full_process(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"""
        
        print("üß™ === –¢–ï–°–¢ SCHEDULER_AND_STAFFER –ü–û–õ–ù–´–ô –ü–†–û–¶–ï–°–° ===")
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç
        project_path = self.setup_test_project()
        
        try:
            # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞
            agent = SchedulerAndStaffer()
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
            print("üîÑ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ scheduler_and_staffer...")
            result = await agent.process(project_path)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if result.get('success'):
                print("‚úÖ –ê–≥–µ–Ω—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                print(f"üìä –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ –ø–∞–∫–µ—Ç–æ–≤: {result.get('packages_scheduled', 0)}")
                print(f"üë• –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∞: {result.get('workforce_valid', False)}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π true.json
                truth_path = os.path.join(project_path, "true.json")
                with open(truth_path, 'r', encoding='utf-8') as f:
                    updated_truth = json.load(f)
                
                work_packages = updated_truth.get('results', {}).get('work_packages', [])
                schedule_info = updated_truth.get('results', {}).get('schedule', {})
                staffing_info = updated_truth.get('results', {}).get('staffing', {})
                
                print(f"üìÖ –ö–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω –ø–æ –ø–∞–∫–µ—Ç–∞–º:")
                for pkg in work_packages:
                    schedule_blocks = pkg.get('schedule_blocks', [])
                    progress_per_block = pkg.get('progress_per_block', {})
                    staffing_per_block = pkg.get('staffing_per_block', {})
                    
                    print(f"  {pkg['package_id']}: {pkg['name']}")
                    print(f"    –ù–µ–¥–µ–ª–∏: {schedule_blocks}")
                    print(f"    –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress_per_block}")
                    print(f"    –ü–µ—Ä—Å–æ–Ω–∞–ª: {staffing_per_block}")
                
                print(f"üìä –°–≤–æ–¥–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
                print(f"  –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤: {schedule_info.get('total_packages', 0)}")
                print(f"  –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ–µ–∫—Ç–∞: {schedule_info.get('project_duration_weeks', 0)} –Ω–µ–¥–µ–ª—å")
                print(f"  –ü–∏–∫–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞: {staffing_info.get('peak_workforce', 0)} —á–µ–ª–æ–≤–µ–∫")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–ø–∫—É –∞–≥–µ–Ω—Ç–∞
                agent_folder = os.path.join(project_path, "7_scheduler_and_staffer")
                if os.path.exists(agent_folder):
                    files = os.listdir(agent_folder)
                    print(f"üìÅ –°–æ–∑–¥–∞–Ω—ã —Ñ–∞–π–ª—ã: {files}")
                
                # –ë–∞–∑–æ–≤—ã–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                assert len(work_packages) == 2, "–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ"
                
                for pkg in work_packages:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∞
                    assert 'schedule_blocks' in pkg, f"–ü–∞–∫–µ—Ç {pkg['package_id']} –Ω–µ –∏–º–µ–µ—Ç –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∞"
                    assert 'progress_per_block' in pkg, f"–ü–∞–∫–µ—Ç {pkg['package_id']} –Ω–µ –∏–º–µ–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"
                    assert 'staffing_per_block' in pkg, f"–ü–∞–∫–µ—Ç {pkg['package_id']} –Ω–µ –∏–º–µ–µ—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–π –ø–µ—Ä—Å–æ–Ω–∞–ª–∞"
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ —Å—É–º–º–µ 100%
                    progress = pkg['progress_per_block']
                    total_progress = sum(int(v) for v in progress.values())
                    assert 90 <= total_progress <= 110, f"–ü—Ä–æ–≥—Ä–µ—Å—Å –ø–∞–∫–µ—Ç–∞ {pkg['package_id']} –Ω–µ —Ä–∞–≤–µ–Ω ~100%: {total_progress}%"
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–ª –Ω–∞ –∫–∞–∂–¥—É—é –Ω–µ–¥–µ–ª—é —Ä–∞–±–æ—Ç
                    staffing = pkg['staffing_per_block']
                    for week in pkg['schedule_blocks']:
                        week_str = str(week)
                        assert week_str in staffing, f"–ü–∞–∫–µ—Ç {pkg['package_id']} –Ω–µ –∏–º–µ–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª–∞ –Ω–∞ –Ω–µ–¥–µ–ª—é {week}"
                        assert staffing[week_str] > 0, f"–ü–∞–∫–µ—Ç {pkg['package_id']} –∏–º–µ–µ—Ç 0 –ø–µ—Ä—Å–æ–Ω–∞–ª–∞ –Ω–∞ –Ω–µ–¥–µ–ª—é {week}"
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                assert 'schedule' in updated_truth['results'], "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å–≤–æ–¥–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–º –ø–ª–∞–Ω–µ"
                assert 'staffing' in updated_truth['results'], "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å–≤–æ–¥–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–µ—Ä—Å–æ–Ω–∞–ª–µ"
                
                print("‚úÖ –í—Å–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–æ–π–¥–µ–Ω—ã")
                return True
                
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∞–≥–µ–Ω—Ç–∞: {result.get('error')}")
                return False
                
        except Exception as e:
            print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –≤ —Ç–µ—Å—Ç–µ: {e}")
            return False
        
        finally:
            # –û—á–∏—â–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            if self.test_project_path and os.path.exists(self.test_project_path):
                shutil.rmtree(self.test_project_path)
                print(f"üßπ –£–¥–∞–ª–µ–Ω —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç: {self.test_project_path}")
    
    async def test_workforce_validation(self):
        """–¢–µ—Å—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ –ø–µ—Ä—Å–æ–Ω–∞–ª—É"""
        
        print("üß™ === –¢–ï–°–¢ –í–ê–õ–ò–î–ê–¶–ò–ò –ü–ï–†–°–û–ù–ê–õ–ê ===")
        
        project_path = self.setup_test_project()
        
        try:
            agent = SchedulerAndStaffer()
            
            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –Ω–∞—Ä—É—à–µ–Ω–∏–µ–º –ª–∏–º–∏—Ç–æ–≤
            test_packages = [
                {
                    "package_id": "pkg_001",
                    "name": "–ü–∞–∫–µ—Ç 1",
                    "schedule_blocks": [1, 2],
                    "staffing_per_block": {"1": 10, "2": 8}  # –í—Å–µ–≥–æ –≤ –Ω–µ–¥–µ–ª—é 1: 18 —á–µ–ª–æ–≤–µ–∫ (–ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ)
                },
                {
                    "package_id": "pkg_002", 
                    "name": "–ü–∞–∫–µ—Ç 2",
                    "schedule_blocks": [1, 3],
                    "staffing_per_block": {"1": 8, "3": 5}
                }
            ]
            
            timeline_blocks = [{"week_id": i} for i in range(1, 5)]
            workforce_range = {"min": 5, "max": 15}
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é
            validation = agent._validate_workforce_constraints(test_packages, timeline_blocks, workforce_range)
            
            print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
            print(f"  –í–∞–ª–∏–¥–µ–Ω: {validation['valid']}")
            print(f"  –ù–∞—Ä—É—à–µ–Ω–∏—è: {validation['violations']}")
            print(f"  –ù–µ–¥–µ–ª—å–Ω—ã–µ –∏—Ç–æ–≥–∏: {validation['weekly_totals']}")
            
            # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞—Ä—É—à–µ–Ω–∏–µ –Ω–∞ –Ω–µ–¥–µ–ª–µ 1 (10+8=18 > 15)
            assert not validation['valid'], "–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã–ª–∞ –≤—ã—è–≤–∏—Ç—å –Ω–∞—Ä—É—à–µ–Ω–∏–µ"
            assert len(validation['violations']) > 0, "–î–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –Ω–∞—Ä—É—à–µ–Ω–∏–µ"
            assert '18' in str(validation['violations']), "–î–æ–ª–∂–Ω–æ –±—ã—Ç—å —É–∫–∞–∑–∞–Ω–æ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ –¥–æ 18 —á–µ–ª–æ–≤–µ–∫"
            
            print("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
            return False
            
        finally:
            if self.test_project_path and os.path.exists(self.test_project_path):
                shutil.rmtree(self.test_project_path)
    
    async def test_schedule_validation(self):
        """–¢–µ—Å—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∞"""
        
        print("üß™ === –¢–ï–°–¢ –í–ê–õ–ò–î–ê–¶–ò–ò –ö–ê–õ–ï–ù–î–ê–†–ù–û–ì–û –ü–õ–ê–ù–ê ===")
        
        project_path = self.setup_test_project()
        
        try:
            agent = SchedulerAndStaffer()
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–∫–µ—Ç–∞
            test_package = {
                "package_id": "pkg_001",
                "name": "–¢–µ—Å—Ç–æ–≤—ã–π –ø–∞–∫–µ—Ç",
                "schedule_blocks": [1, 2, 5],  # –ù–µ–¥–µ–ª—è 5 –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (—Ç–æ–ª—å–∫–æ 4 –Ω–µ–¥–µ–ª–∏)
                "progress_per_block": {"1": 40, "2": 30, "5": 30},  # –ò—Ç–æ–≥–æ 100%
                "staffing_per_block": {"1": 8, "2": 6, "5": 4}
            }
            
            timeline_blocks = [{"week_id": i} for i in range(1, 5)]  # –ù–µ–¥–µ–ª–∏ 1-4
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –ø–∞–∫–µ—Ç
            validated_package = agent._validate_and_fix_package_schedule(test_package, timeline_blocks)
            
            print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–∞–∫–µ—Ç–∞:")
            print(f"  –ò—Å—Ö–æ–¥–Ω—ã–µ –Ω–µ–¥–µ–ª–∏: {test_package['schedule_blocks']}")
            print(f"  –í–∞–ª–∏–¥–Ω—ã–µ –Ω–µ–¥–µ–ª–∏: {validated_package['schedule_blocks']}")
            print(f"  –ü—Ä–æ–≥—Ä–µ—Å—Å: {validated_package['progress_per_block']}")
            print(f"  –ü–µ—Ä—Å–æ–Ω–∞–ª: {validated_package['staffing_per_block']}")
            
            # –ù–µ–¥–µ–ª—è 5 –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —É–¥–∞–ª–µ–Ω–∞
            assert 5 not in validated_package['schedule_blocks'], "–ù–µ–¥–µ–ª—è 5 –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —É–¥–∞–ª–µ–Ω–∞"
            assert len(validated_package['schedule_blocks']) == 2, "–î–æ–ª–∂–Ω–æ –æ—Å—Ç–∞—Ç—å—Å—è 2 –Ω–µ–¥–µ–ª–∏"
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω
            total_progress = sum(validated_package['progress_per_block'].values())
            assert total_progress == 100, f"–û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 100%, –ø–æ–ª—É—á–µ–Ω–æ {total_progress}"
            
            # –ü–µ—Ä—Å–æ–Ω–∞–ª –¥–æ–ª–∂–µ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –æ—Å—Ç–∞–≤—à–∏–º—Å—è –Ω–µ–¥–µ–ª—è–º
            for week in validated_package['schedule_blocks']:
                week_str = str(week)
                assert week_str in validated_package['staffing_per_block'], f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª –¥–ª—è –Ω–µ–¥–µ–ª–∏ {week}"
            
            print("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–ª–∞–Ω–∞: {e}")
            return False
            
        finally:
            if self.test_project_path and os.path.exists(self.test_project_path):
                shutil.rmtree(self.test_project_path)
    
    async def test_error_handling(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫"""
        
        print("üß™ === –¢–ï–°–¢ –û–ë–†–ê–ë–û–¢–ö–ò –û–®–ò–ë–û–ö ===")
        
        project_path = self.setup_test_project()
        
        try:
            # –£–¥–∞–ª—è–µ–º —Ä–∞—Å—á–µ—Ç—ã —É –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç
            truth_path = os.path.join(project_path, "true.json")
            with open(truth_path, 'r', encoding='utf-8') as f:
                truth_data = json.load(f)
            
            # –£–±–∏—Ä–∞–µ–º calculations —É –≤—Å–µ—Ö –ø–∞–∫–µ—Ç–æ–≤
            for pkg in truth_data['results']['work_packages']:
                if 'calculations' in pkg:
                    del pkg['calculations']
            
            with open(truth_path, 'w', encoding='utf-8') as f:
                json.dump(truth_data, f, ensure_ascii=False, indent=2)
            
            agent = SchedulerAndStaffer()
            
            print("üîÑ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ –±–µ–∑ —Ä–∞—Å—á–µ—Ç–æ–≤ –æ–±—ä–µ–º–æ–≤...")
            result = await agent.process(project_path)
            
            # –û–∂–∏–¥–∞–µ–º –æ—à–∏–±–∫—É
            if not result.get('success'):
                print(f"‚úÖ –û—à–∏–±–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞: {result.get('error')}")
                assert "–Ω–µ –∏–º–µ—é—Ç —Ä–∞—Å—á–µ—Ç–æ–≤ –æ–±—ä–µ–º–æ–≤" in result.get('error', ''), "–ù–µ–≤–µ—Ä–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ"
                return True
            else:
                print("‚ùå –û–∂–∏–¥–∞–ª–∞—Å—å –æ—à–∏–±–∫–∞, –Ω–æ –∞–≥–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —É—Å–ø–µ—à–Ω–æ")
                return False
                
        except Exception as e:
            print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–µ: {e}")
            return False
            
        finally:
            if self.test_project_path and os.path.exists(self.test_project_path):
                shutil.rmtree(self.test_project_path)

async def run_all_tests():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    
    print("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ scheduler_and_staffer.py")
    print("=" * 50)
    
    tester = TestSchedulerAndStaffer()
    
    tests = [
        ("–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∞", tester.test_workforce_validation),
        ("–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∞", tester.test_schedule_validation),
        ("–ü–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è", tester.test_scheduler_full_process),
        ("–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫", tester.test_error_handling)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\nüß™ –¢–µ—Å—Ç: {test_name}")
        print("-" * 30)
        
        try:
            success = await test_func()
            results.append((test_name, success))
            
            if success:
                print(f"‚úÖ {test_name}: –ü–†–û–ô–î–ï–ù")
            else:
                print(f"‚ùå {test_name}: –ü–†–û–í–ê–õ–ï–ù")
                
        except Exception as e:
            print(f"üí• {test_name}: –û–®–ò–ë–ö–ê - {e}")
            results.append((test_name, False))
    
    print("\n" + "=" * 50)
    print("üìä –ò–¢–û–ì–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    
    passed = 0
    for test_name, success in results:
        status = "‚úÖ –ü–†–û–ô–î–ï–ù" if success else "‚ùå –ü–†–û–í–ê–õ–ï–ù"
        print(f"  {test_name}: {status}")
        if success:
            passed += 1
    
    print(f"\nüéØ –†–µ–∑—É–ª—å—Ç–∞—Ç: {passed}/{len(results)} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ")
    
    if passed == len(results):
        print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        return True
    else:
        print("‚ö†Ô∏è –ï—Å—Ç—å –Ω–µ—É–¥–∞—á–Ω—ã–µ —Ç–µ—Å—Ç—ã!")
        return False

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
    asyncio.run(run_all_tests())

================================================================================

## –§–ê–ô–õ: tests/test_simple_pdf.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –∫–∏—Ä–∏–ª–ª–∏—Ü—ã –≤ PDF —á–µ—Ä–µ–∑ reportlab
"""

import os
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Paragraph
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont

def test_simple_cyrillic_pdf():
    """–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –∫–∏—Ä–∏–ª–ª–∏—Ü—ã"""
    
    output_file = '/tmp/simple_cyrillic_test.pdf'
    
    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —à—Ä–∏—Ñ—Ç
    font_path = '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'
    if os.path.exists(font_path):
        pdfmetrics.registerFont(TTFont('CyrillicFont', font_path))
        print(f"‚úÖ –®—Ä–∏—Ñ—Ç –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω: {font_path}")
    else:
        print("‚ùå –®—Ä–∏—Ñ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    
    # –°–æ–∑–¥–∞–µ–º PDF
    doc = SimpleDocTemplate(output_file, pagesize=A4)
    styles = getSampleStyleSheet()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∏–ª—å —Å –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–º —à—Ä–∏—Ñ—Ç–æ–º
    styles.add(ParagraphStyle('CyrillicNormal',
                            parent=styles['Normal'],
                            fontName='CyrillicFont',
                            fontSize=12))
    
    story = []
    
    # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π
    test_text = """
    <b>–¢–µ—Å—Ç –∫–∏—Ä–∏–ª–ª–∏—Ü—ã –≤ PDF</b><br/>
    –î–µ–º–æ–Ω—Ç–∞–∂ –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫<br/>
    –ú–æ–Ω—Ç–∞–∂ —Å—Ç—è–∂–∫–∏ –ø–æ–ª–∞<br/>
    –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —á–∏—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è<br/>
    –ï–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è: –º¬≤<br/>
    –û–±—ä–µ–º: 150,5 –º¬≤
    """
    
    story.append(Paragraph(test_text, styles['CyrillicNormal']))
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º PDF
    doc.build(story)
    
    if os.path.exists(output_file):
        file_size = os.path.getsize(output_file)
        print(f"‚úÖ PDF —Å–æ–∑–¥–∞–Ω: {output_file}")
        print(f"üìä –†–∞–∑–º–µ—Ä: {file_size} –±–∞–π—Ç")
        return True
    else:
        print("‚ùå PDF –Ω–µ —Å–æ–∑–¥–∞–Ω")
        return False

if __name__ == "__main__":
    test_simple_cyrillic_pdf()

================================================================================

## –§–ê–ô–õ: tests/test_work_packager.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∞–≥–µ–Ω—Ç–∞ work_packager.py
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ —É–∫—Ä—É–ø–Ω–µ–Ω–Ω—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç
"""

import json
import os
import sys
import asyncio
import tempfile
import shutil
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.ai_agents.work_packager import WorkPackager
from tests.mock_gemini_client import mock_gemini_client

# –ü–æ–¥–º–µ–Ω—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–π gemini_client –Ω–∞ –º–æ–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
import src.ai_agents.work_packager
src.ai_agents.work_packager.gemini_client = mock_gemini_client

class TestWorkPackager:
    
    def __init__(self):
        self.test_project_path = None
    
    def setup_test_project(self):
        """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç —Å mock –¥–∞–Ω–Ω—ã–º–∏"""
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        self.test_project_path = tempfile.mkdtemp(prefix='test_herzog_')
        
        # –°–æ–∑–¥–∞–µ–º mock true.json
        mock_truth_data = {
            "metadata": {
                "project_id": "test_project",
                "project_name": "–¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç",
                "pipeline_status": [
                    {"agent_name": "work_packager", "status": "pending"}
                ]
            },
            "project_inputs": {
                "target_work_package_count": 8,
                "agent_directives": {
                    "conceptualizer": "–≤—Å—é —ç–ª–µ–∫—Ç—Ä–∏–∫—É –æ–±—ä–µ–¥–∏–Ω–∏ –≤ –æ–¥–∏–Ω –ø–∞–∫–µ—Ç"
                }
            },
            "source_work_items": [
                {
                    "id": "work_001",
                    "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫ –∫–∏—Ä–ø–∏—á–Ω—ã—Ö",
                    "code": "08.01.001"
                },
                {
                    "id": "work_002", 
                    "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–æ–∫—Ä—ã—Ç–∏—è –ø–æ–ª–∞ –ª–∏–Ω–æ–ª–µ—É–º",
                    "code": "08.02.015"
                },
                {
                    "id": "work_003",
                    "name": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–∞–±–µ–ª—è –í–í–ì 3—Ö2.5",
                    "code": "19.03.012"
                },
                {
                    "id": "work_004",
                    "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–æ–∑–µ—Ç–æ–∫ —Å–∫—Ä—ã—Ç—ã—Ö",
                    "code": "19.05.001"
                },
                {
                    "id": "work_005",
                    "name": "–ú–æ–Ω—Ç–∞–∂ –≤—ã–∫–ª—é—á–∞—Ç–µ–ª–µ–π",
                    "code": "19.05.003"
                },
                {
                    "id": "work_006",
                    "name": "–®—Ç—É–∫–∞—Ç—É—Ä–∫–∞ —Å—Ç–µ–Ω —Ü–µ–º–µ–Ω—Ç–Ω—ã–º —Ä–∞—Å—Ç–≤–æ—Ä–æ–º",
                    "code": "15.01.001"
                },
                {
                    "id": "work_007",
                    "name": "–ü–æ–∫—Ä–∞—Å–∫–∞ —Å—Ç–µ–Ω –≤–æ–¥–æ—ç–º—É–ª—å—Å–∏–æ–Ω–Ω–æ–π –∫—Ä–∞—Å–∫–æ–π",
                    "code": "15.06.001"
                },
                {
                    "id": "work_008",
                    "name": "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Å—Ç—è–∂–∫–∏ —Ü–µ–º–µ–Ω—Ç–Ω–æ–π",
                    "code": "11.01.001"
                },
                {
                    "id": "work_009",
                    "name": "–£–∫–ª–∞–¥–∫–∞ –ª–∞–º–∏–Ω–∞—Ç–∞",
                    "code": "11.04.001"
                },
                {
                    "id": "work_010",
                    "name": "–ú–æ–Ω—Ç–∞–∂ –ø–æ–¥–≤–µ—Å–Ω–æ–≥–æ –ø–æ—Ç–æ–ª–∫–∞",
                    "code": "15.07.001"
                },
                {
                    "id": "work_011",
                    "name": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ —Ç—Ä—É–± –≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥–∞",
                    "code": "18.01.001"  
                },
                {
                    "id": "work_012",
                    "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–º–µ—Å–∏—Ç–µ–ª—è",
                    "code": "18.03.001"
                }
            ],
            "results": {
                "work_packages": []
            }
        }
        
        truth_path = os.path.join(self.test_project_path, "true.json")
        with open(truth_path, 'w', encoding='utf-8') as f:
            json.dump(mock_truth_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç: {self.test_project_path}")
        return self.test_project_path
    
    async def test_work_packager(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ—Å—Ç —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞"""
        
        print("üß™ === –¢–ï–°–¢ WORK_PACKAGER ===")
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç
        project_path = self.setup_test_project()
        
        try:
            # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞
            agent = WorkPackager()
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
            print("üîÑ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ work_packager...")
            result = await agent.process(project_path)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if result.get('success'):
                print("‚úÖ –ê–≥–µ–Ω—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                print(f"üìä –°–æ–∑–¥–∞–Ω–æ –ø–∞–∫–µ—Ç–æ–≤: {result.get('work_packages_created', 0)}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π true.json
                truth_path = os.path.join(project_path, "true.json")
                with open(truth_path, 'r', encoding='utf-8') as f:
                    updated_truth = json.load(f)
                
                work_packages = updated_truth.get('results', {}).get('work_packages', [])
                
                print(f"üìã –°–æ–∑–¥–∞–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç:")
                for i, pkg in enumerate(work_packages, 1):
                    print(f"  {i}. {pkg.get('package_id')}: {pkg.get('name')}")
                    print(f"     {pkg.get('description', '')}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–ø–∫—É –∞–≥–µ–Ω—Ç–∞
                agent_folder = os.path.join(project_path, "4_work_packager")
                if os.path.exists(agent_folder):
                    files = os.listdir(agent_folder)
                    print(f"üìÅ –°–æ–∑–¥–∞–Ω—ã —Ñ–∞–π–ª—ã: {files}")
                
                # –ë–∞–∑–æ–≤—ã–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                assert len(work_packages) > 0, "–ù–µ —Å–æ–∑–¥–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞ —Ä–∞–±–æ—Ç"
                assert len(work_packages) <= 10, "–°–æ–∑–¥–∞–Ω–æ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–æ–≤"
                
                for pkg in work_packages:
                    assert 'package_id' in pkg, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç package_id"
                    assert 'name' in pkg, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç name"
                    assert 'description' in pkg, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç description"
                    assert pkg['package_id'].startswith('pkg_'), "–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç package_id"
                
                print("‚úÖ –í—Å–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–æ–π–¥–µ–Ω—ã")
                return True
                
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∞–≥–µ–Ω—Ç–∞: {result.get('error')}")
                return False
                
        except Exception as e:
            print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –≤ —Ç–µ—Å—Ç–µ: {e}")
            return False
        
        finally:
            # –û—á–∏—â–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            if self.test_project_path and os.path.exists(self.test_project_path):
                shutil.rmtree(self.test_project_path)
                print(f"üßπ –£–¥–∞–ª–µ–Ω —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç: {self.test_project_path}")
    
    async def test_input_extraction(self):
        """–¢–µ—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        
        print("üß™ === –¢–ï–°–¢ –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –î–ê–ù–ù–´–• ===")
        
        project_path = self.setup_test_project()
        
        try:
            agent = WorkPackager()
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º true.json
            truth_path = os.path.join(project_path, "true.json")
            with open(truth_path, 'r', encoding='utf-8') as f:
                truth_data = json.load(f)
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            input_data = agent._extract_input_data(truth_data)
            
            print("üìä –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
            print(f"  - –†–∞–±–æ—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(input_data['source_work_items'])}")
            print(f"  - –¶–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞–∫–µ—Ç–æ–≤: {input_data['target_work_package_count']}")
            print(f"  - –î–∏—Ä–µ–∫—Ç–∏–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: '{input_data['user_directive']}'")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏–∏
            assert len(input_data['source_work_items']) == 12, "–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—Ç"
            assert input_data['target_work_package_count'] == 8, "–ù–µ–≤–µ—Ä–Ω–æ–µ —Ü–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ"
            assert '—ç–ª–µ–∫—Ç—Ä–∏–∫—É' in input_data['user_directive'], "–î–∏—Ä–µ–∫—Ç–∏–≤–∞ –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω–∞"
            
            print("‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {e}")
            return False
            
        finally:
            if self.test_project_path and os.path.exists(self.test_project_path):
                shutil.rmtree(self.test_project_path)
    
    async def test_prompt_loading(self):
        """–¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–º–ø—Ç–∞"""
        
        print("üß™ === –¢–ï–°–¢ –ó–ê–ì–†–£–ó–ö–ò –ü–†–û–ú–ü–¢–ê ===")
        
        try:
            agent = WorkPackager()
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É –ø—Ä–æ–º–ø—Ç–∞
            prompt = agent._load_prompt()
            
            print(f"üìù –ó–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–æ–º–ø—Ç, –¥–ª–∏–Ω–∞: {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            assert '{source_work_items}' in prompt, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç placeholder –¥–ª—è —Ä–∞–±–æ—Ç"
            assert '{target_work_package_count}' in prompt, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç placeholder –¥–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞"
            assert '{user_directive}' in prompt, "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç placeholder –¥–ª—è –¥–∏—Ä–µ–∫—Ç–∏–≤—ã"
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
            mock_input = {
                'source_work_items': [{'id': '1', 'name': 'Test'}],
                'target_work_package_count': 5,
                'user_directive': 'test directive',
                'total_work_items': 1
            }
            
            formatted = agent._format_prompt(mock_input, prompt)
            
            assert 'test directive' in formatted, "–î–∏—Ä–µ–∫—Ç–∏–≤–∞ –Ω–µ –ø–æ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞"
            assert '5' in formatted, "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ –ø–æ–¥—Å—Ç–∞–≤–ª–µ–Ω–æ"
            
            print("‚úÖ –ü—Ä–æ–º–ø—Ç –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞: {e}")
            return False

async def run_all_tests():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    
    print("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ work_packager.py")
    print("=" * 50)
    
    tester = TestWorkPackager()
    
    tests = [
        ("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö", tester.test_input_extraction),
        ("–ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞", tester.test_prompt_loading),
        ("–ü–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –∞–≥–µ–Ω—Ç–∞", tester.test_work_packager)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\nüß™ –¢–µ—Å—Ç: {test_name}")
        print("-" * 30)
        
        try:
            success = await test_func()
            results.append((test_name, success))
            
            if success:
                print(f"‚úÖ {test_name}: –ü–†–û–ô–î–ï–ù")
            else:
                print(f"‚ùå {test_name}: –ü–†–û–í–ê–õ–ï–ù")
                
        except Exception as e:
            print(f"üí• {test_name}: –û–®–ò–ë–ö–ê - {e}")
            results.append((test_name, False))
    
    print("\n" + "=" * 50)
    print("üìä –ò–¢–û–ì–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    
    passed = 0
    for test_name, success in results:
        status = "‚úÖ –ü–†–û–ô–î–ï–ù" if success else "‚ùå –ü–†–û–í–ê–õ–ï–ù"
        print(f"  {test_name}: {status}")
        if success:
            passed += 1
    
    print(f"\nüéØ –†–µ–∑—É–ª—å—Ç–∞—Ç: {passed}/{len(results)} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ")
    
    if passed == len(results):
        print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        return True
    else:
        print("‚ö†Ô∏è –ï—Å—Ç—å –Ω–µ—É–¥–∞—á–Ω—ã–µ —Ç–µ—Å—Ç—ã!")
        return False

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
    asyncio.run(run_all_tests())

================================================================================

## –§–ê–ô–õ: tests/test_works_to_packages.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∞–≥–µ–Ω—Ç–∞ works_to_packages.py
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–±–æ—Ç –ø–æ –ø–∞–∫–µ—Ç–∞–º —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –±–∞—Ç—á–∏–Ω–≥–∞
"""

import json
import os
import sys
import asyncio
import tempfile
import shutil
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.ai_agents.works_to_packages import WorksToPackagesAssigner
from tests.mock_gemini_client import mock_gemini_client

# –ü–æ–¥–º–µ–Ω—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–π gemini_client –Ω–∞ –º–æ–∫ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
import src.ai_agents.works_to_packages
src.ai_agents.works_to_packages.gemini_client = mock_gemini_client

class TestWorksToPackages:
    
    def __init__(self):
        self.test_project_path = None
    
    def setup_test_project(self):
        """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç —Å mock –¥–∞–Ω–Ω—ã–º–∏"""
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        self.test_project_path = tempfile.mkdtemp(prefix='test_herzog_')
        
        # –°–æ–∑–¥–∞–µ–º mock true.json —Å –ø–∞–∫–µ—Ç–∞–º–∏ —Ä–∞–±–æ—Ç –∏ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ä–∞–±–æ—Ç–∞–º–∏
        mock_truth_data = {
            "metadata": {
                "project_id": "test_project",
                "project_name": "–¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç",
                "pipeline_status": [
                    {"agent_name": "work_packager", "status": "completed"},
                    {"agent_name": "works_to_packages", "status": "pending"}
                ]
            },
            "project_inputs": {
                "target_work_package_count": 6,
                "agent_directives": {
                    "conceptualizer": "–≤—Å—é —ç–ª–µ–∫—Ç—Ä–∏–∫—É –æ–±—ä–µ–¥–∏–Ω–∏ –≤ –æ–¥–∏–Ω –ø–∞–∫–µ—Ç"
                }
            },
            "source_work_items": [
                {
                    "id": "work_001",
                    "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫ –∫–∏—Ä–ø–∏—á–Ω—ã—Ö",
                    "code": "08.01.001"
                },
                {
                    "id": "work_002",
                    "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–æ–∫—Ä—ã—Ç–∏—è –ø–æ–ª–∞ –ª–∏–Ω–æ–ª–µ—É–º", 
                    "code": "08.02.015"
                },
                {
                    "id": "work_003",
                    "name": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–∞–±–µ–ª—è –í–í–ì 3—Ö2.5",
                    "code": "19.03.012"
                },
                {
                    "id": "work_004",
                    "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–æ–∑–µ—Ç–æ–∫ —Å–∫—Ä—ã—Ç—ã—Ö",
                    "code": "19.05.001"
                },
                {
                    "id": "work_005",
                    "name": "–ú–æ–Ω—Ç–∞–∂ –≤—ã–∫–ª—é—á–∞—Ç–µ–ª–µ–π",
                    "code": "19.05.003"
                },
                {
                    "id": "work_006",
                    "name": "–®—Ç—É–∫–∞—Ç—É—Ä–∫–∞ —Å—Ç–µ–Ω —Ü–µ–º–µ–Ω—Ç–Ω—ã–º —Ä–∞—Å—Ç–≤–æ—Ä–æ–º",
                    "code": "15.01.001"
                },
                {
                    "id": "work_007",
                    "name": "–ü–æ–∫—Ä–∞—Å–∫–∞ —Å—Ç–µ–Ω –≤–æ–¥–æ—ç–º—É–ª—å—Å–∏–æ–Ω–Ω–æ–π –∫—Ä–∞—Å–∫–æ–π",
                    "code": "15.06.001"
                },
                {
                    "id": "work_008",
                    "name": "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Å—Ç—è–∂–∫–∏ —Ü–µ–º–µ–Ω—Ç–Ω–æ–π",
                    "code": "11.01.001"
                },
                {
                    "id": "work_009",
                    "name": "–£–∫–ª–∞–¥–∫–∞ –ª–∞–º–∏–Ω–∞—Ç–∞",
                    "code": "11.04.001"
                },
                {
                    "id": "work_010",
                    "name": "–ú–æ–Ω—Ç–∞–∂ –ø–æ–¥–≤–µ—Å–Ω–æ–≥–æ –ø–æ—Ç–æ–ª–∫–∞",
                    "code": "15.07.001"
                },
                {
                    "id": "work_011",
                    "name": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ —Ç—Ä—É–± –≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥–∞",
                    "code": "18.01.001"
                },
                {
                    "id": "work_012",
                    "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–º–µ—Å–∏—Ç–µ–ª—è",
                    "code": "18.03.001"
                }
            ],
            "results": {
                "work_packages": [
                    {
                        "package_id": "pkg_001",
                        "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π",
                        "description": "–°–Ω–æ—Å –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫, –¥–µ–º–æ–Ω—Ç–∞–∂ –ø–æ–∫—Ä—ã—Ç–∏–π –ø–æ–ª–∞ –∏ –ø–æ—Ç–æ–ª–∫–∞"
                    },
                    {
                        "package_id": "pkg_002",
                        "name": "–≠–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã", 
                        "description": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–∞–±–µ–ª–µ–π, —É—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–æ–∑–µ—Ç–æ–∫ –∏ –≤—ã–∫–ª—é—á–∞—Ç–µ–ª–µ–π"
                    },
                    {
                        "package_id": "pkg_003",
                        "name": "–û—Ç–¥–µ–ª–æ—á–Ω—ã–µ —Ä–∞–±–æ—Ç—ã —Å—Ç–µ–Ω",
                        "description": "–®—Ç—É–∫–∞—Ç—É—Ä–∫–∞ –∏ –ø–æ–∫—Ä–∞—Å–∫–∞ —Å—Ç–µ–Ω –ø–æ–º–µ—â–µ–Ω–∏–π"
                    },
                    {
                        "package_id": "pkg_004",
                        "name": "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ–ª–æ–≤",
                        "description": "–°—Ç—è–∂–∫–∞ –∏ —É–∫–ª–∞–¥–∫–∞ –Ω–∞–ø–æ–ª—å–Ω—ã—Ö –ø–æ–∫—Ä—ã—Ç–∏–π"
                    },
                    {
                        "package_id": "pkg_005",
                        "name": "–†–∞–±–æ—Ç—ã –ø–æ –ø–æ—Ç–æ–ª–∫–∞–º",
                        "description": "–ú–æ–Ω—Ç–∞–∂ –ø–æ–¥–≤–µ—Å–Ω—ã—Ö –∏ –Ω–∞—Ç—è–∂–Ω—ã—Ö –ø–æ—Ç–æ–ª–∫–æ–≤"
                    },
                    {
                        "package_id": "pkg_006",
                        "name": "–°–∞–Ω—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ä–∞–±–æ—Ç—ã",
                        "description": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ —Ç—Ä—É–± –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∞–Ω—Ç–µ—Ö–Ω–∏–∫–∏"
                    }
                ]
            }
        }
        
        truth_path = os.path.join(self.test_project_path, "true.json")
        with open(truth_path, 'w', encoding='utf-8') as f:
            json.dump(mock_truth_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç: {self.test_project_path}")
        return self.test_project_path
    
    async def test_works_to_packages_full(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–±–æ—Ç"""
        
        print("üß™ === –¢–ï–°–¢ WORKS_TO_PACKAGES –ü–û–õ–ù–´–ô –ü–†–û–¶–ï–°–° ===")
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç
        project_path = self.setup_test_project()
        
        try:
            # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞
            agent = WorksToPackagesAssigner(batch_size=5)  # –ú–∞–ª–µ–Ω—å–∫–∏–π –±–∞—Ç—á –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
            print("üîÑ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ works_to_packages...")
            result = await agent.process(project_path)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if result.get('success'):
                print("‚úÖ –ê–≥–µ–Ω—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ä–∞–±–æ—Ç: {result.get('works_processed', 0)}")
                print(f"üì¶ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –±–∞—Ç—á–µ–π: {result.get('batches_processed', 0)}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π true.json
                truth_path = os.path.join(project_path, "true.json")
                with open(truth_path, 'r', encoding='utf-8') as f:
                    updated_truth = json.load(f)
                
                source_work_items = updated_truth.get('source_work_items', [])
                
                print(f"üìã –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–±–æ—Ç –ø–æ –ø–∞–∫–µ—Ç–∞–º:")
                package_counts = {}
                
                for work in source_work_items:
                    package_id = work.get('package_id', '–ù–ï_–ù–ê–ó–ù–ê–ß–ï–ù')
                    work_name = work.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
                    print(f"  {work['id']}: {work_name[:40]}... ‚Üí {package_id}")
                    
                    if package_id not in package_counts:
                        package_counts[package_id] = 0
                    package_counts[package_id] += 1
                
                print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∞–∫–µ—Ç–∞–º:")
                for pkg_id, count in package_counts.items():
                    print(f"  {pkg_id}: {count} —Ä–∞–±–æ—Ç")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–ø–∫—É –∞–≥–µ–Ω—Ç–∞
                agent_folder = os.path.join(project_path, "5_works_to_packages")
                if os.path.exists(agent_folder):
                    files = os.listdir(agent_folder)
                    batch_files = [f for f in files if f.startswith('batch_')]
                    print(f"üìÅ –°–æ–∑–¥–∞–Ω—ã —Ñ–∞–π–ª—ã –±–∞—Ç—á–µ–π: {len(batch_files)} —Ñ–∞–π–ª–æ–≤")
                
                # –ë–∞–∑–æ–≤—ã–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                assert len(source_work_items) == 12, "–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ"
                
                works_with_packages = [w for w in source_work_items if w.get('package_id')]
                assert len(works_with_packages) == 12, "–ù–µ –≤—Å–µ —Ä–∞–±–æ—Ç—ã –Ω–∞–∑–Ω–∞—á–µ–Ω—ã –∫ –ø–∞–∫–µ—Ç–∞–º"
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ package_id —Å—É—â–µ—Å—Ç–≤—É—é—Ç
                valid_packages = {'pkg_001', 'pkg_002', 'pkg_003', 'pkg_004', 'pkg_005', 'pkg_006'}
                for work in source_work_items:
                    assert work.get('package_id') in valid_packages, f"–ù–µ–≤–µ—Ä–Ω—ã–π package_id: {work.get('package_id')}"
                
                print("‚úÖ –í—Å–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–æ–π–¥–µ–Ω—ã")
                return True
                
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∞–≥–µ–Ω—Ç–∞: {result.get('error')}")
                return False
                
        except Exception as e:
            print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –≤ —Ç–µ—Å—Ç–µ: {e}")
            return False
        
        finally:
            # –û—á–∏—â–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            if self.test_project_path and os.path.exists(self.test_project_path):
                shutil.rmtree(self.test_project_path)
                print(f"üßπ –£–¥–∞–ª–µ–Ω —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç: {self.test_project_path}")
    
    async def test_batch_processing(self):
        """–¢–µ—Å—Ç –±–∞—Ç—á–∏–Ω–≥–∞ –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ —Ä–∞–±–æ—Ç"""
        
        print("üß™ === –¢–ï–°–¢ –ë–ê–¢–ß–ò–ù–ì–ê ===")
        
        project_path = self.setup_test_project()
        
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º –±–æ–ª—å—à–µ —Ä–∞–±–æ—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–∞—Ç—á–∏–Ω–≥–∞
            truth_path = os.path.join(project_path, "true.json")
            with open(truth_path, 'r', encoding='utf-8') as f:
                truth_data = json.load(f)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –µ—â–µ —Ä–∞–±–æ—Ç (–≤—Å–µ–≥–æ –±—É–¥–µ—Ç 22)
            extra_works = []
            for i in range(13, 23):
                extra_works.append({
                    "id": f"work_{i:03d}",
                    "name": f"–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞ {i}",
                    "code": f"99.99.{i:03d}"
                })
            
            truth_data['source_work_items'].extend(extra_works)
            
            with open(truth_path, 'w', encoding='utf-8') as f:
                json.dump(truth_data, f, ensure_ascii=False, indent=2)
            
            # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞ —Å –º–∞–ª–µ–Ω—å–∫–∏–º —Ä–∞–∑–º–µ—Ä–æ–º –±–∞—Ç—á–∞
            agent = WorksToPackagesAssigner(batch_size=6)  # –ë–∞—Ç—á–∏ –ø–æ 6 —Ä–∞–±–æ—Ç
            
            print("üîÑ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ —Å –±–∞—Ç—á–∏–Ω–≥–æ–º...")
            result = await agent.process(project_path)
            
            if result.get('success'):
                expected_batches = 22 // 6 + (1 if 22 % 6 > 0 else 0)  # 4 –±–∞—Ç—á–∞
                actual_batches = result.get('batches_processed', 0)
                
                print(f"üì¶ –û–∂–∏–¥–∞–µ–º–æ –±–∞—Ç—á–µ–π: {expected_batches}")
                print(f"üì¶ –§–∞–∫—Ç–∏—á–µ—Å–∫–∏ –±–∞—Ç—á–µ–π: {actual_batches}")
                
                assert actual_batches == expected_batches, "–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π"
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ —Ä–∞–±–æ—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
                with open(truth_path, 'r', encoding='utf-8') as f:
                    updated_truth = json.load(f)
                
                works_with_packages = [w for w in updated_truth['source_work_items'] if w.get('package_id')]
                assert len(works_with_packages) == 22, "–ù–µ –≤—Å–µ —Ä–∞–±–æ—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –≤ –±–∞—Ç—á–∞—Ö"
                
                print("‚úÖ –ë–∞—Ç—á–∏–Ω–≥ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
                return True
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∞–≥–µ–Ω—Ç–∞ –±–∞—Ç—á–∏–Ω–≥–∞: {result.get('error')}")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–∞—Ç—á–∏–Ω–≥–∞: {e}")
            return False
            
        finally:
            if self.test_project_path and os.path.exists(self.test_project_path):
                shutil.rmtree(self.test_project_path)
    
    async def test_error_handling(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫"""
        
        print("üß™ === –¢–ï–°–¢ –û–ë–†–ê–ë–û–¢–ö–ò –û–®–ò–ë–û–ö ===")
        
        project_path = self.setup_test_project()
        
        try:
            # –£–¥–∞–ª—è–µ–º –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç —á—Ç–æ–±—ã —Å–ø—Ä–æ–≤–æ—Ü–∏—Ä–æ–≤–∞—Ç—å –æ—à–∏–±–∫—É
            truth_path = os.path.join(project_path, "true.json")
            with open(truth_path, 'r', encoding='utf-8') as f:
                truth_data = json.load(f)
            
            # –û—á–∏—â–∞–µ–º –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç
            truth_data['results']['work_packages'] = []
            
            with open(truth_path, 'w', encoding='utf-8') as f:
                json.dump(truth_data, f, ensure_ascii=False, indent=2)
            
            agent = WorksToPackagesAssigner()
            
            print("üîÑ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ –±–µ–∑ –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç...")
            result = await agent.process(project_path)
            
            # –û–∂–∏–¥–∞–µ–º –æ—à–∏–±–∫—É
            if not result.get('success'):
                print(f"‚úÖ –û—à–∏–±–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞: {result.get('error')}")
                assert "–ù–µ –Ω–∞–π–¥–µ–Ω—ã –ø–∞–∫–µ—Ç—ã —Ä–∞–±–æ—Ç" in result.get('error', ''), "–ù–µ–≤–µ—Ä–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ"
                return True
            else:
                print("‚ùå –û–∂–∏–¥–∞–ª–∞—Å—å –æ—à–∏–±–∫–∞, –Ω–æ –∞–≥–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —É—Å–ø–µ—à–Ω–æ")
                return False
                
        except Exception as e:
            print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–µ: {e}")
            return False
            
        finally:
            if self.test_project_path and os.path.exists(self.test_project_path):
                shutil.rmtree(self.test_project_path)

async def run_all_tests():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    
    print("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ works_to_packages.py")
    print("=" * 50)
    
    tester = TestWorksToPackages()
    
    tests = [
        ("–ü–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è", tester.test_works_to_packages_full),
        ("–ë–∞—Ç—á–∏–Ω–≥ –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤", tester.test_batch_processing),
        ("–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫", tester.test_error_handling)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\nüß™ –¢–µ—Å—Ç: {test_name}")
        print("-" * 30)
        
        try:
            success = await test_func()
            results.append((test_name, success))
            
            if success:
                print(f"‚úÖ {test_name}: –ü–†–û–ô–î–ï–ù")
            else:
                print(f"‚ùå {test_name}: –ü–†–û–í–ê–õ–ï–ù")
                
        except Exception as e:
            print(f"üí• {test_name}: –û–®–ò–ë–ö–ê - {e}")
            results.append((test_name, False))
    
    print("\n" + "=" * 50)
    print("üìä –ò–¢–û–ì–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    
    passed = 0
    for test_name, success in results:
        status = "‚úÖ –ü–†–û–ô–î–ï–ù" if success else "‚ùå –ü–†–û–í–ê–õ–ï–ù"
        print(f"  {test_name}: {status}")
        if success:
            passed += 1
    
    print(f"\nüéØ –†–µ–∑—É–ª—å—Ç–∞—Ç: {passed}/{len(results)} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ")
    
    if passed == len(results):
        print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        return True
    else:
        print("‚ö†Ô∏è –ï—Å—Ç—å –Ω–µ—É–¥–∞—á–Ω—ã–µ —Ç–µ—Å—Ç—ã!")
        return False

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
    asyncio.run(run_all_tests())

================================================================================

## –§–ê–ô–õ: tests/real_api/test_real_full_pipeline.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–ü–û–õ–ù–´–ô –ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–´–ô –¢–ï–°–¢ —Å —Ä–µ–∞–ª—å–Ω—ã–º Gemini API
–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É –≤—Å–µ—Ö —á–µ—Ç—ã—Ä–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —Å –Ω–∞—Å—Ç–æ—è—â–∏–º –ò–ò
"""

import json
import os
import sys
import asyncio
import tempfile
import shutil
from datetime import datetime, timedelta
from typing import Dict, List

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

from src.ai_agents.work_packager import WorkPackager
from src.ai_agents.works_to_packages import WorksToPackagesAssigner
from src.ai_agents.counter import WorkVolumeCalculator
from src.ai_agents.scheduler_and_staffer import SchedulerAndStaffer

class TestRealFullPipeline:
    
    def __init__(self):
        self.test_project_path = None
        self.api_stats = {
            'total_calls': 0,
            'total_tokens': 0,
            'calls_per_agent': {},
            'tokens_per_agent': {}
        }
    
    def setup_real_full_project(self):
        """–°–æ–∑–¥–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        self.test_project_path = tempfile.mkdtemp(prefix='test_real_full_herzog_')
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏ (12 –Ω–µ–¥–µ–ª—å –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞)
        start_date = datetime(2024, 3, 1)
        timeline_blocks = []
        
        for week in range(1, 13):
            week_start = start_date + timedelta(weeks=week-1)
            week_end = week_start + timedelta(days=6)
            
            timeline_blocks.append({
                "week_id": week,
                "start_date": week_start.strftime("%Y-%m-%d"),
                "end_date": week_end.strftime("%Y-%m-%d")
            })
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—à–∏—Ä–Ω—ã–π –Ω–∞–±–æ—Ä —Ä–µ–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–±–æ—Ç
        real_work_items = [
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç–µ–ª—å–Ω—ã–µ –∏ –¥–µ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã
            {"id": "work_001", "name": "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–æ–π –ø–ª–æ—â–∞–¥–∫–∏", "code": "01.01.001"},
            {"id": "work_002", "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫ –∏–∑ –∫–∏—Ä–ø–∏—á–∞", "code": "08.01.001"},
            {"id": "work_003", "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–æ–∫—Ä—ã—Ç–∏—è –ø–æ–ª–∞ –ª–∏–Ω–æ–ª–µ—É–º", "code": "08.02.015"},
            {"id": "work_004", "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–æ–¥–≤–µ—Å–Ω–æ–≥–æ –ø–æ—Ç–æ–ª–∫–∞ –ê—Ä–º—Å—Ç—Ä–æ–Ω–≥", "code": "08.03.001"},
            {"id": "work_005", "name": "–û—á–∏—Å—Ç–∫–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ –æ—Ç –æ–±–æ–µ–≤", "code": "08.04.001"},
            {"id": "work_006", "name": "–î–µ–º–æ–Ω—Ç–∞–∂ —Å—Ç–∞—Ä–æ–π —ç–ª–µ–∫—Ç—Ä–æ–ø—Ä–æ–≤–æ–¥–∫–∏", "code": "08.05.001"},
            {"id": "work_007", "name": "–í—ã–≤–æ–∑ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–æ–≥–æ –º—É—Å–æ—Ä–∞", "code": "08.99.001"},
            
            # –û–±—â–µ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–±–æ—Ç—ã
            {"id": "work_008", "name": "–í–æ–∑–≤–µ–¥–µ–Ω–∏–µ –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫ –∏–∑ –ø–µ–Ω–æ–±–ª–æ–∫–æ–≤ D500", "code": "07.01.001"},
            {"id": "work_009", "name": "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–≤–µ—Ä–Ω—ã—Ö –∏ –æ–∫–æ–Ω–Ω—ã—Ö –ø—Ä–æ–µ–º–æ–≤", "code": "07.02.001"},
            {"id": "work_010", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–µ—Ä–µ–º—ã—á–µ–∫ –Ω–∞–¥ –ø—Ä–æ–µ–º–∞–º–∏", "code": "07.03.001"},
            {"id": "work_011", "name": "–ê—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª–∞–¥–∫–∏", "code": "07.04.001"},
            
            # –≠–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã
            {"id": "work_012", "name": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–∞–±–µ–ª—è –í–í–ì 3—Ö2.5 —Å–∫—Ä—ã—Ç–æ –≤ —Å—Ç–µ–Ω–∞—Ö", "code": "19.03.012"},
            {"id": "work_013", "name": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–∞–±–µ–ª—è –í–í–ì 3—Ö1.5 –¥–ª—è –æ—Å–≤–µ—â–µ–Ω–∏—è", "code": "19.03.015"},
            {"id": "work_014", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ–¥—Ä–æ–∑–µ—Ç–Ω–∏–∫–æ–≤ —Å–∫—Ä—ã—Ç—ã—Ö", "code": "19.04.001"},
            {"id": "work_015", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–∞—Å–ø–∞—è—á–Ω—ã—Ö –∫–æ—Ä–æ–±–æ–∫", "code": "19.04.002"},
            {"id": "work_016", "name": "–ú–æ–Ω—Ç–∞–∂ —Ä–æ–∑–µ—Ç–æ–∫ —Å–∫—Ä—ã—Ç–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏", "code": "19.05.001"},
            {"id": "work_017", "name": "–ú–æ–Ω—Ç–∞–∂ –≤—ã–∫–ª—é—á–∞—Ç–µ–ª–µ–π –æ–¥–Ω–æ–∫–ª–∞–≤–∏—à–Ω—ã—Ö", "code": "19.05.003"},
            {"id": "work_018", "name": "–ú–æ–Ω—Ç–∞–∂ –≤—ã–∫–ª—é—á–∞—Ç–µ–ª–µ–π –¥–≤—É—Ö–∫–ª–∞–≤–∏—à–Ω—ã—Ö", "code": "19.05.004"},
            {"id": "work_019", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–≤–µ—Ç–∏–ª—å–Ω–∏–∫–æ–≤ –ø–æ—Ç–æ–ª–æ—á–Ω—ã—Ö LED", "code": "19.06.001"},
            {"id": "work_020", "name": "–ú–æ–Ω—Ç–∞–∂ —ç–ª–µ–∫—Ç—Ä–æ—â–∏—Ç–∫–∞ –Ω–∞ 24 –º–æ–¥—É–ª—è", "code": "19.07.001"},
            {"id": "work_021", "name": "–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∏ –ø—É—Å–∫–æ–Ω–∞–ª–∞–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–æ–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è", "code": "19.08.001"},
            
            # –°–∞–Ω—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ä–∞–±–æ—Ç—ã
            {"id": "work_022", "name": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ —Ç—Ä—É–± –≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥–∞ –ü–ù–î 25–º–º", "code": "18.01.001"},
            {"id": "work_023", "name": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ —Ç—Ä—É–± –≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥–∞ –ü–ù–î 32–º–º", "code": "18.01.002"},
            {"id": "work_024", "name": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ —Ç—Ä—É–± –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –ü–í–• 50–º–º", "code": "18.02.001"},
            {"id": "work_025", "name": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ —Ç—Ä—É–± –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –ü–í–• 110–º–º", "code": "18.02.002"},
            {"id": "work_026", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤–æ–¥–æ—Ä–æ–∑–µ—Ç–æ–∫", "code": "18.03.001"},
            {"id": "work_027", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã—Ö –≤—ã–ø—É—Å–∫–æ–≤", "code": "18.03.002"},
            {"id": "work_028", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–º–µ—Å–∏—Ç–µ–ª—è –¥–ª—è —Ä–∞–∫–æ–≤–∏–Ω—ã", "code": "18.04.001"},
            {"id": "work_029", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–º–µ—Å–∏—Ç–µ–ª—è –¥–ª—è –≤–∞–Ω–Ω—ã", "code": "18.04.002"},
            {"id": "work_030", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —É–Ω–∏—Ç–∞–∑–∞ –Ω–∞–ø–æ–ª—å–Ω–æ–≥–æ", "code": "18.05.001"},
            {"id": "work_031", "name": "–ú–æ–Ω—Ç–∞–∂ —Ä–∞–∫–æ–≤–∏–Ω—ã —Å –ø—å–µ–¥–µ—Å—Ç–∞–ª–æ–º", "code": "18.06.001"},
            {"id": "work_032", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤–∞–Ω–Ω—ã –∞–∫—Ä–∏–ª–æ–≤–æ–π", "code": "18.07.001"},
            
            # –°—Ç–æ–ª—è—Ä–Ω–æ-–ø–ª–æ—Ç–Ω–∏—á–Ω—ã–µ —Ä–∞–±–æ—Ç—ã
            {"id": "work_033", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–≤–µ—Ä–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö", "code": "10.01.001"},
            {"id": "work_034", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–≤–µ—Ä–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –≤—Ö–æ–¥–Ω—ã—Ö", "code": "10.01.002"},
            {"id": "work_035", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–∫–æ–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤ –ü–í–•", "code": "10.02.001"},
            {"id": "work_036", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ–¥–æ–∫–æ–Ω–Ω–∏–∫–æ–≤", "code": "10.03.001"},
            {"id": "work_037", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—Ç–∫–æ—Å–æ–≤ –æ–∫–æ–Ω–Ω—ã—Ö", "code": "10.04.001"},
            
            # –û—Ç–¥–µ–ª–æ—á–Ω—ã–µ —Ä–∞–±–æ—Ç—ã —Å—Ç–µ–Ω
            {"id": "work_038", "name": "–®—Ç—É–∫–∞—Ç—É—Ä–∫–∞ —Å—Ç–µ–Ω —Ü–µ–º–µ–Ω—Ç–Ω–æ-–ø–µ—Å—á–∞–Ω—ã–º —Ä–∞—Å—Ç–≤–æ—Ä–æ–º", "code": "15.01.001"},
            {"id": "work_039", "name": "–®—Ç—É–∫–∞—Ç—É—Ä–∫–∞ —Å—Ç–µ–Ω –≥–∏–ø—Å–æ–≤–æ–π —Å–º–µ—Å—å—é", "code": "15.01.002"},
            {"id": "work_040", "name": "–®–ø–∞–∫–ª–µ–≤–∫–∞ —Å—Ç–µ–Ω —Å—Ç–∞—Ä—Ç–æ–≤–∞—è", "code": "15.02.001"},
            {"id": "work_041", "name": "–®–ø–∞–∫–ª–µ–≤–∫–∞ —Å—Ç–µ–Ω —Ñ–∏–Ω–∏—à–Ω–∞—è", "code": "15.02.002"},
            {"id": "work_042", "name": "–ì—Ä—É–Ω—Ç–æ–≤–∫–∞ —Å—Ç–µ–Ω –≥–ª—É–±–æ–∫–æ–≥–æ –ø—Ä–æ–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏—è", "code": "15.03.001"},
            {"id": "work_043", "name": "–ü–æ–∫—Ä–∞—Å–∫–∞ —Å—Ç–µ–Ω –≤–æ–¥–æ—ç–º—É–ª—å—Å–∏–æ–Ω–Ω–æ–π –∫—Ä–∞—Å–∫–æ–π", "code": "15.06.001"},
            {"id": "work_044", "name": "–ü–æ–∫–ª–µ–π–∫–∞ –æ–±–æ–µ–≤ –≤–∏–Ω–∏–ª–æ–≤—ã—Ö", "code": "15.05.001"},
            {"id": "work_045", "name": "–£–∫–ª–∞–¥–∫–∞ –∫–µ—Ä–∞–º–∏—á–µ—Å–∫–æ–π –ø–ª–∏—Ç–∫–∏ –Ω–∞ —Å—Ç–µ–Ω—ã", "code": "15.04.001"},
            
            # –†–∞–±–æ—Ç—ã –ø–æ –ø–æ–ª–∞–º
            {"id": "work_046", "name": "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Å—Ç—è–∂–∫–∏ –ø–æ–ª–∞ —Ü–µ–º–µ–Ω—Ç–Ω–æ-–ø–µ—Å—á–∞–Ω–æ–π", "code": "11.01.001"},
            {"id": "work_047", "name": "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –Ω–∞–ª–∏–≤–Ω–æ–≥–æ –ø–æ–ª–∞ —Å–∞–º–æ–≤—ã—Ä–∞–≤–Ω–∏–≤–∞—é—â–µ–≥–æ—Å—è", "code": "11.01.002"},
            {"id": "work_048", "name": "–ì–∏–¥—Ä–æ–∏–∑–æ–ª—è—Ü–∏—è –ø–æ–ª–∞ —Ä—É–ª–æ–Ω–Ω–∞—è", "code": "11.02.001"},
            {"id": "work_049", "name": "–¢–µ–ø–ª–æ–∏–∑–æ–ª—è—Ü–∏—è –ø–æ–ª–∞ –ø–µ–Ω–æ–ø–æ–ª–∏—Å—Ç–∏—Ä–æ–ª–æ–º", "code": "11.02.002"},
            {"id": "work_050", "name": "–£–∫–ª–∞–¥–∫–∞ –∫–µ—Ä–∞–º–∏—á–µ—Å–∫–æ–π –ø–ª–∏—Ç–∫–∏ –Ω–∞ –ø–æ–ª", "code": "11.03.001"},
            {"id": "work_051", "name": "–£–∫–ª–∞–¥–∫–∞ –∫–µ—Ä–∞–º–æ–≥—Ä–∞–Ω–∏—Ç–∞ –Ω–∞ –ø–æ–ª", "code": "11.03.002"},
            {"id": "work_052", "name": "–£–∫–ª–∞–¥–∫–∞ –ª–∞–º–∏–Ω–∞—Ç–∞ 32 –∫–ª–∞—Å—Å", "code": "11.04.001"},
            {"id": "work_053", "name": "–£–∫–ª–∞–¥–∫–∞ –ª–∞–º–∏–Ω–∞—Ç–∞ 33 –∫–ª–∞—Å—Å", "code": "11.04.002"},
            {"id": "work_054", "name": "–£–∫–ª–∞–¥–∫–∞ –ª–∏–Ω–æ–ª–µ—É–º–∞ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ", "code": "11.04.003"},
            {"id": "work_055", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–ª–∏–Ω—Ç—É—Å–∞ –ø–ª–∞—Å—Ç–∏–∫–æ–≤–æ–≥–æ", "code": "11.05.001"},
            {"id": "work_056", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–ª–∏–Ω—Ç—É—Å–∞ –¥–µ—Ä–µ–≤—è–Ω–Ω–æ–≥–æ", "code": "11.05.002"},
            
            # –†–∞–±–æ—Ç—ã –ø–æ –ø–æ—Ç–æ–ª–∫–∞–º
            {"id": "work_057", "name": "–ú–æ–Ω—Ç–∞–∂ –∫–∞—Ä–∫–∞—Å–∞ –ø–æ–¥–≤–µ—Å–Ω–æ–≥–æ –ø–æ—Ç–æ–ª–∫–∞", "code": "15.07.001"},
            {"id": "work_058", "name": "–û–±—à–∏–≤–∫–∞ –ø–æ—Ç–æ–ª–∫–∞ –≥–∏–ø—Å–æ–∫–∞—Ä—Ç–æ–Ω–æ–º –≤ –æ–¥–∏–Ω —Å–ª–æ–π", "code": "15.07.002"},
            {"id": "work_059", "name": "–ó–∞–¥–µ–ª–∫–∞ —à–≤–æ–≤ –≥–∏–ø—Å–æ–∫–∞—Ä—Ç–æ–Ω–∞ —Å–µ—Ä–ø—è–Ω–∫–æ–π", "code": "15.07.003"},
            {"id": "work_060", "name": "–®–ø–∞–∫–ª–µ–≤–∫–∞ –ø–æ—Ç–æ–ª–∫–∞ —Å—Ç–∞—Ä—Ç–æ–≤–∞—è", "code": "15.07.004"},
            {"id": "work_061", "name": "–®–ø–∞–∫–ª–µ–≤–∫–∞ –ø–æ—Ç–æ–ª–∫–∞ —Ñ–∏–Ω–∏—à–Ω–∞—è", "code": "15.07.005"},
            {"id": "work_062", "name": "–ü–æ–∫—Ä–∞—Å–∫–∞ –ø–æ—Ç–æ–ª–∫–∞ –≤–æ–¥–æ—ç–º—É–ª—å—Å–∏–æ–Ω–Ω–æ–π –∫—Ä–∞—Å–∫–æ–π", "code": "15.07.006"},
            {"id": "work_063", "name": "–ú–æ–Ω—Ç–∞–∂ –ø–æ—Ç–æ–ª–∫–∞ —Ç–∏–ø–∞ –ê—Ä–º—Å—Ç—Ä–æ–Ω–≥", "code": "15.08.001"},
            {"id": "work_064", "name": "–ú–æ–Ω—Ç–∞–∂ –Ω–∞—Ç—è–∂–Ω–æ–≥–æ –ø–æ—Ç–æ–ª–∫–∞", "code": "15.09.001"},
            
            # –ü—Ä–æ—á–∏–µ –∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–∞–±–æ—Ç—ã
            {"id": "work_065", "name": "–ú–∞–ª—è—Ä–Ω—ã–µ —Ä–∞–±–æ—Ç—ã –ø–æ –º–µ—Ç–∞–ª–ª–æ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º", "code": "16.01.001"},
            {"id": "work_066", "name": "–ê–Ω—Ç–∏–∫–æ—Ä—Ä–æ–∑–∏–π–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ—Ç–∞–ª–ª–∞", "code": "16.02.001"},
            {"id": "work_067", "name": "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –æ—Ç–º–æ—Å—Ç–∫–∏ –≤–æ–∫—Ä—É–≥ –∑–¥–∞–Ω–∏—è", "code": "05.01.001"},
            {"id": "work_068", "name": "–ë–ª–∞–≥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø—Ä–∏–ª–µ–≥–∞—é—â–µ–π —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∏", "code": "05.02.001"},
            {"id": "work_069", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—á—Ç–æ–≤—ã—Ö —è—â–∏–∫–æ–≤", "code": "10.99.001"},
            {"id": "work_070", "name": "–£–±–æ—Ä–∫–∞ –ø–æ–º–µ—â–µ–Ω–∏–π –ø–æ—Å–ª–µ —Ä–µ–º–æ–Ω—Ç–∞", "code": "99.01.001"},
            {"id": "work_071", "name": "–°–¥–∞—á–∞ –æ–±—ä–µ–∫—Ç–∞ –∑–∞–∫–∞–∑—á–∏–∫—É", "code": "99.02.001"},
        ]
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π truth.json –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞
        full_truth_data = {
            "metadata": {
                "project_id": "real_full_test_project",
                "project_name": "–ö–∞–ø–∏—Ç–∞–ª—å–Ω—ã–π —Ä–µ–º–æ–Ω—Ç 3-–∫–æ–º–Ω–∞—Ç–Ω–æ–π –∫–≤–∞—Ä—Ç–∏—Ä—ã 85 –º¬≤",
                "pipeline_status": [
                    {"agent_name": "work_packager", "status": "pending"}
                ]
            },
            "project_inputs": {
                "target_work_package_count": 12,
                "project_timeline": {
                    "start_date": "2024-03-01",
                    "end_date": "2024-05-24"
                },
                "workforce_range": {
                    "min": 6,
                    "max": 18
                },
                "agent_directives": {
                    "conceptualizer": "–¥–µ–º–æ–Ω—Ç–∞–∂ –æ—Ç–¥–µ–ª—å–Ω–æ –æ—Ç –º–æ–Ω—Ç–∞–∂–∞, –≤—Å—é —ç–ª–µ–∫—Ç—Ä–∏–∫—É –∏ —Å–ª–∞–±–æ—Ç–æ—á–∫—É –≤ –æ–¥–∏–Ω –ø–∞–∫–µ—Ç, —Å–∞–Ω—Ç–µ—Ö–Ω–∏–∫—É –≤ –æ–¥–∏–Ω –±–ª–æ–∫, –æ—Ç–¥–µ–ª–∫—É —Ä–∞–∑–±–∏—Ç—å –ø–æ —Ç–∏–ø–∞–º —Ä–∞–±–æ—Ç",
                    "strategist": "–¥–µ–º–æ–Ω—Ç–∞–∂ –≤ –ø–µ—Ä–≤—ã–µ 2 –Ω–µ–¥–µ–ª–∏, –ø–æ—Ç–æ–º –æ–±—â–µ—Å—Ç—Ä–æ–π–∫–∞, –∏–Ω–∂–µ–Ω–µ—Ä–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ, –æ—Ç–¥–µ–ª–∫–∞ –≤ –∫–æ–Ω—Ü–µ",
                    "accountant": "–ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ –ø–ª–æ—â–∞–¥–Ω—ã—Ö —Ä–∞–±–æ—Ç –±–µ—Ä–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –ø–ª–æ—â–∞–¥—å, –ø—Ä–∏ –ª–∏–Ω–µ–π–Ω—ã—Ö - —Å—É–º–º–∏—Ä—É–π",
                    "foreman": "–Ω–∞ –æ—Ç–¥–µ–ª–æ—á–Ω—ã–µ —Ä–∞–±–æ—Ç—ã –º–∞–∫—Å–∏–º—É–º –ª—é–¥–µ–π, –Ω–∞ –¥–µ–º–æ–Ω—Ç–∞–∂ –∏ —ç–ª–µ–∫—Ç—Ä–∏–∫—É –ø–æ–º–µ–Ω—å—à–µ"
                },
                "external_context": {
                    "object_characteristics": {
                        "project_type": "–ö–∞–ø–∏—Ç–∞–ª—å–Ω—ã–π —Ä–µ–º–æ–Ω—Ç –∫–≤–∞—Ä—Ç–∏—Ä—ã",
                        "building_type": "–ñ–∏–ª–æ–π –¥–æ–º",
                        "area": "85 –º¬≤",
                        "rooms": "3 –∫–æ–º–Ω–∞—Ç—ã + –∫—É—Ö–Ω—è + —Å–∞–Ω—É–∑–µ–ª"
                    },
                    "site_conditions": {
                        "location_type": "–ñ–∏–ª–æ–π –¥–æ–º –≤ —Ü–µ–Ω—Ç—Ä–µ –≥–æ—Ä–æ–¥–∞",
                        "work_time_restrictions": ["–†–∞–±–æ—Ç—ã —Ç–æ–ª—å–∫–æ –≤ –±—É–¥–Ω–∏–µ –¥–Ω–∏ 9:00-18:00", "–®—É–º–Ω—ã–µ —Ä–∞–±–æ—Ç—ã –¥–æ 17:00"],
                        "access_limitations": "–ü–æ–¥—ä–µ–º –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –Ω–∞ 5 —ç—Ç–∞–∂ –±–µ–∑ –ª–∏—Ñ—Ç–∞"
                    }
                }
            },
            "timeline_blocks": timeline_blocks,
            "source_work_items": real_work_items,
            "results": {
                "work_packages": []
            }
        }
        
        truth_path = os.path.join(self.test_project_path, "true.json")
        with open(truth_path, 'w', encoding='utf-8') as f:
            json.dump(full_truth_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω –ø–æ–ª–Ω—ã–π —Ä–µ–∞–ª—å–Ω—ã–π –ø—Ä–æ–µ–∫—Ç: {self.test_project_path}")
        print(f"üìä –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(real_work_items)} —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–±–æ—Ç")
        print(f"üìÖ –í—Ä–µ–º–µ–Ω–Ω–æ–π –ø–ª–∞–Ω: {len(timeline_blocks)} –Ω–µ–¥–µ–ª—å")
        return self.test_project_path
    
    def track_api_usage(self, agent_name: str, api_response: Dict):
        """–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ API"""
        usage = api_response.get('usage_metadata', {})
        tokens = usage.get('total_token_count', 0)
        
        self.api_stats['total_calls'] += 1
        self.api_stats['total_tokens'] += tokens
        
        if agent_name not in self.api_stats['calls_per_agent']:
            self.api_stats['calls_per_agent'][agent_name] = 0
            self.api_stats['tokens_per_agent'][agent_name] = 0
        
        self.api_stats['calls_per_agent'][agent_name] += 1
        self.api_stats['tokens_per_agent'][agent_name] += tokens
    
    async def test_real_full_pipeline(self):
        """–ü–æ–ª–Ω—ã–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤ —Å —Ä–µ–∞–ª—å–Ω—ã–º API"""
        
        print("ü§ñ === –ü–û–õ–ù–´–ô –ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–´–ô –¢–ï–°–¢ –° –†–ï–ê–õ–¨–ù–´–ú GEMINI API ===")
        print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ–∞–ª—å–Ω—ã–µ API –≤—ã–∑–æ–≤—ã!")
        print("üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–π!")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–∞
        if not os.getenv('GEMINI_API_KEY'):
            print("‚ùå GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
            return False
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç
        project_path = self.setup_real_full_project()
        pipeline_start_time = datetime.now()
        
        try:
            # =============================================
            # –®–ê–ì 1: WORK_PACKAGER
            # =============================================
            print(f"\n{'='*60}")
            print("üèóÔ∏è –®–ê–ì 1: –ó–ê–ü–£–°–ö WORK_PACKAGER")
            print(f"{'='*60}")
            
            agent1 = WorkPackager()
            step1_start = datetime.now()
            result1 = await agent1.process(project_path)
            step1_duration = (datetime.now() - step1_start).total_seconds()
            
            if not result1.get('success'):
                print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —à–∞–≥–µ 1: {result1.get('error')}")
                return False
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç work_packager
            truth_path = os.path.join(project_path, "true.json")
            with open(truth_path, 'r', encoding='utf-8') as f:
                truth_data = json.load(f)
            
            work_packages = truth_data['results']['work_packages']
            print(f"‚úÖ –®–∞–≥ 1 –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {step1_duration:.1f}—Å")
            print(f"üì¶ –°–æ–∑–¥–∞–Ω–æ –ø–∞–∫–µ—Ç–æ–≤: {len(work_packages)}")
            
            for i, pkg in enumerate(work_packages[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                print(f"   {i+1}. {pkg['name']}")
            if len(work_packages) > 3:
                print(f"   ... –∏ –µ—â–µ {len(work_packages)-3} –ø–∞–∫–µ—Ç–æ–≤")
            
            # =============================================
            # –®–ê–ì 2: WORKS_TO_PACKAGES
            # =============================================
            print(f"\n{'='*60}")
            print("üìã –®–ê–ì 2: –ó–ê–ü–£–°–ö WORKS_TO_PACKAGES")
            print(f"{'='*60}")
            
            agent2 = WorksToPackagesAssigner(batch_size=15)  # –ë–∞—Ç—á–∏ –ø–æ 15 –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ API
            step2_start = datetime.now()
            result2 = await agent2.process(project_path)
            step2_duration = (datetime.now() - step2_start).total_seconds()
            
            if not result2.get('success'):
                print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —à–∞–≥–µ 2: {result2.get('error')}")
                return False
            
            print(f"‚úÖ –®–∞–≥ 2 –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {step2_duration:.1f}—Å")
            print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ä–∞–±–æ—Ç: {result2.get('works_processed')}")
            print(f"üì¶ –ë–∞—Ç—á–µ–π: {result2.get('batches_processed')}")
            
            # =============================================
            # –®–ê–ì 3: COUNTER
            # =============================================
            print(f"\n{'='*60}")
            print("üßÆ –®–ê–ì 3: –ó–ê–ü–£–°–ö COUNTER")
            print(f"{'='*60}")
            
            agent3 = WorkVolumeCalculator()
            step3_start = datetime.now()
            result3 = await agent3.process(project_path)
            step3_duration = (datetime.now() - step3_start).total_seconds()
            
            if not result3.get('success'):
                print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —à–∞–≥–µ 3: {result3.get('error')}")
                return False
            
            print(f"‚úÖ –®–∞–≥ 3 –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {step3_duration:.1f}—Å")
            print(f"üìä –†–∞—Å—Å—á–∏—Ç–∞–Ω–æ –ø–∞–∫–µ—Ç–æ–≤: {result3.get('packages_calculated')}")
            
            # =============================================
            # –®–ê–ì 4: SCHEDULER_AND_STAFFER
            # =============================================
            print(f"\n{'='*60}")
            print("üìÖ –®–ê–ì 4: –ó–ê–ü–£–°–ö SCHEDULER_AND_STAFFER")
            print(f"{'='*60}")
            
            agent4 = SchedulerAndStaffer()
            step4_start = datetime.now()
            result4 = await agent4.process(project_path)
            step4_duration = (datetime.now() - step4_start).total_seconds()
            
            if not result4.get('success'):
                print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —à–∞–≥–µ 4: {result4.get('error')}")
                return False
            
            print(f"‚úÖ –®–∞–≥ 4 –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {step4_duration:.1f}—Å")
            print(f"üìÖ –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ –ø–∞–∫–µ—Ç–æ–≤: {result4.get('packages_scheduled')}")
            
            # =============================================
            # –§–ò–ù–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó
            # =============================================
            pipeline_duration = (datetime.now() - pipeline_start_time).total_seconds()
            
            print(f"\n{'='*60}")
            print("üìä –§–ò–ù–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
            print(f"{'='*60}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            with open(truth_path, 'r', encoding='utf-8') as f:
                final_data = json.load(f)
            
            final_packages = final_data['results']['work_packages']
            schedule_info = final_data['results'].get('schedule', {})
            staffing_info = final_data['results'].get('staffing', {})
            
            print(f"üèóÔ∏è –ò–¢–û–ì–ò –û–ë–†–ê–ë–û–¢–ö–ò –ü–†–û–ï–ö–¢–ê:")
            print(f"   üìã –ò—Å—Ö–æ–¥–Ω–æ —Ä–∞–±–æ—Ç: 71")
            print(f"   üì¶ –°–æ–∑–¥–∞–Ω–æ –ø–∞–∫–µ—Ç–æ–≤: {len(final_packages)}")
            print(f"   üìÖ –ü—Ä–æ–µ–∫—Ç –Ω–∞: {schedule_info.get('project_duration_weeks', 0)} –Ω–µ–¥–µ–ª—å")
            print(f"   üë• –ü–∏–∫–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞: {staffing_info.get('peak_workforce', 0)} —á–µ–ª–æ–≤–µ–∫")
            print(f"   ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {pipeline_duration:.1f} —Å–µ–∫—É–Ω–¥")
            
            print(f"\nüèóÔ∏è –°–û–ó–î–ê–ù–ù–´–ï –ü–ê–ö–ï–¢–´ –†–ê–ë–û–¢:")
            for i, pkg in enumerate(final_packages, 1):
                name = pkg.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
                calc = pkg.get('calculations', {})
                volume = calc.get('quantity', 0)
                unit = calc.get('unit', '')
                schedule = pkg.get('schedule_blocks', [])
                
                print(f"   {i:2d}. {name}")
                print(f"       –û–±—ä–µ–º: {volume} {unit}")
                print(f"       –ù–µ–¥–µ–ª–∏: {schedule}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            errors = self._validate_final_result(final_data)
            
            if errors:
                print(f"\n‚ö†Ô∏è –û–ë–ù–ê–†–£–ñ–ï–ù–´ –ü–†–û–ë–õ–ï–ú–´:")
                for error in errors:
                    print(f"   - {error}")
                print(f"\nüí° API —Ç–µ—Å—Ç –ø—Ä–æ—à–µ–ª, –Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏")
                return True
            else:
                print(f"\nüéâ –í–°–ï –≠–¢–ê–ü–´ –ó–ê–í–ï–†–®–ï–ù–´ –£–°–ü–ï–®–ù–û!")
                print(f"‚úÖ –†–µ–∞–ª—å–Ω—ã–π –ò–ò —Å–æ–∑–¥–∞–ª –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω!")
                return True
            
        except Exception as e:
            print(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º —Ç–µ—Å—Ç–µ: {e}")
            return False
        
        finally:
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è API
            print(f"\nüí∞ –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø API:")
            print(f"   üî¢ –í—Å–µ–≥–æ –≤—ã–∑–æ–≤–æ–≤: {self.api_stats['total_calls']}")
            print(f"   üéØ –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {self.api_stats['total_tokens']}")
            
            for agent, calls in self.api_stats['calls_per_agent'].items():
                tokens = self.api_stats['tokens_per_agent'][agent]
                print(f"   üì° {agent}: {calls} –≤—ã–∑–æ–≤–æ–≤, {tokens} —Ç–æ–∫–µ–Ω–æ–≤")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if self.test_project_path and os.path.exists(self.test_project_path):
                backup_path = f"/tmp/herzog_real_full_test_{int(datetime.now().timestamp())}"
                shutil.copytree(self.test_project_path, backup_path)
                print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {backup_path}")
                
                shutil.rmtree(self.test_project_path)
                print(f"üßπ –í—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–ø–∫–∞ —É–¥–∞–ª–µ–Ω–∞: {self.test_project_path}")
    
    def _validate_final_result(self, final_data: Dict) -> List[str]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        errors = []
        
        work_packages = final_data['results']['work_packages']
        source_works = final_data['source_work_items']
        
        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ —Ä–∞–±–æ—Ç—ã –Ω–∞–∑–Ω–∞—á–µ–Ω—ã
        unassigned = [w for w in source_works if not w.get('package_id')]
        if unassigned:
            errors.append(f"–ù–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–æ —Ä–∞–±–æ—Ç: {len(unassigned)}")
        
        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —É –ø–∞–∫–µ—Ç–æ–≤ –µ—Å—Ç—å —Ä–∞—Å—á–µ—Ç—ã
        without_calc = [p for p in work_packages if 'calculations' not in p]
        if without_calc:
            errors.append(f"–ü–∞–∫–µ—Ç–æ–≤ –±–µ–∑ —Ä–∞—Å—á–µ—Ç–æ–≤: {len(without_calc)}")
        
        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —É –ø–∞–∫–µ—Ç–æ–≤ –µ—Å—Ç—å –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –ø–ª–∞–Ω
        without_schedule = [p for p in work_packages if 'schedule_blocks' not in p]
        if without_schedule:
            errors.append(f"–ü–∞–∫–µ—Ç–æ–≤ –±–µ–∑ –ø–ª–∞–Ω–∞: {len(without_schedule)}")
        
        return errors

async def run_real_full_api_test():
    """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ —Å —Ä–µ–∞–ª—å–Ω—ã–º API"""
    
    print("üöÄ –ü–û–õ–ù–´–ô –ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–´–ô –¢–ï–°–¢ –° –†–ï–ê–õ–¨–ù–´–ú GEMINI API")
    print("=" * 70)
    print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –≠—Ç–æ—Ç —Ç–µ—Å—Ç –¥–µ–ª–∞–µ—Ç –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ï –≤—ã–∑–æ–≤—ã –∫ Gemini API")
    print("üí∞ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ API –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ—Ä–æ–≥–∏–º (–æ–∂–∏–¥–∞–µ—Ç—Å—è 10-15 –≤—ã–∑–æ–≤–æ–≤)")
    print("üîë –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ GEMINI_API_KEY —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –∏–º–µ–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –ª–∏–º–∏—Ç")
    print("‚è≥ –û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: 15-30 —Å–µ–∫—É–Ω–¥")
    print("=" * 70)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        print("‚ùå GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return False
    
    print(f"üîë API –∫–ª—é—á –Ω–∞–π–¥–µ–Ω: {api_key[:10]}...{api_key[-4:]}")
    
    # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ 
    print("\n‚ùì –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø–æ–ª–Ω—ã–π —Ç–µ—Å—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º API? (y/N): ", end='')
    confirmation = 'y'  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
    
    if confirmation.lower() != 'y':
        print("üö´ –¢–µ—Å—Ç –æ—Ç–º–µ–Ω–µ–Ω")
        return False
    
    print("\nüéØ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û –ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–û–ì–û –¢–ï–°–¢–ê...")
    
    tester = TestRealFullPipeline()
    
    try:
        success = await tester.test_real_full_pipeline()
        
        if success:
            print("\n" + "=" * 70)
            print("üéâ –ü–û–õ–ù–´–ô –ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–´–ô –¢–ï–°–¢ –ü–†–û–ô–î–ï–ù –£–°–ü–ï–®–ù–û!")
            print("‚úÖ –í—Å–µ —á–µ—Ç—ã—Ä–µ –∞–≥–µ–Ω—Ç–∞ —Ä–∞–±–æ—Ç–∞—é—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º Gemini AI")
            print("üèóÔ∏è –°–∏—Å—Ç–µ–º–∞ HerZog v3.0 –ø–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤–∞ –∫ –ø—Ä–æ–¥–∞–∫—à–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
            return True
        else:
            print("\n" + "=" * 70)
            print("‚ùå –ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–´–ô –¢–ï–°–¢ –ü–†–û–í–ê–õ–ï–ù")
            print("üîß –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å —Ä–µ–∞–ª—å–Ω—ã–º AI")
            return False
            
    except Exception as e:
        print(f"\nüí• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        return False

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞
    asyncio.run(run_real_full_api_test())

================================================================================

## –§–ê–ô–õ: tests/real_api/test_real_work_packager.py
------------------------------------------------------------
#!/usr/bin/env python3
"""
–†–ï–ê–õ–¨–ù–´–ô –¢–ï–°–¢ –∞–≥–µ–Ω—Ç–∞ work_packager.py —Å –Ω–∞—Å—Ç–æ—è—â–∏–º–∏ –≤—ã–∑–æ–≤–∞–º–∏ Gemini API
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç—É —Å —Ä–µ–∞–ª—å–Ω—ã–º –ò–ò –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞–∫–µ—Ç–æ–≤ —Ä–∞–±–æ—Ç
"""

import json
import os
import sys
import asyncio
import tempfile
import shutil
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

from src.ai_agents.work_packager import WorkPackager

class TestRealWorkPackager:
    
    def __init__(self):
        self.test_project_path = None
    
    def setup_real_test_project(self):
        """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        self.test_project_path = tempfile.mkdtemp(prefix='test_real_herzog_')
        
        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–±–æ—Ç –∏–∑ —Å–º–µ—Ç—ã
        real_work_items = [
            # –î–µ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã
            {"id": "work_001", "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫ –∏–∑ –∫–∏—Ä–ø–∏—á–∞", "code": "08.01.001"},
            {"id": "work_002", "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–æ–∫—Ä—ã—Ç–∏—è –ø–æ–ª–∞ –ª–∏–Ω–æ–ª–µ—É–º", "code": "08.02.015"}, 
            {"id": "work_003", "name": "–î–µ–º–æ–Ω—Ç–∞–∂ –ø–æ–¥–≤–µ—Å–Ω–æ–≥–æ –ø–æ—Ç–æ–ª–∫–∞ –ê—Ä–º—Å—Ç—Ä–æ–Ω–≥", "code": "08.03.001"},
            {"id": "work_004", "name": "–û—á–∏—Å—Ç–∫–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ –æ—Ç –æ–±–æ–µ–≤", "code": "08.04.001"},
            {"id": "work_005", "name": "–í—ã–≤–æ–∑ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–æ–≥–æ –º—É—Å–æ—Ä–∞", "code": "08.99.001"},
            
            # –≠–ª–µ–∫—Ç—Ä–æ–º–æ–Ω—Ç–∞–∂–Ω—ã–µ —Ä–∞–±–æ—Ç—ã
            {"id": "work_006", "name": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–∞–±–µ–ª—è –í–í–ì 3—Ö2.5 —Å–∫—Ä—ã—Ç–æ", "code": "19.03.012"},
            {"id": "work_007", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–æ–∑–µ—Ç–æ–∫ —Å–∫—Ä—ã—Ç–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏", "code": "19.05.001"},
            {"id": "work_008", "name": "–ú–æ–Ω—Ç–∞–∂ –≤—ã–∫–ª—é—á–∞—Ç–µ–ª–µ–π –æ–¥–Ω–æ–∫–ª–∞–≤–∏—à–Ω—ã—Ö", "code": "19.05.003"},
            {"id": "work_009", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–≤–µ—Ç–∏–ª—å–Ω–∏–∫–æ–≤ –ø–æ—Ç–æ–ª–æ—á–Ω—ã—Ö", "code": "19.06.001"},
            {"id": "work_010", "name": "–ú–æ–Ω—Ç–∞–∂ —ç–ª–µ–∫—Ç—Ä–æ—â–∏—Ç–∫–∞ –Ω–∞ 12 –º–æ–¥—É–ª–µ–π", "code": "19.07.001"},
            {"id": "work_011", "name": "–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∏ –ø—É—Å–∫–æ–Ω–∞–ª–∞–¥–∫–∞ —ç–ª–µ–∫—Ç—Ä–æ–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è", "code": "19.08.001"},
            
            # –°–∞–Ω—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ä–∞–±–æ—Ç—ã  
            {"id": "work_012", "name": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ —Ç—Ä—É–± –≤–æ–¥–æ–ø—Ä–æ–≤–æ–¥–∞ –ü–ù–î 25–º–º", "code": "18.01.001"},
            {"id": "work_013", "name": "–ü—Ä–æ–∫–ª–∞–¥–∫–∞ —Ç—Ä—É–± –∫–∞–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –ü–í–• 110–º–º", "code": "18.02.001"},
            {"id": "work_014", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–º–µ—Å–∏—Ç–µ–ª—è –¥–ª—è —Ä–∞–∫–æ–≤–∏–Ω—ã", "code": "18.03.001"},
            {"id": "work_015", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —É–Ω–∏—Ç–∞–∑–∞ –Ω–∞–ø–æ–ª—å–Ω–æ–≥–æ", "code": "18.04.001"},
            {"id": "work_016", "name": "–ú–æ–Ω—Ç–∞–∂ —Ä–∞–∫–æ–≤–∏–Ω—ã —Å –ø—å–µ–¥–µ—Å—Ç–∞–ª–æ–º", "code": "18.05.001"},
            
            # –û–±—â–µ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–±–æ—Ç—ã
            {"id": "work_017", "name": "–í–æ–∑–≤–µ–¥–µ–Ω–∏–µ –ø–µ—Ä–µ–≥–æ—Ä–æ–¥–æ–∫ –∏–∑ –ø–µ–Ω–æ–±–ª–æ–∫–æ–≤", "code": "07.01.001"},
            {"id": "work_018", "name": "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–≤–µ—Ä–Ω—ã—Ö –ø—Ä–æ–µ–º–æ–≤", "code": "07.02.001"},
            {"id": "work_019", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–≤–µ—Ä–Ω—ã—Ö –±–ª–æ–∫–æ–≤", "code": "10.01.001"},
            {"id": "work_020", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–∫–æ–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤", "code": "10.02.001"},
            
            # –û—Ç–¥–µ–ª–æ—á–Ω—ã–µ —Ä–∞–±–æ—Ç—ã
            {"id": "work_021", "name": "–®—Ç—É–∫–∞—Ç—É—Ä–∫–∞ —Å—Ç–µ–Ω —Ü–µ–º–µ–Ω—Ç–Ω–æ-–ø–µ—Å—á–∞–Ω—ã–º —Ä–∞—Å—Ç–≤–æ—Ä–æ–º", "code": "15.01.001"},
            {"id": "work_022", "name": "–®–ø–∞–∫–ª–µ–≤–∫–∞ —Å—Ç–µ–Ω —Ñ–∏–Ω–∏—à–Ω–∞—è", "code": "15.02.001"},
            {"id": "work_023", "name": "–ì—Ä—É–Ω—Ç–æ–≤–∫–∞ —Å—Ç–µ–Ω –≥–ª—É–±–æ–∫–æ–≥–æ –ø—Ä–æ–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏—è", "code": "15.03.001"},
            {"id": "work_024", "name": "–ü–æ–∫—Ä–∞—Å–∫–∞ —Å—Ç–µ–Ω –≤–æ–¥–æ—ç–º—É–ª—å—Å–∏–æ–Ω–Ω–æ–π –∫—Ä–∞—Å–∫–æ–π", "code": "15.06.001"},
            {"id": "work_025", "name": "–ü–æ–∫–ª–µ–π–∫–∞ –æ–±–æ–µ–≤ –≤–∏–Ω–∏–ª–æ–≤—ã—Ö", "code": "15.05.001"},
            
            # –†–∞–±–æ—Ç—ã –ø–æ –ø–æ–ª–∞–º
            {"id": "work_026", "name": "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Å—Ç—è–∂–∫–∏ –ø–æ–ª–∞ —Ü–µ–º–µ–Ω—Ç–Ω–æ–π", "code": "11.01.001"},
            {"id": "work_027", "name": "–ì–∏–¥—Ä–æ–∏–∑–æ–ª—è—Ü–∏—è –ø–æ–ª–∞ —Ä—É–ª–æ–Ω–Ω–∞—è", "code": "11.02.001"},
            {"id": "work_028", "name": "–£–∫–ª–∞–¥–∫–∞ –∫–µ—Ä–∞–º–∏—á–µ—Å–∫–æ–π –ø–ª–∏—Ç–∫–∏ –Ω–∞ –ø–æ–ª", "code": "11.03.001"},
            {"id": "work_029", "name": "–£–∫–ª–∞–¥–∫–∞ –ª–∞–º–∏–Ω–∞—Ç–∞ 32 –∫–ª–∞—Å—Å", "code": "11.04.001"},
            {"id": "work_030", "name": "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–ª–∏–Ω—Ç—É—Å–∞ –ø–ª–∞—Å—Ç–∏–∫–æ–≤–æ–≥–æ", "code": "11.05.001"},
            
            # –†–∞–±–æ—Ç—ã –ø–æ –ø–æ—Ç–æ–ª–∫–∞–º
            {"id": "work_031", "name": "–ú–æ–Ω—Ç–∞–∂ –∫–∞—Ä–∫–∞—Å–∞ –ø–æ–¥–≤–µ—Å–Ω–æ–≥–æ –ø–æ—Ç–æ–ª–∫–∞", "code": "15.07.001"},
            {"id": "work_032", "name": "–û–±—à–∏–≤–∫–∞ –ø–æ—Ç–æ–ª–∫–∞ –≥–∏–ø—Å–æ–∫–∞—Ä—Ç–æ–Ω–æ–º", "code": "15.07.002"},
            {"id": "work_033", "name": "–ó–∞–¥–µ–ª–∫–∞ —à–≤–æ–≤ –≥–∏–ø—Å–æ–∫–∞—Ä—Ç–æ–Ω–∞", "code": "15.07.003"},
            {"id": "work_034", "name": "–®–ø–∞–∫–ª–µ–≤–∫–∞ –ø–æ—Ç–æ–ª–∫–∞", "code": "15.07.004"},
            {"id": "work_035", "name": "–ü–æ–∫—Ä–∞—Å–∫–∞ –ø–æ—Ç–æ–ª–∫–∞", "code": "15.07.005"},
            
            # –ü—Ä–æ—á–∏–µ —Ä–∞–±–æ—Ç—ã
            {"id": "work_036", "name": "–ú–∞–ª—è—Ä–Ω—ã–µ —Ä–∞–±–æ—Ç—ã –ø–æ –º–µ—Ç–∞–ª–ª–æ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º", "code": "16.01.001"},
            {"id": "work_037", "name": "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –æ—Ç–º–æ—Å—Ç–∫–∏", "code": "05.01.001"},
            {"id": "work_038", "name": "–ë–ª–∞–≥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∏", "code": "05.02.001"},
            {"id": "work_039", "name": "–£–±–æ—Ä–∫–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–æ–≥–æ –º—É—Å–æ—Ä–∞", "code": "99.01.001"},
            {"id": "work_040", "name": "–ü—Ä–∏–µ–º–æ-—Å–¥–∞—Ç–æ—á–Ω—ã–µ —Ä–∞–±–æ—Ç—ã", "code": "99.02.001"}
        ]
        
        # –°–æ–∑–¥–∞–µ–º mock true.json —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        real_truth_data = {
            "metadata": {
                "project_id": "real_test_project",
                "project_name": "–ö–∞–ø–∏—Ç–∞–ª—å–Ω—ã–π —Ä–µ–º–æ–Ω—Ç –æ—Ñ–∏—Å–∞ 120 –º¬≤",
                "pipeline_status": [
                    {"agent_name": "work_packager", "status": "pending"}
                ]
            },
            "project_inputs": {
                "target_work_package_count": 10,
                "agent_directives": {
                    "conceptualizer": "–≤—Å—é —ç–ª–µ–∫—Ç—Ä–∏–∫—É –∏ —Å–ª–∞–±–æ—Ç–æ—á–∫—É –≤ –æ–¥–∏–Ω –ø–∞–∫–µ—Ç, —Å–∞–Ω—Ç–µ—Ö–Ω–∏–∫—É –æ—Ç–¥–µ–ª—å–Ω–æ, –¥–µ–º–æ–Ω—Ç–∞–∂ –æ—Ç–¥–µ–ª—å–Ω–æ –æ—Ç –º–æ–Ω—Ç–∞–∂–∞"
                },
                "external_context": {
                    "object_characteristics": {
                        "project_type": "–ö–∞–ø–∏—Ç–∞–ª—å–Ω—ã–π —Ä–µ–º–æ–Ω—Ç –æ—Ñ–∏—Å–∞",
                        "building_type": "–û—Ñ–∏—Å–Ω–æ–µ –ø–æ–º–µ—â–µ–Ω–∏–µ",
                        "area": "120 –º¬≤"
                    },
                    "site_conditions": {
                        "location_type": "–ë–∏–∑–Ω–µ—Å-—Ü–µ–Ω—Ç—Ä",
                        "work_time_restrictions": ["–†–∞–±–æ—Ç—ã —Ç–æ–ª—å–∫–æ –≤ —Ä–∞–±–æ—á–∏–µ –¥–Ω–∏ 9:00-18:00"]
                    }
                }
            },
            "source_work_items": real_work_items,
            "results": {
                "work_packages": []
            }
        }
        
        truth_path = os.path.join(self.test_project_path, "true.json")
        with open(truth_path, 'w', encoding='utf-8') as f:
            json.dump(real_truth_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω —Ä–µ–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç: {self.test_project_path}")
        print(f"üìä –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(real_work_items)} —Ä–µ–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–±–æ—Ç")
        return self.test_project_path
    
    async def test_real_work_packager(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ—Å—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º Gemini API"""
        
        print("ü§ñ === –†–ï–ê–õ–¨–ù–´–ô –¢–ï–°–¢ WORK_PACKAGER –° GEMINI API ===")
        print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ä–µ–∞–ª—å–Ω—ã–µ API –≤—ã–∑–æ–≤—ã!")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–∞
        if not os.getenv('GEMINI_API_KEY'):
            print("‚ùå GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
            print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∫–ª—é—á: export GEMINI_API_KEY='your_key'")
            return False
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç
        project_path = self.setup_real_test_project()
        
        try:
            # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞ (–ë–ï–ó –ø–æ–¥–º–µ–Ω—ã –Ω–∞ –º–æ–∫!)
            agent = WorkPackager()
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Å —Ä–µ–∞–ª—å–Ω—ã–º AI
            print("üîÑ –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ —Å —Ä–µ–∞–ª—å–Ω—ã–º Gemini API...")
            print("üì° –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –∑–∞–ø—Ä–æ—Å –≤ Google AI...")
            
            start_time = datetime.now()
            result = await agent.process(project_path)
            end_time = datetime.now()
            
            processing_time = (end_time - start_time).total_seconds()
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if result.get('success'):
                print(f"‚úÖ –ê–≥–µ–Ω—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ –∑–∞ {processing_time:.1f} —Å–µ–∫—É–Ω–¥")
                print(f"üìä –°–æ–∑–¥–∞–Ω–æ –ø–∞–∫–µ—Ç–æ–≤: {result.get('work_packages_created', 0)}")
                
                # –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                truth_path = os.path.join(project_path, "true.json")
                with open(truth_path, 'r', encoding='utf-8') as f:
                    updated_truth = json.load(f)
                
                work_packages = updated_truth.get('results', {}).get('work_packages', [])
                
                print(f"\nüèóÔ∏è –ü–ê–ö–ï–¢–´ –†–ê–ë–û–¢, –°–û–ó–î–ê–ù–ù–´–ï –†–ï–ê–õ–¨–ù–´–ú –ò–ò:")
                print("=" * 60)
                
                for i, pkg in enumerate(work_packages, 1):
                    print(f"{i}. üì¶ {pkg.get('package_id')}: {pkg.get('name')}")
                    print(f"   üìã {pkg.get('description', '')}")
                    print()
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã LLM
                agent_folder = os.path.join(project_path, "4_work_packager")
                if os.path.exists(agent_folder):
                    
                    # –ß–∏—Ç–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è LLM
                    llm_input_path = os.path.join(agent_folder, "llm_input.json")
                    if os.path.exists(llm_input_path):
                        with open(llm_input_path, 'r', encoding='utf-8') as f:
                            llm_input = json.load(f)
                        print(f"üìù –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è AI: {len(llm_input.get('source_work_items', []))} —Ä–∞–±–æ—Ç")
                    
                    # –ß–∏—Ç–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç LLM
                    llm_response_path = os.path.join(agent_folder, "llm_response.json")
                    if os.path.exists(llm_response_path):
                        with open(llm_response_path, 'r', encoding='utf-8') as f:
                            llm_response = json.load(f)
                        
                        usage = llm_response.get('usage_metadata', {})
                        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ API –≤—ã–∑–æ–≤–∞:")
                        print(f"   üî§ –¢–æ–∫–µ–Ω–æ–≤ –≤ –ø—Ä–æ–º–ø—Ç–µ: {usage.get('prompt_token_count', 0)}")
                        print(f"   üí¨ –¢–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ: {usage.get('candidates_token_count', 0)}")
                        print(f"   üìà –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {usage.get('total_token_count', 0)}")
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç AI (–æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π)
                        raw_response = llm_response.get('raw_text', '')[:500]
                        print(f"\nü§ñ –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç AI (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤):")
                        print("-" * 40)
                        print(raw_response)
                        if len(llm_response.get('raw_text', '')) > 500:
                            print("... (–æ–±—Ä–µ–∑–∞–Ω–æ)")
                        print("-" * 40)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                errors = []
                
                if len(work_packages) == 0:
                    errors.append("–ù–µ —Å–æ–∑–¥–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞ —Ä–∞–±–æ—Ç")
                elif len(work_packages) > 15:
                    errors.append(f"–°–æ–∑–¥–∞–Ω–æ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–æ–≤: {len(work_packages)}")
                
                for pkg in work_packages:
                    if not pkg.get('package_id', '').startswith('pkg_'):
                        errors.append(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç ID –ø–∞–∫–µ—Ç–∞: {pkg.get('package_id')}")
                    if len(pkg.get('name', '')) < 5:
                        errors.append(f"–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–∞–∫–µ—Ç–∞: {pkg.get('name')}")
                    if len(pkg.get('description', '')) < 10:
                        errors.append(f"–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–∞–∫–µ—Ç–∞: {pkg.get('description')}")
                
                if errors:
                    print(f"\n‚ö†Ô∏è –û–ë–ù–ê–†–£–ñ–ï–ù–´ –ü–†–û–ë–õ–ï–ú–´ –ö–ê–ß–ï–°–¢–í–ê:")
                    for error in errors:
                        print(f"  - {error}")
                    print(f"\nüí° –ò–ò —Å—Ä–∞–±–æ—Ç–∞–ª, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏")
                    return True  # –í—Å–µ-—Ç–∞–∫–∏ —Å—á–∏—Ç–∞–µ–º —É—Å–ø–µ—Ö–æ–º, —Ç.–∫. API —Å—Ä–∞–±–æ—Ç–∞–ª
                else:
                    print(f"\nüéâ –†–ï–ê–õ–¨–ù–´–ô –ò–ò –°–û–ó–î–ê–õ –ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–ï –ü–ê–ö–ï–¢–´ –†–ê–ë–û–¢!")
                    print(f"‚úÖ –í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–π–¥–µ–Ω—ã")
                    return True
                
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∞–≥–µ–Ω—Ç–∞: {result.get('error')}")
                print(f"‚è±Ô∏è –í—Ä–µ–º—è –¥–æ –æ—à–∏–±–∫–∏: {processing_time:.1f} —Å–µ–∫—É–Ω–¥")
                
                # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ—à–∏–±–∫—É
                if "API" in str(result.get('error', '')):
                    print("üí° –í–æ–∑–º–æ–∂–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ —Å API –∫–ª—é—á–æ–º –∏–ª–∏ –ª–∏–º–∏—Ç–∞–º–∏")
                elif "JSON" in str(result.get('error', '')):
                    print("üí° –í–æ–∑–º–æ–∂–Ω–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Å –ø–∞—Ä—Å–∏–Ω–≥–æ–º –æ—Ç–≤–µ—Ç–∞ AI")
                
                return False
                
        except Exception as e:
            print(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º —Ç–µ—Å—Ç–µ: {e}")
            return False
        
        finally:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–µ—Ä–µ–¥ –æ—á–∏—Å—Ç–∫–æ–π
            if self.test_project_path and os.path.exists(self.test_project_path):
                backup_path = f"/tmp/herzog_real_test_backup_{int(datetime.now().timestamp())}"
                print(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤: {backup_path}")
                shutil.copytree(self.test_project_path, backup_path)
                
                # –û—á–∏—â–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –ø–∞–ø–∫—É
                shutil.rmtree(self.test_project_path)
                print(f"üßπ –£–¥–∞–ª–µ–Ω —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç: {self.test_project_path}")

async def run_real_api_test():
    """–ó–∞–ø—É—Å–∫ —Ä–µ–∞–ª—å–Ω–æ–≥–æ API —Ç–µ—Å—Ç–∞"""
    
    print("üöÄ –ó–ê–ü–£–°–ö –†–ï–ê–õ–¨–ù–û–ì–û API –¢–ï–°–¢–ê WORK_PACKAGER")
    print("=" * 60)
    print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –≠—Ç–æ—Ç —Ç–µ—Å—Ç –¥–µ–ª–∞–µ—Ç –Ω–∞—Å—Ç–æ—è—â–∏–µ –≤—ã–∑–æ–≤—ã –∫ Gemini API")
    print("üí∞ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ API –º–æ–∂–µ—Ç —Ç–∞—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å—Å—è")
    print("üîë –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ GEMINI_API_KEY —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ —Ç–µ—Å—Ç—É
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        print("‚ùå GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è:")
        print("   export GEMINI_API_KEY='your_actual_key'")
        return False
    
    print(f"üîë API –∫–ª—é—á –Ω–∞–π–¥–µ–Ω: {api_key[:10]}...{api_key[-4:]}")
    
    # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    print("\n‚ùì –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ç–µ—Å—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º API? (y/N): ", end='')
    
    # –í –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º —Ä–µ–∂–∏–º–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –≤–≤–æ–¥–∞
    confirmation = 'y'  # –ú–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∞ input() –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    
    if confirmation.lower() != 'y':
        print("üö´ –¢–µ—Å—Ç –æ—Ç–º–µ–Ω–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return False
    
    print("\nüéØ –ù–ê–ß–ò–ù–ê–ï–ú –†–ï–ê–õ–¨–ù–´–ô –¢–ï–°–¢...")
    
    tester = TestRealWorkPackager()
    
    try:
        success = await tester.test_real_work_packager()
        
        if success:
            print("\n" + "=" * 60)
            print("üéâ –†–ï–ê–õ–¨–ù–´–ô API –¢–ï–°–¢ –ü–†–û–ô–î–ï–ù –£–°–ü–ï–®–ù–û!")
            print("‚úÖ –ê–≥–µ–Ω—Ç work_packager —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –Ω–∞—Å—Ç–æ—è—â–∏–º Gemini AI")
            print("üèóÔ∏è –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è")
            return True
        else:
            print("\n" + "=" * 60)
            print("‚ùå –†–ï–ê–õ–¨–ù–´–ô API –¢–ï–°–¢ –ü–†–û–í–ê–õ–ï–ù")
            print("üîß –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–µ–∞–ª—å–Ω—ã–º AI")
            return False
            
    except Exception as e:
        print(f"\nüí• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –í –†–ï–ê–õ–¨–ù–û–ú –¢–ï–°–¢–ï: {e}")
        return False

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ —Ä–µ–∞–ª—å–Ω–æ–≥–æ API —Ç–µ—Å—Ç–∞
    asyncio.run(run_real_api_test())

================================================================================

## –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ù–ê–ü–®–û–¢–ê
–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –≤–∫–ª—é—á–µ–Ω–æ: 82
–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: 2025-09-14 23:02:46
